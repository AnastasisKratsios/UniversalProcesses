{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------#\n",
    "#                                      Define Predictive Model                                   #\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def def_simple_deep_classifer(height, depth, learning_rate, input_dim, output_dim):\n",
    "    # Initialize Simple Deep Classifier\n",
    "    simple_deep_classifier = tf.keras.Sequential()\n",
    "    for d_i in range(depth):\n",
    "        simple_deep_classifier.add(tf.keras.layers.Dense(height, activation='relu'))\n",
    "\n",
    "    simple_deep_classifier.add(tf.keras.layers.Dense(output_dim, activation='softmax'))    \n",
    "    \n",
    "    # Compile Simple Deep Classifier\n",
    "    simple_deep_classifier.compile(optimizer='adam',\n",
    "                  loss=\"mae\",#loss = categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Return Output\n",
    "    return simple_deep_classifier\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "#                                  Build Deep Classifier Model                                   #\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "from tensorflow.keras import Sequential\n",
    "def build_simple_deep_classifier(n_folds , n_jobs, n_iter, param_grid_in, X_train, y_train,X_test):\n",
    "\n",
    "    # Deep Feature Network\n",
    "    CV_simple_deep_classifier = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=def_simple_deep_classifer, verbose=True)\n",
    "    \n",
    "    # Randomized CV\n",
    "    CV_simple_deep_classifier_CVer = RandomizedSearchCV(estimator=CV_simple_deep_classifier, \n",
    "                                    n_jobs=n_jobs,\n",
    "                                    cv=KFold(n_folds, random_state=2020, shuffle=True),\n",
    "                                    param_distributions=param_grid_in,\n",
    "                                    n_iter=n_iter,\n",
    "                                    return_train_score=True,\n",
    "                                    random_state=2020,\n",
    "                                    verbose=10)\n",
    "    \n",
    "    # Fit\n",
    "    CV_simple_deep_classifier_CVer.fit(X_train,y_train)\n",
    "\n",
    "    # Make Prediction(s)\n",
    "    predicted_classes_train = CV_simple_deep_classifier_CVer.predict(X_train)\n",
    "    predicted_classes_test = CV_simple_deep_classifier_CVer.predict(X_test)\n",
    "    \n",
    "    # Counter number of parameters #\n",
    "    #------------------------------#\n",
    "    # Extract Best Model\n",
    "    best_model = CV_simple_deep_classifier_CVer.best_estimator_\n",
    "    # Count Number of Parameters\n",
    "    N_params_best_classifier = np.sum([np.prod(v.get_shape().as_list()) for v in best_model.model.trainable_variables])\n",
    "\n",
    "    \n",
    "    # Return Values\n",
    "    return predicted_classes_train, predicted_classes_test, N_params_best_classifier\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print('Deep Classifier - Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "----\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------#\n",
    "#                                      Define Predictive Model                                   #\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "def get_deep_classifer(height, depth, learning_rate, input_dim, output_dim):\n",
    "    #----------------------------#\n",
    "    # Maximally Interacting Layer #\n",
    "    #-----------------------------#\n",
    "    # Initialize Inputs\n",
    "    input_layer = tf.keras.Input(shape=(input_dim,))\n",
    "   \n",
    "    \n",
    "    #------------------#\n",
    "    #   Core Layers    #\n",
    "    #------------------#\n",
    "    core_layers = fullyConnected_Dense(height)(input_layer)\n",
    "    # Activation\n",
    "    core_layers = tf.nn.swish(core_layers)\n",
    "    # Train additional Depth?\n",
    "    if depth>1:\n",
    "        # Add additional deep layer(s)\n",
    "        for depth_i in range(1,depth):\n",
    "            core_layers = fullyConnected_Dense(height)(core_layers)\n",
    "            # Activation\n",
    "            core_layers = tf.nn.swish(core_layers)\n",
    "    \n",
    "    #------------------#\n",
    "    #  Readout Layers  #\n",
    "    #------------------# \n",
    "    # Affine (Readout) Layer (Dense Fully Connected)\n",
    "    readout_layer = fullyConnected_Dense(output_dim)(core_layers)  \n",
    "    output_layers = tf.nn.softmax(readout_layer)  \n",
    "    # Define Input/Output Relationship (Arch.)\n",
    "    trainable_layers_model = tf.keras.Model(input_layer, output_layers)\n",
    "    \n",
    "    \n",
    "    #----------------------------------#\n",
    "    # Define Optimizer & Compile Archs.\n",
    "    #----------------------------------#\n",
    "    opt = Adam(lr=learning_rate, amsgrad=False)\n",
    "    trainable_layers_model.compile(optimizer=opt, \n",
    "                                   loss=\"categorical_crossentropy\", \n",
    "                                   metrics=[\"accuracy\", \"mae\"])\n",
    "\n",
    "    return trainable_layers_model\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def build_simple_deep_classifier(n_folds , n_jobs, n_iter, param_grid_in, X_train, y_train,X_test):\n",
    "    # Update Dictionary\n",
    "    param_grid_in_internal = param_grid_in\n",
    "    param_grid_in_internal['input_dim'] = [1]#[(X_train.shape[1])]\n",
    "    \n",
    "    # Deep Feature Network\n",
    "    ffNN_CV = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=get_deep_classifer, \n",
    "                                                            verbose=True)\n",
    "    \n",
    "    # Randomized CV\n",
    "    ffNN_CVer = RandomizedSearchCV(estimator=ffNN_CV, \n",
    "                                    n_jobs=n_jobs,\n",
    "                                    cv=KFold(n_folds, random_state=2020, shuffle=True),\n",
    "                                    param_distributions=param_grid_in_internal,\n",
    "                                    n_iter=n_iter,\n",
    "                                    return_train_score=True,\n",
    "                                    random_state=2020,\n",
    "                                    verbose=10)\n",
    "    \n",
    "    # Fit Model #\n",
    "    #-----------#\n",
    "    ffNN_CVer.fit(X_train,y_train)\n",
    "\n",
    "    # Write Predictions #\n",
    "    #-------------------#\n",
    "    y_hat_train = ffNN_CVer.predict(X_train)\n",
    "    y_hat_test = ffNN_CVer.predict(X_test)\n",
    "    \n",
    "    # Counter number of parameters #\n",
    "    #------------------------------#\n",
    "    # Extract Best Model\n",
    "    best_model = ffNN_CVer.best_estimator_\n",
    "    # Count Number of Parameters\n",
    "    N_params_best_ffNN = np.sum([np.prod(v.get_shape().as_list()) for v in best_model.model.trainable_variables])\n",
    "    \n",
    "    \n",
    "    #-----------------#\n",
    "    # Save Full-Model #\n",
    "    #-----------------#\n",
    "    print('Benchmark-Model: Saving')\n",
    "#     joblib.dump(best_model, './outputs/models/Benchmarks/ffNN_trained_CV.pkl', compress = 1)\n",
    "#     ffNN_CVer.best_params_['N_Trainable_Parameters'] = N_params_best_ffNN\n",
    "#     pd.DataFrame.from_dict(ffNN_CVer.best_params_,orient='index').to_latex(\"./outputs/models/Benchmarks/Best_Parameters.tex\")\n",
    "    print('Benchmark-Model: Saved')\n",
    "    \n",
    "    # Return Values #\n",
    "    #---------------#\n",
    "    return y_hat_train, y_hat_test, N_params_best_ffNN\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print('Deep Feature Builder - Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
