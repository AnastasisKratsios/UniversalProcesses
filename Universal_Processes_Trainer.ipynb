{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "# N_Euler_Maruyama_Steps = 2\n",
    "N_Monte_Carlo_Samples = 1\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 20\n",
    "Max_Grid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "*This hyperparameter describes the proportion of the data used as sample-barycenters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantization_Proportion = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Algorithm\n",
    "---\n",
    "Given a set of training inputs $\\mathbb{X}$ and a stochastic process $(X_t)_{t\\geq 0}$ which we can sample from:\n",
    "1. **For:** x in $\\mathbb{X}$:\n",
    "    - *Simulate:* $\\{x\\mapsto X_T(\\omega_n)\\}_{n=1}^N$\n",
    "    - *Set*: $\\hat{\\nu}_{x,T}\\triangleq \\frac1{N}\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$\n",
    "2. **Learn:** Wasserstein Barycenters $\\hat{\\mu}_1,\\dots,\\hat{\\mu}_N\n",
    "    \\in \\underset{{\\hat{\\mu}_n\\in\\mathscr{P}_{N}(\\mathbb{R}^d)}}{\\operatorname{argmin}}\n",
    "    \\, \\sum_{n=1}^N W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$\n",
    "3. **Train Classifier:** $\\hat{f}:x\\mapsto \\operatorname{n\\leq N}\\, W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Grid\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Grid Instances:  20\n"
     ]
    }
   ],
   "source": [
    "# Get Input Data\n",
    "x_Grid = np.arange(start=-Max_Grid,\n",
    "                   stop=Max_Grid,\n",
    "                   step=(2*Max_Grid/N_Grid_Finess))\n",
    "\n",
    "# Get Number of Instances in Grid\n",
    "N_Grid_Instances = len(x_Grid)\n",
    "\n",
    "# Updater User\n",
    "print(\"\\u2022 Grid Instances: \", N_Grid_Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Counting Parameters\n",
    "Initialize the \"conting\" type parameters which will help us to determine the length of loops and to intialize object's size later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• 20  Centers will be produced; from a total datasize of:  20 !  (That's  1  percent).\n",
      "• Each Wasserstein-1 Ball should contain:  1 elements from the training set.\n"
     ]
    }
   ],
   "source": [
    "# Get Internal (Counting) Parameters\n",
    "N_Quantizers_to_parameterize = round(Quantization_Proportion*N_Grid_Finess)\n",
    "N_Elements_Per_Cluster = int(round(N_Grid_Instances/N_Quantizers_to_parameterize))\n",
    "\n",
    "# Update User\n",
    "print(\"\\u2022\",N_Quantizers_to_parameterize,\" Centers will be produced; from a total datasize of: \",N_Grid_Finess,\n",
    "      \"!  (That's \",Quantization_Proportion,\n",
    "      \" percent).\")\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Path\n",
    "$d X_t = \\alpha(t,x)dt + \\beta(t,x)dW_t ;\\qquad X_0 =x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return 0#np.sin(math.pi*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 1#(t+1)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List of Barycenters\n",
    "Wasserstein_Barycenters = []\n",
    "# Initialize Terminal-Time Empirical Measures\n",
    "measures_locations_list = []\n",
    "measures_weights_list = []\n",
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "# Initialize Quantizer\n",
    "Init_Quantizer_generic = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $\\{\\hat{\\nu}^{N}_{T,x}\\}_{x \\in \\mathbb{X}}$ Build Wasserstein Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 20877.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step:\n",
      "Done Simulation Step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"Current Monte-Carlo Step:\")\n",
    "\n",
    "# Perform Monte-Carlo Data Generation\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    # Get Terminal Distribution Shape\n",
    "    ###\n",
    "    # DIRECT SAMPLING\n",
    "    measures_locations_loop = (np.random.normal(x_Grid[i],np.abs(x_Grid[i]), N_Monte_Carlo_Samples).reshape(-1,))/N_Monte_Carlo_Samples\n",
    "    \n",
    "    # Append to List\n",
    "    measures_locations_list.append(measures_locations_loop.reshape(-1,1))\n",
    "    measures_weights_list.append(measure_weights)\n",
    "    \n",
    "# Update User\n",
    "print(\"Done Simulation Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dissimilarity (Distance) Matrix\n",
    "*In this step we build a dissimularity matrix of the dataset on the Wasserstein-1 space.  Namely:*\n",
    "$$\n",
    "\\operatorname{Mat}_{\\# \\mathbb{X},\\# \\mathbb{X}}\\left(\\mathbb{R}\\right)\\ni D; \\text{ where}\\qquad \\, D_{i,j}\\triangleq \\mathcal{W}_1\\left(f(x_i),f(x_j)\\right)\n",
    ";\n",
    "$$\n",
    "*where $f\\in C\\left((\\mathcal{X},\\mathcal{P}_1(\\mathcal{Y})\\right)$ is the \"target\" function we are learning.*\n",
    "\n",
    "**Note**: *Computing the dissimularity matrix is the most costly part of the entire algorithm with a complexity of at-most $\\mathcal{O}\\left(E_{W} \\# \\mathbb{X})^2\\right)$ where $E_W$ denotes the complexity of a single Wasserstein-1 evaluation between two elements of the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😚  Begin Building Distance Matrix  😚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [00:00<00:00, 237.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😀  Done Building Distance Matrix 😀 !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Disimilarity Matrix\n",
    "Dissimilarity_matrix_ot = np.zeros([N_Grid_Instances,N_Grid_Instances])\n",
    "\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Building Distance Matrix\",\" \\U0001F61A\")\n",
    "# Build Disimilarity Matrix\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    for j in range(N_Grid_Instances):\n",
    "        Dissimilarity_matrix_ot[i,j] = ot.emd2_1d(measures_locations_list[j],\n",
    "                                                  measures_locations_list[i])\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Building Distance Matrix\",\"\\U0001F600\",\"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Quantities to Loop Over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\" and Generate Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Locations Matrix (Internal to Loop)\n",
    "measures_locations_list_current = copy.copy(measures_locations_list)\n",
    "Dissimilarity_matrix_ot_current = copy.copy(Dissimilarity_matrix_ot)\n",
    "\n",
    "# Initialize masker vector\n",
    "masker = np.ones(N_Grid_Instances)\n",
    "\n",
    "# Initialize Sorting Reference Vector (This helps us efficiently scroll through the disimularity matrix to identify the barycenter without having to re-compute the dissimultarity matrix of a sub-saple at every iteration (which is the most costly part of the algorithm!))\n",
    "Distances_Loop = Dissimilarity_matrix_ot_current.sum(axis=1)\n",
    "\n",
    "# Initialize Classes (In-Sample)\n",
    "Classifer_Wasserstein_Centers = np.zeros([N_Quantizers_to_parameterize,N_Grid_Instances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/usr/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n",
      "100%|██████████| 20/20 [00:00<00:00, 9131.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😚  Begin Identifying Sample Barycenters  😚\n",
      "😀  Done Identifying Sample Barycenters 😀 !\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Identifying Sample Barycenters\",\" \\U0001F61A\")\n",
    "\n",
    "# Identify Sample Barycenters\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    # GET BARYCENTER #\n",
    "    #----------------#\n",
    "    ## Identify row with minimum total distance\n",
    "    Barycenter_index = int(Distances_Loop.argsort()[:1][0])\n",
    "    ## Get Barycenter\n",
    "    ## Update Barycenters Array ##\n",
    "    #----------------------------#\n",
    "    ### Get next Barycenter\n",
    "    new_barycenter_loop = measures_locations_list_current[Barycenter_index].reshape(-1,1)\n",
    "    ### Update Array of Barycenters\n",
    "    if i == 0:\n",
    "        # Initialize Barycenters Array\n",
    "        Barycenters_Array = new_barycenter_loop\n",
    "    else:\n",
    "        # Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,new_barycenter_loop,axis=-1)\n",
    "\n",
    "    # GET CLUSTER #\n",
    "    #-------------#\n",
    "    # Identify Cluster for this barycenter (which elements are closest to it)\n",
    "    Cluster_indices = (masker*Dissimilarity_matrix_ot_current[:,Barycenter_index]).argsort()[:N_Elements_Per_Cluster]\n",
    "    ## UPDATES Set  M^{(n)}  ##\n",
    "    #-------------------------#\n",
    "    Dissimilarity_matrix_ot_current[Cluster_indices,:] = 0\n",
    "    # Distance-Based Sorting\n",
    "    Distances_Loop[Cluster_indices] = math.inf\n",
    "\n",
    "    # Update Cluster\n",
    "    masker[Cluster_indices] = math.inf\n",
    "    \n",
    "    # Update Classes\n",
    "    Classifer_Wasserstein_Centers[i,Cluster_indices] = 1\n",
    "#     print(Cluster_indices)\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Identifying Sample Barycenters\",\"\\U0001F600\",\"!\")\n",
    "print(Classifer_Wasserstein_Centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# %run ParaGAN_Backend.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9755 - accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9668 - accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 963us/step - loss: 2.9583 - accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9498 - accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9415 - accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9332 - accuracy: 0.1500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9249 - accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9165 - accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9078 - accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8990 - accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8899 - accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8805 - accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8709 - accuracy: 0.1000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8610 - accuracy: 0.1000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8508 - accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8403 - accuracy: 0.1000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8295 - accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8182 - accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8065 - accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7945 - accuracy: 0.1000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7823 - accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7695 - accuracy: 0.1000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7565 - accuracy: 0.1000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7432 - accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7296 - accuracy: 0.1000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7157 - accuracy: 0.1000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7015 - accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6871 - accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6726 - accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6578 - accuracy: 0.1000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6430 - accuracy: 0.1000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6280 - accuracy: 0.1000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6130 - accuracy: 0.1000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5979 - accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5829 - accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5679 - accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5530 - accuracy: 0.1000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5383 - accuracy: 0.1000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5238 - accuracy: 0.1000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5094 - accuracy: 0.1000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4954 - accuracy: 0.1000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4816 - accuracy: 0.1000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4680 - accuracy: 0.1000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4548 - accuracy: 0.1000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4419 - accuracy: 0.1000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4292 - accuracy: 0.1000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4168 - accuracy: 0.1000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4047 - accuracy: 0.1000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3928 - accuracy: 0.1000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3813 - accuracy: 0.1000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3700 - accuracy: 0.1000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3590 - accuracy: 0.1000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3485 - accuracy: 0.1500\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3382 - accuracy: 0.1000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3282 - accuracy: 0.1000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3184 - accuracy: 0.1000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3087 - accuracy: 0.1000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2993 - accuracy: 0.1000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2901 - accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2811 - accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2722 - accuracy: 0.1500\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2636 - accuracy: 0.1500\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2550 - accuracy: 0.1500\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2466 - accuracy: 0.1500\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2382 - accuracy: 0.1500\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2300 - accuracy: 0.1500\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2218 - accuracy: 0.1500\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2136 - accuracy: 0.2000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2054 - accuracy: 0.2000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1973 - accuracy: 0.2000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1891 - accuracy: 0.2000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1808 - accuracy: 0.2000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1725 - accuracy: 0.2000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1643 - accuracy: 0.2000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1561 - accuracy: 0.2000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1478 - accuracy: 0.2000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1396 - accuracy: 0.3000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1313 - accuracy: 0.3000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1228 - accuracy: 0.3000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1143 - accuracy: 0.3000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1057 - accuracy: 0.3000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0968 - accuracy: 0.3000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0878 - accuracy: 0.3000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0787 - accuracy: 0.3000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0695 - accuracy: 0.3000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0602 - accuracy: 0.3000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0509 - accuracy: 0.3000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0415 - accuracy: 0.3000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0321 - accuracy: 0.3000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0225 - accuracy: 0.3000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 917us/step - loss: 2.0128 - accuracy: 0.3000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0030 - accuracy: 0.3000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9930 - accuracy: 0.3000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9830 - accuracy: 0.3500\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9731 - accuracy: 0.3500\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9632 - accuracy: 0.3500\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9531 - accuracy: 0.3500\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9429 - accuracy: 0.3500\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9327 - accuracy: 0.3500\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9223 - accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 821us/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "# param_grid_Deep_Classifier['input_dim'] = [1]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = x_Grid, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers.T,\n",
    "                                                                                                        X_test = x_Grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Weights\n",
    "Predicted_Weights = np.array([])\n",
    "for i in range(N_Quantizers_to_parameterize):\n",
    "    b = np.repeat(np.array(Classifer_Wasserstein_Centers.T[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "        \n",
    "# Format Points of Mass\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      W1  E[X']-E[X]  E[X'^2]-E[X^2]\n",
      "MAE  0.0         0.0             0.0\n",
      "MSE  0.0         0.0             0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in range(len(measures_locations_list)):\n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         measures_locations_list[x_i].reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measures_weights_list[x_i].reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(measures_locations_list[x_i])\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    # Get Vars\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(measures_locations_list[x_i]**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var))\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.mean(np.abs(W1_errors)),np.mean(W1_errors**2)])\n",
    "Mean_prediction_Performance = np.array([np.mean(np.abs(Mean_errors)),np.mean(Mean_errors**2)])\n",
    "Var_prediction_Performance = np.array([np.mean(np.abs(Var_errors)),np.mean(Var_errors**2)])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"E[X'^2]-E[X^2]\":Var_prediction_Performance},index=[\"MAE\",\"MSE\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+\"Type_A_Prediction.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "print(Type_A_Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Performance\n",
    "Randomly subsample from output space and visualize empirical measures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjust if is number of plots to visualizes is larger than number of output distributions (But only if there is not enough data!)\n",
    "if N_Grid_Instances <= Visualization_Size**2:\n",
    "        Visualization_Size = int(round(np.sqrt(min(N_Grid_Instances,Visualization_Size**2)))-1)\n",
    "\n",
    "\n",
    "# Initialize Random Sample of input-output pairs to visualize\n",
    "plotting_distribution_indices = random.sample(range(N_Grid_Instances), (Visualization_Size)**2)\n",
    "\n",
    "# Generate Plot\n",
    "f, axarr = plt.subplots(Visualization_Size,Visualization_Size,figsize=(6, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.suptitle(\"Sample of Predictions\")\n",
    "for i in range(Visualization_Size):\n",
    "    for j in range(Visualization_Size):\n",
    "        # Get Current (Randomly chosen (uniformly)) Index\n",
    "        current_index = (i*Visualization_Size + j)\n",
    "        current_random_index = plotting_distribution_indices[current_index]\n",
    "        # Generate Current Plot\n",
    "        axarr[i,j].bar(Barycenters_Array,(Predicted_Weights[current_random_index].reshape(-1,)), alpha=0.5,label=\"Prediction\",color=\"chartreuse\")\n",
    "        axarr[i,j].bar(measures_locations_list[current_random_index].reshape(-1,),measures_weights_list[current_random_index], alpha=0.5,label=\"Target\",color=\"purple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
