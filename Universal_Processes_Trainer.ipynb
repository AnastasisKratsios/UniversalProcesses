{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Weak Stochastic Processes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 2\n",
    "N_Monte_Carlo_Samples = 50\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 100\n",
    "Max_Grid = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "*This hyperparameter describes the proportion of the data used as sample-barycenters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantization_Proportion = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Algorithm\n",
    "---\n",
    "Given a set of training inputs $\\mathbb{X}$ and a stochastic process $(X_t)_{t\\geq 0}$ which we can sample from:\n",
    "1. **For:** x in $\\mathbb{X}$:\n",
    "    - *Simulate:* $\\{x\\mapsto X_T(\\omega_n)\\}_{n=1}^N$\n",
    "    - *Set*: $\\hat{\\nu}_{x,T}\\triangleq \\frac1{N}\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$\n",
    "2. **Learn:** Wasserstein Barycenters $\\hat{\\mu}_1,\\dots,\\hat{\\mu}_N\n",
    "    \\in \\underset{{\\hat{\\mu}_n\\in\\mathscr{P}_{N}(\\mathbb{R}^d)}}{\\operatorname{argmin}}\n",
    "    \\, \\sum_{n=1}^N W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$\n",
    "3. **Train Classifier:** $\\hat{f}:x\\mapsto \\operatorname{n\\leq N}\\, W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Quantizers_to_parameterize = round(Quantization_Proportion*N_Grid_Finess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Path\n",
    "$d X_t = \\alpha(t,x)dt + \\beta(t,x)dW_t ;\\qquad X_0 =x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return np.sin(math.pi*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return (t+1)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Grid\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Instances:  100\n"
     ]
    }
   ],
   "source": [
    "# Get Input Data\n",
    "x_Grid = np.arange(start=-Max_Grid,\n",
    "                   stop=Max_Grid,\n",
    "                   step=(2*Max_Grid/N_Grid_Finess))\n",
    "\n",
    "# Get Number of Instances in Grid\n",
    "N_Grid_Instances = len(x_Grid)\n",
    "\n",
    "# Updater User\n",
    "print(\"Grid Instances: \", N_Grid_Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List of Barycenters\n",
    "Wasserstein_Barycenters = []\n",
    "# Initialize Terminal-Time Empirical Measures\n",
    "measures_locations_list = []\n",
    "measures_weights_list = []\n",
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "# Initialize Quantizer\n",
    "Init_Quantizer_generic = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $\\{\\hat{\\nu}^{N}_{T,x}\\}_{x \\in \\mathbb{X}}$ Build Wasserstein Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 10638.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step: 0.0\n",
      "Current Monte-Carlo Step: 0.1\n",
      "Current Monte-Carlo Step: 0.2\n",
      "Current Monte-Carlo Step: 0.3\n",
      "Current Monte-Carlo Step: 0.4\n",
      "Current Monte-Carlo Step: 0.5\n",
      "Current Monte-Carlo Step: 0.6\n",
      "Current Monte-Carlo Step: 0.7\n",
      "Current Monte-Carlo Step: 0.8\n",
      "Current Monte-Carlo Step: 0.9\n",
      "Done Simulation Step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    # Get Terminal Distribution Shape\n",
    "    ###\n",
    "    # DIRECT SAMPLING\n",
    "    measures_locations_loop = np.random.normal(x_Grid[i],np.abs(x_Grid[i]), N_Monte_Carlo_Samples).reshape(-1,)\n",
    "    \n",
    "    # Append to List\n",
    "    measures_locations_list.append(measures_locations_loop.reshape(-1,1))\n",
    "    measures_weights_list.append(measure_weights)\n",
    "    \n",
    "    # Print Update User #\n",
    "    #-------------------#\n",
    "    if (i/N_Grid_Instances)*100 % 10 ==0:\n",
    "        print(\"Current Monte-Carlo Step:\",i/N_Grid_Instances)\n",
    "    \n",
    "# Update User\n",
    "print(\"Done Simulation Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dissimilarity (Distance) Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:00<00:01, 86.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😚  Begin Building Distance Matrix  😚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 90.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😀  Done Building Distance Matrix 😀 !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Disimilarity Matrix\n",
    "Dissimilarity_matrix_ot = np.zeros([N_Grid_Instances,N_Grid_Instances])\n",
    "\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Building Distance Matrix\",\" \\U0001F61A\")\n",
    "# Build Disimilarity Matrix\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    for j in range(N_Grid_Instances):\n",
    "        Dissimilarity_matrix_ot[i,j] = ot.emd2_1d(measures_locations_list[j],\n",
    "                                                  measures_locations_list[i])\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Building Distance Matrix\",\"\\U0001F600\",\"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Quantities to Loop Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Locations Matrix (Internal to Loop)\n",
    "measures_locations_list_current = copy.copy(measures_locations_list)\n",
    "Dissimilarity_matrix_ot_current = Dissimilarity_matrix_ot\n",
    "Barycenters_sample = []\n",
    "\n",
    "# Initialize Classes (In-Sample)\n",
    "Classifer_Wasserstein_Centers = np.zeros([N_Grid_Instances,N_Quantizers_to_parameterize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\" and Generate Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2415.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😚  Begin Identifying Sample Barycenters  😚\n",
      "😀  Done Identifying Sample Barycenters 😀 !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Identifying Sample Barycenters\",\" \\U0001F61A\")\n",
    "\n",
    "# Identify Sample Barycenters\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    # Distance-Based Sorting\n",
    "    ## Get Distances from training data\n",
    "    Distances_Loop = Dissimilarity_matrix_ot_current.sum(axis=1)\n",
    "\n",
    "    ## Get Barycenter\n",
    "    Barycenter_index = Distances_Loop.argsort()[:1][0]\n",
    "    measures_locations_list_current[Barycenter_index]\n",
    "    ## Identify Cluster for this barycenter (which elements are closest to it)\n",
    "    Cluster_indices = Distances_Loop.argsort()[:N_Quantizers_to_parameterize]\n",
    "\n",
    "    # Updates\n",
    "    ## Get Barycenter \n",
    "    Barycenter_loop = measures_locations_list_current[Barycenter_index]\n",
    "    ## Update Barycenters List\n",
    "    Barycenters_sample.append(Barycenter_loop)\n",
    "    ## Update Barycenters Array\n",
    "    if i == 0:\n",
    "        # Initialize Barycenters Array\n",
    "        Barycenters_Array = Barycenter_loop\n",
    "    else:\n",
    "        # Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,Barycenter_loop,axis=-1)\n",
    "    \n",
    "    ## Update Samples List\n",
    "    ### Remove from Pairwise Distance Matrix\n",
    "    Dissimilarity_matrix_ot_current = np.delete(Dissimilarity_matrix_ot_current,Cluster_indices, axis=1)\n",
    "    Dissimilarity_matrix_ot_current = np.delete(Dissimilarity_matrix_ot_current,Cluster_indices, axis=0)\n",
    "    ### Remove from Sample Measures\n",
    "    for index in sorted(Cluster_indices, reverse=True):\n",
    "        del measures_locations_list_current[index]\n",
    "\n",
    "    # Update Classes\n",
    "    Classifer_Wasserstein_Centers[Cluster_indices,i] = 1\n",
    "\n",
    "    \n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Identifying Sample Barycenters\",\"\\U0001F600\",\"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [1]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.3209 - accuracy: 0.0600\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3002 - accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2863 - accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2735 - accuracy: 0.0800\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2615 - accuracy: 0.0600\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2504 - accuracy: 0.0600\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2391 - accuracy: 0.0600\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.2281 - accuracy: 0.0600\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2203 - accuracy: 0.0500\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2097 - accuracy: 0.0700\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.2022 - accuracy: 0.0700\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1965 - accuracy: 0.0700\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.1900 - accuracy: 0.0900\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.1871 - accuracy: 0.0900\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.1826 - accuracy: 0.0900\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1783 - accuracy: 0.0900\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.1759 - accuracy: 0.1100\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.1721 - accuracy: 0.1200\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1663 - accuracy: 0.1200\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1670 - accuracy: 0.1300\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1673 - accuracy: 0.1300\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1658 - accuracy: 0.1300\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.1621 - accuracy: 0.1400\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1639 - accuracy: 0.1400\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1631 - accuracy: 0.1400\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1687 - accuracy: 0.1400\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1700 - accuracy: 0.1400\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1762 - accuracy: 0.1400\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1799 - accuracy: 0.0800\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1779 - accuracy: 0.0800\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1731 - accuracy: 0.0900\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1660 - accuracy: 0.1000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1693 - accuracy: 0.1100\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1978 - accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2224 - accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.2288 - accuracy: 0.1600\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2201 - accuracy: 0.1600\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2078 - accuracy: 0.1500\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2001 - accuracy: 0.0800\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1916 - accuracy: 0.0900\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.1908 - accuracy: 0.0900\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.1905 - accuracy: 0.1000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1935 - accuracy: 0.1000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2479 - accuracy: 0.0900\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.2982 - accuracy: 0.0700\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3226 - accuracy: 0.0600\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3261 - accuracy: 0.1300\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3100 - accuracy: 0.1200\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3096 - accuracy: 0.1500\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3047 - accuracy: 0.1500\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2808 - accuracy: 0.1300\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2663 - accuracy: 0.1100\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2681 - accuracy: 0.1200\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2766 - accuracy: 0.1100\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3015 - accuracy: 0.1200\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3374 - accuracy: 0.1100\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3114 - accuracy: 0.1200\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3041 - accuracy: 0.1100\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3362 - accuracy: 0.0900\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3781 - accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3786 - accuracy: 0.1000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4449 - accuracy: 0.0800\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.5168 - accuracy: 0.1600\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.5834 - accuracy: 0.0900\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4987 - accuracy: 0.1000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4701 - accuracy: 0.1100\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4897 - accuracy: 0.1000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4248 - accuracy: 0.1100\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4754 - accuracy: 0.1200\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.5238 - accuracy: 0.1400\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.4997 - accuracy: 0.1200\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.4559 - accuracy: 0.1200\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.4716 - accuracy: 0.1300\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4322 - accuracy: 0.1300\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4153 - accuracy: 0.1400\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4511 - accuracy: 0.1100\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4732 - accuracy: 0.0900\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4608 - accuracy: 0.0900\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.5008 - accuracy: 0.1500\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.5889 - accuracy: 0.1400\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.5785 - accuracy: 0.0900\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.6463 - accuracy: 0.0900\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.5982 - accuracy: 0.1200\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 2.6630 - accuracy: 0.1200\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8114 - accuracy: 0.1400\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.9786 - accuracy: 0.1500\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7252 - accuracy: 0.1000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.6578 - accuracy: 0.1100\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.6165 - accuracy: 0.1100\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.5824 - accuracy: 0.0800\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7655 - accuracy: 0.0800\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.9155 - accuracy: 0.0800\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8948 - accuracy: 0.0800\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.1102 - accuracy: 0.0900\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8803 - accuracy: 0.1100\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8981 - accuracy: 0.1100\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0323 - accuracy: 0.0900\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.1786 - accuracy: 0.1200\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.1925 - accuracy: 0.1000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.5441 - accuracy: 0.1500\n",
      "4/4 [==============================] - 0s 860us/step\n",
      "4/4 [==============================] - 0s 789us/step\n"
     ]
    }
   ],
   "source": [
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = x_Grid, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers,\n",
    "                                                                                                        X_test = x_Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Type_A_timer_End = time.time() - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Centers_Wasserstein_Open_balls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5dabd8dcb7ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPredictions_Train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_classes_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCenters_Wasserstein_Open_balls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mPredictions_Test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_classes_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCenters_Wasserstein_Open_balls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Centers_Wasserstein_Open_balls' is not defined"
     ]
    }
   ],
   "source": [
    "Predictions_Train = np.matmul(predicted_classes_train,Centers_Wasserstein_Open_balls.T)\n",
    "Predictions_Test = np.matmul(predicted_classes_test,Centers_Wasserstein_Open_balls.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Centers_Wasserstein_Open_balls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-14e914cbc85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCenters_Wasserstein_Open_balls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Centers_Wasserstein_Open_balls' is not defined"
     ]
    }
   ],
   "source": [
    "Centers_Wasserstein_Open_balls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "\n",
    "# Get Predicted Means\n",
    "predicted_means = Predictions_Train.mean(axis=1)\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in range(len(measures_locations_list)):\n",
    "    # Get Laws\n",
    "    W1_errors = np.append(W1_errors,ot.emd2_1d(Predictions_Train[x_i,].reshape(-1,1),\n",
    "                                               measures_locations_list[x_i]))\n",
    "    # Get Means\n",
    "    Mean_errors = np.array(predicted_means[x_i]-np.mean(measures_locations_list[x_i]))\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.mean(np.abs(W1_errors)),np.mean(W1_errors**2)])\n",
    "Mean_prediction_Performance = np.array([np.mean(np.abs(Mean_errors)),np.mean(Mean_errors**2)])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\"EX\":Mean_prediction_Performance},index=[\"MAE\",\"MSE\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+\"Type_A_Prediction.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "print(Type_A_Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 0\n",
    "for i in range(len(measures_locations_list)):\n",
    "    avg = avg + np.mean(measures_locations_list[i])\n",
    "avg = avg/len(measures_locations_list)\n",
    "# Update User\n",
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
