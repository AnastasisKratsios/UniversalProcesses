{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics and Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize \"Higher Moments\" Loss Metric\n",
    "$$\n",
    "\\sum_{k=1}^K \\frac{|\\sum_{x \\in \\mathbb{X}}x^k\\hat{\\nu}(x) - \\mu_k|}{k!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Higher_Moments_Loss(Mu_hat_input,Mu_hat_MC_input):\n",
    "    for k in range(10):\n",
    "        moment_hat_loop = np.sum((Mu_hat_input**k)*points_of_mass)/np.math.factorial(k)\n",
    "        moment_MC_hat_loop = np.mean(Mu_hat_MC_input**k)/np.math.factorial(k)\n",
    "        if k == 0:\n",
    "            moment_hat = moment_hat_loop\n",
    "            moment_MC_hat = moment_MC_hat_loop\n",
    "        else:\n",
    "            moment_hat = np.append(moment_hat,moment_hat_loop)\n",
    "            moment_MC_hat = np.append(moment_MC_hat,moment_MC_hat_loop)\n",
    "\n",
    "    return moment_hat,moment_MC_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get OT Comparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transport-problem initializations #\n",
    "#-----------------------------------#\n",
    "if output_dim != 1:\n",
    "    ## Multi-dimensional\n",
    "    # Externally Update Empirical Weights for multi-dimensional case\n",
    "    empirical_weights = np.full((N_Monte_Carlo_Samples,),1/N_Monte_Carlo_Samples)\n",
    "    # Also Initialize\n",
    "    Sinkhorn_regularization = 0.1\n",
    "else:\n",
    "    ## Single-Dimensional\n",
    "    # Initialize Empirical Weights\n",
    "    empirical_weights = (np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples).reshape(-1,)\n",
    "\n",
    "#-------------------------#\n",
    "# Define Transport Solver #\n",
    "#-------------------------#\n",
    "def transport_dist(x_source,w_source,x_sink,w_sink,output_dim,OT_method=\"Sliced\"):\n",
    "    # Decide which problem to solve (1D or multi-D)?\n",
    "    if output_dim == 1:\n",
    "        OT_out = ot.emd2_1d(x_source,\n",
    "                            x_sink,\n",
    "                            w_source,\n",
    "                            w_sink)\n",
    "    else:\n",
    "        # COERCSION\n",
    "        ## Update Source Distribution\n",
    "        x_source = points_of_mass.reshape(-1,output_dim)\n",
    "        ## Update Sink Distribution\n",
    "        x_sink = np.array(Y_train[i,]).reshape(-1,output_dim)\n",
    "        \n",
    "        if OT_method == \"Sinkhorn\":\n",
    "            OT_out = ot.bregman.empirical_sinkhorn2(X_s = x_source, \n",
    "                                                    X_t = x_sink,\n",
    "                                                    a = w_source, \n",
    "                                                    b = w_sink, \n",
    "                                                    reg=0.01, \n",
    "                                                    verbose=False,\n",
    "                                                    method = \"sinkhorn_stabilized\")\n",
    "            # COERSION\n",
    "            OT_out = float(OT_out[0])\n",
    "        else:\n",
    "            OT_out = ot.sliced.sliced_wasserstein_distance(X_s = x_source, \n",
    "                                                    X_t = x_sink,\n",
    "                                                    a = w_source, \n",
    "                                                    b = w_sink, \n",
    "                                                    seed = 2020)\n",
    "            # COERSION\n",
    "            OT_out = float(OT_out)\n",
    "    # Return (regularized?) Transport Distance\n",
    "    return OT_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Dimensional Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deterministic_errors(X_inputs, mean_predictions,Y_targets,N_Bootstraps=10):\n",
    "    print(\"#------------#\")\n",
    "    print(\" Get Error(s) \")\n",
    "    print(\"#------------#\")\n",
    "    for i in tqdm(range((mean_predictions.shape[0]))):    \n",
    "        # Compute Error(s)\n",
    "        ## W1\n",
    "        if output_dim > 1:\n",
    "            W1_loop = ot.sliced.sliced_wasserstein_distance(X_s = mean_predictions[i,].reshape(1,-1),\n",
    "                                                            X_t = (Y_targets[i,]))\n",
    "            ## M1\n",
    "            Mu_hat = mean_predictions[i,]\n",
    "            Mu_MC = np.mean(Y_targets[i,],axis=0)\n",
    "            Mu = Mu_MC\n",
    "            \n",
    "        else:\n",
    "            W1_loop = ot.emd2_1d(np.array([mean_predictions[i]]),\n",
    "                                     np.array(Y_targets[i,]).reshape(-1,),\n",
    "                                     np.ones(1),\n",
    "                                     empirical_weights)\n",
    "\n",
    "            ## M1\n",
    "            Mu_hat = mean_predictions[i]\n",
    "            Mu_MC = np.mean(np.array(Y_targets[i,]))\n",
    "            ###\n",
    "            if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "                Mu = direct_facts[i,]\n",
    "            else:\n",
    "                Mu = Mu_MC\n",
    "            ### Error(s)\n",
    "        Mean_loop = np.sum(np.abs((Mu_hat-Mu)))\n",
    "        Mean_loop_MC = np.sum(np.abs((Mu_hat-Mu_MC)))\n",
    "        # Update\n",
    "        if i == 0:\n",
    "            W1_errors = W1_loop\n",
    "            # Moments\n",
    "            ## DNM\n",
    "            Mean_errors =  Mean_loop\n",
    "            \n",
    "        else:\n",
    "            W1_errors = np.append(W1_errors,W1_loop)\n",
    "            # Moments\n",
    "            ## DNM\n",
    "            Mean_errors =  np.append(Mean_errors,Mean_loop)\n",
    "            \n",
    "            \n",
    "    # Compute Error Metrics with Bootstrapped Confidence Intervals\n",
    "    W1_Errors = np.array(bootstrap(np.abs(W1_errors),n=N_Bootstraps)(.95))\n",
    "    Mean_Errors = np.array(bootstrap(np.abs(Mean_errors),n=N_Bootstraps)(.95))\n",
    "    \n",
    "    print(\"#-----------------#\")\n",
    "    print(\" Get Error(s): END \")\n",
    "    print(\"#-----------------#\")\n",
    "    return W1_Errors, Mean_Errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
