{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*.\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth:\n",
    "*The build-in Options:*\n",
    "- rSDE \n",
    "- pfBM\n",
    "- 2lnflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth = \"2lnflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 10\n",
    "N_Monte_Carlo_Samples = 10**1\n",
    "N_Monte_Carlo_Samples_Test = 10**1 # How many MC-samples to draw from test-set?\n",
    "\n",
    "# End times for Time-Grid\n",
    "T_end = 1\n",
    "T_end_test = 1.1\n",
    "\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 10\n",
    "Max_Grid = 1\n",
    "\n",
    "# \n",
    "N_Quantizers_to_parameterize = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "N_measures_per_center = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP:\n",
    "from operator import itemgetter \n",
    "from itertools import compress\n",
    "# Set Minibatch Size\n",
    "Random_Cover_Mini_Batch_Size = 100\n",
    "# Proportion of Clusters per Minibatch Sample\n",
    "# Quantization_Proportion = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Measure-Valued $2$-Parameter Gaussian Flow\n",
    "$$\n",
    "X_{t,x} \\sim \\mathcal{N}\\left(\\alpha(t,x),\\beta(t,x)\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** *$\\alpha$ and $\\beta$ are specified below in the SDE Example*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Rough SDE\n",
    "Simulate via Euler-M method from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T((1-\\eta)\\beta(s,x)+\\eta\\sigma_s^H)dW_s.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return .1*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rougness = 0.9 # Hurst Parameter\n",
    "Ratio_fBM_to_typical_vol = 0 # $\\eta$ in equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed Fractional Brownian Motion\n",
    "Simulate from:\n",
    "$$\n",
    "X_t^x(\\omega) = f_1(x)f_2(t) + B_t^H(\\omega).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_dirction_x(x):\n",
    "    return x*np.cos(x)\n",
    "\n",
    "def finite_variation_t(t):\n",
    "    return t*(np.sin(math.pi*t) + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "# %run ParaGAN_Backend.ipynb\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of Auxiliary Internal-Variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "measure_weights_test = np.ones(N_Monte_Carlo_Samples_Test)/N_Monte_Carlo_Samples_Test\n",
    "\n",
    "# Get number of centers\n",
    "N_Centers_per_box = max(1,int(round(np.sqrt(N_Quantizers_to_parameterize))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Centers Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grid of Barycenters\n",
    "x_Grid_barycenters = np.arange(start=-Max_Grid,\n",
    "                               stop=Max_Grid,\n",
    "                               step = (2*Max_Grid/N_Centers_per_box))\n",
    "t_Grid_barycenters = np.arange(start=0,\n",
    "                               stop=T_end,\n",
    "                               step = (T_end/N_Centers_per_box))\n",
    "for x_i in range(len(x_Grid_barycenters)):\n",
    "    for t_j in range(len(t_Grid_barycenters)):\n",
    "        new_grid_entry = np.array([t_Grid_barycenters[t_j],x_Grid_barycenters[x_i]]).reshape(1,-1)\n",
    "        if (x_i==0 and t_j ==0):\n",
    "            Grid_Barycenters = new_grid_entry\n",
    "        else:\n",
    "            Grid_Barycenters = np.append(Grid_Barycenters,new_grid_entry,axis=0)\n",
    "\n",
    "# Update Number of Quantizers Generated\n",
    "N_Quantizers_to_parameterize = Grid_Barycenters.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Simulator.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer (Model Type A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training Data\n",
    "for i in range(Grid_Barycenters.shape[0]):\n",
    "    # Get output for center (mu-hat)\n",
    "    if groud_truth == \"2lnflow\":\n",
    "        center_current, trash = twoparameter_flow_sampler((Grid_Barycenters[i]).reshape(1,2),N_Monte_Carlo_Samples)\n",
    "    \n",
    "    # Get random sample in delta ball around ith center\n",
    "    sub_grid_loop = np.random.uniform(0,delta,(N_measures_per_center,2)) + Grid_Barycenters[i]\n",
    "    \n",
    "    # Get Measures for this random sample\n",
    "    if groud_truth == \"2lnflow\":\n",
    "        measures_locations_list_current, measures_weights_list_current = twoparameter_flow_sampler(sub_grid_loop,N_Monte_Carlo_Samples)\n",
    "    ##\n",
    "    measures_locations_list_current = measures_locations_list_current + center_current\n",
    "    measures_weights_list_current = measures_weights_list_current + trash\n",
    "    # Update Classes\n",
    "    Classifer_Wasserstein_Centers_loop = np.zeros([(N_measures_per_center+1),N_Quantizers_to_parameterize]) # The +1 is to account for the center which will be added to the random ball\n",
    "    Classifer_Wasserstein_Centers_loop[:, i] =  1\n",
    "    # Updates Classes\n",
    "    if i==0:\n",
    "        # INITIALIZE: Classifiers\n",
    "        Classifer_Wasserstein_Centers = Classifer_Wasserstein_Centers_loop\n",
    "        # INITIALIZE: Training Data\n",
    "        X_train = np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0)\n",
    "        # INITIALIZE: Barycenters Array\n",
    "        Barycenters_Array = (center_current[0]).reshape(-1,1)\n",
    "        # INITIALIZE: Measures and locations\n",
    "        measures_locations_list = measures_locations_list_current\n",
    "        measures_weights_list = measures_weights_list_current\n",
    "    else:\n",
    "        # UPDATE: Classifer\n",
    "        Classifer_Wasserstein_Centers = np.append(Classifer_Wasserstein_Centers,Classifer_Wasserstein_Centers_loop,axis=0)\n",
    "        # UPDATE: Training Data\n",
    "        X_train = np.append(X_train,np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0),axis=0)\n",
    "        # UPDATE: Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,((center_current[0]).reshape(-1,1)),axis=-1)\n",
    "        # UPDATE: Measures and locations\n",
    "        measures_locations_list = measures_locations_list + measures_locations_list_current\n",
    "        measures_weights_list = measures_locations_list + measures_weights_list_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP\n",
    "X_test = X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDEBUG\n",
    "\n",
    "# if groud_truth == \"2lnflow\":\n",
    "#     print(\"2lnflow!\")\n",
    "#     measures_locations_list, measures_weights_list, X_train = measure_valued_direct_sampling(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "#     measures_locations_list_test, measures_weights_list_test, X_test = measure_valued_direct_sampling(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)     \n",
    "\n",
    "# DEBUG LATER...\n",
    "# if groud_truth == \"rSDE\":\n",
    "#     print(\"rSDE!\")\n",
    "#     measures_locations_list, measures_weights_list, X_train = Euler_Maruyama_simulator(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "#     measures_locations_list_test, measures_weights_list_test, X_test = Euler_Maruyama_simulator(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)     \n",
    "    \n",
    "# if groud_truth == \"pfBM\":\n",
    "#     print(\"pFBM!\")\n",
    "#     measures_locations_list, measures_weights_list, X_train= perturbed_fBM_simulator(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "#     measures_locations_list_test, measures_weights_list_test, X_test= perturbed_fBM_simulator(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2190 - accuracy: 0.0400\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.1849 - accuracy: 0.0400\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.1633 - accuracy: 0.1200\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.1405 - accuracy: 0.1300\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.1186 - accuracy: 0.1300\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0946 - accuracy: 0.1300\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0678 - accuracy: 0.1600\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.0375 - accuracy: 0.1700\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0028 - accuracy: 0.2000\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.9638 - accuracy: 0.2500\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.9207 - accuracy: 0.1200\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.8743 - accuracy: 0.1200\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8242 - accuracy: 0.1200\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7722 - accuracy: 0.1200\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7176 - accuracy: 0.1200\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.6616 - accuracy: 0.1600\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.6040 - accuracy: 0.1800\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.5489 - accuracy: 0.1800\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.4937 - accuracy: 0.1800\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.4415 - accuracy: 0.2700\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3881 - accuracy: 0.2600\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.3325 - accuracy: 0.3100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2757 - accuracy: 0.3100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2250 - accuracy: 0.2800\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.1719 - accuracy: 0.3100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1228 - accuracy: 0.3300\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0710 - accuracy: 0.3200\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9753 - accuracy: 0.28 - 0s 2ms/step - loss: 2.0186 - accuracy: 0.4300\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9662 - accuracy: 0.4400\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9127 - accuracy: 0.4200\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8601 - accuracy: 0.4400\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8130 - accuracy: 0.5200\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7561 - accuracy: 0.6000\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7093 - accuracy: 0.6200\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6550 - accuracy: 0.6000\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6065 - accuracy: 0.7200\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5666 - accuracy: 0.6300\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5259 - accuracy: 0.5900\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4933 - accuracy: 0.5300\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4509 - accuracy: 0.6700\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4001 - accuracy: 0.7400\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3622 - accuracy: 0.7200\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3200 - accuracy: 0.7600\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2932 - accuracy: 0.7700\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2643 - accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2282 - accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1992 - accuracy: 0.8000\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1675 - accuracy: 0.8400\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1280 - accuracy: 0.8200\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0917 - accuracy: 0.8300\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0714 - accuracy: 0.7600\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0431 - accuracy: 0.7600\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0045 - accuracy: 0.8400\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9690 - accuracy: 0.8700\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9338 - accuracy: 0.8900\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9057 - accuracy: 0.8500\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8760 - accuracy: 0.8900\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8633 - accuracy: 0.8800\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8357 - accuracy: 0.9200\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8161 - accuracy: 0.9400\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7903 - accuracy: 0.8300\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7649 - accuracy: 0.8200\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7364 - accuracy: 0.8600\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.9400\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.9300\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.9200\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.9200\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.9700\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.9600\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.9800\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.9600\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.9300\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.9200\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.9400\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.9600\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.9800\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 1.0000\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.9700\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.9700\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.9600\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2733 - accuracy: 0.9800\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.9600\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.9400\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2422 - accuracy: 0.9900\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1570 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 1.0000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [2]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 14445.19it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 17011.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n",
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Format Weights\n",
    "## Train\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): START\")\n",
    "print(\"#---------------------------------------#\")\n",
    "Predicted_Weights = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    b = np.repeat(np.array(predicted_classes_train[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): END\")\n",
    "print(\"#-------------------------------------#\")\n",
    "\n",
    "## Test\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): START\")\n",
    "print(\"#-------------------------------------#\")\n",
    "Predicted_Weights_test = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):\n",
    "    b_test = np.repeat(np.array(predicted_classes_test[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b_test = b_test/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights_test = b_test\n",
    "    else:\n",
    "        Predicted_Weights_test = np.append(Predicted_Weights_test,b_test,axis=1)\n",
    "print(\"#-----------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): END\")\n",
    "print(\"#-----------------------------------#\")\n",
    "        \n",
    "# Format Points of Mass\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: START\")\n",
    "print(\"#-----------------------------#\")\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: END\")\n",
    "print(\"#-----------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 1951.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>5.461635e-07</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>2.881870e-09</td>\n",
       "      <td>0.044256</td>\n",
       "      <td>0.105015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>4.931459e-05</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>8.135484e-05</td>\n",
       "      <td>0.179280</td>\n",
       "      <td>0.289522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>3.752425e-04</td>\n",
       "      <td>0.018073</td>\n",
       "      <td>1.356504e-03</td>\n",
       "      <td>0.383267</td>\n",
       "      <td>0.525926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  5.461635e-07    0.000024         2.881870e-09                0.044256   \n",
       "MAE  4.931459e-05    0.003101         8.135484e-05                0.179280   \n",
       "Max  3.752425e-04    0.018073         1.356504e-03                0.383267   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.105015  \n",
       "MAE              0.289522  \n",
       "Max              0.525926  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Training Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "Skewness_errors = np.array([])\n",
    "Kurtosis_errors = np.array([])\n",
    "predictions_mean = np.array([])\n",
    "true_mean = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measure_weights.reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(np.array(measures_locations_list[x_i]))\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    ## Update Erros\n",
    "    predictions_mean = np.append(predictions_mean,Mu_hat)\n",
    "    true_mean = np.append(true_mean,Mu)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(np.array(measures_locations_list[x_i])**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat = np.sum((Barycenters_Array**3)*(Predicted_Weights[x_i]))\n",
    "    Skewness = np.mean(np.array(measures_locations_list[x_i])**3)\n",
    "    Skewness_errors = np.append(Skewness_errors,(abs(Skewness_hat-Skewness))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat = np.sum((Barycenters_Array**4)*(Predicted_Weights[x_i]))\n",
    "    Kurtosis = np.mean(np.array(measures_locations_list[x_i])**4)\n",
    "    Kurtosis_errors = np.append(Kurtosis_errors,(abs(Kurtosis_hat-Kurtosis))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.min(np.abs(W1_errors)),np.mean(np.abs(W1_errors)),np.max(np.abs(W1_errors))])\n",
    "Mean_prediction_Performance = np.array([np.min(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors)),np.max(np.abs(Mean_errors))])\n",
    "Var_prediction_Performance = np.array([np.min(np.abs(Var_errors)),np.mean(np.abs(Var_errors)),np.max(np.abs(Var_errors))])\n",
    "Skewness_prediction_Performance = np.array([np.min(np.abs(Skewness_errors)),np.mean(np.abs(Skewness_errors)),np.max(np.abs(Skewness_errors))])\n",
    "Kurtosis_prediction_Performance = np.array([np.min(np.abs(Kurtosis_errors)),np.mean(np.abs(Kurtosis_errors)),np.max(np.abs(Kurtosis_errors))])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Train.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f62768a5dd0>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VFX+//HXZya9ESAR6UVUBKQZARUFO3YQC1hQvyq7lv1ZVlfdZtl11V37rmV1RSwIKjZUsFEUC6yAdKSDhKAE0ntm5vP7497IEFImyWA2k8/z8ZjHzJx77p1zM5B37jn3niuqijHGGONp7gYYY4z532CBYIwxBrBAMMYY47JAMMYYA1ggGGOMcVkgGGOMASwQjDHGuCwQjDHGABYIxhhjXFHN3YCGSEtL0x49ejR3M4wxpkVZsmTJblVNr69evYEgIpOBs4Fdqtq/huUCPAGcCZQAV6rqUhE5EXgsqGofYLyqvisiU4CRQL677EpVXVZfW3r06MHixYvrq2aMMSaIiGwLpV4oRwhTgH8BL9ey/AzgUPcxDHgGGKaq84BBbmPaARuBT4LWu11VZ4TSSGOMMQdevWMIqvoFkFNHlfOAl9WxEEgVkY7V6lwAzFbVksY31RhjzIEUjkHlzsD2oPeZblmw8cC0amX3i8gKEXlMRGLD0A5jjDFNEI5AkBrKfp5T2z1aOBL4OGj5XThjCkcD7YA7at24yCQRWSwii7Ozs8PQXGOMMTUJRyBkAl2D3ncBsoLeXwS8o6qVVQWqutPtYioHXgSG1rZxVX1OVTNUNSM9vd5BcmOMMY0UjkCYCUwUx3AgX1V3Bi2fQLXuoqoxBvcMpTHAqjC0wxhjTBOEctrpNGAUkCYimcDdQDSAqj4LzMI55XQjzmmnVwWt2wPn6OHzapudKiLpON1Ny4BfN203jDHGNFW9gaCqE+pZrsANtSzbyv4DzKjqSSG2zxhjwu+HhRAVC50GN3dL/qfY1BXGmNbnzatg8mjYNK+5W/I/xQLBGNO6FOyEwizQAEybAFsWNHeL/mdYIBhjWpespc7zBS9C2+7w2kWw/mNQrXu9X5K/ErLX/+Ifa4FgjGlddiwF8cIhJ8EV70ObLk4oPDEAPrsHtn4FezZBeeGBCYnsdfX/sl/0LDx1NLx3o9OOX0iLmu3UGGOaLOs7NL0P2eUeAoEU9OLZRK//kPh175Dw1ZPIl3vn5Ay0643n+q+dAehwUHW6qSqK4IZFEN+25npbFkBMEnz3KmxdAOc/D11rvVwrbCwQjDGthypkLWUuQ7n6/jlBC9KAa2nPRfT3bCWNfA73bGdSzoeUrXiHuCHjw/P5P66AnE3O60/+COc9tX+dQAAy/wv9z4eBE+DtX8Hk0+HqT6FLRnjaUQsLBGNM65G7FUpzmVvZmXMHdmJ4r/Z4PeD1eIiJ8hDjFUCo9AfYkVvMlrmLSVrwbPgCYfU7TnfV4Mtg6UvQ/wI45MR96+zZCKW50HUYdD8WrvsKlr4MnY8KTxvqYIFgjIksgQB4ahkezfoOgOWBXjx84iH0OTil1s2oKs8tPJNf5b4IP62GDv2a1i5VJxB6jYIzHoJtX8H7/w+uXwgxiXvrbV/kPHcd5jzHpcCxNzbts0Nkg8rGmMixaR78oxcsnlzz8qylVBJNfvKhHN4huc5NiQjJw66gXKPJ+fyZBjdl6+5iPl+fzbx1u5j7/U/895t5kLuVNe1O5rMNBXw74D7I+4G8D/+874rb3bGF9r0b/JlNZUcIxpjI8MMimH6Jc8rmh7dBanfoffI+VQKZS1mr3RnRpzPOVGp1O3NYPz6cdwxnfT8Dyh+A2BpCpIYjkiXbchn/3DdU+veepXRH1DQGe71MWJBG/gLnzo8PRY1izLKXeCHpUq48eTBej8D2/zpHByG0L9wsEIwxLd/OFTD1QkjuCJe+CW9MhDevhGs+g/TDnToBP5q1jGX+Yznx8NBmTk5NiGFbrwnEbv2CiqXTiBl2tXPWz7rZkP097N4Axbth1J0w4hYQIbuwnOunLqFjm3gevnAg0V5BgCPevIPSNiN4+fTTEQFBiM1OIfa9+Wyd/xKXbangwTO70H33Osr6XkhZSQUVvgDl7qNbuwRiog5sp44FgjGmZSvKhlfGOn+9T3wPUrvChGnw/EnO9QXXzIHENNizEa+vmNUcwrjeaSFv/rgTTmfV5h4cMv/v8PVjzlXO0YlwUB/ocbwzADznXsjdgm/0w9z42lLySyt5+7qh9O3kjlHsWAqF24k96U4Gdk3du/Eux6OLjuTWkkUcu/0M7n76M6bEwBWfCos++XSfdsz57UgOSU8Kx0+sVhYIxpiWbecyKNkNl7/rhAFAajcYPw2mnAUvneMs2+Feodx5CImxof/qO7pnO+5PGMedZY+zu/0J/DjgDvZ0OolAVJxTIaD0iH6cnkufZvP6taze/SseuPiYvWEAzmCyJxr6nLXf9mXwRNrOvp05l6aye1Eega1ezhh9Jqd744mJ8hAb5ZwBlZ584G8saYFgjGnZyvKd55RqEyt3PRoufQOmXQIvjqak7eGoxnJYvyEN2ryI0GnE5Rz2wWACmz2wGWBltVojuNDr42+FL/DuQc/Te8DYvYvyfoBlrzmnl9Z0IdqAC+GTP9Jp0ww66ffQcQBXjuzboDaGiwWCMaZlK8tznuPa7L+s1yiY+C5MvYCEnNks0j6MOqJjgz/iimN7cHSPdvgCgRqXe0TwyAj2bOhN789/51x0dsaDUJIDr45zBrpPva/mjce3hSPOgZVvOPWGTGxw+8LFAsEY07KVOoGwqzKWwuwiist9eD1CXLSX2CgPJTFHUHbKa3SadQVLoodxXVpiPRvcn9cjHNmlhsCprsuvoHwrLHwa2vV0uopyt8Ll78BBR9S+3pCJsGqG8/oXmKKiNhYIxpgWLTdnN/EazdC/f1VPzSe45rieIZ1u2iSn/sWZwG7275z3F0yGHiPqXqfH8c5psnnb9l6Q1gwsEIwxLVpx/h4qSeTGE3tzaIckEmOi8AWUsko/5T4/CTFRtEuMITUhut6L0cLCGwUXvggz/g8OPwP6j6t/HY8HTrgNvv/QmX21mVggGGNaNC3Lp0ATuPjornRtl9DczXHEtYHL3mrYOkMmNuv4AdjUFcaYFs5Tnkc+ibRJiG7uprR49QaCiEwWkV0isqqW5SIiT4rIRhFZISJDgpb5RWSZ+5gZVN5TRBaJyAYReV1EYsKzO8aY1sZbXkAhiSQ34NoCU7NQjhCmAKPrWH4GcKj7mAQEzwJVqqqD3Me5QeUPAY+p6qFALnB1g1ptjDGuqMpCSr1JB36wuBWoNxBU9Qsgp44q5wEvq2MhkCoitZ7oK863dhLgnmPFS8CY0JtsjDF7xfkKqPD+AoPFrUA4xhA6A9uD3me6ZQBxIrJYRBaKSNUv/fZAnqr6aqhvjDGhUyU+UERFTO33NTChC0enW03HaVVzvnZT1SwR6QXMFZGVQEEd9fffuMgknK4ounXr1tS2GmMiSUUxXgIELBDCIhxHCJlA16D3XYAsAFWtet4MzAcGA7txupWiqteviao+p6oZqpqRnh7alLXGmFbCncdIa5q2wjRYOAJhJjDRPdtoOJCvqjtFpK2IxAKISBpwHLBGVRWYB1zgrn8F8F4Y2mGMaW3ceYw88an1VDShqLfLSESmAaOANBHJBO4GogFU9VlgFnAmsBEoAa5yVz0C+LeIBHCC50FVXeMuuwOYLiJ/Bb4DXgjXDhljWg9fSS5RgDfBAiEc6g0EVZ1Qz3IFbqih/GvgyFrW2Qw03wxOxpiIUFqQSzIQnVjDtNKmwexKZWNMi1VWuAeAuGQLhHCwQDDGtFjlhc4lUvEpod8S09TOAsEY02JVluQCkNimXTO3JDJYIBhjWix/ST5FGkdqYnxzNyUiWCAYY1osLc0ln0RSE2x+zHCwQDDGtFhSVkCBJpASZzOdhoMFgjGmxfJWFFAiSUR57VdZONhP0RjTYsVUFlDqTWruZkQMCwRjTIsV6yukPNqmvg4XCwRjTIsVHyjCF20znYaLBYIxpmUKBIjXEvw29XXYWCAYY1qm8nw8KBpnE9uFiwWCMaZF0lJn6muJt3shhIsFgjGmRSopcOYxikqwie3CxQLBGNMiFec7M51GJ1qXUbhYIBhjWqQyd6bT2OT2zdySyGGBYEykqyiGmb+BvB+auyVhVV7kzHSakGIznYaLBYIxke77D2Hpy7BudnO3JKwqip1ASGpjRwjhYoFgTKRb857znLO5edsRZoGSXPwqpLSxQeVwsUAwJpKVF8KGT53XERYIWppPIQmkJMQ2d1MiRr2BICKTRWSXiKyqZbmIyJMislFEVojIELd8kIh8IyKr3fKLg9aZIiJbRGSZ+xgUvl0yxvxs/cfgL4eUzhEXCFKeTyGJxEV7m7spESOUI4QpwOg6lp8BHOo+JgHPuOUlwERV7eeu/7iIBJ8fdruqDnIfyxrccmNM/Va/A0kHw5EXQO428Puau0VhE1WRT4knsbmbEVHqDQRV/QLIqaPKecDL6lgIpIpIR1Vdr6ob3G1kAbuA9HA02hgTgvIi2PgZ9D0X2veGQCUUZNZev7IU/JW/XPuaKLqikBKvzXQaTuEYQ+gMbA96n+mW/UxEhgIxwKag4vvdrqTHRMQ6AY0Jt/Ufga8M+o6Bdr2csj2b9q0T8MOmufDWNfBQT5h6oVPWAsT4C6mIskAIp3AEgtRQpj8vFOkIvAJcpaoBt/guoA9wNNAOuKPWjYtMEpHFIrI4Ozs7DM01ppVY8y4kHgTdhkO7Q5yy4HEEVZhyFrwy1hl47jUSNs+Dr55onvY2ULy/iEq7F0JYhSMQMoGuQe+7AFkAIpICfAj80e1OAkBVd7pdTOXAi8DQ2jauqs+paoaqZqSnW4+TMSEp/BE2uN1FHi8kHwxR8ZCzZW+dgh3wwzdwzI3w23UwYTr0Gwvz7ofMJc3X9hAlaRGBGJu2IpzCcWfqmcCNIjIdGAbkq+pOEYkB3sEZX3gzeAV3jGGniAgwBqjxDCZjTAP4KmD5a7Dqbdi6wCkbMN55FnG6jYKPEDK/dZ77j4PoOOf12Y87YfDW/8GvFkBcA+41ULATUjruV+wPKMUVPsoq/JRW+vGIEBPlIcbrQQGfP0BlQDk4JQ6vp6YOh5r3NZ5ytCHtM/WqNxBEZBowCkgTkUzgbiAaQFWfBWYBZwIbcc4suspd9SLgBKC9iFzpll3pnlE0VUTScbqblgG/DtP+GNN6rZ0J79/kdA+NuNX5Rd+h797l7XrC7g1732cuhqg46NB/b1l8Kox7Hl48Az75A5z7z9A+e+UMZxzi/z6GbsN+Lt5VWMZpj31BXkltg9XKYNnIRd75FLTrz9U33UeUt/6Oi7KiXOIAibcjhHCqNxBUdUI9yxW4oYbyV4FXa1nnpFAbaIwJUYkz+ydXfwqJNUzn0K4XbPjEGTT2eJ0jhI6DICpm33rdhkPG1bD0JTjlXkioZ66gQAA+/zugsPDpfQLh5a+3kV9aye2nH06b+Gjior2oKp6SbDrv+JjDdrxNu6L1ABTmL+S5zy7k+tMH1rurhXm7icOmvg43u1LZmEhRVuA819aN0v4Q8FdAQZbTvZS1DLpk1Fz3qCucuivfrHl5sHUfwu51kH4ErH3f2T5QUuHj1UXbOPWIDtxwYm8uG9qVC7xfcOHq6xk372SGr3uQdkmxTjfVpW+RLKVsX/AKy7fn7d32xs9g9h1QUbLPRxbn7wYgOskCIZwsEIyJFOX5zsCxN7rm5VWnnuZshp9WOlcwdzm65roHH+kcPXz3St2fqQpfPOxse/xU0AAsngzAW0syySup5NoTejmD2S+dA+9e54w1nHA7XL8Qfv0lZFwFvU/G3/5wLo+eyy1vLKO0wu/M0vrejbDoWXj1fCjdGxSlhc7EdnEWCGEVjkFlY8z/grICiK3jNMyfA2HT3gvQagsEgMGXwazbYOdy6FhLN86mubBzGZzzpHMEcthoWDIF/4jbeOHLLQzq0oaMXW/B1LudbqrznoJBlzqD3MFE8B79f/T96A7id69iwvPRXOmfwZjCncxMGc+ZP8wg69ETeTL9Hg7xbWREnjNhX7xNfR1WdoRgTKQoL6j7rKDkTuCNdY4QMr913rfpXHv9Iy9w6i91jxJUYe798PgA5zlvOyx4xJknaaA71DhsEhRns/qzKfy0J4en455CZt3mjEtc/40TMtXDoMrAiyEqjn/0XIKU7ObUnGl8Ez2cF2In8pc295BemcXDWRO5btd9dKr8gZnxY+l4SP3jDSZ0doRgTKQoK4DYOgLB43HONMrZAj+tqn38oEp8WzjiHFj5Bpz2V/j6Sfji7wTSDkO++Ad88Q8EpejEv+KvELx+H76DjyWpbW/aLH2G9+OhY+Y2OOUeOO7m2oMg+PP6nU/ftTN5p28CLK/gmEn/5L30w4DjIOt4Z4yi10jadz+Ocz02qV24WSAYEynqO0IA55TUzMVQ9KNzJlF9hlwOq2ZQ+uoE4rfN5bPoE7k282o6yx7Ge+fSW7K4eXZnymZ/8vMqE73HcV/0S5RHpSDjZ0DvU0Lfh4yrnGsplr0KR10J6YftXdZpkPMwB4wFgjGRoqwAkve/MGwf7Xo6ZwUBP6X05+bnFrIpu4hKf4BKv+IPKLp35hmEAJ950ui8bS4f+ofy0kG/5ZbhB5MYG0WMdxR7PMLvA+quGyDa6yGO3qzZnsyhp1wNab0atg9djoaD+kHuFhh1V0N/AqaJLBCMiRTlhSEcITi/oFW8jHm7mCKt5KwjOxIT5SHK4yHK63TrBHfu/DfnFg4rW8nAMQ/xRlqoF4Ld3/D2g9OtNO4/UJrrTLdhflEWCMZECC0vINcfz5I1P7Ezv5RdBeWU+/w//+WfEOulX2kc5wKr/d1ITE3htYkZ9Eyr754CR/wSzd8r+Opq84uyQDAmEgT8SEURLy3J4Yn/LgbA6xFivM5f/V6PUFLu56BAJefGQnbqkbx7w3EkxdqvALOX/WswJhKUO1cpFxHPa9cMo3eHJNISY/EETRanqpRV+Cib9R0nDrsKLAxMNfYvwphI4E5bUUgCw3q1r3HWUBEhPjYaxraM+x2YX55dmGZMJHCPEPwxyaFPIW1MNRYIxkSCqont6rowzZh6WCAYEwncIwRPfJtmbohpySwQjIkE5YUARCXYDWNM41kgGBMJyvIBiE60IwTTeBYIxkQCt8vI7g9gmsJOOzUmAvhL8/FpFMmJSc3dFNOCWSAYEwHKi/IoJZ7UxJj6KxtTC+syMiYC+EryKNQE2ibUcvtMY0IQUiCIyGQR2SUiq2pZLiLypIhsFJEVIjIkaNkVIrLBfVwRVH6UiKx013lSpL67ZxhjauMvzaeQeNom2BGCabxQjxCmAKPrWH4GcKj7mAQ8AyAi7YC7gWHAUOBuEaka9XrGrVu1Xl3bN8bUpayAQk0g1Y4QTBOEFAiq+gWQU0eV84CX1bEQSBWRjsDpwKeqmqOqucCnwGh3WYqqfqOqCrwMjGnSnhjTiklFIYUk2BGCaZJwjSF0BrYHvc90y+oqz6yhfD8iMklEFovI4uzs7DA115jI4nUDwY4QTFOEKxBq6v/XRpTvX6j6nKpmqGpGenp6E5poTOSK9hVRLAnER9uN503jhSsQMoGuQe+7AFn1lHepodwY01CBADH+YnxRSdi5GaYpwhUIM4GJ7tlGw4F8Vd0JfAycJiJt3cHk04CP3WWFIjLcPbtoIvBemNpiTOtSUYQHJRCT3NwtMS1cSBemicg0YBSQJiKZOGcORQOo6rPALOBMYCNQAlzlLssRkb8A37qbuk9Vqwanr8M5eykemO0+jDEN5U5boTb1tWmikAJBVSfUs1yBG2pZNhmYXEP5YqB/KJ9vjKmDey8EibOJ7UzT2JXKxrR07hGCN8ECwTSNBYIxLZy6RwjRFgimiSwQjGnhyopyAYhNspvjmKaxQDCmhSstdAIhLrldM7fEtHQWCMa0cOVFeQAkplggmKaxQDCmhasoycOnHtok22mnpmksEIxp4fwl+RQRT2pibHM3xbRwFgjGtHBalm9TX5uwsEAwpooqbP0K3p4Em+Y2d2tCV+7OdBpvgWCaxu6pbAzA+o/h87/DjsXO+/IiOOSk5m1TiLwVhZR4Eojy2t93pmnsX5AxmUvgtYugZDec+TD0Hwc/fAOBQHO3LCRRlYWUe5OauxkmAtgRgmndVOHTP0FiOvz6S4hNhqg4WPUW7NkA6Yc3dwsdZQXgK4ek/e8JEuMroiKqaw0rGdMwdoRgWrd1s2HbVzDqTicMALod4zz/8E3ztStYZSlMPh3+lQFZy/ZbHBcoxh9tU1+bprNAMK2X3wef3Q3te8OQK/aWtz8EEtLgh4W/TDu+fQF2b6h9+Ud3wa41EBULL5+3byiokqDFBGzqaxMG1mVkIo6qsm1PCUXlPsoq/ZT7AoiAR8R9gNcjHLxhOh13r4eLp4I36AwdEeg2/Jc5QshaBh/eCr1Pgcve2n/5mvdgyYtw7P+Do6+BKWc7oTDxPeg0CCpLiCKAxNoRgmk6CwQTcV5d9AN/endVnXVSKOKz2AfZ3W4waX3O2r9C92Ph+w+gYCekdNx/+eIXnTOSzvkneJpwoP3t887zxs9g11o46Ii9y3K3wXu/gc5HwUl/gqgYuPIDJxSmXgg3LcNXkkcU4Im3mU5N01kgmIizPaeE+CjltRPy6L7ldZJzVrLx+MfJ7TiCQADUV8aRc68kIbuIuwITeaSm+xB3G+5ubCH0G7vvMl8FzLsfirMpSRtI0YCJBALOUUe0V/B4BJ9f8QUCxEV7SYmr5fqAkhxYOQP6nuec9rrwaTj3n84yvw/evhZQGPeCEwYAbbvDuP/A5NNg8WQKO59IWyA6wWY6NU1ngWAiTurupcyP+iMdvs6B5I6Q1J4j5l7j/CI94lx4+xrI/pbP+z/AW4s7cGVmPkd2qfYX9sEDIDrBGUeoHgjfvw/F2WRqGqmf/Ikx78eSRVpQBeUoWc/F3vkc5d3AspP/yQknnLJ/Q5dNBV8ZnPA7iG8Hy16Dk++GxDT48jHYvgjOfx7a9dx3vW7DoNco+OoJSk45zAmERDtCME1ng8om4vTI+Yo08mD8a3DzKrhmjtPt8uaV8Or5zimlp9zL4LOvJT7ay9RF2/bfiDcaumTUOI5Q9NVz/BBI59nujxMbJczoPJ2/jenPX885jFcGr+O7dn/krdh7GRv7LWmeIg6bcy2LllfrwgoEnMHkbsfAwf1h+PXgL3fKdiyB+Q9A/wtgwEU17+TIO6E4m8TFTwMQb1NfmzCwQDARJ7oynyJJgj5ngTcK4lPh8nfg0FNh8zxncPa4m0iJi+bcgZ14b1kWBWWV+2+o2zHw48qf71kMoNnrSNq5kPeiTueOS0YTffpf6LTnay7JfpTLFl/I8WvvpW2bFDj3X0T/bgOeK2eSIqUkvn05KzZn7d32pjmQu8VpC0D6YXDo6c6YwtuTnCObsx6ufSe7HwM9jid1x3wAEiwQTBiEFAgiMlpE1onIRhG5s4bl3UVkjoisEJH5ItLFLT9RRJYFPcpEZIy7bIqIbAlaNii8u2Zaq5jKfEq91U7DjElwjhgmzoQz/u6cSQRcOrwbpZV+3lm6Y/8NdRsOGoDMb38u2vzRv6hQL91OupbkuGjIuBq6j4AlUyA2CSZMh0mfw5DLITaJ5O6DqRjzHH1lC9kvT+Tup17kzqensnzG38j1tGXc/Pac8cQCRj/+BXdkHQ/F2QT2bOKL/veRG0ise0dH7f2vmNSmbWN/XMb8rN4xBBHxAk8BpwKZwLciMlNV1wRVexh4WVVfEpGTgAeAy1V1HjDI3U47YCPwSdB6t6vqjPDsijGOeF8BZTWdl++Nhl4j9yka0CWVIzu3YeqibUw8pjsSPMDc5WgQD6ydCT1PoKSslPRNb/FN7HGcc+xAp47HAxe/4hxJ9Di+xjOOUgedS87uuzn5y3s4OXtvuLydfAnJSYm09XjwCOTqcL7dNZJvSrvx6Nw4PPM+5aDkuKrswhdQyt3TaCv9ARSYHt2HYZ7vSWnbvok/NWNCG1QeCmxU1c0AIjIdOA8IDoS+wC3u63nAuzVs5wJgtqqWNL65xtQvMVBIRXSHkOtfNrwbd7y1kpumLyMu2oMvoHjEOWPo8pQR9F0yhYLl77Mu6nCOppiDTrwOjycoOBLa7Rc01bU75RbodzIU7QJfKfgrOf+w0Zwfk1Ct5kyOCigjd+Qz5/td/Jhf+vMSr0eIjfISG+0h2uNBBNaW3ENi2Tf0t7ulmTAIJRA6A9uD3mcCw6rVWQ6MA54AxgLJItJeVfcE1RkPPFptvftF5M/AHOBOVS1vSOONqc4fUJIDhRTHHhbyOucM7MQrC7excPMevB7n4jVVpTKgfOy7geM8I5jgn82xvq/Jju/FEcPPaFzjOg4IqZrHIwzsmsrArqGcSno40Mj2GFNNKIFQw0naaLX3twH/EpErgS+AHYDv5w2IdASOBD4OWucu4EcgBngOuAO4b78PF5kETALo1q1bCM01rVlhWSWpUkxhXOh96gkxUXzwm+PrqDEauANytpAeFffz+IMxkSaUQeVMIHgqxS5AVnAFVc1S1fNVdTDwB7csP6jKRcA7qloZtM5OdZQDL+J0Te1HVZ9T1QxVzUhP33+mR2OC5ReXkSIlSPwBGGRt17Pmq5aNiRChBMK3wKEi0lNEYnC6fmYGVxCRNBGp2tZdwORq25gATKu2Tkf3WYAxQN1zDRgTguL8HAA8CdanbkxD1RsIquoDbsTp7lkLvKGqq0XkPhE51602ClgnIuuBDsD9VeuLSA+cI4zPq216qoisBFYCacBfm7QnxgAl+dkARCdZIBjTUCFNXaGqs4BZ1cr+HPR6BlDj6aOquhVnYLp6ecu4P6FpUcoLnfMYYpLtNExjGsquVDYRpaLICYT4Nmn11DTGVGeBYCKKv9gZQ0i0QDCmwSwQTETRklwA4qzLyJgGs0AwkaUsD+DAnHZqTISzQDARxVueRxEJziynxpgGsUAwESWmIp9ij91f2JjGsEAwESW2Mp/SqBpmOjXG1MsCwUSUeH8BZRYIxjSKBYKJKIkqROfPAAAXBUlEQVSBQipj7P7CxjSGBYKJGIGAkqxF+GMtEIxpDAsEEzGKyitpQzHagKmvjTF7WSCYiFGQn0e0+PHYNQjGNIoFgokYVTOdehJtplNjGsMCwUSM0oLdAEQn2bQVxjSGBYKJGOUFzkyncSkWCMY0hgWCiRiVxTb1tTFNYYFgIkbApr42pkksEEzECJQ6M51aIBjTOBYIJmJ4yvIoIxqJSWjuphjTIlkgmIjhLc+jUGymU2MaK6RAEJHRIrJORDaKyJ01LO8uInNEZIWIzBeRLkHL/CKyzH3MDCrvKSKLRGSDiLwuIjHh2SXTWtnU18Y0Tb2BICJe4CngDKAvMEFE+lar9jDwsqoOAO4DHghaVqqqg9zHuUHlDwGPqeqhQC5wdRP2wxjifDbTqTFNEcoRwlBgo6puVtUKYDpwXrU6fYE57ut5NSzfh4gIcBIwwy16CRgTaqONqUm8v4DyKJvYzpjGCiUQOgPbg95numXBlgPj3NdjgWQRqbo6KE5EFovIQhGp+qXfHshTVV8d2zSmQZIChVTaTKfGNFoogSA1lGm197cBI0XkO2AksAOo+mXfTVUzgEuAx0XkkBC36Xy4yCQ3UBZnZ2eH0FxTr/JCWP0uaI0/8hZJVUnRIvyxqc3dFGNarFACIRPoGvS+C5AVXEFVs1T1fFUdDPzBLcuvWuY+bwbmA4OB3UCqiETVts2gbT+nqhmqmpGenh7qfpm6zH8Q3rwCfvimuVsSNiUlxcRLBcRZIBjTWKEEwrfAoe5ZQTHAeGBmcAURSRORqm3dBUx2y9uKSGxVHeA4YI2qKs5YwwXuOlcA7zV1Z0wISvNgyRTn9fLpzdqUcCrMcya28yTYTKfGNFa9geD2898IfAysBd5Q1dUicp+IVJ01NApYJyLrgQ7A/W75EcBiEVmOEwAPquoad9kdwK0ishFnTOGFMO2TqcviyVBRBJ2GON1GlWXN3aKwqJr62ptkgWBMY0XVXwVUdRYwq1rZn4Nez2DvGUPBdb4Gjqxlm5txzmAyv5TKMlj0LBxyEhz7G3hlLKz/CPqF6QSvyjIozYXkg0FqGiZqpKqxjjq2WZbvHCHE2NTXxjRaSIFgIsSK16HoJxj7b+h5AiQd7JSFKxBm3ggr34SENOg0GPqfD4Muado2/ZXw7AjnechEGHQpJO0/llReaFNfG9NUNnVFaxEIwNf/hIMHQK9R4PHCkRfAhk/AnTaa/B3wwS2Qu63h2y/Kdrqgep8Ch42GPRvh3esgb3vt66jCjiVQWVp7nZVvQvb3EBULn90Njx4Bc+7br5rPnek0oY2deGBMY1kgtBar34Y9G+C4m/Z2vQwcDwGfsyx7HbxwmjPG8NF+s5PUb/lrEKiE0/8GY56Cy992P/edmusHAjD7d/D8SfDwYTDzN7Dt631PhQ34YcGj0OFIuO5ruH6RczSz4BFY9O99N1c19XWqBYIxjWWBEMHKKv0s2ZbL2q9m4n/3egrb9uPLmBF8vXE3X2/azTfFnShOPZzyL59CJ58O/goYfBmsmwVbFuzdUGUpvPNr+O7Vmj9IFZa+DN2OgfTDnbJ2vZyB61Vv7V8/4IcPboL/PgdHXQl9zoaVb8GLZ8Bn9+ytt/Z9J8SOv9UJsYP6ON1dfc52Qmv9x6gq/oCipbn41ENysp12akxj2RhCBHvkk3Ws+HIWU2IeYr124JKdvyH3xSX71JnkHcLvo6eRHd2JlGs/ILZtJ9j8OXz8e5j0uVPp3eudo4jl05xwGHrtvh+07Suni+j43+5b3n8cfPIH2LMJ2h/ilPl98N71ztjFCb+DE3/v/LI/62H46C746nFI7QYZ/wcLHqG8TS8unNuO9a/Pxh9QfAElTs/njZhV9Jw6kcd8F3CCZwXHeVaxW9pysNf+xjGmsSwQIljUT8t4MfYfaJtulJ4+jecT0lAgEFACbs+Mt6IfX32Tws0bBtHh9Sz+fXknOp/8Z3j7WlgxHXK2OGFw4h8haynMus05Ihg2ae8HLXkJYttA32qD0/3GOoGw6m0YebtTtuARJwxO+iOccPveujGJcNajUPgjzLoN3b0R+XEFd/t+xU8JPiYe04Moj+D1CCLC1+VP02PFlfxJXiU/tjPL0ifiGzCegw/oT9SYyCbagqYvyMjI0MWLFzd3M1qM+f+4mKNLFpB461LnVNA6zFn7EzdPX4bXKxyensj9e26ik38HCVrCZ3Gn80zKTXi1kt/mP8CwioWs6HY5Ay76M3ii4JE+MORyOOuR/Tc8+QznVNQbFsKuteizx7Mk8XieTfs9AYWAKqrOvCWqSmyglD/s+i09KzeyQ9tz/yFTuX/cUbRNrGF29PwdULwLOg4K72muxkQYEVniTiFUJzu+jmCxlfnkRB1UbxgAnHxEB9678TiG9miHx+vl1Ta/IkFLWB0zkJfa/Ya4GC+xcfE8c9Cf+Cz2FPpvexXfI/1g6oXgL4chV9S84f7nQ/Za+HElJTOuIy8Qz22Fl7Azv4zswnJyiivIK6kgv7SSwjIfOZXR/C31XtZF9+WHIXfy1OXDaw4DgDadndNbLQyMCQvrMopgcb4CymNDvz9Ar/QknptY9UfEcNhxFP3SD+eVmMR96vkDx/HA1A/pvm4y43d+SVTXYdBxQM0b7TsGZv+O8tcuI6FgKw9F3cKUX59Jj7TEmuv/7OyQ222MCQ8LhAiWGCikMqZ74zfQeUiNxV6PcOelZ3HL6535+/INjPR2wDP9u6AuICUQAHUnsL0pbjB9C5bwpedorrnudrq2ry8MjDHNwQIhQgUCSpIWkXOApoP2eoRHLxrIn+OiWLAhG6/kISII4PEIXhFEnPHnN+U0fu3NoveV/+ZgCwNj/mdZIESownIfbShmT9yBu2FMlNfD38bWOFVVNScAjbjYzRjzi7JB5QhVUFRMopRDfNvmbooxpoWwQIhQRe79AbwJFgjGmNBYIESo0gInEKLt/gDGmBBZIESoMnc66Nhkmw7aGBMaC4QIVVmUC0BCGwsEY0xoLBAilM+9x0Gi3R/AGBMiC4QIpSV5AMRZl5ExJkQWCBFKypwuI4m3+wMYY0ITUiCIyGgRWSciG0VkvyuMRKS7iMwRkRUiMl9Eurjlg0TkGxFZ7S67OGidKSKyRUSWuY9B4dst4ynPp4hE51aZxhgTgnoDQUS8wFPAGUBfYIKI9K1W7WHgZVUdANwHPOCWlwATVbUfMBp4XESC/2S9XVUHuY9lTdwXEyS6ooBiT1JzN8MY04KEcoQwFNioqptVtQKYDpxXrU5fYI77el7VclVdr6ob3NdZwC7ARjl/AbGV+ZRGhT7TqTHGhBIInYHtQe8z3bJgy4Fx7uuxQLKI7DOaKSJDgRhgU1Dx/W5X0mMiEtuglps6xfkLKY9Kbu5mGGNakFACoaa7j1S/zdptwEgR+Q4YCewAfD9vQKQj8ApwlaoG3OK7gD7A0UA74I4aP1xkkogsFpHF2dnZITTXQNXU1wduYjtjTOQJJRAyga5B77sAWcEVVDVLVc9X1cHAH9yyfAARSQE+BP6oqguD1tmpjnLgRZyuqf2o6nOqmqGqGenp1tsUikBASdYi/Ado6mtjTGQKJRC+BQ4VkZ4iEgOMB2YGVxCRNBGp2tZdwGS3PAZ4B2fA+c1q63R0nwUYA6xqyo6YvYrKK0mhGA7g1NfGmMhTbyCoqg+4EfgYWAu8oaqrReQ+ETnXrTYKWCci64EOwP1u+UU4k+FfWcPppVNFZCWwEkgD/hqunWrtCgoKiBUfxNvEdsaY0IV0gxxVnQXMqlb256DXM4AZNaz3KvBqLds8qUEtNSGrmvo6KtGmvjbGhM6uVI5Ae6e+tkAwxoTOAiEClf889XVaM7fEGNOSWCBEoIqiHADiU2xiO2NM6CwQIpC/xAmEpFQ7TdcYEzoLhAhUNfV1fIqdZWSMCZ0FQgSSslx8eJBYm8vIGBM6C4QI5C3Pp0iSQGqadcQYY2pmgRCBoisLKLGpr40xDWSBEIFiKwso9Vp3kTGmYSwQIlC8v5DyaAsEY0zDtL5AWP0ufHZPc7figEoMFOCzqa+NMQ3UugKhsgxm3wFfPgZ52+uvX10gAF88DLlb6673+uXwaD8neLLXN6aljeZMfV1sU18bYxqsdQXC8teg6Efn9Zr3Gr7+pjkw9y9OKNTmpzWwdiZEx8NXT8JTR8ObV4FWv6fQgVFUXmFTXxtjGqX1BILfB18+Dp0z4OABsPqdmuupws4VsPRl8Ffuu+zbF5zn1e9CRXHN6y96BqLi4epP4Na1MOw6WP02bPg0fPtSh4K8HLyiSIJNbGeMaZiQpr9u6V5duI24tTO4IG8bU9teR3rZVk7b8SyPvPkZ+TEH4xEhxl/M6Pw3GFwwF8lxb/tcmgvH3eS8ztsOGz6GHsfD1gWw9gMYePG+H1S8G5a/DoMugQT3KuHT/gLrP3K6j3qfDB7vAd3XYnfqa2+iXaVsjGmYVnGEsHBTNoO2vcgGuvLI1p7866f+AMia95i5PIt3vtvBkcvvY9CW//AjaXD243DIyfD5P6Bol7ORJVOco4fznoLU7k73U3VLXgR/OQz79d4ybzSc/CfYtRpWvrn/Oo2hCgsehc/uhfWfQGnez4vK3KmvYywQjDEN1CqOEP511E+wYTuc/zxLB4x2Cv/9PLd6VnPrtf+ETXPhlQW8nXIJ9+SMYV6fUbTvMQKeHg5z/wpnPgxLX4LDRkPb7s4RwPwHnaOGVPd2074K+O9/nCA5qM++Deg7Fjo+AXPvh35jISqW4nIfa3YW4PMrqds+ovOa/1CcPoCC7qdR1nEYAVU8xbuI9RdzeP+jkOAji5UzYM69gACPOs/H3QSn3kt5oTOxXazNdGqMaaBWEQh8/U/nr/p+5+8t6zfWPQtoHXxwK7TvzcBx91Hyr2956KPv+fsFA2HoJFj4DCS0h+JsOPpqZ92B42H+A7BiOpxwOwAly2eQUPQjWaP+QdFPhfuNISccdSddP5jA2g8e56mSU5mzdhellT6u9s7mD1FT2aFpHJS9ko5rp1CqMcRSiUecjaz5/DT6Xj8NvFFQkAWzfgtdhsJlb8HOZbDo3/D1kzBkIpXFzr0QEiwQjDEN1DoCYdwLkL/d+YVape8YJxCmXgh52+CK9zmkUzpXj+jJv7/YzPih3Rgy8newfDp8+agTKIec7Kzbtgd0HwHLplE2/BbmvPcSg1Y9QJZ24tQZgvJFjc14Jbo/w797iIkykzO6nsTAxD102TCVnG6j+fH4x9jh95G0YwEpPy7CH5uML6EDWzeu4dQ908ibehWpl06G9250BrvHPgtxKdDzBEjv4xzlzH8QX3lvAJJS7eY4xpiGEf2FTocMh4yMDF28eHH4Nvjvkc5f2AMvgbHPAFBU7uPkR+bTPjGWa47vSc8t0xm88i+sOuIW1h96zc+rdvvhHTKW/ZHN0pVeup2fojuzfviD5KVlIAKeahPLqUJsWTZ9tr1K512fI9nfOwuOuRFO/Qt4ah7OyS+t5JWHb+ZG/6sE0o/Ak73W6cIaeu2+FT/9M3z1JKvSRtN/92z09zuRmITw/ayMMS2WiCxR1Yx667XqQFgyxblI7Zq5kLi3i2XWyp3c+NpSAgoeApztWcjHgQzKifm5TgJlfB37Gyo9ceQNvZVDT/uVM4AcqpwtUJoDnY+qt+qctT+x6NW7+X30NOh1Ilz29v4BUrwHnhgAFUWUE03sPbtDb4sxJqKFNRBEZDTwBOAF/qOqD1Zb3h2YDKQDOcBlqprpLrsC+KNb9a+q+pJbfhQwBYgHZgE3aT2NCXsg1GFXYRmlFf4663hL99DxoHS8MfEHvD03T/+OnSvncdTRI6iISsIf9KMShIAqIzOf5cRdL7Nb2pJ299YD3iZjTMsQaiDUO4YgIl7gKeBUIBP4VkRmquqaoGoPAy+r6ksichLwAHC5iLQD7gYyAAWWuOvmAs8Ak4CFOIEwGpjdkJ08kA5KjguhVuIBb0eVu8/px4QfC5m8ZA9eyXG6pARQ5wfrEfjccyJHMwO1aSuMMY0QyqDyUGCjqm4GEJHpwHlAcCD0BW5xX88D3nVfnw58qqo57rqfAqNFZD6QoqrfuOUvA2P4HwqE/zVtE2P46OYT6q+4JoqkytID3yBjTMQJ5cK0zkDwTHCZblmw5cA49/VYIFlE2texbmf3dV3bBEBEJonIYhFZnJ2dHUJzW7m+5+5/BbUxxoQglECo6T6M1fv6bwNGish3wEhgB+CrY91QtukUqj6nqhmqmpGenh5Cc40xxjRGKF1GmUDXoPddgKzgCqqaBZwPICJJwDhVzReRTGBUtXXnu9vsUtc2jTHG/LJCOUL4FjhURHqKSAwwHpgZXEFE0kSkalt34ZxxBPAxcJqItBWRtsBpwMequhMoFJHhIiLARKAR81EbY4wJl3oDQVV9wI04v9zXAm+o6moRuU9EznWrjQLWich6oANwv7tuDvAXnFD5FrivaoAZuA74D7AR2IQNKBtjTLNq3RemGWNMKxDqdQitYvprY4wx9bNAMMYYA1ggGGOMcbWoMQQRyQa2NXL1NKA1zvhm+926tNb9hta776Hsd3dVrfdCrhYVCE0hIotDGVSJNLbfrUtr3W9ovfsezv22LiNjjDGABYIxxhhXawqE55q7Ac3E9rt1aa37Da1338O2361mDMEYY0zdWtMRgjHGmDq0ikAQkdEisk5ENorInc3dngNFRLqKyDwRWSsiq0XkJre8nYh8KiIb3Oe2zd3WcBMRr4h8JyIfuO97isgid59fdydmjDgikioiM0Tke/d7P6aVfN+3uP/GV4nINBGJi8TvXEQmi8guEVkVVFbj9yuOJ93fcytEZEhDPy/iAyHoFqBn4NzZbYKI9G3eVh0wPuC3qnoEMBy4wd3XO4E5qnooMMd9H2luwpl8scpDwGPuPucCVzdLqw68J4CPVLUPMBDnZxDR37eIdAb+H5Chqv1x7vU+nsj8zqfg3F44WG3f7xnAoe5jEs5tihsk4gOBoFuAqmoFUHUL0IijqjtVdan7uhDnl0NnnP19ya32Es7tSiOGiHQBzsKZPRd3SvWTgBlulYjbZwARSQFOAF4AUNUKVc0jwr9vVxQQLyJRQAKwkwj8zlX1CyCnWnFt3+95OPe2V1VdCKSKSMeGfF5rCIRQbgEacUSkBzAYWAR0cO9Bgft8UPO17IB4HPgdEHDftwfy3KnbIXK/815ANvCi2132HxFJJMK/b1XdATwM/IATBPnAElrHdw61f79N/l3XGgIh5Nt1Rgr3rnVvATerakFzt+dAEpGzgV2quiS4uIaqkfidRwFDgGdUdTBQTIR1D9XE7TM/D+gJdAIScbpLqovE77wuTf533xoCod5bgEYSEYnGCYOpqvq2W/xT1aGj+7yrudp3ABwHnCsiW3G6A0/COWJIdbsTIHK/80wgU1UXue9n4AREJH/fAKcAW1Q1W1UrgbeBY2kd3znU/v02+XddawiEem8BGincvvMXgLWq+mjQopnAFe7rK4ig25Wq6l2q2kVVe+B8t3NV9VJgHnCBWy2i9rmKqv4IbBeRw92ik4E1RPD37foBGC4iCe6/+ar9jvjv3FXb9zsTmOiebTQcyK/qWgpVq7gwTUTOxPmr0QtMVtX7m7lJB4SIjAAWACvZ25/+e5xxhDeAbjj/mS4MupVpxBCRUcBtqnq2iPTCOWJoB3wHXKaq5c3ZvgNBRAbhDKbHAJuBq3D+0Ivo71tE7gUuxjmz7jvgGpz+8oj6zkVkGs4titOAn4C7gXep4ft1w/FfOGcllQBXqWqDbjHZKgLBGGNM/VpDl5ExxpgQWCAYY4wBLBCMMca4LBCMMcYAFgjGGGNcFgjGGGMACwRjjDEuCwRjjDEA/H98tJQSaH/0eAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean)\n",
    "plt.plot(true_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set Performance Metrics\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'measures_locations_test_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-8f490e15968d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Populate Error Distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasures_locations_test_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Get Laws\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'measures_locations_test_list' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Building Test Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors_test = np.array([])\n",
    "Mean_errors_test = np.array([])\n",
    "Var_errors_test = np.array([])\n",
    "Skewness_errors_test = np.array([])\n",
    "Kurtosis_errors_test = np.array([])\n",
    "# Initialize Prediction Metrics\n",
    "predictions_mean_test = np.array([])\n",
    "true_mean_test = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_test_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_test_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights_test[x_i,].reshape(-1,),\n",
    "                         measure_weights_test.reshape(-1,))\n",
    "    W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "    # Get Means\n",
    "    Mu_hat_test = np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array))\n",
    "    Mu_test = np.mean(np.array(measures_locations_test_list[x_i]))\n",
    "    Mean_errors_test = np.append(Mean_errors_test,(Mu_hat_test-Mu_test))\n",
    "    ## Update Predictions\n",
    "    predictions_mean_test = np.append(predictions_mean_test,Mu_hat_test)\n",
    "    true_mean_test = np.append(true_mean_test,Mu_test)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat_test = np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))\n",
    "    Var_test = np.mean(np.array(measures_locations_test_list[x_i])**2)\n",
    "    Var_errors_test = np.append(Var_errors_test,(Var_hat_test-Var_test)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat_test = np.sum((Barycenters_Array**3)*(Predicted_Weights_test[x_i]))\n",
    "    Skewness_test = np.mean(np.array(measures_locations_test_list[x_i])**3)\n",
    "    Skewness_errors_test = np.append(Skewness_errors_test,(abs(Skewness_hat_test-Skewness_test))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat_test = np.sum((Barycenters_Array**4)*(Predicted_Weights_test[x_i]))\n",
    "    Kurtosis_test = np.mean(np.array(measures_locations_test_list[x_i])**4)\n",
    "    Kurtosis_errors_test = np.append(Kurtosis_errors_test,(abs(Kurtosis_hat_test-Kurtosis_test))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance_test = np.array([np.min(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test))])\n",
    "Mean_prediction_Performance_test = np.array([np.min(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test))])\n",
    "Var_prediction_Performance_test = np.array([np.min(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test))])\n",
    "Skewness_prediction_Performance_test = np.array([np.min(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test))])\n",
    "Kurtosis_prediction_Performance_test = np.array([np.min(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test))])\n",
    "\n",
    "Type_A_Prediction_test = pd.DataFrame({\"W1\":W1_Performance_test,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance_test,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance_test,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance_test,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance_test},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction_test.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Test.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f624c608710>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean_test)\n",
    "plt.plot(true_mean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print for Terminal Legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  0.056513    0.070872             0.003580                0.364390   \n",
      "MAE  0.729807    0.690816             0.191332                0.770925   \n",
      "Max  2.589013    1.592739             0.426912                1.035913   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.444625  \n",
      "MAE              0.745037  \n",
      "Max              1.016187  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  0.421870    0.522966             0.177975                0.698171   \n",
      "MAE  0.603158    0.707736             0.279910                0.755721   \n",
      "Max  0.876459    0.885260             0.343648                0.778926   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.723850  \n",
      "MAE              0.766805  \n",
      "Max              0.785711  \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------------#\")\n",
    "print(\"Training-Set Performance\")\n",
    "print(\"#----------------------#\")\n",
    "print(Type_A_Prediction)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"#------------------#\")\n",
    "print(\"Test-Set Performance\")\n",
    "print(\"#------------------#\")\n",
    "print(Type_A_Prediction_test)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facts of Simulation Experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      " Experiment's Facts \n",
      "====================\n",
      "------------------------------------------------------\n",
      "=====\n",
      "Model\n",
      "=====\n",
      "• N Centers: 82\n",
      "• Each Wasserstein-1 Ball should contain:  1 elements from the training set.\n",
      "------------------------------------------------------\n",
      "========\n",
      "Training\n",
      "========\n",
      "• Data-size: 110\n",
      "• N Points per training datum: 10\n",
      "------------------------------------------------------\n",
      "=======\n",
      "Testing\n",
      "=======\n",
      "• Data-size Test: 6\n",
      "• N Points per testing datum: 10\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"====================\")\n",
    "print(\" Experiment's Facts \")\n",
    "print(\"====================\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"=====\")\n",
    "print(\"Model\")\n",
    "print(\"=====\")\n",
    "print(\"\\u2022 N Centers:\",N_Quantizers_to_parameterize)\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"========\")\n",
    "print(\"Training\")\n",
    "print(\"========\")\n",
    "print(\"\\u2022 Data-size:\",(len(x_Grid)*len(t_Grid)))\n",
    "print(\"\\u2022 N Points per training datum:\",N_Monte_Carlo_Samples)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"=======\")\n",
    "print(\"Testing\")\n",
    "print(\"=======\")\n",
    "print(\"\\u2022 Data-size Test:\",(len(x_Grid_test)*len(t_Grid_test)))\n",
    "print(\"\\u2022 N Points per testing datum:\",N_Monte_Carlo_Samples_Test)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.056513</td>\n",
       "      <td>0.070872</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.364390</td>\n",
       "      <td>0.444625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.729807</td>\n",
       "      <td>0.690816</td>\n",
       "      <td>0.191332</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>0.745037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>2.589013</td>\n",
       "      <td>1.592739</td>\n",
       "      <td>0.426912</td>\n",
       "      <td>1.035913</td>\n",
       "      <td>1.016187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.056513    0.070872             0.003580                0.364390   \n",
       "MAE  0.729807    0.690816             0.191332                0.770925   \n",
       "Max  2.589013    1.592739             0.426912                1.035913   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.444625  \n",
       "MAE              0.745037  \n",
       "Max              1.016187  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.421870</td>\n",
       "      <td>0.522966</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.698171</td>\n",
       "      <td>0.723850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.603158</td>\n",
       "      <td>0.707736</td>\n",
       "      <td>0.279910</td>\n",
       "      <td>0.755721</td>\n",
       "      <td>0.766805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.876459</td>\n",
       "      <td>0.885260</td>\n",
       "      <td>0.343648</td>\n",
       "      <td>0.778926</td>\n",
       "      <td>0.785711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.421870    0.522966             0.177975                0.698171   \n",
       "MAE  0.603158    0.707736             0.279910                0.755721   \n",
       "Max  0.876459    0.885260             0.343648                0.778926   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.723850  \n",
       "MAE              0.766805  \n",
       "Max              0.785711  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
