{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "# N_Euler_Maruyama_Steps = 2\n",
    "N_Monte_Carlo_Samples = 1\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 20\n",
    "Max_Grid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "*This hyperparameter describes the proportion of the data used as sample-barycenters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantization_Proportion = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Algorithm\n",
    "---\n",
    "Given a set of training inputs $\\mathbb{X}$ and a stochastic process $(X_t)_{t\\geq 0}$ which we can sample from:\n",
    "1. **For:** x in $\\mathbb{X}$:\n",
    "    - *Simulate:* $\\{x\\mapsto X_T(\\omega_n)\\}_{n=1}^N$\n",
    "    - *Set*: $\\hat{\\nu}_{x,T}\\triangleq \\frac1{N}\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$\n",
    "2. **Learn:** Wasserstein Barycenters $\\hat{\\mu}_1,\\dots,\\hat{\\mu}_N\n",
    "    \\in \\underset{{\\hat{\\mu}_n\\in\\mathscr{P}_{N}(\\mathbb{R}^d)}}{\\operatorname{argmin}}\n",
    "    \\, \\sum_{n=1}^N W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$\n",
    "3. **Train Classifier:** $\\hat{f}:x\\mapsto \\operatorname{n\\leq N}\\, W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Grid\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Grid Instances:  20\n"
     ]
    }
   ],
   "source": [
    "# Get Input Data\n",
    "x_Grid = np.arange(start=-Max_Grid,\n",
    "                   stop=Max_Grid,\n",
    "                   step=(2*Max_Grid/N_Grid_Finess))\n",
    "\n",
    "# Get Number of Instances in Grid\n",
    "N_Grid_Instances = len(x_Grid)\n",
    "\n",
    "# Updater User\n",
    "print(\"\\u2022 Grid Instances: \", N_Grid_Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Counting Parameters\n",
    "Initialize the \"conting\" type parameters which will help us to determine the length of loops and to intialize object's size later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ 20  Centers will be produced; from a total datasize of:  20 !  (That's  1  percent).\n",
      "â€¢ Each Wasserstein-1 Ball should contain:  1 elements from the training set.\n"
     ]
    }
   ],
   "source": [
    "# Get Internal (Counting) Parameters\n",
    "N_Quantizers_to_parameterize = round(Quantization_Proportion*N_Grid_Finess)\n",
    "N_Elements_Per_Cluster = int(round(N_Grid_Instances/N_Quantizers_to_parameterize))\n",
    "\n",
    "# Update User\n",
    "print(\"\\u2022\",N_Quantizers_to_parameterize,\" Centers will be produced; from a total datasize of: \",N_Grid_Finess,\n",
    "      \"!  (That's \",Quantization_Proportion,\n",
    "      \" percent).\")\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Path\n",
    "$d X_t = \\alpha(t,x)dt + \\beta(t,x)dW_t ;\\qquad X_0 =x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return 0#np.sin(math.pi*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 1#(t+1)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List of Barycenters\n",
    "Wasserstein_Barycenters = []\n",
    "# Initialize Terminal-Time Empirical Measures\n",
    "measures_locations_list = []\n",
    "measures_weights_list = []\n",
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "# Initialize Quantizer\n",
    "Init_Quantizer_generic = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $\\{\\hat{\\nu}^{N}_{T,x}\\}_{x \\in \\mathbb{X}}$ Build Wasserstein Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 35187.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step:\n",
      "Done Simulation Step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"Current Monte-Carlo Step:\")\n",
    "\n",
    "# Perform Monte-Carlo Data Generation\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    # Get Terminal Distribution Shape\n",
    "    ###\n",
    "    # DIRECT SAMPLING\n",
    "    measures_locations_loop = (np.random.normal(x_Grid[i],np.abs(x_Grid[i]), N_Monte_Carlo_Samples).reshape(-1,))/N_Monte_Carlo_Samples\n",
    "    \n",
    "    # Append to List\n",
    "    measures_locations_list.append(measures_locations_loop.reshape(-1,1))\n",
    "    measures_weights_list.append(measure_weights)\n",
    "    \n",
    "# Update User\n",
    "print(\"Done Simulation Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dissimilarity (Distance) Matrix\n",
    "*In this step we build a dissimularity matrix of the dataset on the Wasserstein-1 space.  Namely:*\n",
    "$$\n",
    "\\operatorname{Mat}_{\\# \\mathbb{X},\\# \\mathbb{X}}\\left(\\mathbb{R}\\right)\\ni D; \\text{ where}\\qquad \\, D_{i,j}\\triangleq \\mathcal{W}_1\\left(f(x_i),f(x_j)\\right)\n",
    ";\n",
    "$$\n",
    "*where $f\\in C\\left((\\mathcal{X},\\mathcal{P}_1(\\mathcal{Y})\\right)$ is the \"target\" function we are learning.*\n",
    "\n",
    "**Note**: *Computing the dissimularity matrix is the most costly part of the entire algorithm with a complexity of at-most $\\mathcal{O}\\left(E_{W} \\# \\mathbb{X})^2\\right)$ where $E_W$ denotes the complexity of a single Wasserstein-1 evaluation between two elements of the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜š  Begin Building Distance Matrix  ðŸ˜š\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 371.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜€  Done Building Distance Matrix ðŸ˜€ !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Disimilarity Matrix\n",
    "Dissimilarity_matrix_ot = np.zeros([N_Grid_Instances,N_Grid_Instances])\n",
    "\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Building Distance Matrix\",\" \\U0001F61A\")\n",
    "# Build Disimilarity Matrix\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    for j in range(N_Grid_Instances):\n",
    "        Dissimilarity_matrix_ot[i,j] = ot.emd2_1d(measures_locations_list[j],\n",
    "                                                  measures_locations_list[i])\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Building Distance Matrix\",\"\\U0001F600\",\"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Quantities to Loop Over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\" and Generate Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Locations Matrix (Internal to Loop)\n",
    "measures_locations_list_current = copy.copy(measures_locations_list)\n",
    "Dissimilarity_matrix_ot_current = copy.copy(Dissimilarity_matrix_ot)\n",
    "\n",
    "# Initialize masker vector\n",
    "masker = np.ones(N_Grid_Instances)\n",
    "\n",
    "# Initialize Sorting Reference Vector (This helps us efficiently scroll through the disimularity matrix to identify the barycenter without having to re-compute the dissimultarity matrix of a sub-saple at every iteration (which is the most costly part of the algorithm!))\n",
    "Distances_Loop = Dissimilarity_matrix_ot_current.sum(axis=1)\n",
    "\n",
    "# Initialize Classes (In-Sample)\n",
    "Classifer_Wasserstein_Centers = np.zeros([N_Quantizers_to_parameterize,N_Grid_Instances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/usr/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 10826.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜š  Begin Identifying Sample Barycenters  ðŸ˜š\n",
      "ðŸ˜€  Done Identifying Sample Barycenters ðŸ˜€ !\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Identifying Sample Barycenters\",\" \\U0001F61A\")\n",
    "\n",
    "# Identify Sample Barycenters\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    # GET BARYCENTER #\n",
    "    #----------------#\n",
    "    ## Identify row with minimum total distance\n",
    "    Barycenter_index = int(Distances_Loop.argsort()[:1][0])\n",
    "    ## Get Barycenter\n",
    "    ## Update Barycenters Array ##\n",
    "    #----------------------------#\n",
    "    ### Get next Barycenter\n",
    "    new_barycenter_loop = measures_locations_list_current[Barycenter_index].reshape(-1,1)\n",
    "    ### Update Array of Barycenters\n",
    "    if i == 0:\n",
    "        # Initialize Barycenters Array\n",
    "        Barycenters_Array = new_barycenter_loop\n",
    "    else:\n",
    "        # Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,new_barycenter_loop,axis=-1)\n",
    "\n",
    "    # GET CLUSTER #\n",
    "    #-------------#\n",
    "    # Identify Cluster for this barycenter (which elements are closest to it)\n",
    "    Cluster_indices = (masker*Dissimilarity_matrix_ot_current[:,Barycenter_index]).argsort()[:N_Elements_Per_Cluster]\n",
    "    ## UPDATES Set  M^{(n)}  ##\n",
    "    #-------------------------#\n",
    "    Dissimilarity_matrix_ot_current[Cluster_indices,:] = 0\n",
    "    # Distance-Based Sorting\n",
    "    Distances_Loop[Cluster_indices] = math.inf\n",
    "\n",
    "    # Update Cluster\n",
    "    masker[Cluster_indices] = math.inf\n",
    "    \n",
    "    # Update Classes\n",
    "    Classifer_Wasserstein_Centers[i,Cluster_indices] = 1\n",
    "#     print(Cluster_indices)\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Identifying Sample Barycenters\",\"\\U0001F600\",\"!\")\n",
    "print(Classifer_Wasserstein_Centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# %run ParaGAN_Backend.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9755 - accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 984us/step - loss: 2.9668 - accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9583 - accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 907us/step - loss: 2.9498 - accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9415 - accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9332 - accuracy: 0.1500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9249 - accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9165 - accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9078 - accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8990 - accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8899 - accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8805 - accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8709 - accuracy: 0.1000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8610 - accuracy: 0.1000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8508 - accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8403 - accuracy: 0.1000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8295 - accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8182 - accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8065 - accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7945 - accuracy: 0.1000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7823 - accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.7695 - accuracy: 0.1000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7565 - accuracy: 0.1000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7432 - accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7296 - accuracy: 0.1000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7157 - accuracy: 0.1000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7015 - accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6871 - accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6726 - accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6578 - accuracy: 0.1000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6430 - accuracy: 0.1000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6280 - accuracy: 0.1000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6130 - accuracy: 0.1000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5979 - accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5829 - accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5679 - accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5530 - accuracy: 0.1000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5383 - accuracy: 0.1000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5238 - accuracy: 0.1000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5094 - accuracy: 0.1000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4954 - accuracy: 0.1000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4816 - accuracy: 0.1000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4680 - accuracy: 0.1000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4548 - accuracy: 0.1000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4419 - accuracy: 0.1000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4292 - accuracy: 0.1000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4168 - accuracy: 0.1000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4047 - accuracy: 0.1000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3928 - accuracy: 0.1000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3813 - accuracy: 0.1000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3700 - accuracy: 0.1000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3590 - accuracy: 0.1000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3485 - accuracy: 0.1500\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3382 - accuracy: 0.1000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3282 - accuracy: 0.1000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3184 - accuracy: 0.1000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3087 - accuracy: 0.1000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2993 - accuracy: 0.1000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2901 - accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2811 - accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2722 - accuracy: 0.1500\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2636 - accuracy: 0.1500\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2550 - accuracy: 0.1500\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2466 - accuracy: 0.1500\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2382 - accuracy: 0.1500\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2300 - accuracy: 0.1500\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2218 - accuracy: 0.1500\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2136 - accuracy: 0.2000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2054 - accuracy: 0.2000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1973 - accuracy: 0.2000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1891 - accuracy: 0.2000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1808 - accuracy: 0.2000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1725 - accuracy: 0.2000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1643 - accuracy: 0.2000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1561 - accuracy: 0.2000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1478 - accuracy: 0.2000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1396 - accuracy: 0.3000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1313 - accuracy: 0.3000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1228 - accuracy: 0.3000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1143 - accuracy: 0.3000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1057 - accuracy: 0.3000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0968 - accuracy: 0.3000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0878 - accuracy: 0.3000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0787 - accuracy: 0.3000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0695 - accuracy: 0.3000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0602 - accuracy: 0.3000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0509 - accuracy: 0.3000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0415 - accuracy: 0.3000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0321 - accuracy: 0.3000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0225 - accuracy: 0.3000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0128 - accuracy: 0.3000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0030 - accuracy: 0.3000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9930 - accuracy: 0.3000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9830 - accuracy: 0.3500\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9731 - accuracy: 0.3500\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9632 - accuracy: 0.3500\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9531 - accuracy: 0.3500\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9429 - accuracy: 0.3500\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9327 - accuracy: 0.3500\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9223 - accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "# param_grid_Deep_Classifier['input_dim'] = [1]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = x_Grid, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers.T,\n",
    "                                                                                                        X_test = x_Grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Weights\n",
    "Predicted_Weights = np.array([])\n",
    "for i in range(N_Quantizers_to_parameterize):\n",
    "    b = np.repeat(np.array(Classifer_Wasserstein_Centers.T[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "        \n",
    "# Format Points of Mass\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0578 -0.1065 -0.      0.0162  0.0523 -0.1787 -0.2414 -0.2665 -0.269\n",
      " -0.2916 -0.3631  0.2818  0.3308  0.4886  0.5424 -0.8528 -1.1348  1.0501\n",
      " -1.2646  1.1733]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[-0.85275214]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "hello=5\n",
    "print(np.round(Barycenters_Array,4))\n",
    "print(Predicted_Weights[hello,].reshape(-1,))\n",
    "print(measures_locations_list[hello].reshape(-1,))\n",
    "print(measures_weights_list[hello].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      W1  E[X']-E[X]  E[X'^2]-E[X^2]\n",
      "MAE  0.0    1.114682        1.318081\n",
      "MSE  0.0    1.242516        1.737338\n"
     ]
    }
   ],
   "source": [
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in range(len(measures_locations_list)):\n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         measures_locations_list[x_i].reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measures_weights_list[x_i].reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    b = np.mean((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mean_errors = np.array(b-np.mean(measures_locations_list[x_i]))\n",
    "    # Get Vars\n",
    "    b = np.mean((Predicted_Weights[x_i]**2)*(Barycenters_Array))\n",
    "    Mean_var = np.array(b-np.mean(measures_locations_list[x_i]**2))\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.mean(np.abs(W1_errors)),np.mean(W1_errors**2)])\n",
    "Mean_prediction_Performance = np.array([np.mean(np.abs(Mean_errors)),np.mean(Mean_errors**2)])\n",
    "Var_prediction_Performance = np.array([np.mean(np.abs(Mean_var)),np.mean(Mean_var**2)])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"E[X'^2]-E[X^2]\":Var_prediction_Performance},index=[\"MAE\",\"MSE\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+\"Type_A_Prediction.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "print(Type_A_Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Performance\n",
    "Randomly subsample from output space and visualize empirical measures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjust if is number of plots to visualizes is larger than number of output distributions (But only if there is not enough data!)\n",
    "if N_Grid_Instances <= Visualization_Size**2:\n",
    "        Visualization_Size = int(round(np.sqrt(min(N_Grid_Instances,Visualization_Size**2)))-1)\n",
    "\n",
    "\n",
    "# Initialize Random Sample of input-output pairs to visualize\n",
    "plotting_distribution_indices = random.sample(range(N_Grid_Instances), (Visualization_Size)**2)\n",
    "\n",
    "# Generate Plot\n",
    "f, axarr = plt.subplots(Visualization_Size,Visualization_Size,figsize=(6, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.suptitle(\"Sample of Predictions\")\n",
    "for i in range(Visualization_Size):\n",
    "    for j in range(Visualization_Size):\n",
    "        # Get Current (Randomly chosen (uniformly)) Index\n",
    "        current_index = (i*Visualization_Size + j)\n",
    "        current_random_index = plotting_distribution_indices[current_index]\n",
    "        # Generate Current Plot\n",
    "        axarr[i,j].bar(Barycenters_Array,(Predicted_Weights[5].reshape(-1,)), alpha=0.5,label=\"Prediction\",color=\"chartreuse\")\n",
    "        axarr[i,j].bar(measures_locations_list[current_random_index].reshape(-1,),measures_weights_list[current_random_index], alpha=0.5,label=\"Target\",color=\"purple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
