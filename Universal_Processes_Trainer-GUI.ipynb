{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)* by simulating from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T\\beta(s,x)dW_s.\n",
    "$$\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "*This hyperparameter describes the proportion of the data used as sample-barycenters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantization_Proportion = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 2\n",
    "N_Monte_Carlo_Samples = 100\n",
    "\n",
    "N_Monte_Carlo_Samples_Test = 10 # How many MC-samples to draw from test-set?\n",
    "T_end = 1\n",
    "Direct_Sampling = True #This hyperparameter determines if we use a Euler-Maryama scheme or if we use something else.  \n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 20\n",
    "Max_Grid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDE Simulation Hyper-Parameter(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return np.sin(math.pi*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 1+ (x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run Backend:\n",
    "*Runs the backend with these pre-specified hyperparameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 9305.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 24691.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 271.46it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]/usr/lib/python3.7/site-packages/ipykernel_launcher.py:328: RuntimeWarning: invalid value encountered in multiply\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 11621.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "â€¢ Grid Instances:  20 and : 15  Testing instances.\n",
      "â€¢ 20  Centers will be produced; from a total datasize of:  20 !  (That's  1  percent).\n",
      "â€¢ Each Wasserstein-1 Ball should contain:  1 elements from the training set.\n",
      "Current Monte-Carlo Step:\n",
      "Using Euler-Maruyama distritization + Monte-Carlo Sampling.\n",
      "Done Simulation Step (Train Set)\n",
      "Done Simulation Step (Test Set)\n",
      "ðŸ˜š  Begin Building Distance Matrix  ðŸ˜š\n",
      "ðŸ˜€  Done Building Distance Matrix ðŸ˜€ !\n",
      "ðŸ˜š  Begin Identifying Sample Barycenters  ðŸ˜š\n",
      "ðŸ˜€  Done Identifying Sample Barycenters ðŸ˜€ !\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9937 - accuracy: 0.1500\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9854 - accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9774 - accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9697 - accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9622 - accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9550 - accuracy: 0.1000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9479 - accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9408 - accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9335 - accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9262 - accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9189 - accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 2.9115 - accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9040 - accuracy: 0.1000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8962 - accuracy: 0.1000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8882 - accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8798 - accuracy: 0.1000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8712 - accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8624 - accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8533 - accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8439 - accuracy: 0.1000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8341 - accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8239 - accuracy: 0.1000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8134 - accuracy: 0.1000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8026 - accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7914 - accuracy: 0.1000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7799 - accuracy: 0.1000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7680 - accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.7557 - accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7431 - accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7302 - accuracy: 0.1000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7171 - accuracy: 0.1000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.7036 - accuracy: 0.1000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6898 - accuracy: 0.1000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6759 - accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6619 - accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6476 - accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6332 - accuracy: 0.1000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6186 - accuracy: 0.1000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6041 - accuracy: 0.1000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5896 - accuracy: 0.1000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5751 - accuracy: 0.1000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5607 - accuracy: 0.1000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5464 - accuracy: 0.1000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5323 - accuracy: 0.1000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5184 - accuracy: 0.1000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5046 - accuracy: 0.1000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4911 - accuracy: 0.1000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4778 - accuracy: 0.1000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4645 - accuracy: 0.1000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4514 - accuracy: 0.1000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4385 - accuracy: 0.1000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4258 - accuracy: 0.1000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4134 - accuracy: 0.1000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4011 - accuracy: 0.1000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3890 - accuracy: 0.1000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3771 - accuracy: 0.1000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3653 - accuracy: 0.1000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3538 - accuracy: 0.1000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3425 - accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3314 - accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3205 - accuracy: 0.1000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3097 - accuracy: 0.1000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2990 - accuracy: 0.1000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2883 - accuracy: 0.1000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2779 - accuracy: 0.1500\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2676 - accuracy: 0.1000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2574 - accuracy: 0.1500\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2474 - accuracy: 0.1500\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2375 - accuracy: 0.1500\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2276 - accuracy: 0.1500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2177 - accuracy: 0.2000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2080 - accuracy: 0.2000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1983 - accuracy: 0.2000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1885 - accuracy: 0.2000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1788 - accuracy: 0.2000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1692 - accuracy: 0.3000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1594 - accuracy: 0.3000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1497 - accuracy: 0.3000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1401 - accuracy: 0.3000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1304 - accuracy: 0.3000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1207 - accuracy: 0.3000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1111 - accuracy: 0.3000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1014 - accuracy: 0.3000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0917 - accuracy: 0.3000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0819 - accuracy: 0.3000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0721 - accuracy: 0.3000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0622 - accuracy: 0.3000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0524 - accuracy: 0.3000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0424 - accuracy: 0.3000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0323 - accuracy: 0.3000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0222 - accuracy: 0.3000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0121 - accuracy: 0.3500\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0019 - accuracy: 0.3500\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9917 - accuracy: 0.4000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9814 - accuracy: 0.4000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9712 - accuracy: 0.4000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9610 - accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9509 - accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9408 - accuracy: 0.4000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9306 - accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 10692.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 5252.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 1202.97it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 975.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n",
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n",
      "Building Training Set Performance Metrics\n",
      "               W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "MAE  1.935638e-05    0.002554         2.553679e-09                0.009252   \n",
      "MSE  5.189960e-10    0.000009         1.434493e-17                0.000095   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "MAE              0.015228  \n",
      "MSE              0.000237  \n",
      "Building Test Set Performance Metrics\n",
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "               W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "MAE  1.935638e-05    0.002554         2.553679e-09                0.009252   \n",
      "MSE  5.189960e-10    0.000009         1.434493e-17                0.000095   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "MAE              0.015228  \n",
      "MSE              0.000237  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "MAE  0.018464    0.064062             0.000665                0.145973   \n",
      "MSE  0.000483    0.005617             0.000001                0.022725   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "MAE              0.178892  \n",
      "MSE              0.034803  \n",
      " \n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use is user prefers GUI\n",
    "# %run Universal_Processes_Trainer_BACKEND.ipynb\n",
    "# Use for faster/shorter execution times (note: more amenable to terminal)\n",
    "exec(open('Universal_Processes_Trainer_BACKEND.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
