{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wasserstein_esque(y_true, y_predicted):\n",
    "    # Initialize Barycenters\n",
    "    Barycenters_Applier = tf.constant(Barycenters_Array,dtype=tf.float32)\n",
    "#     def ES_p_loss(y_true, y_predicted):\n",
    "    mixed_barycenters = tf.linalg.matvec(Barycenters_Applier,y_predicted)\n",
    "    loss_internal = tf.math.reduce_mean(y_true * mixed_barycenters)\n",
    "#         return loss_internal\n",
    "    return loss_internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing Layer\n",
    "This is the custom layer induced by the *\"Sample Barycenters Procedure\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------#\n",
    "#------------------------------------------------------------------------------------------------------------------------#\n",
    "# Para-GAN\n",
    "#------------------------------------------------------------------------------------------------------------------------#\n",
    "#------------------------------------------------------------------------------------------------------------------------#\n",
    "### WGAN Related\n",
    "def Mixing_Layer(x):\n",
    "    # Initialize Barycenters\n",
    "    Barycenters_Applier = tf.constant(Barycenters_Array)\n",
    "    # Mix Barycenters\n",
    "    mixed_barycenters = tf.linalg.matvec(Barycenters_Applier,x)\n",
    "    return mixed_barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9e3e8d1fda69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMixing_Layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMixing_Layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class Mixing_Layer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=16, input_dim=32):\n",
    "        super(Mixing_Layer, self).__init__()\n",
    "        self.units = units\n",
    "        # Initialize Barycenters\n",
    "        Barycenters_Applier = tf.constant(Barycenters_Array.T)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, Barycenters_Applier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para-GAN Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_ParaGAN(height, depth, learning_rate, input_dim, output_dim):\n",
    "    #----------------------------#\n",
    "    # Maximally Interacting Layer #\n",
    "    #-----------------------------#\n",
    "    # Initialize Inputs\n",
    "    input_layer = tf.keras.Input(shape=(input_dim,))\n",
    "\n",
    "        \n",
    "    \n",
    "    #------------------#\n",
    "    #   Core Layers    #\n",
    "    #------------------#\n",
    "    core_layers = fullyConnected_Dense(height)(input_layer)\n",
    "    # Activation\n",
    "    core_layers = tf.nn.swish(core_layers)\n",
    "    # Train additional Depth?\n",
    "    if depth>1:\n",
    "        # Add additional deep layer(s)\n",
    "        for depth_i in range(1,depth):\n",
    "            core_layers = fullyConnected_Dense(height)(core_layers)\n",
    "            # Activation\n",
    "            core_layers = tf.nn.swish(core_layers)\n",
    "    \n",
    "    #------------------#\n",
    "    #  Readout Layers  #\n",
    "    #------------------# \n",
    "    # Readout Layer (Dense Fully Connected)\n",
    "    output_layers = fullyConnected_Dense(output_dim)(core_layers)  \n",
    "    output_layers = tf.nn.softmax(output_layers)\n",
    "#     output_layers = Mixing_Layer(output_layers)  \n",
    "    output_layers = fullyConnected_Dense(height)(output_layers)\n",
    "    \n",
    "    # Define Input/Output Relationship (Arch.)\n",
    "    trainable_layers_model = tf.keras.Model(input_layer, output_layers)\n",
    "    \n",
    "    \n",
    "    #----------------------------------#\n",
    "    # Define Optimizer & Compile Archs.\n",
    "    #----------------------------------#\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    trainable_layers_model.compile(optimizer=opt, loss=\"mae\", metrics=[\"mse\", \"mae\", \"mape\"])\n",
    "\n",
    "    return trainable_layers_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------#\n",
    "#                                      Build Predictive Model                                    #\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def build_ParaGAN(n_folds , n_jobs, n_iter, param_grid_in, X_train, y_train,X_test):\n",
    "\n",
    "    # Deep Feature Network\n",
    "    Nice_Model_CV = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=def_ParaGAN, verbose=True)\n",
    "    \n",
    "    # Randomized CV\n",
    "    Nice_Model_CVer = RandomizedSearchCV(estimator=Nice_Model_CV, \n",
    "                                    n_jobs=n_jobs,\n",
    "                                    cv=KFold(n_folds, random_state=2020, shuffle=True),\n",
    "                                    param_distributions=param_grid_in,\n",
    "                                    n_iter=n_iter,\n",
    "                                    return_train_score=True,\n",
    "                                    random_state=2020,\n",
    "                                    verbose=10)\n",
    "    \n",
    "    # Fit Model #\n",
    "    #-----------#\n",
    "    Nice_Model_CVer.fit(X_train,y_train)\n",
    "\n",
    "    # Write Predictions #\n",
    "    #-------------------#\n",
    "    y_hat_train = Nice_Model_CVer.predict(X_test_partial)\n",
    "    y_hat_test = Nice_Model_CVer.predict(X_test)\n",
    "    \n",
    "    # Counter number of parameters #\n",
    "    #------------------------------#\n",
    "    # Extract Best Model\n",
    "    best_model = Nice_Model_CVer.best_estimator_\n",
    "    # Count Number of Parameters\n",
    "    N_params_best_ffNN = np.sum([np.prod(v.get_shape().as_list()) for v in best_model.model.trainable_variables])\n",
    "    \n",
    "    # Return Values #\n",
    "    #---------------#\n",
    "    return y_hat_train, y_hat_test, N_params_best_ffNN\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print('Deep Feature Builder - Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------#\n",
    "#                                      Define Predictive Model                                   #\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def def_simple_deep_classifer(height, depth, learning_rate, input_dim, output_dim):\n",
    "    # Initialize Simple Deep Classifier\n",
    "    simple_deep_classifier = tf.keras.Sequential()\n",
    "    for d_i in range(depth):\n",
    "        simple_deep_classifier.add(tf.keras.layers.Dense(height, activation='relu'))\n",
    "\n",
    "    simple_deep_classifier.add(tf.keras.layers.Dense(output_dim, activation='softmax'))\n",
    "\n",
    "    # Compile Simple Deep Classifier\n",
    "    simple_deep_classifier.compile(optimizer='adam',\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Return Output\n",
    "    return simple_deep_classifier\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "#                                  Build Deep Classifier Model                                   #\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "from tensorflow.keras import Sequential\n",
    "def build_simple_deep_classifier(n_folds , n_jobs, n_iter, param_grid_in, X_train, y_train,X_test):\n",
    "\n",
    "    # Deep Feature Network\n",
    "    CV_simple_deep_classifier = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=def_simple_deep_classifer, verbose=True)\n",
    "    \n",
    "    # Randomized CV\n",
    "    CV_simple_deep_classifier_CVer = RandomizedSearchCV(estimator=CV_simple_deep_classifier, \n",
    "                                    n_jobs=n_jobs,\n",
    "                                    cv=KFold(n_folds, random_state=2020, shuffle=True),\n",
    "                                    param_distributions=param_grid_in,\n",
    "                                    n_iter=n_iter,\n",
    "                                    return_train_score=True,\n",
    "                                    random_state=2020,\n",
    "                                    verbose=10)\n",
    "    \n",
    "    # Fit\n",
    "    CV_simple_deep_classifier_CVer.fit(X_train,y_train)\n",
    "\n",
    "    # Make Prediction(s)\n",
    "    predicted_classes_train = CV_simple_deep_classifier_CVer.predict(X_train)\n",
    "    predicted_classes_test = CV_simple_deep_classifier_CVer.predict(X_test)\n",
    "    \n",
    "    # Counter number of parameters #\n",
    "    #------------------------------#\n",
    "    # Extract Best Model\n",
    "    best_model = CV_simple_deep_classifier_CVer.best_estimator_\n",
    "    # Count Number of Parameters\n",
    "    N_params_best_classifier = np.sum([np.prod(v.get_shape().as_list()) for v in best_model.model.trainable_variables])\n",
    "\n",
    "    \n",
    "    # Return Values\n",
    "    return predicted_classes_train, predicted_classes_test, N_params_best_classifier\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print('Deep Classifier - Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
