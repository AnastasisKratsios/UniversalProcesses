{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "# N_Euler_Maruyama_Steps = 2\n",
    "N_Monte_Carlo_Samples = 1\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 20\n",
    "Max_Grid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "*This hyperparameter describes the proportion of the data used as sample-barycenters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantization_Proportion = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Algorithm\n",
    "---\n",
    "Given a set of training inputs $\\mathbb{X}$ and a stochastic process $(X_t)_{t\\geq 0}$ which we can sample from:\n",
    "1. **For:** x in $\\mathbb{X}$:\n",
    "    - *Simulate:* $\\{x\\mapsto X_T(\\omega_n)\\}_{n=1}^N$\n",
    "    - *Set*: $\\hat{\\nu}_{x,T}\\triangleq \\frac1{N}\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$\n",
    "2. **Learn:** Wasserstein Barycenters $\\hat{\\mu}_1,\\dots,\\hat{\\mu}_N\n",
    "    \\in \\underset{{\\hat{\\mu}_n\\in\\mathscr{P}_{N}(\\mathbb{R}^d)}}{\\operatorname{argmin}}\n",
    "    \\, \\sum_{n=1}^N W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$\n",
    "3. **Train Classifier:** $\\hat{f}:x\\mapsto \\operatorname{n\\leq N}\\, W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Grid\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Grid Instances:  20\n"
     ]
    }
   ],
   "source": [
    "# Get Input Data\n",
    "x_Grid = np.arange(start=-Max_Grid,\n",
    "                   stop=Max_Grid,\n",
    "                   step=(2*Max_Grid/N_Grid_Finess))\n",
    "\n",
    "# Get Number of Instances in Grid\n",
    "N_Grid_Instances = len(x_Grid)\n",
    "\n",
    "# Updater User\n",
    "print(\"\\u2022 Grid Instances: \", N_Grid_Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Counting Parameters\n",
    "Initialize the \"conting\" type parameters which will help us to determine the length of loops and to intialize object's size later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ 20  Centers will be produced; from a total datasize of:  20 !  (That's  1  percent).\n",
      "â€¢ Each Wasserstein-1 Ball should contain:  1 elements from the training set.\n"
     ]
    }
   ],
   "source": [
    "# Get Internal (Counting) Parameters\n",
    "N_Quantizers_to_parameterize = round(Quantization_Proportion*N_Grid_Finess)\n",
    "N_Elements_Per_Cluster = int(round(N_Grid_Instances/N_Quantizers_to_parameterize))\n",
    "\n",
    "# Update User\n",
    "print(\"\\u2022\",N_Quantizers_to_parameterize,\" Centers will be produced; from a total datasize of: \",N_Grid_Finess,\n",
    "      \"!  (That's \",Quantization_Proportion,\n",
    "      \" percent).\")\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Path\n",
    "$d X_t = \\alpha(t,x)dt + \\beta(t,x)dW_t ;\\qquad X_0 =x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return 0#np.sin(math.pi*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 1#(t+1)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List of Barycenters\n",
    "Wasserstein_Barycenters = []\n",
    "# Initialize Terminal-Time Empirical Measures\n",
    "measures_locations_list = []\n",
    "measures_weights_list = []\n",
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "# Initialize Quantizer\n",
    "Init_Quantizer_generic = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $\\{\\hat{\\nu}^{N}_{T,x}\\}_{x \\in \\mathbb{X}}$ Build Wasserstein Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 28197.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step:\n",
      "Done Simulation Step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"Current Monte-Carlo Step:\")\n",
    "\n",
    "# Perform Monte-Carlo Data Generation\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    # Get Terminal Distribution Shape\n",
    "    ###\n",
    "    # DIRECT SAMPLING\n",
    "    measures_locations_loop = (np.random.normal(x_Grid[i],np.abs(x_Grid[i]), N_Monte_Carlo_Samples).reshape(-1,))/N_Monte_Carlo_Samples\n",
    "    \n",
    "    # Append to List\n",
    "    measures_locations_list.append(measures_locations_loop.reshape(-1,1))\n",
    "    measures_weights_list.append(measure_weights)\n",
    "    \n",
    "# Update User\n",
    "print(\"Done Simulation Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dissimilarity (Distance) Matrix\n",
    "*In this step we build a dissimularity matrix of the dataset on the Wasserstein-1 space.  Namely:*\n",
    "$$\n",
    "\\operatorname{Mat}_{\\# \\mathbb{X},\\# \\mathbb{X}}\\left(\\mathbb{R}\\right)\\ni D; \\text{ where}\\qquad \\, D_{i,j}\\triangleq \\mathcal{W}_1\\left(f(x_i),f(x_j)\\right)\n",
    ";\n",
    "$$\n",
    "*where $f\\in C\\left((\\mathcal{X},\\mathcal{P}_1(\\mathcal{Y})\\right)$ is the \"target\" function we are learning.*\n",
    "\n",
    "**Note**: *Computing the dissimularity matrix is the most costly part of the entire algorithm with a complexity of at-most $\\mathcal{O}\\left(E_{W} \\# \\mathbb{X})^2\\right)$ where $E_W$ denotes the complexity of a single Wasserstein-1 evaluation between two elements of the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜š  Begin Building Distance Matrix  ðŸ˜š\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 378.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜€  Done Building Distance Matrix ðŸ˜€ !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Disimilarity Matrix\n",
    "Dissimilarity_matrix_ot = np.zeros([N_Grid_Instances,N_Grid_Instances])\n",
    "\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Building Distance Matrix\",\" \\U0001F61A\")\n",
    "# Build Disimilarity Matrix\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    for j in range(N_Grid_Instances):\n",
    "        Dissimilarity_matrix_ot[i,j] = ot.emd2_1d(measures_locations_list[j],\n",
    "                                                  measures_locations_list[i])\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Building Distance Matrix\",\"\\U0001F600\",\"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Quantities to Loop Over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\" and Generate Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Locations Matrix (Internal to Loop)\n",
    "measures_locations_list_current = copy.copy(measures_locations_list)\n",
    "Dissimilarity_matrix_ot_current = copy.copy(Dissimilarity_matrix_ot)\n",
    "\n",
    "# Initialize masker vector\n",
    "masker = np.ones(N_Grid_Instances)\n",
    "\n",
    "# Initialize Sorting Reference Vector (This helps us efficiently scroll through the disimularity matrix to identify the barycenter without having to re-compute the dissimultarity matrix of a sub-saple at every iteration (which is the most costly part of the algorithm!))\n",
    "Distances_Loop = Dissimilarity_matrix_ot_current.sum(axis=1)\n",
    "\n",
    "# Initialize Classes (In-Sample)\n",
    "Classifer_Wasserstein_Centers = np.zeros([N_Quantizers_to_parameterize,N_Grid_Instances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/usr/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 9463.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜š  Begin Identifying Sample Barycenters  ðŸ˜š\n",
      "ðŸ˜€  Done Identifying Sample Barycenters ðŸ˜€ !\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Identifying Sample Barycenters\",\" \\U0001F61A\")\n",
    "\n",
    "# Identify Sample Barycenters\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    # GET BARYCENTER #\n",
    "    #----------------#\n",
    "    ## Identify row with minimum total distance\n",
    "    Barycenter_index = int(Distances_Loop.argsort()[:1][0])\n",
    "    ## Get Barycenter\n",
    "    ## Update Barycenters Array ##\n",
    "    #----------------------------#\n",
    "    ### Get next Barycenter\n",
    "    new_barycenter_loop = measures_locations_list_current[Barycenter_index].reshape(-1,1)\n",
    "    ### Update Array of Barycenters\n",
    "    if i == 0:\n",
    "        # Initialize Barycenters Array\n",
    "        Barycenters_Array = new_barycenter_loop\n",
    "    else:\n",
    "        # Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,new_barycenter_loop,axis=-1)\n",
    "\n",
    "    # GET CLUSTER #\n",
    "    #-------------#\n",
    "    # Identify Cluster for this barycenter (which elements are closest to it)\n",
    "    Cluster_indices = (masker*Dissimilarity_matrix_ot_current[:,Barycenter_index]).argsort()[:N_Elements_Per_Cluster]\n",
    "    ## UPDATES Set  M^{(n)}  ##\n",
    "    #-------------------------#\n",
    "    Dissimilarity_matrix_ot_current[Cluster_indices,:] = 0\n",
    "    # Distance-Based Sorting\n",
    "    Distances_Loop[Cluster_indices] = math.inf\n",
    "\n",
    "    # Update Cluster\n",
    "    masker[Cluster_indices] = math.inf\n",
    "    \n",
    "    # Update Classes\n",
    "    Classifer_Wasserstein_Centers[i,Cluster_indices] = 1\n",
    "#     print(Cluster_indices)\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Identifying Sample Barycenters\",\"\\U0001F600\",\"!\")\n",
    "print(Classifer_Wasserstein_Centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# %run ParaGAN_Backend.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9755 - accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9668 - accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9583 - accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9498 - accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9415 - accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9332 - accuracy: 0.1500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9249 - accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9165 - accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9078 - accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 2.8990 - accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8899 - accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 984us/step - loss: 2.8805 - accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8709 - accuracy: 0.1000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8610 - accuracy: 0.1000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8508 - accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8403 - accuracy: 0.1000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8295 - accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8182 - accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8065 - accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7945 - accuracy: 0.1000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7823 - accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7695 - accuracy: 0.1000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7565 - accuracy: 0.1000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7432 - accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7296 - accuracy: 0.1000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7157 - accuracy: 0.1000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7015 - accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6871 - accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6726 - accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6578 - accuracy: 0.1000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6430 - accuracy: 0.1000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6280 - accuracy: 0.1000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6130 - accuracy: 0.1000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5979 - accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5829 - accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5679 - accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5530 - accuracy: 0.1000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5383 - accuracy: 0.1000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5238 - accuracy: 0.1000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5094 - accuracy: 0.1000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4954 - accuracy: 0.1000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4816 - accuracy: 0.1000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4680 - accuracy: 0.1000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4548 - accuracy: 0.1000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4419 - accuracy: 0.1000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4292 - accuracy: 0.1000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4168 - accuracy: 0.1000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4047 - accuracy: 0.1000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3928 - accuracy: 0.1000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3813 - accuracy: 0.1000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3700 - accuracy: 0.1000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3590 - accuracy: 0.1000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3485 - accuracy: 0.1500\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3382 - accuracy: 0.1000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3282 - accuracy: 0.1000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3184 - accuracy: 0.1000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3087 - accuracy: 0.1000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2993 - accuracy: 0.1000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2901 - accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2811 - accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2722 - accuracy: 0.1500\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2636 - accuracy: 0.1500\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2550 - accuracy: 0.1500\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2466 - accuracy: 0.1500\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2382 - accuracy: 0.1500\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2300 - accuracy: 0.1500\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 970us/step - loss: 2.2218 - accuracy: 0.1500\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2136 - accuracy: 0.2000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2054 - accuracy: 0.2000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1973 - accuracy: 0.2000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1891 - accuracy: 0.2000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1808 - accuracy: 0.2000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1725 - accuracy: 0.2000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1643 - accuracy: 0.2000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1561 - accuracy: 0.2000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1478 - accuracy: 0.2000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1396 - accuracy: 0.3000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1313 - accuracy: 0.3000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1228 - accuracy: 0.3000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1143 - accuracy: 0.3000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1057 - accuracy: 0.3000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0968 - accuracy: 0.3000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0878 - accuracy: 0.3000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0787 - accuracy: 0.3000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0695 - accuracy: 0.3000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0602 - accuracy: 0.3000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0509 - accuracy: 0.3000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0415 - accuracy: 0.3000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0321 - accuracy: 0.3000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0225 - accuracy: 0.3000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0128 - accuracy: 0.3000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0030 - accuracy: 0.3000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9930 - accuracy: 0.3000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9830 - accuracy: 0.3500\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9731 - accuracy: 0.3500\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9632 - accuracy: 0.3500\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9531 - accuracy: 0.3500\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9429 - accuracy: 0.3500\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9327 - accuracy: 0.3500\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9223 - accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 905us/step\n",
      "1/1 [==============================] - 0s 861us/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "# param_grid_Deep_Classifier['input_dim'] = [1]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = x_Grid, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers.T,\n",
    "                                                                                                        X_test = x_Grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Weights\n",
    "Predicted_Weights = np.array([])\n",
    "for i in range(N_Quantizers_to_parameterize):\n",
    "    b = np.repeat(np.array(Classifer_Wasserstein_Centers.T[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "        \n",
    "# Format Points of Mass\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      W1  E[X']-E[X]  E[X'^2]-E[X^2]\n",
      "MAE  0.0         0.0             0.0\n",
      "MSE  0.0         0.0             0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in range(len(measures_locations_list)):\n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         measures_locations_list[x_i].reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measures_weights_list[x_i].reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(measures_locations_list[x_i])\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    # Get Vars\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(measures_locations_list[x_i]**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var))\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.mean(np.abs(W1_errors)),np.mean(W1_errors**2)])\n",
    "Mean_prediction_Performance = np.array([np.mean(np.abs(Mean_errors)),np.mean(Mean_errors**2)])\n",
    "Var_prediction_Performance = np.array([np.mean(np.abs(Var_errors)),np.mean(Var_errors**2)])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"E[X'^2]-E[X^2]\":Var_prediction_Performance},index=[\"MAE\",\"MSE\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+\"Type_A_Prediction.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "print(Type_A_Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Performance\n",
    "Randomly subsample from output space and visualize empirical measures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjust if is number of plots to visualizes is larger than number of output distributions (But only if there is not enough data!)\n",
    "if N_Grid_Instances <= Visualization_Size**2:\n",
    "        Visualization_Size = int(round(np.sqrt(min(N_Grid_Instances,Visualization_Size**2)))-1)\n",
    "\n",
    "\n",
    "# Initialize Random Sample of input-output pairs to visualize\n",
    "plotting_distribution_indices = random.sample(range(N_Grid_Instances), (Visualization_Size)**2)\n",
    "\n",
    "# Generate Plot\n",
    "f, axarr = plt.subplots(Visualization_Size,Visualization_Size,figsize=(6, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.suptitle(\"Sample of Predictions\")\n",
    "for i in range(Visualization_Size):\n",
    "    for j in range(Visualization_Size):\n",
    "        # Get Current (Randomly chosen (uniformly)) Index\n",
    "        current_index = (i*Visualization_Size + j)\n",
    "        current_random_index = plotting_distribution_indices[current_index]\n",
    "        # Generate Current Plot\n",
    "        axarr[i,j].bar(Barycenters_Array,(Predicted_Weights[current_random_index].reshape(-1,)), alpha=0.5,label=\"Prediction\",color=\"chartreuse\")\n",
    "        axarr[i,j].bar(measures_locations_list[current_random_index].reshape(-1,),measures_weights_list[current_random_index], alpha=0.5,label=\"Target\",color=\"purple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
