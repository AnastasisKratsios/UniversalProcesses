{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Conditional Laws for Random-Fields - via:\n",
    "\n",
    "## Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$.\n",
    "\n",
    "---\n",
    "\n",
    "By: [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---\n",
    "\n",
    "This is the main component of this implementation; namely, it implements and trains the paper's main *deep neural model* $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-Parameter Dump (easy access for debugging):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_run = True\n",
    "# exec(open('Init_Dump.py').read())\n",
    "# exec(open('Loader.py').read())\n",
    "# exec(open('Debug_Menu.py').read())\n",
    "# %run Debug_Menu.ipynb\n",
    "# Proportion_per_cluster = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Begin Implementation of $\\mathcal{NN}_{1_{\\mathbb{R}^d},\\mathcal{D}}^{\\max\\{0,\\cdot\\}:\\star}$:\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the measures $\\hat{\\mu}_n$ via Barycenters...*aka \"K-Means\"*!\n",
    "- We first identify N-balls in the input space (which is equivalent to identifying N balls in the output space by uniform continuity)\n",
    "- We then project each of the centers of these balls onto the nearest element of the training set.\n",
    "- The corresponing (observed) $f(x)\\in \\mathcal{P}_1(\\mathbb{R})$ are our $\\hat{\\mu}_n$ (for $n=1,\\dots,N$).\n",
    "\n",
    "\n",
    "**NB:** *This is essentially what is done in the proof, exect there, we have access to the correct N and the optimal balls (outside the training dataset)...which we clearly do not here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index and identify: $\\{f^{-1}[\\hat{\\mu}_{n=1}^N]\\}_{n=1}^N\\subset \\mathbb{X}!$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-28737e91b4fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize k_means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mN_Quantizers_to_parameterize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProportion_per_cluster\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_Quantizers_to_parameterize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get Classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTrain_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize k_means\n",
    "N_Quantizers_to_parameterize = int(np.maximum(2,round(Proportion_per_cluster*X_train.shape[0])))\n",
    "kmeans = KMeans(n_clusters=N_Quantizers_to_parameterize, random_state=0).fit(X_train)\n",
    "# Get Classes\n",
    "Train_classes = np.array(pd.get_dummies(kmeans.labels_))\n",
    "# Get Center Measures\n",
    "Barycenters_Array_x = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get $\\{\\hat{\\mu}_{n=1}^{N}\\}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 14405.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(Barycenters_Array_x.shape[0])):\n",
    "    # Identify Nearest Datapoint to a ith Barycenter\n",
    "    #------------------------------------------------------------------------------------------------------#\n",
    "    ## Get Barycenter \"out of sample\" in X (NB there is no data-leakage since we know nothing about Y!)\n",
    "    Bar_x_loop = Barycenters_Array_x[i,]\n",
    "    ## Project Barycenter onto testset\n",
    "    distances = np.sum(np.abs(X_train-Bar_x_loop.reshape(-1,)),axis=1)\n",
    "\n",
    "    # Update Subsetting Index\n",
    "    if i == 0:\n",
    "        Barycenters_index = np.array(np.argmin(distances))\n",
    "    else:\n",
    "        Barycenters_index = np.append(Barycenters_index,np.array(np.argmin(distances)))\n",
    "\n",
    "# Subset Training Set-Outputs\n",
    "if f_unknown_mode != \"Rough_SDE\":\n",
    "    Barycenters_Array = Y_train[Barycenters_index,]\n",
    "else:\n",
    "    Barycenters_Array = Y_train[Barycenters_index,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Packages and CV Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Training Classifer Portion of Type-A Model\n",
      "==========================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 5.4949 - accuracy: 0.0042\n",
      "Epoch 2/2\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 5.4153 - accuracy: 0.0021\n",
      "30/30 [==============================] - 0s 606us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "===============================================\n",
      "Training Classifer Portion of Type Model: Done!\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "print(\"==========================================\")\n",
    "print(\"Training Classifer Portion of Type-A Model\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [problem_dim]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier, timer_output = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Train_classes,\n",
    "                                                                                                        X_test = X_test)\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"Training Classifer Portion of Type Model: Done!\")\n",
    "print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if f_unknown_mode != \"Rough_SDE\":\n",
    "#     for i in range(Barycenters_Array.shape[0]):\n",
    "#         if i == 0:\n",
    "#             points_of_mass = Barycenters_Array[i,]\n",
    "#         else:\n",
    "\n",
    "#             points_of_mass = np.append(points_of_mass,Barycenters_Array[i,])\n",
    "# else:\n",
    "#     for i in range(Barycenters_Array.shape[0]):\n",
    "#         if i == 0:\n",
    "#             points_of_mass = Barycenters_Array[i,]\n",
    "#         else:\n",
    "\n",
    "#             points_of_mass = np.append(points_of_mass,Barycenters_Array[i,],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (f_unknown_mode != \"GD_with_randomized_input\") and (f_unknown_mode != \"Rough_SDE\") and (f_unknown_mode != \"Extreme_Learning_Machine\"):\n",
    "#     # Get Noisless Mean\n",
    "#     direct_facts = np.apply_along_axis(f_unknown, 1, X_train)\n",
    "#     direct_facts_test = np.apply_along_axis(f_unknown, 1, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Error(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run Evaluation.ipynb\n",
    "exec(open('Evaluation.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Relevant Solvers\n",
    "Solve using either:\n",
    "- Sinkhorn Regularized Wasserstein Distance of: [Cuturi - Sinkhorn Distances: Lightspeed Computation of Optimal Transport (2016)](https://papers.nips.cc/paper/2013/hash/af21d0c97db2e27e13572cbf59eb343d-Abstract.html)\n",
    "- Slices Wasserstein Distance of: [Bonneel, Nicolas, et al. “Sliced and radon wasserstein barycenters of measures.” Journal of Mathematical Imaging and Vision 51.1 (2015): 22-45](https://dl.acm.org/doi/10.1007/s10851-014-0506-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transport-problem initializations #\n",
    "# #-----------------------------------#\n",
    "# if output_dim != 1:\n",
    "#     ## Multi-dimensional\n",
    "#     # Externally Update Empirical Weights for multi-dimensional case\n",
    "#     empirical_weights = np.full((N_Monte_Carlo_Samples,),1/N_Monte_Carlo_Samples)\n",
    "#     # Also Initialize\n",
    "#     Sinkhorn_regularization = 0.1\n",
    "# else:\n",
    "#     ## Single-Dimensional\n",
    "#     # Initialize Empirical Weights\n",
    "#     empirical_weights = (np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples).reshape(-1,)\n",
    "\n",
    "# #-------------------------#\n",
    "# # Define Transport Solver #\n",
    "# #-------------------------#\n",
    "# def transport_dist(x_source,w_source,x_sink,w_sink,output_dim,OT_method=\"Sliced\"):\n",
    "#     # Decide which problem to solve (1D or multi-D)?\n",
    "#     if output_dim == 1:\n",
    "#         OT_out = ot.emd2_1d(x_source,\n",
    "#                             x_sink,\n",
    "#                             w_source,\n",
    "#                             w_sink)\n",
    "#     else:\n",
    "#         # COERCSION\n",
    "#         ## Update Source Distribution\n",
    "#         x_source = points_of_mass.reshape(-1,output_dim)\n",
    "#         ## Update Sink Distribution\n",
    "#         x_sink = np.array(Y_train[i,]).reshape(-1,output_dim)\n",
    "        \n",
    "#         if OT_method == \"Sinkhorn\":\n",
    "#             OT_out = ot.bregman.empirical_sinkhorn2(X_s = x_source, \n",
    "#                                                     X_t = x_sink,\n",
    "#                                                     a = w_source, \n",
    "#                                                     b = w_sink, \n",
    "#                                                     reg=0.01, \n",
    "#                                                     verbose=False,\n",
    "#                                                     method = \"sinkhorn_stabilized\")\n",
    "#             # COERSION\n",
    "#             OT_out = float(OT_out[0])\n",
    "#         else:\n",
    "#             OT_out = ot.sliced.sliced_wasserstein_distance(X_s = x_source, \n",
    "#                                                     X_t = x_sink,\n",
    "#                                                     a = w_source, \n",
    "#                                                     b = w_sink, \n",
    "#                                                     seed = 2020)\n",
    "#             # COERSION\n",
    "#             OT_out = float(OT_out)\n",
    "#     # Return (regularized?) Transport Distance\n",
    "#     return OT_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute *Training* Error(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/479 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 24000 is different from 240)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-9babcc0f43af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m## M1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mMu_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_of_mass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mMu_MC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf_unknown_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Heteroskedastic_NonLinear_Regression\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 24000 is different from 240)"
     ]
    }
   ],
   "source": [
    "# print(\"#--------------------#\")\n",
    "# print(\" Get Training Error(s)\")\n",
    "# print(\"#--------------------#\")\n",
    "# for i in tqdm(range((X_train.shape[0]))):\n",
    "#     for j in range(N_Quantizers_to_parameterize):\n",
    "#         b_loop = np.repeat(predicted_classes_train[i,j],N_Monte_Carlo_Samples)\n",
    "#         if j == 0:\n",
    "#             b = b_loop\n",
    "#         else:\n",
    "#             b = np.append(b,b_loop)\n",
    "#         b = b.reshape(-1,1)\n",
    "#         b = b\n",
    "#     b = np.array(b,dtype=float).reshape(-1,)\n",
    "#     b = b/N_Monte_Carlo_Samples\n",
    "    \n",
    "#     # Compute Error(s)\n",
    "#     ## W1\n",
    "#     W1_loop = transport_dist(x_source = points_of_mass,\n",
    "#                              w_source = b,\n",
    "#                              x_sink = np.array(Y_train[i,]).reshape(-1,),\n",
    "#                              w_sink = empirical_weights,\n",
    "#                              output_dim = output_dim)\n",
    "    \n",
    "#     ## M1\n",
    "#     Mu_hat = np.matmul(points_of_mass.T,b).reshape(-1,)\n",
    "#     Mu_MC = np.mean(np.array(Y_train[i,]),axis=0).reshape(-1,)\n",
    "#     if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "#         Mu = direct_facts[i,]\n",
    "#     else:\n",
    "#         Mu = Mu_MC\n",
    "#     ## Tally W1-Related Errors\n",
    "#     ## Mu\n",
    "#     Mean_loop = np.sum(np.abs((Mu_hat-Mu)))\n",
    "#     Mean_loop_MC = np.sum(np.abs((Mu-Mu_MC)))\n",
    "    \n",
    "#     if f_unknown_mode != \"Rough_SDE\":\n",
    "#         ## Variance\n",
    "#         Var_hat = np.sum(((points_of_mass-Mu_hat)**2)*b)\n",
    "#         Var_MC = np.mean(np.array(Y_train[i]-Mu_MC)**2)\n",
    "#         if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "#             Var = 2*np.sum(X_train[i,]**2)\n",
    "#         else:\n",
    "#             Var = Var_MC     \n",
    "\n",
    "#         # Skewness\n",
    "#         Skewness_hat = np.sum((((points_of_mass-Mu_hat)/Var_hat)**3)*b)\n",
    "#         Skewness_MC = np.mean((np.array(Y_train[i]-Mu_MC)/Var_MC)**3)\n",
    "#         if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "#             Skewness = 0\n",
    "#         else:\n",
    "#             Skewness = Skewness_MC\n",
    "\n",
    "#         # Excess Kurtosis\n",
    "#         Ex_Kurtosis_hat = np.sum((((points_of_mass-Mu_hat)/Var_hat)**4)*b) - 3\n",
    "#         Ex_Kurtosis_MC = np.mean((np.array(Y_train[i]-Mu_MC)/Var_MC)**4) - 3\n",
    "#         if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "#             Ex_Kurtosis = 3\n",
    "#         else:\n",
    "#             Ex_Kurtosis = Ex_Kurtosis_MC\n",
    "#         # Tally Higher-Order Error(s)\n",
    "#         ## Var\n",
    "#         Var_loop = np.sum(np.abs(Var_hat-Var))\n",
    "#         Var_loop_MC = np.sum(np.abs(Var_MC-Var))\n",
    "#         ## Skewness\n",
    "#         Skewness_loop = np.abs(Skewness_hat-Skewness)\n",
    "#         Skewness_loop_MC = np.abs(Skewness_MC-Skewness)\n",
    "#         ## Excess Kurtosis\n",
    "#         Ex_Kurtosis_loop = np.abs(Ex_Kurtosis-Ex_Kurtosis_hat)\n",
    "#         Ex_Kurtosis_loop_MC = np.abs(Ex_Kurtosis-Ex_Kurtosis_MC)\n",
    "    \n",
    "    \n",
    "#     # Update\n",
    "#     if i == 0:\n",
    "#         W1_errors = W1_loop\n",
    "#         ## DNM\n",
    "#         Mean_errors =  Mean_loop\n",
    "#         ## Monte-Carlo\n",
    "#         Mean_errors_MC =  Mean_loop_MC\n",
    "#         # Higher-Order Moments\n",
    "#         if f_unknown_mode != \"Rough_SDE\":\n",
    "#             ## DNM\n",
    "#             Var_errors = Var_loop\n",
    "#             Skewness_errors = Skewness_loop\n",
    "#             Ex_Kurtosis_errors = Ex_Kurtosis_loop\n",
    "#             ## Monte-Carlo\n",
    "#             Mean_errors_MC =  Mean_loop_MC\n",
    "#             Var_errors_MC = Var_loop_MC\n",
    "#             Skewness_errors_MC = Skewness_loop_MC\n",
    "#             Ex_Kurtosis_errors_MC = Ex_Kurtosis_loop_MC\n",
    "        \n",
    "        \n",
    "#     else:\n",
    "#         W1_errors = np.append(W1_errors,W1_loop)\n",
    "#         # Moments\n",
    "#         ## DNM\n",
    "#         Mean_errors =  np.append(Mean_errors,Mean_loop)\n",
    "#         ## Monte-Carlo\n",
    "#         Mean_errors_MC =  np.append(Mean_errors_MC,Mean_loop_MC)\n",
    "#         ## Higher-Order Moments\n",
    "#         if f_unknown_mode != \"Rough_SDE\":\n",
    "#             ## DNM\n",
    "#             Var_errors = np.append(Var_errors,Var_loop)\n",
    "#             Skewness_errors = np.append(Skewness_errors,Skewness_loop)\n",
    "#             Ex_Kurtosis_errors = np.append(Ex_Kurtosis_errors,Ex_Kurtosis_loop)\n",
    "#             ## Monte-Carlo\n",
    "#             Var_errors_MC = np.append(Var_errors_MC,Var_loop_MC)\n",
    "#             Skewness_errors_MC = np.append(Skewness_errors_MC,Skewness_loop_MC)\n",
    "#             Ex_Kurtosis_errors_MC = np.append(Ex_Kurtosis_errors_MC,Ex_Kurtosis_loop_MC)\n",
    "            \n",
    "\n",
    "# ## Get Error Statistics\n",
    "# W1_Errors = np.array(bootstrap(np.abs(W1_errors),n=N_Boostraps_BCA)(.95))\n",
    "# Mean_Errors =  np.array(bootstrap(np.abs(Mean_errors),n=N_Boostraps_BCA)(.95))\n",
    "# Mean_Errors_MC =  np.array(bootstrap(np.abs(Mean_errors_MC),n=N_Boostraps_BCA)(.95))\n",
    "# print(\"#-------------------------#\")\n",
    "# print(\" Get Training Error(s): END\")\n",
    "# print(\"#-------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute *Testing* Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [00:00<00:00, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------#\n",
      " Get Test Error(s)\n",
      "#----------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 12.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n"
     ]
    }
   ],
   "source": [
    "# print(\"#----------------#\")\n",
    "# print(\" Get Test Error(s)\")\n",
    "# print(\"#----------------#\")\n",
    "# for i in tqdm(range((X_test.shape[0]))):\n",
    "#     for j in range(N_Quantizers_to_parameterize):\n",
    "#         b_loop_test = np.repeat(predicted_classes_test[i,j],N_Monte_Carlo_Samples)\n",
    "#         if j == 0:\n",
    "#             b_test = b_loop_test\n",
    "#         else:\n",
    "#             b_test = np.append(b,b_loop)\n",
    "#         b_test = b_test.reshape(-1,1)\n",
    "#     b_test = np.array(b,dtype=float).reshape(-1,)\n",
    "#     b_test = b/N_Monte_Carlo_Samples\n",
    "    \n",
    "#     # Compute Error(s)\n",
    "#     ## W1\n",
    "#     W1_loop_test = transport_dist(x_source = points_of_mass,\n",
    "#                                   w_source = b,\n",
    "#                                   x_sink = np.array(Y_test[i,]).reshape(-1,),\n",
    "#                                   w_sink = empirical_weights,\n",
    "#                                   output_dim = output_dim)\n",
    "    \n",
    "#     ## M1\n",
    "#     Mu_hat_test = np.matmul(points_of_mass.T,b).reshape(-1,)\n",
    "#     Mu_MC_test = np.mean(np.array(Y_test[i,]),axis=0).reshape(-1,)\n",
    "#     if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "#         Mu_test = direct_facts_test[i,]\n",
    "#     else:\n",
    "#         Mu_test = Mu_MC_test\n",
    "#     ## Tally W1-Related Errors\n",
    "#     ## Mu\n",
    "#     Mean_loop_test = np.sum(np.abs((Mu_hat_test-Mu_test)))\n",
    "#     Mean_loop_MC_test = np.sum(np.abs((Mu_test-Mu_MC_test)))\n",
    "    \n",
    "#     if f_unknown_mode != \"Rough_SDE\":\n",
    "#         ## M2\n",
    "#         Var_hat_test = np.sum(((points_of_mass-Mu_hat_test)**2)*b)\n",
    "#         Var_MC_test = np.mean(np.array(Y_test[i]-Mu_MC)**2)\n",
    "#         if f_unknown_mode == \"Rough_SDE\":\n",
    "#             Var_test = 2*np.sum(X_test[i,]**2)\n",
    "#         else:\n",
    "#             Var_test = Var_MC\n",
    "\n",
    "#         ### Error(s)\n",
    "#         Var_loop_test = np.abs(Var_hat_test-Var_test)\n",
    "#         Var_loop_MC_test = np.abs(Var_MC_test-Var_test)\n",
    "\n",
    "#         # Skewness\n",
    "#         Skewness_hat_test = np.sum((((points_of_mass-Mu_hat_test)/Var_hat_test)**3)*b)\n",
    "#         Skewness_MC_test = np.mean((np.array(Y_test[i]-Mu_MC_test)/Var_MC_test)**3)\n",
    "#         if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "#             Skewness_test = 0\n",
    "#         else:\n",
    "#             Skewness_test = Skewness_MC_test\n",
    "#         ### Error(s)\n",
    "#         Skewness_loop_test = np.abs(Skewness_hat_test-Skewness_test)\n",
    "#         Skewness_loop_MC_test = np.abs(Skewness_MC_test-Skewness_test)\n",
    "\n",
    "#         # Skewness\n",
    "#         Ex_Kurtosis_hat_test = np.sum((((points_of_mass-Mu_hat_test)/Var_hat_test)**4)*b) - 3\n",
    "#         Ex_Kurtosis_MC_test = np.mean((np.array(Y_test[i]-Mu_MC_test)/Var_MC_test)**4) - 3\n",
    "#         if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "#             Ex_Kurtosis_test = 3\n",
    "#         else:\n",
    "#             Ex_Kurtosis_test = Ex_Kurtosis_MC_test\n",
    "#         ### Error(s)\n",
    "#         Ex_Kurtosis_loop_test = np.abs(Ex_Kurtosis_test-Ex_Kurtosis_hat_test)\n",
    "#         Ex_Kurtosis_loop_MC_test = np.abs(Ex_Kurtosis_test-Ex_Kurtosis_MC_test)\n",
    "    \n",
    "    \n",
    "#     # Update\n",
    "#     if i == 0:\n",
    "#         W1_errors_test = W1_loop_test\n",
    "#         ## DNM\n",
    "#         Mean_errors_test =  Mean_loop_test\n",
    "#         ## Monte-Carlo\n",
    "#         Mean_errors_MC_test =  Mean_loop_MC_test\n",
    "#         ### Get Higher-Moments\n",
    "#         if f_unknown_mode != \"Rough_SDE\":\n",
    "#             ## DNM\n",
    "#             Var_errors_test = Var_loop_test\n",
    "#             Skewness_errors_test = Skewness_loop_test\n",
    "#             Ex_Kurtosis_errors_test = Ex_Kurtosis_loop_test\n",
    "#             ## Monte-Carlo\n",
    "#             Var_errors_MC_test = Var_loop_MC_test\n",
    "#             Skewness_errors_MC_test = Skewness_loop_MC_test\n",
    "#             Ex_Kurtosis_errors_MC_test = Ex_Kurtosis_loop_MC_test\n",
    "            \n",
    "        \n",
    "#     else:\n",
    "#         W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "#         ## DNM\n",
    "#         Mean_errors_test =  np.append(Mean_errors_test,Mean_loop_test)\n",
    "#         ## Monte-Carlo\n",
    "#         Mean_errors_MC_test =  np.append(Mean_errors_MC_test,Mean_loop_MC_test)\n",
    "#         ### Get Higher Moments\n",
    "#         if f_unknown_mode != \"Rough_SDE\":\n",
    "#             Var_errors_test = np.append(Var_errors_test,Var_loop_test)\n",
    "#             Skewness_errors_test = np.append(Skewness_errors_test,Skewness_loop_test)\n",
    "#             Ex_Kurtosis_errors_test = np.append(Ex_Kurtosis_errors_test,Ex_Kurtosis_loop_test)\n",
    "#             ## Monte-Carlo\n",
    "#             Var_errors_MC_test = np.append(Var_errors_MC_test,Var_loop_MC_test)\n",
    "#             Skewness_errors_MC_test = np.append(Skewness_errors_MC_test,Skewness_loop_MC_test)\n",
    "#             Ex_Kurtosis_errors_MC_test = np.append(Ex_Kurtosis_errors_MC_test,Ex_Kurtosis_loop_MC_test)\n",
    "\n",
    "            \n",
    "# ## Get Error Statistics\n",
    "# W1_Errors_test = np.array(bootstrap(np.abs(W1_errors_test),n=N_Boostraps_BCA)(.95))\n",
    "# Mean_Errors_test =  np.array(bootstrap(np.abs(Mean_errors_test),n=N_Boostraps_BCA)(.95))\n",
    "# Mean_Errors_MC_test =  np.array(bootstrap(np.abs(Mean_errors_MC_test),n=N_Boostraps_BCA)(.95))\n",
    "# print(\"#------------------------#\")\n",
    "# print(\" Get Testing Error(s): END\")\n",
    "# print(\"#------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stop Timer\n",
    "# Type_A_timer_end = time.time()\n",
    "# # Compute Lapsed Time Needed For Training\n",
    "# Time_Lapse_Model_DNM = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary_pred_Qual_models = pd.DataFrame({\"DNM\":np.append(np.append(W1_Errors,\n",
    "#                                                                    Mean_Errors),\n",
    "#                                                          np.array([N_params_deep_classifier,\n",
    "#                                                                    Time_Lapse_Model_DNM,\n",
    "#                                                                    (timer_output/Test_Set_PredictionTime_MC)])),\n",
    "#                                     \"MC-Oracle\":np.append(np.append(np.repeat(0,3),\n",
    "#                                                                    Mean_Errors_MC),\n",
    "#                                                          np.array([0,\n",
    "#                                                                    Train_Set_PredictionTime_MC,\n",
    "#                                                                    (Test_Set_PredictionTime_MC/Test_Set_PredictionTime_MC)])),\n",
    "#                                    },index=[\"W1-95L\",\"W1\",\"W1-95R\",\"M-95L\",\"M\",\"M-95R\",\"N_Par\",\"Train_Time\",\"Test_Time/MC-Oracle_Test_Time\"])\n",
    "\n",
    "# Summary_pred_Qual_models_test = pd.DataFrame({\"DNM\":np.append(np.append(W1_Errors_test,\n",
    "#                                                                    Mean_Errors_test),\n",
    "#                                                          np.array([N_params_deep_classifier,\n",
    "#                                                                    Time_Lapse_Model_DNM,\n",
    "#                                                                    (timer_output/Test_Set_PredictionTime_MC)])),\n",
    "#                                     \"MC-Oracle\":np.append(np.append(np.repeat(0,3),\n",
    "#                                                                    Mean_Errors_MC_test),\n",
    "#                                                          np.array([0,\n",
    "#                                                                    Train_Set_PredictionTime_MC,\n",
    "#                                                                    (Test_Set_PredictionTime_MC/Test_Set_PredictionTime_MC)])),\n",
    "#                                    },index=[\"W1-95L\",\"W1\",\"W1-95R\",\"M-95L\",\"M\",\"M-95R\",\"N_Par\",\"Train_Time\",\"Test_Time/MC-Oracle_Test_Time\"])\n",
    "# ## Get Worst-Case\n",
    "# Summary_pred_Qual_models_train = Summary_pred_Qual_models\n",
    "# Summary_pred_Qual_models_internal = Summary_pred_Qual_models.copy()\n",
    "# Summary_pred_Qual_models = np.maximum(Summary_pred_Qual_models_internal,Summary_pred_Qual_models_test)\n",
    "# ## Write Performance Metrics\n",
    "# Summary_pred_Qual_models.to_latex((results_tables_path+\"Performance_metrics_Problem_Type_\"+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS.tex\"))\n",
    "# Summary_pred_Qual_models_train.to_latex((results_tables_path+\"Performance_metrics_Problem_Type_\"+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS_train.tex\"))\n",
    "# Summary_pred_Qual_models_test.to_latex((results_tables_path+\"Performance_metrics_Problem_Type_\"+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS_test.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      DNM     MC-Oracle\n",
      "W1-95L                           1.141484  0.000000e+00\n",
      "W1                               1.404066  0.000000e+00\n",
      "W1-95R                           1.647374  0.000000e+00\n",
      "M-95L                            0.936562  9.953533e-01\n",
      "M                                1.320928  1.320928e+00\n",
      "M-95R                            1.727533  1.698788e+00\n",
      "N_Par                          940.000000  0.000000e+00\n",
      "Train_Time                      16.282669  1.619738e+09\n",
      "Test_Time/MC-Oracle_Test_Time    0.956535  1.000000e+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>1.141484</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>1.404066</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>1.647374</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.936562</td>\n",
       "      <td>9.953533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1.320928</td>\n",
       "      <td>1.320928e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>1.727533</td>\n",
       "      <td>1.698788e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>940.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>16.282669</td>\n",
       "      <td>1.619738e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>0.956535</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      DNM     MC-Oracle\n",
       "W1-95L                           1.141484  0.000000e+00\n",
       "W1                               1.404066  0.000000e+00\n",
       "W1-95R                           1.647374  0.000000e+00\n",
       "M-95L                            0.936562  9.953533e-01\n",
       "M                                1.320928  1.320928e+00\n",
       "M-95R                            1.727533  1.698788e+00\n",
       "N_Par                          940.000000  0.000000e+00\n",
       "Train_Time                      16.282669  1.619738e+09\n",
       "Test_Time/MC-Oracle_Test_Time    0.956535  1.000000e+00"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(Summary_pred_Qual_models_test)\n",
    "# Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
