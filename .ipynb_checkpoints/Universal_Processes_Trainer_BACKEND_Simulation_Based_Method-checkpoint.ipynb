{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*.\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth:\n",
    "*The build-in Options:*\n",
    "- rSDE \n",
    "- pfBM\n",
    "- 2lnflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth = \"2lnflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 100\n",
    "N_Monte_Carlo_Samples = 10**3\n",
    "N_Monte_Carlo_Samples_Test = 10**3 # How many MC-samples to draw from test-set?\n",
    "\n",
    "# End times for Time-Grid\n",
    "T_end = 1\n",
    "T_end_test = 1.1\n",
    "\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 100\n",
    "Max_Grid = 1\n",
    "\n",
    "# \n",
    "N_Quantizers_to_parameterize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "N_measures_per_center = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP:\n",
    "from operator import itemgetter \n",
    "from itertools import compress\n",
    "# Set Minibatch Size\n",
    "Random_Cover_Mini_Batch_Size = 100\n",
    "# Proportion of Clusters per Minibatch Sample\n",
    "# Quantization_Proportion = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Measure-Valued $2$-Parameter Log-Gaussian Flow\n",
    "$$\n",
    "X_{t,x} \\sim \\log\\text{-}\\mathcal{N}\\left(\\alpha(t,x),\\beta(t,x)\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** *$\\alpha$ and $\\beta$ are specified below in the SDE Example*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Rough SDE\n",
    "Simulate via Euler-M method from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T((1-\\eta)\\beta(s,x)+\\eta\\sigma_s^H)dW_s.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return (t*np.sin(math.pi*x) + np.exp(t + np.cos(x)))-x + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 0.1*(1+t)*np.abs(np.cos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rougness = 0.9 # Hurst Parameter\n",
    "Ratio_fBM_to_typical_vol = 0 # $\\eta$ in equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed Fractional Brownian Motion\n",
    "Simulate from:\n",
    "$$\n",
    "X_t^x(\\omega) = f_1(x)f_2(t) + B_t^H(\\omega).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_dirction_x(x):\n",
    "    return x*np.cos(x)\n",
    "\n",
    "def finite_variation_t(t):\n",
    "    return t*(np.sin(math.pi*t) + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "# %run ParaGAN_Backend.ipynb\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of Auxiliary Internal-Variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "measure_weights_test = np.ones(N_Monte_Carlo_Samples_Test)/N_Monte_Carlo_Samples_Test\n",
    "\n",
    "# Get number of centers\n",
    "N_Centers_per_box = max(1,int(round(np.sqrt(N_Quantizers_to_parameterize))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Centers Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grid of Barycenters\n",
    "x_Grid_barycenters = np.arange(start=-Max_Grid,\n",
    "                               stop=Max_Grid,\n",
    "                               step = (2*Max_Grid/N_Centers_per_box))\n",
    "t_Grid_barycenters = np.arange(start=0,\n",
    "                               stop=T_end,\n",
    "                               step = (T_end/N_Centers_per_box))\n",
    "for x_i in range(len(x_Grid_barycenters)):\n",
    "    for t_j in range(len(t_Grid_barycenters)):\n",
    "        new_grid_entry = np.array([t_Grid_barycenters[t_j],x_Grid_barycenters[x_i]]).reshape(1,-1)\n",
    "        if (x_i==0 and t_j ==0):\n",
    "            Grid_Barycenters = new_grid_entry\n",
    "        else:\n",
    "            Grid_Barycenters = np.append(Grid_Barycenters,new_grid_entry,axis=0)\n",
    "\n",
    "# Update Number of Quantizers Generated\n",
    "N_Quantizers_to_parameterize = Grid_Barycenters.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Simulator.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer (Model Type A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training Data\n",
    "for i in range(Grid_Barycenters.shape[0]):\n",
    "    # Get output for center (mu-hat)\n",
    "    if groud_truth == \"2lnflow\":\n",
    "        center_current, trash = twoparameter_flow_sampler((Grid_Barycenters[i]).reshape(1,2),N_Monte_Carlo_Samples)\n",
    "    \n",
    "    # Get random sample in delta ball around ith center\n",
    "    sub_grid_loop = np.random.uniform(0,delta,(N_measures_per_center,2)) + Grid_Barycenters[i]\n",
    "    \n",
    "    # Get Measures for this random sample\n",
    "    if groud_truth == \"2lnflow\":\n",
    "        measures_locations_list_current, measures_weights_list_current = twoparameter_flow_sampler(sub_grid_loop,N_Monte_Carlo_Samples)\n",
    "    ##\n",
    "    measures_locations_list_current = measures_locations_list_current + center_current\n",
    "    measures_weights_list_current = measures_weights_list_current + trash\n",
    "    # Update Classes\n",
    "    Classifer_Wasserstein_Centers_loop = np.zeros([(N_measures_per_center+1),N_Quantizers_to_parameterize]) # The +1 is to account for the center which will be added to the random ball\n",
    "    Classifer_Wasserstein_Centers_loop[:, i] =  1\n",
    "    # Updates Classes\n",
    "    if i==0:\n",
    "        # INITIALIZE: Classifiers\n",
    "        Classifer_Wasserstein_Centers = Classifer_Wasserstein_Centers_loop\n",
    "        # INITIALIZE: Training Data\n",
    "        X_train = np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0)\n",
    "        # INITIALIZE: Barycenters Array\n",
    "        Barycenters_Array = (center_current[0]).reshape(-1,1)\n",
    "        # INITIALIZE: Measures and locations\n",
    "        measures_locations_list = measures_locations_list_current\n",
    "        measures_weights_list = measures_weights_list_current\n",
    "    else:\n",
    "        # UPDATE: Classifer\n",
    "        Classifer_Wasserstein_Centers = np.append(Classifer_Wasserstein_Centers,Classifer_Wasserstein_Centers_loop,axis=0)\n",
    "        # UPDATE: Training Data\n",
    "        X_train = np.append(X_train,np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0),axis=0)\n",
    "        # UPDATE: Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,((center_current[0]).reshape(-1,1)),axis=-1)\n",
    "        # UPDATE: Measures and locations\n",
    "        measures_locations_list = measures_locations_list + measures_locations_list_current\n",
    "        measures_weights_list = measures_locations_list + measures_weights_list_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Testing Dataset (Inputs)\n",
    "x_tests = x_Grid_barycenters#np.random.uniform(np.min(X_train[:,0]),np.max(X_train[:,0]),10)\n",
    "t_tests = np.arange(start=0,\n",
    "                    stop=T_end,\n",
    "                    step = (T_end_test/N_Euler_Maruyama_Steps))\n",
    "\n",
    "for x_i in range(len(x_tests)):\n",
    "    for t_j in range(len(t_tests)):\n",
    "        test_set_entry = np.array([t_tests[t_j],x_tests[x_i]]).reshape(1,-1)\n",
    "        if (x_i==0 and t_j ==0):\n",
    "            X_test = test_set_entry\n",
    "        else:\n",
    "            X_test = np.append(X_test,test_set_entry,axis=0)\n",
    "\n",
    "# Generate Testing Dataset (Outputs)\n",
    "if groud_truth == \"2lnflow\":\n",
    "        measures_locations_test_list, measures_weights_test_list = twoparameter_flow_sampler(sub_grid_loop,N_Monte_Carlo_Samples_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDEBUG\n",
    "\n",
    "# if groud_truth == \"2lnflow\":\n",
    "#     print(\"2lnflow!\")\n",
    "#     measures_locations_list, measures_weights_list, X_train = measure_valued_direct_sampling(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "#     measures_locations_list_test, measures_weights_list_test, X_test = measure_valued_direct_sampling(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)     \n",
    "\n",
    "# DEBUG LATER...\n",
    "# if groud_truth == \"rSDE\":\n",
    "#     print(\"rSDE!\")\n",
    "#     measures_locations_list, measures_weights_list, X_train = Euler_Maruyama_simulator(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "#     measures_locations_list_test, measures_weights_list_test, X_test = Euler_Maruyama_simulator(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)     \n",
    "    \n",
    "# if groud_truth == \"pfBM\":\n",
    "#     print(\"pFBM!\")\n",
    "#     measures_locations_list, measures_weights_list, X_train= perturbed_fBM_simulator(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "#     measures_locations_list_test, measures_weights_list_test, X_test= perturbed_fBM_simulator(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8840 - accuracy: 0.0306\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8519 - accuracy: 0.0510\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8236 - accuracy: 0.0255\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7939 - accuracy: 0.0561\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7587 - accuracy: 0.0612\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7158 - accuracy: 0.0612\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6629 - accuracy: 0.1020\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5984 - accuracy: 0.1276\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5201 - accuracy: 0.1531\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4327 - accuracy: 0.1378\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3391 - accuracy: 0.1276\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2393 - accuracy: 0.1224\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1414 - accuracy: 0.1327\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.0444 - accuracy: 0.1276\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9531 - accuracy: 0.1480\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8594 - accuracy: 0.2041\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7692 - accuracy: 0.2398\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6803 - accuracy: 0.2143\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6032 - accuracy: 0.2143\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5098 - accuracy: 0.2653\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4193 - accuracy: 0.2857\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.3366 - accuracy: 0.3112\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2592 - accuracy: 0.3980\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1881 - accuracy: 0.3929\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1035 - accuracy: 0.4337\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0486 - accuracy: 0.4490\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9815 - accuracy: 0.4541\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9071 - accuracy: 0.4898\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8649 - accuracy: 0.5459\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7985 - accuracy: 0.5612\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7383 - accuracy: 0.5459\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6842 - accuracy: 0.6173\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6552 - accuracy: 0.5357\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5963 - accuracy: 0.6327\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5244 - accuracy: 0.6990\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4783 - accuracy: 0.7092\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4438 - accuracy: 0.7398\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4052 - accuracy: 0.7092\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3478 - accuracy: 0.7398\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3099 - accuracy: 0.7245\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2761 - accuracy: 0.8214\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2329 - accuracy: 0.8418\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1969 - accuracy: 0.8010\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1501 - accuracy: 0.8469\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1198 - accuracy: 0.8622\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1078 - accuracy: 0.8061\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0582 - accuracy: 0.8622\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0229 - accuracy: 0.8929\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9969 - accuracy: 0.8163\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9752 - accuracy: 0.8265\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9388 - accuracy: 0.8418\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9074 - accuracy: 0.9133\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8628 - accuracy: 0.9286\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8726 - accuracy: 0.8776\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8489 - accuracy: 0.8520\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7929 - accuracy: 0.9388\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7913 - accuracy: 0.8776\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7516 - accuracy: 0.9184\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.9184\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.9643\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.9541\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.9643\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.9796\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.9643\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.9439\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.9796\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.9898\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.9847\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.9796\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.9643\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.9541\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.9847\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.9796\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.9745\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.9694\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.9898\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.9847\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.9694\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.9898\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0782 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 958us/step\n",
      "20/20 [==============================] - 0s 940us/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [2]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 87.78it/s] \n",
      " 22%|██▏       | 11/49 [00:00<00:00, 108.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:01<00:00, 35.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Format Weights\n",
    "## Train\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): START\")\n",
    "print(\"#---------------------------------------#\")\n",
    "Predicted_Weights = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    b = np.repeat(np.array(predicted_classes_train[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): END\")\n",
    "print(\"#-------------------------------------#\")\n",
    "\n",
    "## Test\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): START\")\n",
    "print(\"#-------------------------------------#\")\n",
    "Predicted_Weights_test = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):\n",
    "    b_test = np.repeat(np.array(predicted_classes_test[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b_test = b_test/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights_test = b_test\n",
    "    else:\n",
    "        Predicted_Weights_test = np.append(Predicted_Weights_test,b_test,axis=1)\n",
    "print(\"#-----------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): END\")\n",
    "print(\"#-----------------------------------#\")\n",
    "        \n",
    "# Format Points of Mass\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: START\")\n",
    "print(\"#-----------------------------#\")\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: END\")\n",
    "print(\"#-----------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/195 [00:00<00:02, 88.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:01<00:00, 101.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.079693</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>1.378677e+00</td>\n",
       "      <td>2.602767</td>\n",
       "      <td>8.737523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1219.186777</td>\n",
       "      <td>8.237771</td>\n",
       "      <td>1.275062e+10</td>\n",
       "      <td>136.421835</td>\n",
       "      <td>207.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>43945.911293</td>\n",
       "      <td>179.374987</td>\n",
       "      <td>8.367221e+11</td>\n",
       "      <td>1598.705769</td>\n",
       "      <td>2086.978383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min      0.079693    0.005531         1.378677e+00                2.602767   \n",
       "MAE   1219.186777    8.237771         1.275062e+10              136.421835   \n",
       "Max  43945.911293  179.374987         8.367221e+11             1598.705769   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              8.737523  \n",
       "MAE            207.957600  \n",
       "Max           2086.978383  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Training Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "Skewness_errors = np.array([])\n",
    "Kurtosis_errors = np.array([])\n",
    "predictions_mean = np.array([])\n",
    "true_mean = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measure_weights.reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(np.array(measures_locations_list[x_i]))\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    ## Update Erros\n",
    "    predictions_mean = np.append(predictions_mean,Mu_hat)\n",
    "    true_mean = np.append(true_mean,Mu)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(np.array(measures_locations_list[x_i])**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat = np.sum((Barycenters_Array**3)*(Predicted_Weights[x_i]))\n",
    "    Skewness = np.mean(np.array(measures_locations_list[x_i])**3)\n",
    "    Skewness_errors = np.append(Skewness_errors,(abs(Skewness_hat-Skewness))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat = np.sum((Barycenters_Array**4)*(Predicted_Weights[x_i]))\n",
    "    Kurtosis = np.mean(np.array(measures_locations_list[x_i])**4)\n",
    "    Kurtosis_errors = np.append(Kurtosis_errors,(abs(Kurtosis_hat-Kurtosis))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.min(np.abs(W1_errors)),np.mean(np.abs(W1_errors)),np.max(np.abs(W1_errors))])\n",
    "Mean_prediction_Performance = np.array([np.min(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors)),np.max(np.abs(Mean_errors))])\n",
    "Var_prediction_Performance = np.array([np.min(np.abs(Var_errors)),np.mean(np.abs(Var_errors)),np.max(np.abs(Var_errors))])\n",
    "Skewness_prediction_Performance = np.array([np.min(np.abs(Skewness_errors)),np.mean(np.abs(Skewness_errors)),np.max(np.abs(Skewness_errors))])\n",
    "Kurtosis_prediction_Performance = np.array([np.min(np.abs(Kurtosis_errors)),np.mean(np.abs(Kurtosis_errors)),np.max(np.abs(Kurtosis_errors))])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Train.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff8137a0c10>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean,label=\"prediction\",color=\"purple\")\n",
    "plt.plot(true_mean,label=\"true\",color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 89.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Test Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors_test = np.array([])\n",
    "Mean_errors_test = np.array([])\n",
    "Var_errors_test = np.array([])\n",
    "Skewness_errors_test = np.array([])\n",
    "Kurtosis_errors_test = np.array([])\n",
    "# Initialize Prediction Metrics\n",
    "predictions_mean_test = np.array([])\n",
    "true_mean_test = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_test_list))):    \n",
    "    # Get Laws\n",
    "    W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_test_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights_test[x_i,].reshape(-1,),\n",
    "                         (measures_weights_test_list[x_i]).reshape(-1,))\n",
    "    W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "    # Get Means\n",
    "    Mu_hat_test = np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array))\n",
    "    Mu_test = np.mean(np.array(measures_locations_test_list[x_i]))\n",
    "    Mean_errors_test = np.append(Mean_errors_test,(Mu_hat_test-Mu_test))\n",
    "    ## Update Predictions\n",
    "    predictions_mean_test = np.append(predictions_mean_test,Mu_hat_test)\n",
    "    true_mean_test = np.append(true_mean_test,Mu_test)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat_test = np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))\n",
    "    Var_test = np.mean(np.array(measures_locations_test_list[x_i])**2)\n",
    "    Var_errors_test = np.append(Var_errors_test,(Var_hat_test-Var_test)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat_test = np.sum((Barycenters_Array**3)*(Predicted_Weights_test[x_i]))\n",
    "    Skewness_test = np.mean(np.array(measures_locations_test_list[x_i])**3)\n",
    "    Skewness_errors_test = np.append(Skewness_errors_test,(abs(Skewness_hat_test-Skewness_test))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat_test = np.sum((Barycenters_Array**4)*(Predicted_Weights_test[x_i]))\n",
    "    Kurtosis_test = np.mean(np.array(measures_locations_test_list[x_i])**4)\n",
    "    Kurtosis_errors_test = np.append(Kurtosis_errors_test,(abs(Kurtosis_hat_test-Kurtosis_test))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance_test = np.array([np.min(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test))])\n",
    "Mean_prediction_Performance_test = np.array([np.min(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test))])\n",
    "Var_prediction_Performance_test = np.array([np.min(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test))])\n",
    "Skewness_prediction_Performance_test = np.array([np.min(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test))])\n",
    "Kurtosis_prediction_Performance_test = np.array([np.min(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test))])\n",
    "\n",
    "Type_A_Prediction_test = pd.DataFrame({\"W1\":W1_Performance_test,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance_test,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance_test,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance_test,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance_test},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction_test.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Test.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff7b86d8f90>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean_test,color=\"purple\")\n",
    "plt.plot(true_mean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print for Terminal Legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "               W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min      0.079693    0.005531         1.378677e+00                2.602767   \n",
      "MAE   1219.186777    8.237771         1.275062e+10              136.421835   \n",
      "Max  43945.911293  179.374987         8.367221e+11             1598.705769   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              8.737523  \n",
      "MAE            207.957600  \n",
      "Max           2086.978383  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "                W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  144622.146051  365.484786         3.182769e+10              441.595038   \n",
      "MAE  150487.509883  370.594563         3.423979e+10              451.921356   \n",
      "Max  150487.509883  370.594563         3.423979e+10              451.921356   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min            459.299222  \n",
      "MAE            472.615981  \n",
      "Max            472.615981  \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------------#\")\n",
    "print(\"Training-Set Performance\")\n",
    "print(\"#----------------------#\")\n",
    "print(Type_A_Prediction)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"#------------------#\")\n",
    "print(\"Test-Set Performance\")\n",
    "print(\"#------------------#\")\n",
    "print(Type_A_Prediction_test)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.079693</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>1.378677e+00</td>\n",
       "      <td>2.602767</td>\n",
       "      <td>8.737523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1219.186777</td>\n",
       "      <td>8.237771</td>\n",
       "      <td>1.275062e+10</td>\n",
       "      <td>136.421835</td>\n",
       "      <td>207.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>43945.911293</td>\n",
       "      <td>179.374987</td>\n",
       "      <td>8.367221e+11</td>\n",
       "      <td>1598.705769</td>\n",
       "      <td>2086.978383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min      0.079693    0.005531         1.378677e+00                2.602767   \n",
       "MAE   1219.186777    8.237771         1.275062e+10              136.421835   \n",
       "Max  43945.911293  179.374987         8.367221e+11             1598.705769   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              8.737523  \n",
       "MAE            207.957600  \n",
       "Max           2086.978383  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>144622.146051</td>\n",
       "      <td>365.484786</td>\n",
       "      <td>3.182769e+10</td>\n",
       "      <td>441.595038</td>\n",
       "      <td>459.299222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>150487.509883</td>\n",
       "      <td>370.594563</td>\n",
       "      <td>3.423979e+10</td>\n",
       "      <td>451.921356</td>\n",
       "      <td>472.615981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>150487.509883</td>\n",
       "      <td>370.594563</td>\n",
       "      <td>3.423979e+10</td>\n",
       "      <td>451.921356</td>\n",
       "      <td>472.615981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  144622.146051  365.484786         3.182769e+10              441.595038   \n",
       "MAE  150487.509883  370.594563         3.423979e+10              451.921356   \n",
       "Max  150487.509883  370.594563         3.423979e+10              451.921356   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min            459.299222  \n",
       "MAE            472.615981  \n",
       "Max            472.615981  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
