{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\omega^{-1}(\\epsilon)$-Bounded Random Partitioner\n",
    "Generates a bounded random partition, in the sense of: [Geometry, Flows, and Graph-Partitioning Algorithms](https://cacm.acm.org/magazines/2008/10/515-geometry-flows-and-graph-partitioning-algorithms/fulltext?mobile=false), [A. Naor et al.](https://link.springer.com/article/10.1007/s00222-004-0400-5), as implemented in [Learning Sub-Patterns in Piece-Wise Continuous Functions](https://arxiv.org/abs/2010.15571)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize #\n",
    "#------------#\n",
    "X_training_remaining = np.copy(X_train)\n",
    "possible_indices_for_center = np.repeat(True,X_training_remaining.shape[0])\n",
    "indexing_set = np.array(range(X_training_remaining.shape[0]))\n",
    "\n",
    "# Tweak Radius of Balls\n",
    "# Note: To avoid \"too small\" of a delta\n",
    "dist_matrix = (distance_matrix(X_training_remaining[np.random.choice(indexing_set,max(1,round(X_training_remaining.shape[0]*.5)))],X_training_remaining[np.random.choice(indexing_set,max(1,round(X_training_remaining.shape[0]*.5)))]))\n",
    "dist_matrix = (dist_matrix[np.logical_not(dist_matrix == 0)]).reshape(-1,)\n",
    "delta = np.maximum(delta,np.quantile(dist_matrix,Proportion_per_cluster))\n",
    "\n",
    "\n",
    "\n",
    "# Build #\n",
    "#-------#\n",
    "while np.max(possible_indices_for_center)==True:  \n",
    "    # Randomize Radius\n",
    "    delta_loop = np.random.uniform(low=0,high=delta,size=1)[0]\n",
    "\n",
    "    # Get Random Center\n",
    "    random_center_loop_index = np.random.choice(indexing_set[possible_indices_for_center])\n",
    "    random_center_loop = (X_training_remaining[random_center_loop_index]).reshape([1,-1])\n",
    "\n",
    "    # Get Distances To Current Center\n",
    "    dist_mat_loop = np.sqrt(np.sum((random_center_loop-X_training_remaining)**2,axis=1))\n",
    "    ## Indentify which must lie in cluster but not counting previously removed elements\n",
    "    indices_cluster_loop = (dist_mat_loop<delta_loop)*possible_indices_for_center\n",
    "\n",
    "    # Update(s)\n",
    "    ## Outputs\n",
    "    if np.min(possible_indices_for_center)==True:\n",
    "        ## Initialize Classes\n",
    "        Train_classes = (indices_cluster_loop*1).reshape(-1,1)\n",
    "        ## PointMasses Center\n",
    "        Masses = int(random_center_loop_index)\n",
    "        # INITIALIZE: Barycenters Array\n",
    "        Barycenters_Array = (Y_train[int(random_center_loop_index)]).reshape(-1,)\n",
    "    else:\n",
    "        ## Update Classes\n",
    "        Train_classes = np.append(Train_classes,(indices_cluster_loop*1).reshape(-1,1),axis=-1)\n",
    "        ## PointMasses Center\n",
    "        Masses = np.append(Masses,random_center_loop_index)\n",
    "        # UPDATE: Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,(Y_train[int(random_center_loop_index)]).reshape(-1,),axis=-1)\n",
    "    ## Remove Clusterd Centers from Current Dataset\n",
    "    possible_indices_for_center = np.logical_not(indices_cluster_loop)*possible_indices_for_center\n",
    "\n",
    "# Format Training Classes\n",
    "Train_classes = pd.DataFrame(Train_classes)\n",
    "\n",
    "# Get Number of Classes\n",
    "N_Quantizers_to_parameterize = Train_classes.shape[1]\n",
    "\n",
    "# Update User #\n",
    "print(\"---------------\")\n",
    "print(\"==============---------------------------------------------------=============\")\n",
    "print(\"Number of Classes/measures Which Were Produced:\", N_Quantizers_to_parameterize)\n",
    "print(\"==============---------------------------------------------------=============\")\n",
    "print(\"===========================\")\n",
    "print(\"Training Classes Produced:\")\n",
    "print(\"===========================\")\n",
    "print(Train_classes)\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-15ce80ca783f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.sample(np.array([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "\n",
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\"\n",
    "\n",
    "\n",
    "### Set Seed\n",
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_internal = W_hidden_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.472991])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_unknown(np.ones(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
