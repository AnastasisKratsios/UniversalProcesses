{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*.\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth:\n",
    "*The build-in Options:*\n",
    "- rSDE \n",
    "- pfBM\n",
    "- 2lnflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth = \"rSDE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 10\n",
    "N_Monte_Carlo_Samples = 10**1\n",
    "N_Monte_Carlo_Samples_Test = 10**1 # How many MC-samples to draw from test-set?\n",
    "\n",
    "# End times for Time-Grid\n",
    "T_end = 1\n",
    "T_end_test = 1.1\n",
    "\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 10\n",
    "Max_Grid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP:\n",
    "from operator import itemgetter \n",
    "from itertools import compress\n",
    "# Set Minibatch Size\n",
    "Random_Cover_Mini_Batch_Size = 100\n",
    "# Proportion of Clusters per Minibatch Sample\n",
    "Quantization_Proportion = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Measure-Valued $2$-Parameter Gaussian Flow\n",
    "$$\n",
    "X_{t,x} \\sim \\mathcal{N}\\left(\\alpha(t,x),\\beta(t,x)\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** *$\\alpha$ and $\\beta$ are specified below in the SDE Example*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Rough SDE\n",
    "Simulate via Euler-M method from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T((1-\\eta)\\beta(s,x)+\\eta\\sigma_s^H)dW_s.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return .1*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rougness = 0.9 # Hurst Parameter\n",
    "Ratio_fBM_to_typical_vol = 0 # $\\eta$ in equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed Fractional Brownian Motion\n",
    "Simulate from:\n",
    "$$\n",
    "X_t^x(\\omega) = f_1(x)f_2(t) + B_t^H(\\omega).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_dirction_x(x):\n",
    "    return x*np.cos(x)\n",
    "\n",
    "def finite_variation_t(t):\n",
    "    return t*(np.sin(math.pi*t) + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "# %run ParaGAN_Backend.ipynb\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Grid\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each minibatch grid axis:  10\n",
      "â€¢ Grid Instances:  110 and : 6  Testing instances.\n"
     ]
    }
   ],
   "source": [
    "# Get Input Data\n",
    "#----------------------------------------------------------#\n",
    "## Train\n",
    "x_Grid = np.arange(start=-Max_Grid,\n",
    "                   stop=Max_Grid,\n",
    "                   step=(2*Max_Grid/N_Grid_Finess))\n",
    "t_Grid = np.linspace(0,T_end,(1+N_Euler_Maruyama_Steps))\n",
    "## Get Number of Instances in Grid: Training\n",
    "N_Grid_Instances_x = len(x_Grid)\n",
    "N_Grid_Instances_t = len(t_Grid)\n",
    "N_Grid_Instances = N_Grid_Instances_x*N_Grid_Instances_t \n",
    "\n",
    "#----------------------------------------------------------#\n",
    "## Test\n",
    "x_Grid_test = np.sort(np.random.uniform(low=-Max_Grid,\n",
    "                                        high=Max_Grid,\n",
    "                                        size = max(round(len(x_Grid)*test_size_ratio),2)))\n",
    "t_Grid_test = np.linspace(T_end+0.001,T_end_test,(1+round(N_Euler_Maruyama_Steps*test_size_ratio)))\n",
    "# Get Number of Instances in Grid: Test\n",
    "N_Grid_Instances_x_test = len(x_Grid_test)\n",
    "N_Grid_Instances_t_test = len(t_Grid_test)\n",
    "N_Grid_Instances_test = N_Grid_Instances_x_test*N_Grid_Instances_t_test\n",
    "#----------------------------------------------------------#\n",
    "\n",
    "# Set Minibatch size\n",
    "Covering_Mini_Batch_Size = int(np.max(round(np.sqrt(Random_Cover_Mini_Batch_Size),1)))\n",
    "print(\"Number of points in each minibatch grid axis: \", Covering_Mini_Batch_Size)\n",
    "\n",
    "# Updater User\n",
    "print(\"\\u2022 Grid Instances: \", N_Grid_Instances, \"and :\",N_Grid_Instances_test,\" Testing instances.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Counting Parameters\n",
    "Initialize the \"conting\" type parameters which will help us to determine the length of loops and to intialize object's size later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ 82  Centers will be produced; from a total datasize of:  10 !  (That's  0.75  percent).\n",
      "â€¢ Each Wasserstein-1 Ball should contain:  1 elements from the training set.\n"
     ]
    }
   ],
   "source": [
    "# Get Internal (Counting) Parameters\n",
    "N_Quantizers_to_parameterize = round(Quantization_Proportion*N_Grid_Instances)\n",
    "N_Elements_Per_Cluster = int(round(N_Grid_Instances/N_Quantizers_to_parameterize))\n",
    "\n",
    "# Update User\n",
    "print(\"\\u2022\",N_Quantizers_to_parameterize,\" Centers will be produced; from a total datasize of: \",N_Grid_Finess,\n",
    "      \"!  (That's \",Quantization_Proportion,\n",
    "      \" percent).\")\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate from non-Markovian SDE with rough volatility:\n",
    "$d X_t = \\alpha(t,X_t)dt + ((1-\\eta)\\beta(t,X_t)+\\eta\\sigma_t^H)dW_t ;\\qquad X_0 =x$\n",
    "Where $(\\sigma_t^H)_t$ is a fBM with Hurst parameter $H=0.01$ and $\\eta \\in [0,1]$ controlls the 'abount of long-term memory and roughness in $X_t$'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Sampler - Data-Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Simulator.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List of Barycenters\n",
    "Wasserstein_Barycenters = []\n",
    "# Initialize Terminal-Time Empirical Measures\n",
    "## Training Outputs\n",
    "measures_locations_list = []\n",
    "measures_weights_list = []\n",
    "## Testing Outputs\n",
    "measures_locations_test_list = []\n",
    "measures_weights_test_list = []\n",
    "# Grid (Training and Testing inputs (t,x))\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "measure_weights_test = np.ones(N_Monte_Carlo_Samples_Test)/N_Monte_Carlo_Samples_Test\n",
    "# Initialize Quantizer\n",
    "Init_Quantizer_generic = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $\\{\\hat{\\nu}^{N}_{T,x}\\}_{x \\in \\mathbb{X}}$ Build Wasserstein Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Training and Testing Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian $2$-Parameter Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 128.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 193.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rSDE!\n",
      "Using Euler-Maruyama distritization + Monte-Carlo Sampling.\n",
      "===================================\n",
      "Start Simulation Step: Training Set\n",
      "===================================\n",
      "==================================\n",
      "Done Simulation Step: Training Set\n",
      "==================================\n",
      "Using Euler-Maruyama distritization + Monte-Carlo Sampling.\n",
      "===================================\n",
      "Start Simulation Step: Training Set\n",
      "===================================\n",
      "==================================\n",
      "Done Simulation Step: Training Set\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if groud_truth == \"2lnflow\":\n",
    "    print(\"2lnflow!\")\n",
    "    measures_locations_list, measures_weights_list, X_train = measure_valued_direct_sampling(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "    measures_locations_list_test, measures_weights_list_test, X_test = measure_valued_direct_sampling(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)     \n",
    "\n",
    "if groud_truth == \"rSDE\":\n",
    "    print(\"rSDE!\")\n",
    "    measures_locations_list, measures_weights_list, X_train = Euler_Maruyama_simulator(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "    measures_locations_list_test, measures_weights_list_test, X_test = Euler_Maruyama_simulator(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)     \n",
    "    \n",
    "if groud_truth == \"pfBM\":\n",
    "    print(\"pFBM!\")\n",
    "    measures_locations_list, measures_weights_list, X_train= perturbed_fBM_simulator(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "    measures_locations_list_test, measures_weights_list_test, X_test= perturbed_fBM_simulator(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbed fBM Generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbed_fBM_simulator(x_Grid,t_Grid,N_Monte_Carlo_Samples=10):\n",
    "    ## Get Dimensions\n",
    "    N_Grid_Instances_x = x_Grid.shape[0]\n",
    "    N_Grid_Instances_t = t_Grid.shape[0]\n",
    "    # Initializations\n",
    "    measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "    measures_locations_list_internal = []\n",
    "    measures_weights_list_internal = []\n",
    "\n",
    "\n",
    "    print(\"===================================\")\n",
    "    print(\"Start Simulation Step: Training Set\")\n",
    "    print(\"===================================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator = FBM(n=N_Euler_Maruyama_Steps, hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid).reshape(-1,1) +field_loop_x\n",
    "        for n_MC in range(N_Monte_Carlo_Samples):\n",
    "            fBM_variation_path_loop = fBM_Generator.fbm().reshape(-1,1)\n",
    "            generated_path_loop = finite_variation_path + fBM_variation_path_loop\n",
    "            if n_MC == 0:\n",
    "                paths_loop = generated_path_loop\n",
    "            else:\n",
    "                paths_loop = np.append(paths_loop,generated_path_loop,axis=-1)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_train_loop = np.append(np.repeat(x_Grid[i],(N_Euler_Maruyama_Steps+1)).reshape(-1,1),\n",
    "                                 t_Grid.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_list_internal = measures_locations_list_internal + measures_locations_loop\n",
    "        measures_weights_list_internal.append(measure_weights)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_grid_internal = X_train_loop\n",
    "        else:\n",
    "            X_grid_internal = np.append(X_train,X_train_loop,axis=0)\n",
    "    \n",
    "    # Update User\n",
    "    print(\"======================\")\n",
    "    print(\" Done Simulation Step \")\n",
    "    print(\"======================\")\n",
    "    \n",
    "    return measures_locations_list_internal, measures_weights_list_internal, X_grid_internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step:\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"Current Monte-Carlo Step:\")\n",
    "if groud_truth == \"pfBM\":\n",
    "    print(\"===================================\")\n",
    "    print(\"Start Simulation Step: Training Set\")\n",
    "    print(\"===================================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator = FBM(n=N_Euler_Maruyama_Steps, hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid).reshape(-1,1) +field_loop_x\n",
    "        for n_MC in range(N_Monte_Carlo_Samples):\n",
    "            fBM_variation_path_loop = fBM_Generator.fbm().reshape(-1,1)\n",
    "            generated_path_loop = finite_variation_path + fBM_variation_path_loop\n",
    "            if n_MC == 0:\n",
    "                paths_loop = generated_path_loop\n",
    "            else:\n",
    "                paths_loop = np.append(paths_loop,generated_path_loop,axis=-1)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_train_loop = np.append(np.repeat(x_Grid[i],(N_Euler_Maruyama_Steps+1)).reshape(-1,1),\n",
    "                                 t_Grid.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_list = measures_locations_list + measures_locations_loop\n",
    "        measures_weights_list.append(measure_weights)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_train = X_train_loop\n",
    "        else:\n",
    "            X_train = np.append(X_train,X_train_loop,axis=0)\n",
    "    \n",
    "    # Update User\n",
    "    print(\"==================================\")\n",
    "    print(\"Done Simulation Step: Training Set\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "\n",
    "if groud_truth == \"pfBM\":\n",
    "    print(\"===============================\")\n",
    "    print(\"Start Simulation Step: Test Set\")\n",
    "    print(\"===============================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator_test = FBM(n=(len(t_Grid_test)-1), hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x_test)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid_test[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid_test).reshape(-1,1) +field_loop_x\n",
    "        for n_MC in range(N_Monte_Carlo_Samples_Test):\n",
    "            fBM_variation_path_loop = fBM_Generator_test.fbm().reshape(-1,1)\n",
    "            generated_path_loop = finite_variation_path + fBM_variation_path_loop\n",
    "            if n_MC == 0:\n",
    "                paths_loop = generated_path_loop\n",
    "            else:\n",
    "                paths_loop = np.append(paths_loop,generated_path_loop,axis=-1)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_test_loop = np.append(np.repeat(x_Grid_test[i],len(t_Grid_test)).reshape(-1,1),\n",
    "                                 t_Grid_test.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_test_list = measures_locations_test_list + measures_locations_loop\n",
    "        measures_weights_test_list.append(measure_weights_test)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_test = X_test_loop\n",
    "        else:\n",
    "            X_test = np.append(X_test,X_test_loop,axis=0)\n",
    "    print(\"==============================\")\n",
    "    print(\"Done Simulation Step: Test Set\")\n",
    "    print(\"==============================\")\n",
    "    \n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer (Model Type A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dissimilarity (Distance) Matrix\n",
    "*In this step we build a dissimularity matrix of the dataset on the Wasserstein-1 space.  Namely:*\n",
    "$$\n",
    "\\operatorname{Mat}_{\\# \\mathbb{X},\\# \\mathbb{X}}\\left(\\mathbb{R}\\right)\\ni D; \\text{ where}\\qquad \\, D_{i,j}\\triangleq \\mathcal{W}_1\\left(f(x_i),f(x_j)\\right)\n",
    ";\n",
    "$$\n",
    "*where $f\\in C\\left((\\mathcal{X},\\mathcal{P}_1(\\mathcal{Y})\\right)$ is the \"target\" function we are learning.*\n",
    "\n",
    "**Note**: *Computing the dissimularity matrix is the most costly part of the entire algorithm with a complexity of at-most $\\mathcal{O}\\left(E_{W} \\# \\mathbb{X})^2\\right)$ where $E_W$ denotes the complexity of a single Wasserstein-1 evaluation between two elements of the dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Minibatch Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/110 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜€  Building Random Covering ðŸ˜€ !\n",
      "Data-Points per Random Sample:  12100\n",
      "0\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  0\n",
      "Remaining points to cluster:  110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [00:01<00:00, 68.82it/s]\n",
      "  0%|          | 0/82 [00:00<?, ?it/s]/usr/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in multiply\n",
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:109: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:00<00:00, 8846.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "Average Classes Per Sample Barycenter:  1.0\n",
      "Left-Overs: 0\n",
      "----------------------------------------------------------------------------------------------\n",
      "ðŸ˜€  Done Random Covering ðŸ˜€ !\n",
      "(82, 110)\n",
      "110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"\\U0001F600\",\" Building Random Covering\",\"\\U0001F600\",\"!\")\n",
    "\n",
    "\n",
    "#-----------------#\n",
    "# Initializations #\n",
    "#-----------------#\n",
    "Covering_Mini_Batch_Size = N_Grid_Instances\n",
    "print(\"Data-Points per Random Sample: \", Covering_Mini_Batch_Size**2)\n",
    "\n",
    "# Initialize Inder for intput/output data\n",
    "index_remaining = np.array(range(len(measures_locations_list)))\n",
    "# Count number of remaining datums to cluster:\n",
    "length_of_sample = len(index_remaining)\n",
    "# Initialize Mini-batch iteration counter\n",
    "mini_batch_iteration_counter = 0\n",
    "# Initialize Classes\n",
    "Classifer_Wasserstein_Centers = np.zeros([N_Quantizers_to_parameterize,N_Grid_Instances])\n",
    "i=0\n",
    "#--------------------#\n",
    "# Build Random-Cover #\n",
    "#--------------------#\n",
    "while length_of_sample >0:\n",
    "    print(i) # TEMP\n",
    "    i=i+1 #TEMP\n",
    "    print(\"\\u2922 Current iteration of Mini-Batch Random Covering: \",mini_batch_iteration_counter)\n",
    "    # Update User\n",
    "    print(\"Remaining points to cluster: \",length_of_sample)\n",
    "    \n",
    "    #---------------------------------#\n",
    "    # Get Random Sample for Minibatch #\n",
    "    #---------------------------------#\n",
    "    ## Get indices\n",
    "    which_to_sample = np.random.choice(index_remaining.shape[0], min(Covering_Mini_Batch_Size,length_of_sample), replace=False) \n",
    "    clustering_indices_minibatch = index_remaining[which_to_sample]\n",
    "    ## Get Indices for current sample\n",
    "    indices_to_remove_loop = np.flatnonzero(np.isin(index_remaining,clustering_indices_minibatch))\n",
    "#     print(np.isin(index_remaining,clustering_indices_minibatch))\n",
    "    \n",
    "    ## FAILSAFE\n",
    "    if length_of_sample ==0:\n",
    "        break\n",
    "\n",
    "    #---------------------------#\n",
    "    # Build Disimilarity Matrix #\n",
    "    #---------------------------#\n",
    "    Dissimilarity_matrix_ot_current = np.zeros([Covering_Mini_Batch_Size,Covering_Mini_Batch_Size])\n",
    "    # Build Disimilarity Matrix\n",
    "    for i in tqdm(range(Covering_Mini_Batch_Size)):\n",
    "        index_i = indices_to_remove_loop[i]\n",
    "        for j in range(Covering_Mini_Batch_Size):\n",
    "            index_j = indices_to_remove_loop[j]\n",
    "            Dissimilarity_matrix_ot_current[i,j] = ot.emd2_1d(measures_locations_list[index_j],\n",
    "                                                              measures_locations_list[index_i])\n",
    "\n",
    "\n",
    "    #----------------------------#\n",
    "    # Inidialize Looping Indices #\n",
    "    #----------------------------#\n",
    "    # Initialize \"Internal to loop\" subset of measures\n",
    "    measures_locations_list_current = [measures_locations_list[i] for i in indices_to_remove_loop]\n",
    "    # Initialize masker vector\n",
    "    masker = np.ones(Covering_Mini_Batch_Size)\n",
    "    # Initialize Sorting Reference Vector (This helps us efficiently scroll through the disimularity matrix to identify the barycenter without having to re-compute the dissimultarity matrix of a sub-saple at every iteration (which is the most costly part of the algorithm!))\n",
    "    Distances_Loop = Dissimilarity_matrix_ot_current.sum(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------#\n",
    "    # Build Sample Barycenters #\n",
    "    #--------------------------#\n",
    "    # Identify Sample Barycenters\n",
    "    for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "        # GET BARYCENTER #\n",
    "        #----------------#\n",
    "        ## Identify row with minimum total distance\n",
    "        Barycenter_index = int(Distances_Loop.argsort()[:1][0])\n",
    "        ## Get Barycenter\n",
    "        ## Update Barycenters Array ##\n",
    "        #----------------------------#\n",
    "        ### Get next Barycenter\n",
    "        new_barycenter_loop = np.array(measures_locations_list_current[Barycenter_index]).reshape(-1,1)\n",
    "        ### Update Array of Barycenters\n",
    "        if i == 0:\n",
    "            # Initialize Barycenters Array\n",
    "            Barycenters_Array = new_barycenter_loop\n",
    "        else:\n",
    "            # Populate Barycenters Array\n",
    "            Barycenters_Array = np.append(Barycenters_Array,new_barycenter_loop,axis=-1)\n",
    "\n",
    "        # GET CLUSTER #\n",
    "        #-------------#\n",
    "        # Identify Cluster for this barycenter (which elements are closest to it)\n",
    "        Cluster_indices = (masker*Dissimilarity_matrix_ot_current[:,Barycenter_index]).argsort()[:N_Elements_Per_Cluster]\n",
    "        \n",
    "        ## UPDATE Set  M^{(n)} ##\n",
    "        #-----------------------#\n",
    "        Dissimilarity_matrix_ot_current[Cluster_indices,:] = 0\n",
    "        # Distance-Based Sorting\n",
    "        Distances_Loop[Cluster_indices] = math.inf\n",
    "\n",
    "        # Update Cluster\n",
    "        masker[Cluster_indices] = math.inf\n",
    "\n",
    "        # Update Classes\n",
    "        Classifer_Wasserstein_Centers[i,(indices_to_remove_loop[Cluster_indices])] = 1\n",
    "        \n",
    "        ## UPDATE: Remove Indices from \"Remaining Data\"\n",
    "        index_remaining = np.delete(index_remaining,indices_to_remove_loop)\n",
    "        ## UPDATE: Length of Sample\n",
    "        length_of_sample = len(index_remaining)\n",
    "        ## UPDATE: Mini-batch iteration counter\n",
    "        mini_batch_iteration_counter = mini_batch_iteration_counter+1\n",
    "\n",
    "#     pd.DataFrame(Classifer_Wasserstein_Centers)\n",
    "    # print(np.sum(Classifer_Wasserstein_Centers,axis=0))\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Classes Per Sample Barycenter: \", np.mean(np.sum(Classifer_Wasserstein_Centers,axis=1)))\n",
    "print(\"Left-Overs:\",length_of_sample)\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Random Covering\",\"\\U0001F600\",\"!\")\n",
    "print(Classifer_Wasserstein_Centers.shape)\n",
    "print(N_Grid_Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 6/110 [00:00<00:01, 59.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜š  Begin Building Distance Matrix  ðŸ˜š\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [00:01<00:00, 80.27it/s]\n",
      "  0%|          | 0/82 [00:00<?, ?it/s]/usr/lib/python3.7/site-packages/ipykernel_launcher.py:68: RuntimeWarning: invalid value encountered in multiply\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:00<00:00, 13317.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜€  Done Building Distance Matrix ðŸ˜€ !\n",
      "ðŸ˜š  Begin Identifying Sample Barycenters  ðŸ˜š\n",
      "----------------------------------------------------------------------------------------------\n",
      "Average Classes Per Sample Barycenter:  1.0\n",
      "Left-Overs: 0\n",
      "----------------------------------------------------------------------------------------------\n",
      "ðŸ˜€  Done Random Covering ðŸ˜€ !\n",
      "(82, 110)\n",
      "110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Disimilarity Matrix\n",
    "Dissimilarity_matrix_ot = np.zeros([N_Grid_Instances,N_Grid_Instances])\n",
    "\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Building Distance Matrix\",\" \\U0001F61A\")\n",
    "# Build Disimilarity Matrix\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    for j in range(N_Grid_Instances):\n",
    "        Dissimilarity_matrix_ot[i,j] = ot.emd2_1d(measures_locations_list[j],\n",
    "                                                  measures_locations_list[i])\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Building Distance Matrix\",\"\\U0001F600\",\"!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Locations Matrix (Internal to Loop)\n",
    "measures_locations_list_current = copy.copy(measures_locations_list)\n",
    "Dissimilarity_matrix_ot_current = copy.copy(Dissimilarity_matrix_ot)\n",
    "\n",
    "# Initialize masker vector\n",
    "masker = np.ones(N_Grid_Instances)\n",
    "\n",
    "# Initialize Sorting Reference Vector (This helps us efficiently scroll through the disimularity matrix to identify the barycenter without having to re-compute the dissimultarity matrix of a sub-saple at every iteration (which is the most costly part of the algorithm!))\n",
    "Distances_Loop = Dissimilarity_matrix_ot_current.sum(axis=1)\n",
    "\n",
    "# Initialize Classes (In-Sample)\n",
    "Classifer_Wasserstein_Centers = np.zeros([N_Quantizers_to_parameterize,N_Grid_Instances])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Identifying Sample Barycenters\",\" \\U0001F61A\")\n",
    "\n",
    "# Identify Sample Barycenters\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    # GET BARYCENTER #\n",
    "    #----------------#\n",
    "    ## Identify row with minimum total distance\n",
    "    Barycenter_index = int(Distances_Loop.argsort()[:1][0])\n",
    "    ## Get Barycenter\n",
    "    ## Update Barycenters Array ##\n",
    "    #----------------------------#\n",
    "    ### Get next Barycenter\n",
    "    new_barycenter_loop = np.array(measures_locations_list_current[Barycenter_index]).reshape(-1,1)\n",
    "    ### Update Array of Barycenters\n",
    "    if i == 0:\n",
    "        # Initialize Barycenters Array\n",
    "        Barycenters_Array = new_barycenter_loop\n",
    "    else:\n",
    "        # Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,new_barycenter_loop,axis=-1)\n",
    "\n",
    "    # GET CLUSTER #\n",
    "    #-------------#\n",
    "    # Identify Cluster for this barycenter (which elements are closest to it)\n",
    "    Cluster_indices = (masker*Dissimilarity_matrix_ot_current[:,Barycenter_index]).argsort()[:N_Elements_Per_Cluster]\n",
    "    ## UPDATES Set  M^{(n)}  ##\n",
    "    #-------------------------#\n",
    "    Dissimilarity_matrix_ot_current[Cluster_indices,:] = 0\n",
    "    # Distance-Based Sorting\n",
    "    Distances_Loop[Cluster_indices] = math.inf\n",
    "\n",
    "    # Update Cluster\n",
    "    masker[Cluster_indices] = math.inf\n",
    "    \n",
    "    # Update Classes\n",
    "    Classifer_Wasserstein_Centers[i,Cluster_indices] = 1\n",
    "#     print(Cluster_indices)\n",
    "\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Classes Per Sample Barycenter: \", np.mean(np.sum(Classifer_Wasserstein_Centers,axis=1)))\n",
    "print(\"Left-Overs:\",length_of_sample)\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Random Covering\",\"\\U0001F600\",\"!\")\n",
    "print(Classifer_Wasserstein_Centers.shape)\n",
    "print(N_Grid_Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2899 - accuracy: 0.0091\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2783 - accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2715 - accuracy: 0.0273\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2654 - accuracy: 0.0273\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2580 - accuracy: 0.0273\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2509 - accuracy: 0.0273\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2410 - accuracy: 0.0182\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.2298 - accuracy: 0.0182\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2168 - accuracy: 0.0273\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2010 - accuracy: 0.0273\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.1825 - accuracy: 0.0273\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.1594 - accuracy: 0.0091\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.1352 - accuracy: 0.0273\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.1107 - accuracy: 0.0182\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0818 - accuracy: 0.0091\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.0524 - accuracy: 0.0182\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.0214 - accuracy: 0.0182\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.9866 - accuracy: 0.0273\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.9563 - accuracy: 0.0273\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.9253 - accuracy: 0.0273\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.9015 - accuracy: 0.0273\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8708 - accuracy: 0.0091\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.8455 - accuracy: 0.0273\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8185 - accuracy: 0.0273\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7955 - accuracy: 0.0455\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7781 - accuracy: 0.0545\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7732 - accuracy: 0.0455\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7665 - accuracy: 0.0727\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7627 - accuracy: 0.0545\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7691 - accuracy: 0.0364\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7808 - accuracy: 0.0182\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7601 - accuracy: 0.0273\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7783 - accuracy: 0.0545\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7918 - accuracy: 0.0273\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.7886 - accuracy: 0.0273\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8169 - accuracy: 0.0182\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8335 - accuracy: 0.0455\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8406 - accuracy: 0.0273\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.8285 - accuracy: 0.0727\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.9090 - accuracy: 0.0182\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.9113 - accuracy: 0.0364\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.9279 - accuracy: 0.0545\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.9959 - accuracy: 0.0182\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0435 - accuracy: 0.0273\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0909 - accuracy: 0.0182\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0418 - accuracy: 0.0273\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0808 - accuracy: 0.0364\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2903 - accuracy: 0.0182\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.1205 - accuracy: 0.0273\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3494 - accuracy: 0.0091\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.2415 - accuracy: 0.0273\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.2814 - accuracy: 0.0273\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4341 - accuracy: 0.0091\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4947 - accuracy: 0.0455\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.5235 - accuracy: 0.0182\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7787 - accuracy: 0.0273\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.7343 - accuracy: 0.0091\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7167 - accuracy: 0.0182\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.9618 - accuracy: 0.0455\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.9140 - accuracy: 0.0273\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.9505 - accuracy: 0.0182\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 4.2034 - accuracy: 0.0364\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 4.2467 - accuracy: 0.0182\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.1047 - accuracy: 0.0182\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.2328 - accuracy: 0.0091\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 4.3101 - accuracy: 0.0091\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 4.3933 - accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4.3928 - accuracy: 0.0091\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.3648 - accuracy: 0.0091\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.9013 - accuracy: 0.0273\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.0033 - accuracy: 0.0091\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.0927 - accuracy: 0.0182\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.4636 - accuracy: 0.0273\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.0990 - accuracy: 0.0000e+ - 0s 4ms/step - loss: 6.4547 - accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 6.6364 - accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 6.7495 - accuracy: 0.0455\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.1793 - accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.8390 - accuracy: 0.0000e+ - 0s 3ms/step - loss: 8.1858 - accuracy: 0.0182\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.8857 - accuracy: 0.0091 \n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.3024 - accuracy: 0.0091 \n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.2498 - accuracy: 0.0182\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.9645 - accuracy: 0.0273\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.0419 - accuracy: 0.0182\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 10.1037 - accuracy: 0.0091\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.7014 - accuracy: 0.0091\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 10.5733 - accuracy: 0.0364\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 11.5525 - accuracy: 0.0091\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 12.0868 - accuracy: 0.0091\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 12.7266 - accuracy: 0.0182\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 15.0671 - accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 15.8209 - accuracy: 0.0182\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 16.3378 - accuracy: 0.0182\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 15.5489 - accuracy: 0.0364\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 16.8233 - accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 16.3263 - accuracy: 0.0091\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.1153 - accuracy: 0.0091\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.8211 - accuracy: 0.0182\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.8321 - accuracy: 0.0091\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 19.6577 - accuracy: 0.0091\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 19.6541 - accuracy: 0.0182\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 22.6391 - accuracy: 0.0091\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 22.8609 - accuracy: 0.0273\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 22.3051 - accuracy: 0.0364\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 22.3119 - accuracy: 0.0091\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 24.3057 - accuracy: 0.0182\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 25.9830 - accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 26.5386 - accuracy: 0.0273\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 27.8545 - accuracy: 0.0273\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 27.4886 - accuracy: 0.0182\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 27.6795 - accuracy: 0.0091\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 27.6594 - accuracy: 0.0091\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 30.6006 - accuracy: 0.0182\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 31.4508 - accuracy: 0.0091\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 32.2439 - accuracy: 0.0091\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 37.5360 - accuracy: 0.0091\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 40.0483 - accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 40.0328 - accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 41.1990 - accuracy: 0.0455\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.9515 - accuracy: 0.0182\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 43.7058 - accuracy: 0.0091\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 45.6539 - accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 47.2995 - accuracy: 0.0273\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 50.3273 - accuracy: 0.0182\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 51.4736 - accuracy: 0.0182\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 52.0979 - accuracy: 0.0182\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 50.5280 - accuracy: 0.0182\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 50.8643 - accuracy: 0.0273\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 53.0260 - accuracy: 0.0091\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 53.9080 - accuracy: 0.0182\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 52.5611 - accuracy: 0.0091\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 54.4552 - accuracy: 0.0091\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 57.0221 - accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 59.6870 - accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 67.8242 - accuracy: 0.0091\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 69.9978 - accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 70.0205 - accuracy: 0.0364\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 66.0440 - accuracy: 0.0182\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 62.3384 - accuracy: 0.0273\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 60.5077 - accuracy: 0.0091\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 60.4305 - accuracy: 0.0182\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 59.8872 - accuracy: 0.0091\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 61.5512 - accuracy: 0.0091\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 60.6467 - accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 61.3176 - accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 61.5912 - accuracy: 0.0091\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 61.2356 - accuracy: 0.0091\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 68.7039 - accuracy: 0.0091\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 72.6396 - accuracy: 0.0182\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 74.9071 - accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 71.7105 - accuracy: 0.1182\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 74.0935 - accuracy: 0.0091\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 74.7129 - accuracy: 0.0273\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 75.8642 - accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 79.1748 - accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 76.2033 - accuracy: 0.0091\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 71.2822 - accuracy: 0.0273\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 71.6925 - accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 75.8816 - accuracy: 0.0273\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 79.5521 - accuracy: 0.0273\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 78.6358 - accuracy: 0.0182\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 79.1811 - accuracy: 0.0091\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 82.1723 - accuracy: 0.0182\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 82.5407 - accuracy: 0.0364\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 79.4289 - accuracy: 0.0182\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 77.2419 - accuracy: 0.0182\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 78.3902 - accuracy: 0.0091\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 82.5268 - accuracy: 0.0273\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 89.0134 - accuracy: 0.0182\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 94.0971 - accuracy: 0.0091\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 90.2507 - accuracy: 0.0182\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 88.7526 - accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 92.8412 - accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 96.9895 - accuracy: 0.0091\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.1267 - accuracy: 0.0091 \n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.9489 - accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.5724 - accuracy: 0.0091\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.6526 - accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 96.7600 - accuracy: 0.0091 \n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 101.5671 - accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 100.6958 - accuracy: 0.0364\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 101.1289 - accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 107.1743 - accuracy: 0.0091\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 112.5840 - accuracy: 0.0091\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 119.6201 - accuracy: 0.0091\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 123.2649 - accuracy: 0.0091\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 127.2199 - accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 125.3996 - accuracy: 0.0273\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.1618 - accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.6823 - accuracy: 0.0182\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 125.1829 - accuracy: 0.0182\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 120.8486 - accuracy: 0.0091\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 127.6067 - accuracy: 0.0182\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 132.2765 - accuracy: 0.0818\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 138.1995 - accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 137.3378 - accuracy: 0.0091\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 139.2005 - accuracy: 0.0091\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 133.0023 - accuracy: 0.0091\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 128.0273 - accuracy: 0.0091\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 134.4822 - accuracy: 0.0182\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 129.1584 - accuracy: 0.0273\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 932us/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [2]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers.T,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/82 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:00<00:00, 10900.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:00<00:00, 32149.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Format Weights\n",
    "## Train\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): START\")\n",
    "print(\"#---------------------------------------#\")\n",
    "Predicted_Weights = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    b = np.repeat(np.array(predicted_classes_train[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): END\")\n",
    "print(\"#-------------------------------------#\")\n",
    "\n",
    "## Test\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): START\")\n",
    "print(\"#-------------------------------------#\")\n",
    "Predicted_Weights_test = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):\n",
    "    b_test = np.repeat(np.array(predicted_classes_test[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b_test = b_test/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights_test = b_test\n",
    "    else:\n",
    "        Predicted_Weights_test = np.append(Predicted_Weights_test,b_test,axis=1)\n",
    "print(\"#-----------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): END\")\n",
    "print(\"#-----------------------------------#\")\n",
    "        \n",
    "# Format Points of Mass\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: START\")\n",
    "print(\"#-----------------------------#\")\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: END\")\n",
    "print(\"#-----------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/109 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:00<00:00, 1194.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.056513</td>\n",
       "      <td>0.070872</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.364390</td>\n",
       "      <td>0.444625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.729807</td>\n",
       "      <td>0.690816</td>\n",
       "      <td>0.191332</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>0.745037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>2.589013</td>\n",
       "      <td>1.592739</td>\n",
       "      <td>0.426912</td>\n",
       "      <td>1.035913</td>\n",
       "      <td>1.016187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.056513    0.070872             0.003580                0.364390   \n",
       "MAE  0.729807    0.690816             0.191332                0.770925   \n",
       "Max  2.589013    1.592739             0.426912                1.035913   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.444625  \n",
       "MAE              0.745037  \n",
       "Max              1.016187  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Training Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "Skewness_errors = np.array([])\n",
    "Kurtosis_errors = np.array([])\n",
    "predictions_mean = np.array([])\n",
    "true_mean = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measure_weights.reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(np.array(measures_locations_list[x_i]))\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    ## Update Erros\n",
    "    predictions_mean = np.append(predictions_mean,Mu_hat)\n",
    "    true_mean = np.append(true_mean,Mu)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(np.array(measures_locations_list[x_i])**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat = np.sum((Barycenters_Array**3)*(Predicted_Weights[x_i]))\n",
    "    Skewness = np.mean(np.array(measures_locations_list[x_i])**3)\n",
    "    Skewness_errors = np.append(Skewness_errors,(abs(Skewness_hat-Skewness))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat = np.sum((Barycenters_Array**4)*(Predicted_Weights[x_i]))\n",
    "    Kurtosis = np.mean(np.array(measures_locations_list[x_i])**4)\n",
    "    Kurtosis_errors = np.append(Kurtosis_errors,(abs(Kurtosis_hat-Kurtosis))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.min(np.abs(W1_errors)),np.mean(np.abs(W1_errors)),np.max(np.abs(W1_errors))])\n",
    "Mean_prediction_Performance = np.array([np.min(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors)),np.max(np.abs(Mean_errors))])\n",
    "Var_prediction_Performance = np.array([np.min(np.abs(Var_errors)),np.mean(np.abs(Var_errors)),np.max(np.abs(Var_errors))])\n",
    "Skewness_prediction_Performance = np.array([np.min(np.abs(Skewness_errors)),np.mean(np.abs(Skewness_errors)),np.max(np.abs(Skewness_errors))])\n",
    "Kurtosis_prediction_Performance = np.array([np.min(np.abs(Kurtosis_errors)),np.mean(np.abs(Kurtosis_errors)),np.max(np.abs(Kurtosis_errors))])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Train.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7338035b90>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean)\n",
    "plt.plot(true_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 1569.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Test Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors_test = np.array([])\n",
    "Mean_errors_test = np.array([])\n",
    "Var_errors_test = np.array([])\n",
    "Skewness_errors_test = np.array([])\n",
    "Kurtosis_errors_test = np.array([])\n",
    "# Initialize Prediction Metrics\n",
    "predictions_mean_test = np.array([])\n",
    "true_mean_test = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_test_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_test_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights_test[x_i,].reshape(-1,),\n",
    "                         measure_weights_test.reshape(-1,))\n",
    "    W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "    # Get Means\n",
    "    Mu_hat_test = np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array))\n",
    "    Mu_test = np.mean(np.array(measures_locations_test_list[x_i]))\n",
    "    Mean_errors_test = np.append(Mean_errors_test,(Mu_hat_test-Mu_test))\n",
    "    ## Update Predictions\n",
    "    predictions_mean_test = np.append(predictions_mean_test,Mu_hat_test)\n",
    "    true_mean_test = np.append(true_mean_test,Mu_test)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat_test = np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))\n",
    "    Var_test = np.mean(np.array(measures_locations_test_list[x_i])**2)\n",
    "    Var_errors_test = np.append(Var_errors_test,(Var_hat_test-Var_test)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat_test = np.sum((Barycenters_Array**3)*(Predicted_Weights_test[x_i]))\n",
    "    Skewness_test = np.mean(np.array(measures_locations_test_list[x_i])**3)\n",
    "    Skewness_errors_test = np.append(Skewness_errors_test,(abs(Skewness_hat_test-Skewness_test))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat_test = np.sum((Barycenters_Array**4)*(Predicted_Weights_test[x_i]))\n",
    "    Kurtosis_test = np.mean(np.array(measures_locations_test_list[x_i])**4)\n",
    "    Kurtosis_errors_test = np.append(Kurtosis_errors_test,(abs(Kurtosis_hat_test-Kurtosis_test))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance_test = np.array([np.min(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test))])\n",
    "Mean_prediction_Performance_test = np.array([np.min(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test))])\n",
    "Var_prediction_Performance_test = np.array([np.min(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test))])\n",
    "Skewness_prediction_Performance_test = np.array([np.min(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test))])\n",
    "Kurtosis_prediction_Performance_test = np.array([np.min(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test))])\n",
    "\n",
    "Type_A_Prediction_test = pd.DataFrame({\"W1\":W1_Performance_test,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance_test,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance_test,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance_test,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance_test},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction_test.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Test.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f73380b5e10>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean_test)\n",
    "plt.plot(true_mean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print for Terminal Legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  0.056513    0.070872             0.003580                0.364390   \n",
      "MAE  0.729807    0.690816             0.191332                0.770925   \n",
      "Max  2.589013    1.592739             0.426912                1.035913   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.444625  \n",
      "MAE              0.745037  \n",
      "Max              1.016187  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  0.421870    0.522966             0.177975                0.698171   \n",
      "MAE  0.603158    0.707736             0.279910                0.755721   \n",
      "Max  0.876459    0.885260             0.343648                0.778926   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.723850  \n",
      "MAE              0.766805  \n",
      "Max              0.785711  \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------------#\")\n",
    "print(\"Training-Set Performance\")\n",
    "print(\"#----------------------#\")\n",
    "print(Type_A_Prediction)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"#------------------#\")\n",
    "print(\"Test-Set Performance\")\n",
    "print(\"#------------------#\")\n",
    "print(Type_A_Prediction_test)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facts of Simulation Experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      " Experiment's Facts \n",
      "====================\n",
      "------------------------------------------------------\n",
      "=====\n",
      "Model\n",
      "=====\n",
      "â€¢ N Centers: 82\n",
      "â€¢ Each Wasserstein-1 Ball should contain:  1 elements from the training set.\n",
      "------------------------------------------------------\n",
      "========\n",
      "Training\n",
      "========\n",
      "â€¢ Data-size: 110\n",
      "â€¢ N Points per training datum: 10\n",
      "------------------------------------------------------\n",
      "=======\n",
      "Testing\n",
      "=======\n",
      "â€¢ Data-size Test: 6\n",
      "â€¢ N Points per testing datum: 10\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"====================\")\n",
    "print(\" Experiment's Facts \")\n",
    "print(\"====================\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"=====\")\n",
    "print(\"Model\")\n",
    "print(\"=====\")\n",
    "print(\"\\u2022 N Centers:\",N_Quantizers_to_parameterize)\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"========\")\n",
    "print(\"Training\")\n",
    "print(\"========\")\n",
    "print(\"\\u2022 Data-size:\",(len(x_Grid)*len(t_Grid)))\n",
    "print(\"\\u2022 N Points per training datum:\",N_Monte_Carlo_Samples)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"=======\")\n",
    "print(\"Testing\")\n",
    "print(\"=======\")\n",
    "print(\"\\u2022 Data-size Test:\",(len(x_Grid_test)*len(t_Grid_test)))\n",
    "print(\"\\u2022 N Points per testing datum:\",N_Monte_Carlo_Samples_Test)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.056513</td>\n",
       "      <td>0.070872</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.364390</td>\n",
       "      <td>0.444625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.729807</td>\n",
       "      <td>0.690816</td>\n",
       "      <td>0.191332</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>0.745037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>2.589013</td>\n",
       "      <td>1.592739</td>\n",
       "      <td>0.426912</td>\n",
       "      <td>1.035913</td>\n",
       "      <td>1.016187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.056513    0.070872             0.003580                0.364390   \n",
       "MAE  0.729807    0.690816             0.191332                0.770925   \n",
       "Max  2.589013    1.592739             0.426912                1.035913   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.444625  \n",
       "MAE              0.745037  \n",
       "Max              1.016187  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.421870</td>\n",
       "      <td>0.522966</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.698171</td>\n",
       "      <td>0.723850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.603158</td>\n",
       "      <td>0.707736</td>\n",
       "      <td>0.279910</td>\n",
       "      <td>0.755721</td>\n",
       "      <td>0.766805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.876459</td>\n",
       "      <td>0.885260</td>\n",
       "      <td>0.343648</td>\n",
       "      <td>0.778926</td>\n",
       "      <td>0.785711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.421870    0.522966             0.177975                0.698171   \n",
       "MAE  0.603158    0.707736             0.279910                0.755721   \n",
       "Max  0.876459    0.885260             0.343648                0.778926   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.723850  \n",
       "MAE              0.766805  \n",
       "Max              0.785711  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
