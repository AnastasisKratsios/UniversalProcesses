{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*.\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth:\n",
    "*The build-in Options:*\n",
    "- rSDE \n",
    "- pfBM\n",
    "- 2lnflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth = \"2lnflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 100\n",
    "N_Monte_Carlo_Samples = 10**3\n",
    "N_Monte_Carlo_Samples_Test = 10**1 # How many MC-samples to draw from test-set?\n",
    "\n",
    "# End times for Time-Grid\n",
    "T_end = 1\n",
    "T_end_test = 1.1\n",
    "\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 100\n",
    "Max_Grid = 1\n",
    "\n",
    "# \n",
    "N_Quantizers_to_parameterize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "N_measures_per_center = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP:\n",
    "from operator import itemgetter \n",
    "from itertools import compress\n",
    "# Set Minibatch Size\n",
    "Random_Cover_Mini_Batch_Size = 100\n",
    "# Proportion of Clusters per Minibatch Sample\n",
    "# Quantization_Proportion = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Measure-Valued $2$-Parameter Log-Gaussian Flow\n",
    "$$\n",
    "X_{t,x} \\sim \\log\\text{-}\\mathcal{N}\\left(\\alpha(t,x),\\beta(t,x)\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** *$\\alpha$ and $\\beta$ are specified below in the SDE Example*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Rough SDE\n",
    "Simulate via Euler-M method from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T((1-\\eta)\\beta(s,x)+\\eta\\sigma_s^H)dW_s.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return t*np.sin(math.pi*x) - x + np.exp(-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return .5*(1+t)*np.abs(np.cos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rougness = 0.9 # Hurst Parameter\n",
    "Ratio_fBM_to_typical_vol = 0 # $\\eta$ in equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed Fractional Brownian Motion\n",
    "Simulate from:\n",
    "$$\n",
    "X_t^x(\\omega) = f_1(x)f_2(t) + B_t^H(\\omega).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_dirction_x(x):\n",
    "    return x*np.cos(x)\n",
    "\n",
    "def finite_variation_t(t):\n",
    "    return t*(np.sin(math.pi*t) + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "# %run ParaGAN_Backend.ipynb\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of Auxiliary Internal-Variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "measure_weights_test = np.ones(N_Monte_Carlo_Samples_Test)/N_Monte_Carlo_Samples_Test\n",
    "\n",
    "# Get number of centers\n",
    "N_Centers_per_box = max(1,int(round(np.sqrt(N_Quantizers_to_parameterize))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Centers Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grid of Barycenters\n",
    "x_Grid_barycenters = np.arange(start=-Max_Grid,\n",
    "                               stop=Max_Grid,\n",
    "                               step = (2*Max_Grid/N_Centers_per_box))\n",
    "t_Grid_barycenters = np.arange(start=0,\n",
    "                               stop=T_end,\n",
    "                               step = (T_end/N_Centers_per_box))\n",
    "for x_i in range(len(x_Grid_barycenters)):\n",
    "    for t_j in range(len(t_Grid_barycenters)):\n",
    "        new_grid_entry = np.array([t_Grid_barycenters[t_j],x_Grid_barycenters[x_i]]).reshape(1,-1)\n",
    "        if (x_i==0 and t_j ==0):\n",
    "            Grid_Barycenters = new_grid_entry\n",
    "        else:\n",
    "            Grid_Barycenters = np.append(Grid_Barycenters,new_grid_entry,axis=0)\n",
    "\n",
    "# Update Number of Quantizers Generated\n",
    "N_Quantizers_to_parameterize = Grid_Barycenters.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Simulator.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer (Model Type A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training Data\n",
    "for i in range(Grid_Barycenters.shape[0]):\n",
    "    # Get output for center (mu-hat)\n",
    "    if groud_truth == \"2lnflow\":\n",
    "        center_current, trash = twoparameter_flow_sampler((Grid_Barycenters[i]).reshape(1,2),N_Monte_Carlo_Samples)\n",
    "    \n",
    "    # Get random sample in delta ball around ith center\n",
    "    sub_grid_loop = np.random.uniform(0,delta,(N_measures_per_center,2)) + Grid_Barycenters[i]\n",
    "    \n",
    "    # Get Measures for this random sample\n",
    "    if groud_truth == \"2lnflow\":\n",
    "        measures_locations_list_current, measures_weights_list_current = twoparameter_flow_sampler(sub_grid_loop,N_Monte_Carlo_Samples)\n",
    "    ##\n",
    "    measures_locations_list_current = measures_locations_list_current + center_current\n",
    "    measures_weights_list_current = measures_weights_list_current + trash\n",
    "    # Update Classes\n",
    "    Classifer_Wasserstein_Centers_loop = np.zeros([(N_measures_per_center+1),N_Quantizers_to_parameterize]) # The +1 is to account for the center which will be added to the random ball\n",
    "    Classifer_Wasserstein_Centers_loop[:, i] =  1\n",
    "    # Updates Classes\n",
    "    if i==0:\n",
    "        # INITIALIZE: Classifiers\n",
    "        Classifer_Wasserstein_Centers = Classifer_Wasserstein_Centers_loop\n",
    "        # INITIALIZE: Training Data\n",
    "        X_train = np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0)\n",
    "        # INITIALIZE: Barycenters Array\n",
    "        Barycenters_Array = (center_current[0]).reshape(-1,1)\n",
    "        # INITIALIZE: Measures and locations\n",
    "        measures_locations_list = measures_locations_list_current\n",
    "        measures_weights_list = measures_weights_list_current\n",
    "    else:\n",
    "        # UPDATE: Classifer\n",
    "        Classifer_Wasserstein_Centers = np.append(Classifer_Wasserstein_Centers,Classifer_Wasserstein_Centers_loop,axis=0)\n",
    "        # UPDATE: Training Data\n",
    "        X_train = np.append(X_train,np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0),axis=0)\n",
    "        # UPDATE: Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,((center_current[0]).reshape(-1,1)),axis=-1)\n",
    "        # UPDATE: Measures and locations\n",
    "        measures_locations_list = measures_locations_list + measures_locations_list_current\n",
    "        measures_weights_list = measures_locations_list + measures_weights_list_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Testing Dataset (Inputs)\n",
    "x_tests = np.random.uniform(np.min(X_train[:,0]),np.max(X_train[:,0]),3)\n",
    "t_tests = np.arange(start=0,\n",
    "                    stop=T_end_test,\n",
    "                    step = N_Euler_Maruyama_Steps)\n",
    "\n",
    "for x_i in range(len(x_tests)):\n",
    "    for t_j in range(len(t_tests)):\n",
    "        test_set_entry = np.array([t_tests[t_j],x_tests[x_i]]).reshape(1,-1)\n",
    "        if (x_i==0 and t_j ==0):\n",
    "            X_test = X_test\n",
    "        else:\n",
    "            X_test = np.append(X_test,test_set_entry,axis=0)\n",
    "\n",
    "# Generate Testing Dataset (Outputs)\n",
    "if groud_truth == \"2lnflow\":\n",
    "        measures_locations_test_list, measures_weights_test_list = twoparameter_flow_sampler(sub_grid_loop,N_Monte_Carlo_Samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDEBUG\n",
    "\n",
    "# if groud_truth == \"2lnflow\":\n",
    "#     print(\"2lnflow!\")\n",
    "#     measures_locations_list, measures_weights_list, X_train = measure_valued_direct_sampling(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "#     measures_locations_list_test, measures_weights_list_test, X_test = measure_valued_direct_sampling(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)     \n",
    "\n",
    "# DEBUG LATER...\n",
    "# if groud_truth == \"rSDE\":\n",
    "#     print(\"rSDE!\")\n",
    "#     measures_locations_list, measures_weights_list, X_train = Euler_Maruyama_simulator(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "#     measures_locations_list_test, measures_weights_list_test, X_test = Euler_Maruyama_simulator(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)     \n",
    "    \n",
    "# if groud_truth == \"pfBM\":\n",
    "#     print(\"pFBM!\")\n",
    "#     measures_locations_list, measures_weights_list, X_train= perturbed_fBM_simulator(x_Grid,t_Grid,N_Monte_Carlo_Samples)\n",
    "#     measures_locations_list_test, measures_weights_list_test, X_test= perturbed_fBM_simulator(x_Grid_test,t_Grid_test,N_Monte_Carlo_Samples_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8912 - accuracy: 0.0204\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8568 - accuracy: 0.0612\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8269 - accuracy: 0.0663\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.7947 - accuracy: 0.0714\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7574 - accuracy: 0.0918\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7130 - accuracy: 0.0714\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6595 - accuracy: 0.0612\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5951 - accuracy: 0.0867\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5171 - accuracy: 0.0969\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4341 - accuracy: 0.0918\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3444 - accuracy: 0.1173\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2483 - accuracy: 0.1224\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1532 - accuracy: 0.1173\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0586 - accuracy: 0.1224\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.9698 - accuracy: 0.1633\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8788 - accuracy: 0.2245\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7902 - accuracy: 0.1735\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7043 - accuracy: 0.1735\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6296 - accuracy: 0.1888\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5292 - accuracy: 0.2194\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4430 - accuracy: 0.2653\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3639 - accuracy: 0.3010\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2856 - accuracy: 0.3724\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2105 - accuracy: 0.3469\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1304 - accuracy: 0.4235\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0719 - accuracy: 0.4031\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0001 - accuracy: 0.3827\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9281 - accuracy: 0.4643\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8874 - accuracy: 0.5255\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8213 - accuracy: 0.5714\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7607 - accuracy: 0.5816\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7054 - accuracy: 0.6122\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6711 - accuracy: 0.6071\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6160 - accuracy: 0.5765\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5444 - accuracy: 0.6990\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4937 - accuracy: 0.6837\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4598 - accuracy: 0.7449\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4214 - accuracy: 0.6939\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3659 - accuracy: 0.7449\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3215 - accuracy: 0.7347\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2953 - accuracy: 0.7398\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2525 - accuracy: 0.8316\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2085 - accuracy: 0.7806\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1595 - accuracy: 0.8520\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1320 - accuracy: 0.8673\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1194 - accuracy: 0.8061\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0655 - accuracy: 0.8520\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0361 - accuracy: 0.8163\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0068 - accuracy: 0.8316\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9892 - accuracy: 0.8010\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9517 - accuracy: 0.8061\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9175 - accuracy: 0.8929\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8662 - accuracy: 0.9337\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8908 - accuracy: 0.8520\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8544 - accuracy: 0.8571\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.9439\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7994 - accuracy: 0.8776\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7593 - accuracy: 0.9031\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7631 - accuracy: 0.8929\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7076 - accuracy: 0.9592\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6982 - accuracy: 0.9439\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.9694\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.9745\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.9592\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.9796\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.9796\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.9796\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.9949\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.9796\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.9643\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.9592\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.9847\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.9745\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.9745\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.9847\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.9796\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.9949\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.9949\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.9847\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.9745\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.9847\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.9745\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.9796\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9949\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9949\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9949\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1587 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 911us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [2]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 88.91it/s] \n",
      " 43%|████▎     | 21/49 [00:00<00:00, 198.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 99.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Format Weights\n",
    "## Train\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): START\")\n",
    "print(\"#---------------------------------------#\")\n",
    "Predicted_Weights = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    b = np.repeat(np.array(predicted_classes_train[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): END\")\n",
    "print(\"#-------------------------------------#\")\n",
    "\n",
    "## Test\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): START\")\n",
    "print(\"#-------------------------------------#\")\n",
    "Predicted_Weights_test = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):\n",
    "    b_test = np.repeat(np.array(predicted_classes_test[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b_test = b_test/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights_test = b_test\n",
    "    else:\n",
    "        Predicted_Weights_test = np.append(Predicted_Weights_test,b_test,axis=1)\n",
    "print(\"#-----------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): END\")\n",
    "print(\"#-----------------------------------#\")\n",
    "        \n",
    "# Format Points of Mass\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: START\")\n",
    "print(\"#-----------------------------#\")\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: END\")\n",
    "print(\"#-----------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 9/195 [00:00<00:02, 84.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:01<00:00, 107.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>2.801542e-10</td>\n",
       "      <td>0.150821</td>\n",
       "      <td>0.392883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.099058</td>\n",
       "      <td>0.053682</td>\n",
       "      <td>1.942820e+00</td>\n",
       "      <td>1.842781</td>\n",
       "      <td>3.125614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>1.845063</td>\n",
       "      <td>0.309275</td>\n",
       "      <td>3.755728e+01</td>\n",
       "      <td>6.353853</td>\n",
       "      <td>10.524459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.000085    0.000060         2.801542e-10                0.150821   \n",
       "MAE  0.099058    0.053682         1.942820e+00                1.842781   \n",
       "Max  1.845063    0.309275         3.755728e+01                6.353853   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.392883  \n",
       "MAE              3.125614  \n",
       "Max             10.524459  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Training Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "Skewness_errors = np.array([])\n",
    "Kurtosis_errors = np.array([])\n",
    "predictions_mean = np.array([])\n",
    "true_mean = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measure_weights.reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(np.array(measures_locations_list[x_i]))\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    ## Update Erros\n",
    "    predictions_mean = np.append(predictions_mean,Mu_hat)\n",
    "    true_mean = np.append(true_mean,Mu)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(np.array(measures_locations_list[x_i])**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat = np.sum((Barycenters_Array**3)*(Predicted_Weights[x_i]))\n",
    "    Skewness = np.mean(np.array(measures_locations_list[x_i])**3)\n",
    "    Skewness_errors = np.append(Skewness_errors,(abs(Skewness_hat-Skewness))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat = np.sum((Barycenters_Array**4)*(Predicted_Weights[x_i]))\n",
    "    Kurtosis = np.mean(np.array(measures_locations_list[x_i])**4)\n",
    "    Kurtosis_errors = np.append(Kurtosis_errors,(abs(Kurtosis_hat-Kurtosis))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.min(np.abs(W1_errors)),np.mean(np.abs(W1_errors)),np.max(np.abs(W1_errors))])\n",
    "Mean_prediction_Performance = np.array([np.min(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors)),np.max(np.abs(Mean_errors))])\n",
    "Var_prediction_Performance = np.array([np.min(np.abs(Var_errors)),np.mean(np.abs(Var_errors)),np.max(np.abs(Var_errors))])\n",
    "Skewness_prediction_Performance = np.array([np.min(np.abs(Skewness_errors)),np.mean(np.abs(Skewness_errors)),np.max(np.abs(Skewness_errors))])\n",
    "Kurtosis_prediction_Performance = np.array([np.min(np.abs(Kurtosis_errors)),np.mean(np.abs(Kurtosis_errors)),np.max(np.abs(Kurtosis_errors))])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Train.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8c6c24aad0>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8leX9//HXdXZOcrJDEpJAGEoYKmBQhuJAcGuplOKo46vV1mq12rra/rTTultbtdLhwIHiAKuioihuZIgMGbIhg4SQPc68fn/cOUBIQk5IzoLP0wcPwp079/3xzsk717nu+7oupbVGCCFE/DBFuwAhhBDdI8EthBBxRoJbCCHijAS3EELEGQluIYSIMxLcQggRZ0IKbqXUL5RSa5RSq5VSLyqlHOEuTAghRMe6DG6lVB7wc6BYaz0CMAMzwl2YEEKIjoXaVWIBEpRSFsAJlIavJCGEEAdj6WoHrXWJUupBYDvQDLyntX7vwP2UUtcC1wIkJiYeX1RU1Nu1CiHEYWvZsmW7tdZZoeyruhryrpRKA14FfgjUAHOAV7TWz3X2NcXFxXrp0qWhVyyEEEc4pdQyrXVxKPuG0lVyBrBFa12ptfYCrwHje1KgEEKIQxdKcG8HxiqlnEopBUwC1oa3LCGEEJ3pMri11ouBV4DlwKrWr5kZ5rqEEEJ0osubkwBa67uBu8NcixBCiBDIyEkhhIgzEtxCCBFnJLiFECLOxExwN3ubefDzB1m4ZWG0SxFCiJgW0s3JSLCZbdz73r0MCwxD+zQ7zTt51fwqq8yrWPiThQzIGhDtEoUQIibETIvbbDIz9JuhfKm/5L3H3uPGpht5U7/J1sBWPlr0UbTLE0KImBEzwQ3wwKMP4LP4WPy3xdQn1/P7Y38PQHV9dZQrE0KI2BFTwT02fyyFqYUs2raIMX3HcP7g8wGoa6qLcmVCCBE7Yiq4lVLMGG5M9X3XyXeRnpYOQF2zBLcQQgTFzM3JoF9N+BWD0gdxwZALaGlsAaC+pT7KVQkhROyIueBOT0jnmtHXAJCQmIDFZ6HeJ8EthBBBMRfc+1NKYffYqVcS3EIIERTTwQ1g99tpVI3RLkMIIWJGzAe3w++gSTVFuwwhhIgZMR/cCTqBRqTFLYQQQTH1OGBHnDhppjnaZQghRMyI/eA2OWlWEtxCCBEU810liaZEWlRLtMsQQoiYEfPBnWRJkuAWQoj9xHxXSZItCY/NQyAQiHYpQggRE2I/uO1JBEwBGuobol2KEELEhJgP7mRHMgBV1VVRrkQIIWJD7Ad3ghHc1dUyJ7cQQkAIwa2UGqKUWrHfnzql1M2RKA4gxZkCwJ7aPZE6pRBCxLQunyrRWq8HRgIopcxACfB6mOvaK9WVCkB1rbS4hRACut9VMgnYpLXeFo5iOhIM7pqGmkidUgghYlp3g3sG8GJHn1BKXauUWqqUWlpZWdnzylqlJacBUNcoq+AIIQR0I7iVUjbgAmBOR5/XWs/UWhdrrYuzsrJ6qz7SUo3grm2q7bVjCiFEPOtOi/tsYLnWele4iulIRnoGIOtOCiFEUHeC+2I66SYJp70LBrdIcAshBIQY3EopJzAZeC285bRnt9ox+8w0eGXkpBBCQIiTTGmtm4CMMNfSKbvXToNfglsIISAORk6CsXxZrb+WO9+/k4+3fRztcoQQIqriI7gDDpa4lvCXz/7CKU+fwk3zb8IX8EW7LCGEiIqYn48bwKmdeE1ejs86njE5Y3j0q0fZWLGRORfPwWlzRrs8IYSIqLhocSeaEgEoeqSInItyOOetc3h769v88uFfRrkyIYSIvLhocZ8x4QySNiRx8y9vJuALcFbgLD7e8TGbGzZHuzQhhIi4uAjuB6c+2G6b61YXe3wyY6AQ4sgTF10lHUkhhdqADIMXQhx54ja4Uy2p1JlkNKUQ4sgTt8Gdbk+nwdqADuholyKEEBEVt8GdlZhFk7OJpqqmaJcihBARFb/BnZxFwBygbGdZtEsRQoiIitvgzknPAWBnyc4oVyKEEJEVt8Hdt09fAErKS6JciRBCRFbcBnde3zwAyneXR7kSIYSIrLgN7tzMXAB21UR0QR4hhIi6uA3uTGcmAJX1vbcwsRBCxIO4De4URwqmgImqlqpolyKEEBEVt8FtUiZcfhfV3upolyKEEBEVt8ENkKySZb4SIcQRJy5mB+xMmiWNOksdX/7tS5RJoZRijW8NruEupk2eFtFapsyawmmFp3HnyXdG9LxCiCNPXAd3dko25c5y3r353b3bHv/p41h3WCMa3LubdrNg8wK21myV4BZChF1cd5X0H9gf80Azt1Xdxq8qf8X0TdOpyK6g1hLZ7pPFOxcD8N2e79i0Z1NEzy2EOPKEFNxKqVSl1CtKqXVKqbVKqXHhLiwUmc5Mdjfv5rF1j/Fxzccs3L0QgEZHIz5f5BYTXlyyeO/H72569yB7CiFEz4XaVfI34B2t9TSllA2IiRV6M5wZeANefrXgVyTZkjg642gAtElTuquUfnn9IlLHlzu/5Ljs46j31DN/43yuH3N9RM4rhDgyddniVkolAxOB/wBorT1a65pwFxaKswefzfeKvseLF70IwPKy5eRajBGV23duD/v5K1ZXsOGdDXyx7QuGM5yTnCexcNNC3D532M8thDhyhdJVMhCoBJ5SSn2tlPq3UirxwJ2UUtcqpZYqpZZWVkZmNOPwPsN5/YevM2PEDB458xEALsm7BIAd5TvCem6f28fM4pk8+qNHafA30PhkI01/baLJ38RXK78K67mFEEe2UILbAowGntBajwIagTsO3ElrPVNrXay1Ls7KyurlMrt2zehr2PGLHVxw1AUAlO4uDev5PPUePF4PpT82zvPz+37O2EvGAlBVIaM5hRDhE0of905gp9Y6eAfuFToI7liQn5yPr69xU7KsJrwLLLgb3Tx95dPssO9g2rBpnDr5VKqaq2AF1DfVh/XcQogjW5ctbq11ObBDKTWkddMk4NuwVtUD+fn5qICioqEirOfZU7OHHf12cFX6Vbw87WVjCH6iC4CG5oawnlsIcWQL9amSG4HnW58o2QxcFb6SesZitZDYnEilKbz97DX1xv3ZwqRClFIAEtxCiIgIKbi11iuA4jDX0muSvclUmcLbzxwM7uSE5H3nTTI+bmiR4BZChE9cD3nvTGoglWrCO2tgXUMdAMmJ+4Lb5TJa3I3uxrCeWwhxZIvrIe+dSTOlUWsO77D32kbj+CmJKXu3pSQbHze5m8J6biHEke2wbHFn2DKoM9eF9RzBJ0dSXPuCO9lltL6bvBLcQojwOSxb3FnOLNx2N43N4euyqG8xgjs1KXXvNrPVjNVjleAWQoTVYRnc2a5sYN+wd611r59jb3CnpLbZbvPZaPJLcAshwuewDO7cNGO+kh2lO/D6vRQ9VsQ9H93Tq+docBtPjqQmHxDcfhvN/uZePZcQQuzvsAzuvKw8ALaXbufzbZ+zoWoDv1v0O1759pVeO0eD1whul8PVZrstIMEthAivwzK4BxcMBuDlf7zMb3/8W1RA0bekL5e9cBnV1b3zmGCjrxGT34TNbGuz3Raw0aJbeuUcQgjRkcMyuEccO4Jjbceyfsp6dk3cxQg1gh9afojb6mbZ4mW9co4mXxN2n33vqMkgBw4JbiFEWB2Wwa2U4pazb2E729nABqafPp0p10wBYM2qNb1yjkZ/I3a/vd12h3bgRubjFkKEz2EZ3ADTh08n1WHcODxr8FkMLjS6T77b/F2vHL9JN+EIONptdygHbiXBLYQIn8M2uBOsCVxffD0D0wYyOnc0eS7jhuW2Xdt65fgtuoWEQEK77Q6TA7dJglsIET6HbXAD/OH0P7D+hvWYlIkEawIuXOxy78Jd1/NgbaYZBx20uE0OPCZPj48vhBCdOayD26RMWEz7RvXnJuRSl1xH2fKeL7LQYmohQbVvcTvNTjwWCW4hRPgc1sF9oILMAupd9Wz7eBsBX4D6snpqttXw4tcvdnuYeoupBaep/WL3CZYECW4hRFgdlpNMdaZfRj+Wpi3lo7s/4qO7PwJge8F2/nv1f3low0Pc8sNbQj6W2+LuMLidVicBFcDj9WCz2jr4SiGE6JkjKrjzXHnUJ9Zz9r/OpnFHI4l9Enmq+SlohA2bNnTrWG6Lm0Rzu8XuSbQlgteYrzszLbO3ShdCiL2OrOBOziOgA+RNzyMv2XjK5K5n74ItUFob+qrwfq8fj81Doql9cDttTvBCbV2tBLcQIiyOqD7u4COBJfUlALh9bj7b8RkAu5p3hXychvoGtEmTZEtq97lEuxHm9fWy0rsQIjyOqODu6+oLQGm90bpeXLKYFl8LZm2mKhD6GpXVtcZ8Jy67q93nkhxGmNfWh3cFHiHEkeuICu5g90hJndHi/nDLhygUo/yjqDHXhDxvd02tsVBwoqN9V0kwuOsbpcUthAiPIyq4+yT2wWKyUFJfwtLSpfxjyT84Ie8EBicOpi6pjsaK0FbM6WiF96AkpwS3ECK8jqjgNikT+cn5PPD5A0z47wSSbEnMmjqLgswCvDYvO7/bGdJxgt0gHQW3y2l0n9Q3S3ALIcIjpKdKlFJbgXrAD/i01sXhLCqcnvneM8z/bj71nnruOvku+rr60j+3P5TAps2bKDqpqMtjdLTCe5Ar0QjuhuaG3i1cCCFadedxwNO01rvDVkmETOw/kYn9J7bZNrBwICyFzTs2h3SMuiZjBfngqu77C25rbAnfQsVCiCPbEdVV0pl+Wf0A2FGxI6T965qN4E51pbb73N7gdktwCyHCI9Tg1sB7SqllSqlrO9pBKXWtUmqpUmppZWVl71UYAbkuY3HhUAfhBLtBDlwoGCS4hRDhF2pXyQStdalSqg+wQCm1Tmv98f47aK1nAjMBiouLQ3uuLkakOdKwBCyUVJXw/h3vg4KAN8Bi52JOOe8UJp7Qtmul3m3ceOwwuJON4O7upFVCCBGqkIJba13a+neFUup14ATg44N/VfxQSpFly6IxtZEvHv4CpRSV2ZX8/aq/c8zMY/h69NeYLPvenDR6jdZ0akr74LY5bFh8FpoCEtxCiPDosqtEKZWolHIFPwamAKvDXVik9cvuR+qUVH7j/g2/bvk16/68Dm3SlDpKWfHMijb7NngasHqt2BztZ/9TSmH1WmnySXALIcIjlBZ3NvB662rmFuAFrfU7Ya0qCnJduaypWMPiksXMXj2b9za9R54rj/JAOe/f/T6122uxu+xYE63sqtiFLbXzKVttfhvNujmC1QshjiRdBrfWejNwXARqiarClELmrpvLuP+Mw6zMzBgxgzMGnME1/7uGqqQqPv79vp6h9T9ZT7/mfp0ey+a30UwzDZ6GDieiEkKInjiipnU9mHtOvYdJAyfhC/g4Me9Ecl25LClZAsC4ueO48OgL8TR6KK8q555n7uGGU2/o9Fj2gJ0ViStI+UsK/7ngP1w58soI/V8IIY4EEtytUhwpnHf0eW22DckcAsC63ev4XtH3sLvsLNu5DIDTBpzW6bHs2k6DpYFUWyo3z7+ZE6wnkOPIIW1gGq1dTkIIcchkAM5BJNuTyXPlsW73ur3bPtr6EU6rkzF5Yzr9unN2n8N5/zuPHz3wIxobGxnzzBiyn8rmwX88GImyhRCHOWlxd6Eos4i1u9fu/feHWz9kQsEEbObOb07e+8i97PhiBw3lDaS1pPF+y/t83vI5q6sOu4dxhBBRIMHdhaGZQ3l25bNoralorGB1xWouGXHJQb8msU8iRRcak1UVU8zv+B32X9upD0R3xsCm3U2469wos8JkMaFNmm2+bRxbcGxU6xJCdI8EdxeKMouoc9dRWl/K7NWzATh/yPndPo7D66BO1/V2eSFz17l5OP9h/G7/3m1Lipcw/5z5bL9+O3nZeVGrTQjRPRLcXZjQbwIAjy95nDnfzmF8wXhG9BnR7eM4/U4aAtGb6rWlpgW/28+oq0dRML6AgD/AWxvfImAKsGPHDgluIeKIBHcXRuaM5NJjLuXeT+9Fo/ntxN8e0nGcASeNOnoTT/m9Rku7/yn9Oe5Hx+H1e/n2z99CAGrqaqJWlxCi++SpkhDcd8Z9OK1O0hxpTBs27ZCOkUgijUQvuAPeAMDeOVeWlC6hMWDUI8EtRHyRFncI8pLzmD1tNgEdIMGacEjHSDQlUqErermy0AVb3Gt9a5n/2Xzq3Pv622sbZEV6IeKJBHeIDhyc010us4tmojd/ScAboDS3lAe3PkjDZqOvPcWaQq23ltomCW4h4ol0lUSIy+qixdoStfM3tjTy/KXPk2xJ5olzn8BlczHjqBnAvqXYhBDxQYI7QpLtyXhsHjxuT1TOv7tpN41JjVxfcD0/Kf4JVbdVcffEuwGob5EV6YWIJxLcEZJsN1bG2V0VnfWWWzxGa99hcQBgNVvJSM8AoMEtK9ILEU8kuCMk1WmslhOt4PZ4jZa+3Wrfu81mtWHxWqj3SItbiHgiwR0haUlpAOyujm5w26xt51ix++w0eKXFLUQ8kadKIiTdlQ7Anpo9UTm/2+sG2ge3w+egScsya0LEEwnuCElLMVrce+qjE9x7W9yWA4I7IMEtRLyRrpIIyUzNBKC6vjoq5w+2uB02R5vtDu2QFemFiDMS3BGSmd4a3E3RCW6vzwu07ypJIIFmJQsbCxFPJLgjJCsjCyBqoxTdPqPFbbfZ22x3mpwS3ELEGenjjpDk5GRMARN1vuiMUvT4Wvu4bW1b3ImmRNzKHY2ShBCHKOQWt1LKrJT6Win1ZjgLOlyZTCbsHjt1nugG94F93E6LE7dZgluIeNKdrpKbgLVd7iU65fA5qPdFZ7CL12/0cdvtbbtKkqxJuG1utNbRKEsIcQhCCm6lVD5wLvDv8JZzeIvmKjjBFveBfdxJtiR8Fh/NjdLPLUS8CLXF/VfgNiDQ2Q5KqWuVUkuVUksrKyt7pbjDjVNHbxUcj781uA9ocbscLgCqq6PztIsQovu6DG6l1HlAhdZ62cH201rP1FoXa62Ls7Kyeq3Aw0kSSTSp6DwzHewqObCPOznBmPxqT3V0BgYJIbovlBb3BOACpdRWYDZwulLqubBWdZhKNCfSZIpucB84cjIY3LJ8mRDxo8vg1lrfqbXO11oXAjOAhVrry8Je2WHIZXbRbIlOX3Kwq8RqsrbZnpwowS1EvJHnuCPIZXXhVm6+fuprLHYLJquJtXVrKRhVwImjTwzrub0Bo8VtNbcN7lSXMd1sTb0EtxDxolvBrbX+CPgoLJUcAQr7FOKr9vHgvQ9y9HdHs+K4FbxxwRsMWz2MVaNXhfXcvoAPAJu5bVdJMLjrGmX5MiHihbS4I+ien97DuzPf5a2r3qIio4L3y95HacUeFf4bg8EWt1mZ22xPTZHgFiLeyFwlEZRgTeC1S17DbDazonYFfzztj5zWdBr1lvAPyvEGvJj9ZpRSbbYHp5utbZaV3oWIF9LijrCBaQP57sbvSLAkkGBNYM2CNTSqRgKBACZT+H6PerUXc8Dcbnt6mrHAQ71bli8TIl5IizsK0hPSSbAmAJDpzCRgDlCxuyKs5/QFfJh1++BOTjKeKpEFg4WIHxLcUZadnA3AjpIdYT1PZy1ui8mC1WulwSPBLUS8kK6SKMtJz4HdULKrhDGMCdt5fLrjFjcYCwbX1Naw/n/rMZlNKJNiS2ALEydNbDdEXggRfdLijrK+mX0BKKsqC+t5vNqLRXf8e9qhHawPrOfXd/2aWefP4t5r72XKkik88tQjYa1JCHFopMUdZfk5+QCUV5eH9Tw+7es0uIuHFfPO1nd4ddqr9Bvcj01Vm6AadlSFt/tGCHFoJLijLL+vEdwVdWG+OUnnXSVv/uhNat21/Hz+z3l09aP4tR+A6maZMVCIWCRdJVGWmp6K1WNld9PusJ7Hhw9LJ7+nzSYz6QnpPHr2o/RJ7EOqIxW7x06NO3aGwctCD0LsI8EdZUopktxJVHmqwnqegwV3UHpCOp9c9QkfXvEhye5kar3RG5SjtWbuurmc+dyZJN+bjP2Pdm5bcJsEuBBIV0lMcPlcVJvC2y0RSnADDEofBEBSIIm6QPSGwW/YvYGpL02lD32YbJlMrbmWBz5/gC2rtjDnljlRq0uIWCDBHQNSdAq1hLd161M+rFi73rGVS7moU9EL7m3rtgEw6YVJDNkwBI2m5rwaXil+he07ttOvoF/UahMi2iS4Y0CqOZUSc0lYz+HHTwIJIe+fbEmmNFAaxooOrrnZmLf8tF+fxuVTL8fv8ZPxRgbLti9j1epVEtziiCbBHQMyrBk0WMI7ctGnfFhV6C3uVGsqTTShtW43MVUkNLcYwe10OrG7jEFAw4cPh+2wftN6zuXciNckwq+quorvvvmOAmcBAR3gyz1fMrdsLtedeh0TB06MdnkxQ4I7BmQmZOJRHhqbG0lMSAzLOfzKj0WF/u1OdaTSbG7G0+DZG5yR1OJpASDBvu9dwoiiETAfNpZtjHg9IjJ++Ocf8kHSB6RXpdPkbKIlwXgdeGZ5mHi3BHeQPFUSA7KSjMWVd5btDNs5fMrXreDOSMxAmzSVFZVhq+lggsG9/+LGWa4srD4r22q2RaUmEX7bfNtIb0zn2IHHcmG/C3lo4EMkNCfsfQcmDNLijgHZqdnQCCVlJQwZOCQs5/Cb/N3qKslwZUAdlJWXkT8oPyw1HYzb4wbA4dgX3EopsnxZlLqj1/cuwqvaXM0w3zA+vPnDvdt+96vf4VGeKFYVeyS4Y0DfjL5QAvf/7378S/0kq2S2+7azOWMzt19xe6+cw6+6F9yZqZlQQtinm+1Mi9docTsdzjbbc625lJvLCfgDmMzyhvFworWmzlFHn0CfNtst2oIHCe79ySs/BkweM5nitcW863iXadum8ewfn+WnW37KHVvvoLaudx4T9Jv8WEyh/57uk2788FTsiW5wO+yONtv7JfejJrmG2m2yYs/hprKqEq/VS25SbpvtloBl79J7wiDBHQNS81NZMnsJn172KSpLMfPGmVRlGiMpN2/Z3Cvn8Jv8WE2ht7izs4x5witro9PH7fYaXSUJCW0fYRyYPZDGpEZ2rg3f/QARHZu2bAIgLy2vzXartuLR0uLenwR3DJkweAJvXfoWidZExqaMBWDr9q09Pq7WGr+5e10lOX1yAKiqC+9Q/M54vMYP6v593ABFhUUArPpmFc3VzbTUtuCuc7O7JrxzvcQrf8CPL+CLdhkh2VKyBYB+WW2f0Zfgbk+CO8ZM6DeByl9V8ocxfwBgR1nPp1bVfk3AFOhWizsrxXjSpbopOjMEtviMrpIDH48cnD8YgHf+8w73p9/Pfan3ccvgW8h+JJtX33k14nXGuns+uoeM+zN47KvH8Af80S7noLZXbAegMK+wzXYLFnzExy+fSOmy01Mp5QA+Buyt+7+itb473IUdyaxmKwMGDABgx+6eB7ff6zda3OZuDHm3u1ABRXXLvuCO5GAcj89oYTmdbW9OFqYVApB/XT5TrFNAw1O1TxEwBViybgkXnXVRROqLF+9uepcmbxM3zL8BgJ+d8LMoV9S5kmpj9PDgAYPbbLdixYv0ce8vlBa3Gzhda30cMBI4Syk1NrxliYLsAgDKa3u+wILf4ydg7l6L26RMOH1OajzG1K7PfvMsR//jaMrqw7tST5Dbb/Rx2x1tB//kufIwKROWMRbG/WIc424Zx8YBxoCcnXXS770/j9/DN7u+4eYTb6YwtZBF2xZFu6SDKq0vxeqxktUnq812Ce72ugxubQiOx7a2/pG5NcPMZrbhdDvZ1byrx8dyu40Q7E6LGyDRn0hdoI6SuhJuePsGNu7ZyENfPNTjekLh9rux+CyYLW0Xf7CarQzNHMrTK56mtL6URk8jn+38DIDSZnm+e3+rdq3C4/cwJm8Mx+cez/Ky5dEu6aAqWipIaUnBZGobS1ZlxaskuPcXUh+3UsqslFoBVAALtNaLO9jnWqXUUqXU0srK6DyJcLhJ86VR5e35zcFgcNvMtm59XRJJ1Ot6bph/A76Aj0kDJvHE0ieobAz/99fj92D2d7xiz6yps9jTvIfzXjiPV9e+isfvweK3sMvX819yh5MlpUsAGNN3DKNzR7OpehO1LbH7GOXuwG5Sfantttuw4VPSx72/kIJba+3XWo8E8oETlFIjOthnpta6WGtdnJWV1f4gotvSTelU0/Obg81uY7iwzdK94E42JbM5fTNz183l3A3ncvrzp9PsaeY3//5Nj2vqiidghHFHRuWOYs4P5vBt5bdcMfcK7GY7x1Qfw26TPFkC8J/l/+G+T+9jSckSMhIyKEwtZHTuaABWlK+IcnWGq+ZdxaxvZrXZtse0h0yV2W5fq8kqwX2Abj1VorWuAT4CzgpLNaKNLHsWtbZaAr5Aj44TfLSuu10leQV5uB1u0lrSmLx9Mvm+fHIrclm8td0brl7n8XswBzpucQOcfdTZfHnNlxydcTQXFl1IgamAalv1EbtCTqOnEY/f+D4/tuQx7vjgDl5d+yrFfYtRSjEqZxRATHSXNHubeXrF09ww/wZ2Nex7l1Rjr6GPrU+7/W3KhtckXSX76zK4lVJZSqnU1o8TgDOAdeEuTEB2UjYNiQ007OrZlK97u0q62eLOyzcGQjzwgwe49sNrufyDy8myZVGtwv+IoEd7Ol2VPmhkzkjW/WwdL3z/Bfo6++K1eMO+dmesGvvEWK76x1WsfH4l3+36DoBady3H9zkeMF5Lea48lpdHP7i31BjPa9e567jrg7sAqG2oxWPzkJOY025/q9mK3xTbjzJGWihjoHOBZ5RSZoygf1lr/WZ4yxIAuam5eJo87Nq2i+S85EM+TnDCpu72cU8eNJnyxnKuGHnF3m0Z5gy2mrceci2h8ga8XQY3GBNPmZWZguQC8MCW8i1kDTqyuuoqGytZXbOa6p3V5D+fT8PtDYxaPorNAzeTODsRPdl4jHNU7qiYaHFvrjZGA0/Mn8hTK57irMKzKAwUAtA3tW+7/e0mu3SVHCCUp0pWaq1Haa2P1VqP0Fr/PhKFCSjoYzwSuGX7lh4dJxjcVkv3ukqmDZvGvBnz2sxxkmXPosHREPbBHB7twapDr7dfpjHabuOOI2+u7g+WfABATX7lk1I3AAAecklEQVQNZ3xwBgC33nIrc1Pn4n3Ky7u/eJdl/1pGXmke31Z+y2l/OY3PVnwWtXo37jG+R6NvHU3ejjwufuVizv7v2QAck3tMu/3tJjs+swT3/mR2wBjWv29/WAHbS7f36DjB4LZber4gQnZSNn6vn4qqCnKzcrv+gkPkJbQWd9DAvgOh1GhxH2k+/NqYArWRRlazGoDjhh7H8JOHU7m6ksV/M+5JpNvSGXvaWD4t/pTfPv9bFo5cGJV61+1Yh81tY/yZ45l81GRudN+IO9PNAwkPcMEFF7Tb32oxukqitRpTLJLgjmH9+/YH4LPXPsP0pgmzNlNrrmV20Wxm3TyLQYMHhXScvTcnrd1rcXckNzkXqmDrzq3hDW7t7dbixoUFhZgWm9hWFd1FFho9jXgDXlId7R9rC5el5UtRDoU2ad7e+DYAA1IHoEyKaS9Po7603hh5oeBOdSdDHxga9sWpD2bdznWkVacx9uaxFIwrYEpgCiZlwqQ67gCwm+2gjQbIgbNFHqlkrpIYlpNs3Kj5aPxH3DD+BnY4drAgdwFfZH3BnAVzQj5Ob7a4+2YYfZC9MYfKwXjxYulGuyIlNwVXvYuSuvAuunwwc9bMYdCjgxj5z5E0eHq+hui2mm1UNR38OX6tNetN6zmmwehiWLR1EdmJ2STajDlelFIk5yWTnJ9Mcl4yrr4uknQSDYR3jdOD2VK7hfTqdLKPNWagtJgsnYY2tAY30NTUFJH64oEEdwzLcmahUGxN3EqztZlPL/2UL4/5EoCNFaH35QanSLVZu3dzsiPBofg7K8M7vNyLFxuh1+vMcJJcn0xZS2SG5B9o1a5VTH9lOpnOTLbVbuMPi/7Qo+NprTnl6VO4Yu4VB91v1YZVNDoaOTPrTBKtiXgDXgalH/ydmEu5aKSxR/UdqoAOUKbLyFN52BJD+/7ara3B3SzBHSRdJTHMarZSlFlEUWYRI3NGcvdHxtxeKqDY2rA15OMEJ2wK/gD0RP88o/umtDq8w8t9ytetm5PKpMjwZLBZb6a0vpS+rvZPJ4TT1pqtADwy+hGe2/4cD3/xMCktKVxQeAFFRxdhsbf9UavYWsGyvy1j13LjOWa/8rOkzxIW5i/kp8N+yqTzJ7Gtdhsl9SXsbtpNpjOThd8sZPor06k11eLwO8hvyqcl0AJpcEbxGSzcvJBlZcsYmDbwoLUmmZNoUtEJwdL6UrwmL4MyQuvmg33vFFuaW8JVVtyR4I5xK36yAqvJSrOvmSeXPUmfxD40rG+gxBd6l0Cwj7s3Wtx5+XmY/CZ21Yd3eLlXebs1fzjA5PLJ/L3w75z47xPJT87HH/Dz4kUvdtkC7Q071htdR/POn0d2UzYZl2fwa/1r/vDZH7jpbzfh9LbOcqhhyfFLePust3FanBSMLMAesPNdync0WhtRWnHfsvtYV2IMlfAFfDz+4uMUWYq4Yv0VJDQlcMbuM2i0NVKaXIoyKU6qPYlTJ55KUV0Ry8qWMSjt4P+/KdaUiAR3o6eR29+/nVP6n8LUoVOxmCys3mjcPB3Wf1jIxwkGt7S495HgjnHBZ6+dViefXvUpVrOVy/50GSvVypCPEWxx779i+qGyJ9pJbEqkwh7eJc18ytet2QwBRtpGcv3/rueN779BY2Mj2wPbmfCPCbzz/XcYOWJkmCo17K4yBv5M/OlE+mf1Z0bCDFaykqtKrmLPnXuY4plCOeV8YvqEt0xvMdI0kiHHDWG7Zzs1LTVc1PciLhp6EVurtnLTgpt4se5Fchpz8Fq9PLbrMepd9ST4Enj3oncZc/KYDmsoyjQWmeiqxZ1iT8GNG5/Ph8USvgh4d9O7PLbkMR5b8hgWk4U0exoZOgOAUceOCvk4wddtU4sEd5AEdxwZkGbM0V3oKuRj78c0VDeQlJbU5df1Zh83QIonhSpTeFfG8Zl82ALdqzd3dC7JbyVz2YrLACjPLueZK57h/BfPZ+3da0mydX2tDlVto/GUxpjpYxgwwvg+jWY0s5+bzRvlb6BGKWYunwnAaYWn8dYlb5FgTWh3nJqWGm7/8Hbqk+u58vgrsZlsPLT+IXIduXxw8QcM7Te00xpG9DGmEBqSMeSgtaYmpEILVO6uJDcnfE8GLVq5CJPfxLRXplHat5R6Vz3ritbh0A5Gnzg65OM4rEZwt7ilqyRIgjsODc4ZjC7RrF6zmrEndT01utdnzPNgs/VOcKf6U6nSVcxdN5c6dx2XH3d5rxx3fz6Tr1s3JwFO/d2pjLt1HGj2zlmS+pNU7ht6H9e9eR3PTX0ubM8B1zXXAZCent5m+6/G/4ozZp3BzOUz+cXYX3D5cZdzTJ9jMJs6nocl1ZHKtGHTeG7lc0w/aToD0wayy76L35z8G4ZkHjyQzz/6fOZfOp8T8k446H5piWnQAhWVFWEN7s83fE72rmxuuvomzDYzOqBp9jdj6WchMTWx6wO0stuMrpLmluZwlRp3JLjj0LDCYVACazauCSm4996ctPX85iQYsxbuMO/g+reup85dx/eHfr/XW7OHEtxKKRwpbbuDpgyZwlcffsUL6gWyE7N5aMpDYQnvenc9Vo8VZ2rbFXtOH3A6d550J6NyRvGD4T8I6Vi/nfhbcpNyGZc/DrPJzKyps7r+IsBsMnPW4K7nf0tPSocqY1X1cAnoAGs8azi+8XjG3zq+R8cKdpVIi3sfeRwwDo0YarwlXl+yPqT9ezu4M62Z1CbUUtZQRqO3kTlrQn+mPFR+k7/bc6t0JGdUDid/fDJX97+aR758hDs/uLMXqmuv3lOP3WPHktC2LaSU4s+T/hxyaAMcnXE090++v9NWeU9lpBj9zLurwzch17pd62i2NDO6T+hdIp1JsBtdShLc+0hwx6FBuYMw+U1s2RPa8O7gdJ+9Neqsj9OYejM9IZ3B6YN5asVTvXLcIK01fkvvBHfuqFwUiuuar+OaUddw/2f38/mOz3uhyrYavY3Yffa4GJKdmWbMeb27tneDe+GWhWzaswmABZ8tAOC00af1+LjBFnezR7pKgiS445DZZCbDncGGug088PADfPzkx3wz6xvmzZpHWXn7ASi93ccdHNE5/ajp/N/I/+OT7Z+wtnJtrxwbjHq10ntHzPVESv8UHGkOyleU8/CZD5OfnM/Vb1yN2+fuhUr3afQ34vDHx3DsPunGL97q+t6bnndn3U7OfO5MTnn6FMrqy/h4zcdYPVYmTZnU42MnOIwWd3AEsJDgjlv59nxW5q/ktvrb+NmCn/HkL5/k+999nxsfvbHdvt6AEdzBt5w9dWzWsTiaHZyy8xQmVEwg0ZTIyTNPZt4n83rl+E2NxmNf3Z0/vCNKKXJH5VK+vByX3cWT5z3Jut3r+M3C3l3Fp1E3khDonesbbn2yjODe07inV4638rmVXDL9Evw+Y/KxoXcPZZ53HgNqBuDq4+rx8YPvFFs80lUSJDcn49Qvf/BL5q2Zh9Pk5GmepurEKgJNATbXbW63794V0+2908c9ZugYbv+/21nf+t+VmVcye8ZsLnnrEuon1Ldb7LW7gs/r9kaLG4x+7q/+8RXr/7eegQzk4syLefCLBzkp+SQuHHthr5yjSTeRQkqvHCvcsjKN+cprm3tnoqmvXviKpaOXcrI+mUlM4knXk0wMTOS2C2/rleMHW9wtXgnuIAnuOHXJMZdwyTGX4PF7WP6v5azctZIUXwrlqrzdvj6/MZdxbwV3/th8fv7dz/E0eNABjQ5orK9b+avtr3y78VtGHN1uSdJuaW42+jJ7Y4g+QMH4Ar546AtmXzAbgAHWAWT9OIsZb8zgBdsLTB09tcfnaFbN5KrwPVrXm2xWGzaPjRp/TY+P5W32Mq92Hs32Zv7yf39hXME4/h//rxeq3MfhkBb3gSS445zNbGPejHl8ufNL5rw0h/85/4ff68ds3fdEgsfvAXPvBSFA+uC2zyuP3zaev67+K4tXLe5xcAdb3MGBFz1VNLWIn6z8CX7PvsUfJm2dxKULLuWiNy7iZcfLTBs2rUfnaDG3kGgO/dnkaEvwJlDnr+vxcbZ+vJXPj/+ckYkjGVcwrhcqay8xwbiuvX1fIp5JcB8GClMLKUwtZNkHy/DWeNn83WaOGnbU3s/7Aj5jia8wPV4GcOKxJ8Jq+Hrb1z0+VnAyod6YhhaMfu7sY7LbbOt7fF/+/t7fuXHXjdz48o24Ai6s2koTTaxMXskdt97RrS6fFksLSZbwjczsbU6/k3p/fY+P8/wHz7MnYw9/P/3vvVBVx/benJTg3kuC+zAypGAI1MCqtavaBLcn4MGswhfaAAWDCkitSWWNd02Pj7W3xd0Lc6sczFm/O4up06byRM4T/O3dv3HikhN55fuvsPqY1QxfOJwLzwit/zugA3isHlyBnt+Ii5REnUiD7t6c3LXbaylbXmaMStUQ8Ad4ruE5MswZTB85PUyVQkJCa3B7JbiDJLgPIyOOHgGrYN22dW22ewPeg05U3xuUSZHfnM8m26YeHys40KK3Bgx1Jiknicc+eYx1z67j86mf0/+3/Vm9zJi9bu6auSEHd12T0eXgssdPcCeRxB7VvadKZl84m/IVxj0Un9nHW+e+xabRm7jFeUubdUl7W2Jia1eJX4I7SIL7MDL8qOEAbKxsu8iCL+ALe4sbYJB5EG/a38Tr92I1H/oyacHg7q0+7oNRSvGv8//FVfOu4p/L/klxbjFVn1fxfv/3Qz5GVbUx4VZyQnK4yux1LrOLnYS+GEb15mr+m/tfNl24CWuClUp3JX7t55fDf8l9U+8LY6UYMxhq452jMMhz3IcRl91FkjuJ7fVtFxf2ai+WQPh/Rw9LG4bf7Gftrp4Nxml2G0+VRGp9wUHpg1h05SIWXbmIty59ixP2nMBO007W7Tbeuby0+iX++uVfO/36PXuMlmtKQnw8DgiQbE2myRr6NKnvv/Y+X53wFUdlH8U5Redw+4TbeefSd3hg2gOYzOGNEZPJhMVnkT7u/XT506yUKgCeBXKAADBTa/23cBcmDk22L5tSf9vVabzai1mHv8U9st9IKIPFaxZzbN9jD/k4wce+wt3HvT+lFBP7TwTg1KRTeYmXeH3t65x39HlcMfcKlFJcd/x1HU7FuqemNbiT4ie4U+wptPhb2j2B1Jkn1z2JOc/Mq5e9GvHVhQAsfgsepMUdFMqvSh9wq9Z6KDAW+JlSKvTlK0RE9bX1pdxeztRZU/neC99jU9UmfNqHORD+4D5+2PFYvBYWbFjQo+O43UbLKlorehcNKaLftn785sPfMHnWZPzaT4uvhU+3f9rh/tV1xtDx1KTIrezeU6mOVALmADV72j7LrbVm4zsbeX7m8/zk0Z+w5MUlfPrcp3yS/Qmnq9OjEtoA5oBZukr202WLW2tdBpS1flyvlFoL5AHfhrk2cQgGpg3kE+snzN08F4vXwptr38RqtZLsDX//a+7QXEb+ZSSvmV7jkUmPkK7T2Za6jQ8LP+TlO18mKysrpOMEJxNyOpxd7BkeWcOymHHfDKr+WcXLJS/z4kUvcsmrl7Bg8wImD5rcbv+aOiP80lLSIl3qIQvOyb32i7UcW3wsfq+fbyu/5eWnX6bkkxLeuOANvDYv876dR4ujBW+Kl9sn3R61eq0Bq7S499Otjk+lVCEwCljcweeuBa4F6NevXy+UJg7F2PFjeea9Z7gq4SrOd5zPCy0vsNS0lOPzjg/7uZ0ZTq4vup6rTVfzzsB3GFI1hH8N+xct1hZefudlfvajn4V0nOBjX9FqcfcZ3gdns5NLTZfyrzv+hVKKx5c8znub3uP+yfe327+m0Qju9JT0dp+LVTnZOVAFtz1xG4VbC9lRsIPPx39OIDsA06AotYgbim7g9qW3k2XPYtb4WUwa3/MJow6VWZvxam/Uzt+ZdXPXsfa1ffd07Cl2zvn7OWE/b8jBrZRKAl4FbtZatxtypbWeCcwEKC4u1r1WoeiWy46/jJy0HC4YcgEmZWIqPR/O3R1XPXgV7736HrPVbN7Lf48h6UNYX7We5duWh3yMYHAHB15EWvpR6ZgsJkq+KmHA6cYyZKdkncI9S+6hvKGcnKQc3v7ubYZlDaMwtXDvsmXpafET3D84+wfMrZnLwvEL+WL8FwCck3QON426CU++h5P7nUyKI4WLJ15MojWx1wZDHapYbXF/dPdH7Nm0h8Q+iTRZmwjkBjiHGAlupZQVI7Sf11q/Ft6SRE8k2ZL4XtH3olrDfWfcx5CMIYzMGcnkgZMpvLOQb1XoPWvBpweCAy8izWw1kzk0k6/+/hVf/f0rAEpzS+E6ePzZx7n4Bxdz3gvncVTGUXx93dd7ly3LyMiISr2HIjspm/d//D7barZR1lBGv5R+HfZfpyfExi8jq7biJbZa3H6Pn8q1lYy7dRyn/ek0zn/xfJaVLeMmz01hXd8UQnuqRAH/AdZqrR8OazXisNAvpR/3nHrP3n8X+gvZbGk/a2FngrPARavFDTB11lRKFpfs/XdAB3j7m7d5zPcY3374LTazjQ1VG7htwW3Uu+tRWpGaGj83J4P6p/anf2r/aJfRJQsWPDq2Wty71+9mff/1lOWV8erbrzJ/43yeOPeJsIc2hNbingD8CFillFrRuu0urfXb4StLHE6GuoayzLSM+sZ6XIldjy4MLrXmdEbn5iRAznE55ByX02bbdZdfx2+zf8ura1/lF2N/gdaavy7+K2N8Y7AFbGF/nvlIZsWKD1+0y2hj1ze7mH/2fPZU7YEquGbUNVx3/HUROXeXrzSt9adaa6W1PlZrPbL1j4S2CNnI/JFok+aL5V+EtH+wq8SZEL3g7sjk4skcs/IYHGYHt467lVvH3wrAMssyHN74WP0mXlmIvee4v1n1DXsy9nDPxHv44PIPePzcxyO2dJ00EUTYjTvGmO5z8Zp2DyN1KDgnRXAe5ljR7+R+XPDGBczJm0Nech75yfmM6TuGgArgCMRWrYcbG7aYa3EvKl0EwLTh0zh9wOk9muahuyS4RdgdP/p4rF4rK0pWdL0zRleJ2W/u8Uo6vS372GySnEltHoadWmQ8tRMvy5bFK6uy4lXRuTnp8XsonlnMTfNvwuvfV8MylpHmS2NYVuTHI8okUyLsbA4bfev78pXvK547+zlMJhPbndv5OuNrbrr4JsafMr7N/p6AJyJD9LvLZDZRMKGADf/bwIIUY3RoH9UHEsBJbHXrHG6syopPRafFvXDLQpaVLWNZ2TK+3f0tc384l0B1gA25G5iYMDFi3SP7k+AWEXFJv0u4t+Fe3tz9JptSNrE0bykALf9rYd4pbRcZdvvdWFRsvjSH/3A42z7eZjwm2DpaIefKHPL75Ee3sMOcTUWvq+SVla9g99k5+6OzmXf6PEb+eCRHbTiKprOamDyg/UjaSIjNnw5x2PnTLX9i6XNLeYmXALj7lLv59zv/ZkP9hnb7egKemA3ukVeMZOQVI9tsu775emzmnq9ILzpnM4U/uLXWfFXyFSfknbC3Fe0P+Hlt5WsMWj+Ia465hoHugTw88GE2DtzIENMQrjz/yrDW1JnY/OkQhx2lFP+54D9c9vpl/GzMz5g+fDpffvoln3s/p6G8gaScfc++erUXM7HXVdKZtIT4maMkXtnMNnw6vMH94uoXufS1S/nzkD9zaf6lAHy28zOqVTVXZl7JuY+fy7mcy6nrT8VusTN54OSodJOABLeIoIKUAhZduWjvv0cNGsW7G95l9aLVjP3h2L3bPQEPVhW5O/Qi9kWixf2P+f8A4J6V9/DN775h9YjVbBmwBbPdzC233bJ3v/OHnB/WOkIRW7ftxRHlxONOBOCzxZ+12e7VXixa2hRiH5vZht/s77Xjefwe/vTxn1heZsyhs3PPTr5s/JIxO8ZgTjDz0oyXKB1ZypTCKcw5dw75hbF1D0N+OkTUHJtrLLawfONyarfXYraZMVlMRovbJC1usY/dbMePH7/Pj9nSs2602oZaLpx1IYsqFvHo54/yzsnv8O8P/o02aX5/zu/xjfCxac8mrh59dUSGrx8KCW4RNYWphThwsMm7iZN/cTJp1WmcsugUdv14l/G8tBCtbGYb+KG5uZkk16G/Njat28QZT5zBttRtTPxkIl+M+4LT55xOk7OJAS0DOHPqmVHrt+4OCW4RNSZlYnj2cFaOW0mzNhZP2HzaZsoD5fzx2D9GuToRS+wWe4fBrbXmhfdfoLamlsKEQoYlGYNhtn63lU9e+oQFyQtYMXgFOVU5JDcks6nvJhqSG3gg4wHOu/k85lfP529lf+OUxFO464y74iK0QYJbRNmInBEs27WMk/qdxIl5J/LQFw/x0JSHuGXcLV1/sThiOKwOcMMHSz9gjX8N39Z8y/SjpvPs68/ytnPf1EkF2wtw291UZFfAyWDSJsa4x1CeW85W01YKdAF/PuvPnDfhPACGMISbuTla/1uHTIJbRNUJeSfwwqoXePycxzkm+xjuOvmumJkDWsSOhIQEaICLl1xs/Lspgdc2vwZOmOaextXjr+aLmi943vk8OdYcrs69mqKiIiYUTGBQ+qAoV9/7lNa9v1hNcXGxXrp0aa8fVxx+fAEfFY0VUVuEVsSHLRVbuOuluxhmHsZY61hcfhdvNr6JK8/F7TOitxZmb1JKLdNaF4e0rwS3EEJEX3eCW57jFkKIOCPBLYQQcUaCWwgh4owEtxBCxBkJbiGEiDMS3EIIEWckuIUQIs5IcAshRJwJywAcpVQlsO0QvzwT2N2L5fQmqe3QxHJtENv1SW2HJpZrg47r66+1zgrli8MS3D2hlFoa6uihSJPaDk0s1waxXZ/UdmhiuTboeX3SVSKEEHFGglsIIeJMLAb3zGgXcBBS26GJ5dogtuuT2g5NLNcGPawv5vq4hRBCHFwstriFEEIchAS3EELEmZgJbqXUWUqp9UqpjUqpO6JcS4FS6kOl1Fql1Bql1E2t2+9RSpUopVa0/jknijVuVUqtaq1jaeu2dKXUAqXUd61/p0WhriH7XZ8VSqk6pdTN0bp2Sqn/KqUqlFKr99vW4XVShkdbX4MrlVKjo1DbA0qpda3nf10pldq6vVAp1bzf9ftnOGs7SH2dfh+VUne2Xrv1Sqkzo1DbS/vVtVUptaJ1e0Sv3UHyo/ded1rrqP8BzMAmYCBgA74BhkWxnlxgdOvHLmADMAy4B/hltK9Xa11bgcwDtt0P3NH68R3AfTHwfS0H+kfr2gETgdHA6q6uE3AOMB9QwFhgcRRqmwJYWj++b7/aCvffL4rXrsPvY+vPxzeAHRjQ+vNsjmRtB3z+IeD/RePaHSQ/eu11Fyst7hOAjVrrzVprDzAbuDBaxWity7TWy1s/rgfWAnnRqqcbLgSeaf34GeB7UawFYBKwSWt9qKNoe0xr/TGw54DNnV2nC4FnteFLIFUplRvJ2rTW72mtfa3//BLID9f5u9LJtevMhcBsrbVba70F2Ijxcx3x2pRSCpgOvBiu8x/MQfKj1153sRLcecCO/f69kxgJSqVUITAKWNy66YbWtzP/jUZXxH408J5SaplS6trWbdla6zIwXjxAn6hVZ5hB2x+eWLl2nV2nWHsd/h9GSyxogFLqa6XUIqXUydEqio6/j7F07U4Gdmmtv9tvW1Su3QH50Wuvu1gJbtXBtqg/p6iUSgJeBW7WWtcBTwCDgJFAGcbbsWiZoLUeDZwN/EwpNTGKtbSjlLIBFwBzWjfF0rXrTMy8DpVSvwZ8wPOtm8qAflrrUcAtwAtKqeQolNbZ9zFmrh1wMW0bDFG5dh3kR6e7drDtoNcuVoJ7J1Cw37/zgdIo1QKAUsqKcdGf11q/BqC13qW19mutA8C/CONbwa5orUtb/64AXm+tZVfwLVbr3xXRqg/jF8pyrfUuiK1rR+fXKSZeh0qpK4DzgEt1aydoaxdEVevHyzD6kI+OdG0H+T7GyrWzAN8HXgpui8a16yg/6MXXXawE9xLgKKXUgNaW2gzgjWgV09pH9h9grdb64f2279/vNBVYfeDXRoJSKlEp5Qp+jHFDazXGNbuidbcrgHnRqK9Vm1ZPrFy7Vp1dpzeAy1vv8o8FaoNvbSNFKXUWcDtwgda6ab/tWUopc+vHA4GjgM2RrK313J19H98AZiil7EqpAa31fRXp+oAzgHVa653BDZG+dp3lB735uovUndYQ7sSeg3H3dRPw6yjXchLGW5WVwIrWP+cAs4BVrdvfAHKjVN9AjDv43wBrgtcLyAA+AL5r/Ts9SvU5gSogZb9tUbl2GL88ygAvRsvm6s6uE8Zb1sdaX4OrgOIo1LYRo78z+Lr7Z+u+F7V+r78BlgPnR+nadfp9BH7deu3WA2dHurbW7U8DPzlg34heu4PkR6+97mTIuxBCxJlY6SoRQggRIgluIYSIMxLcQggRZyS4hRAizkhwCyFEnJHgFkKIOCPBLYQQceb/A2mnK8Kh96A/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean,label=\"prediction\",color=\"purple\")\n",
    "plt.plot(true_mean,label=\"true\",color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 891 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-8f490e15968d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                          \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasures_locations_test_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                          \u001b[0mPredicted_Weights_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                          measure_weights_test.reshape(-1,))\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mW1_errors_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1_errors_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW1_loop_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Get Means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/ot/lp/__init__.py\u001b[0m in \u001b[0;36memd2_1d\u001b[0;34m(x_a, x_b, a, b, metric, p, dense, log)\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;31m# (useless overhead)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     G, log_emd = emd_1d(x_a=x_a, x_b=x_b, a=a, b=b, metric=metric, p=p,\n\u001b[0;32m--> 736\u001b[0;31m                         dense=dense and log, log=True)\n\u001b[0m\u001b[1;32m    737\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_emd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/ot/lp/__init__.py\u001b[0m in \u001b[0;36memd_1d\u001b[0;34m(x_a, x_b, a, b, metric, p, dense, log)\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0mperm_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_b_1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m     G_sorted, indices, cost = emd_1d_sorted(a[perm_a], b[perm_b],\n\u001b[0m\u001b[1;32m    636\u001b[0m                                             \u001b[0mx_a_1d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_b_1d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                                             metric=metric, p=p)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 891 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "print(\"Building Test Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors_test = np.array([])\n",
    "Mean_errors_test = np.array([])\n",
    "Var_errors_test = np.array([])\n",
    "Skewness_errors_test = np.array([])\n",
    "Kurtosis_errors_test = np.array([])\n",
    "# Initialize Prediction Metrics\n",
    "predictions_mean_test = np.array([])\n",
    "true_mean_test = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_test_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_test_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights_test[x_i,].reshape(-1,),\n",
    "                         measure_weights_test.reshape(-1,))\n",
    "    W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "    # Get Means\n",
    "    Mu_hat_test = np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array))\n",
    "    Mu_test = np.mean(np.array(measures_locations_test_list[x_i]))\n",
    "    Mean_errors_test = np.append(Mean_errors_test,(Mu_hat_test-Mu_test))\n",
    "    ## Update Predictions\n",
    "    predictions_mean_test = np.append(predictions_mean_test,Mu_hat_test)\n",
    "    true_mean_test = np.append(true_mean_test,Mu_test)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat_test = np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))\n",
    "    Var_test = np.mean(np.array(measures_locations_test_list[x_i])**2)\n",
    "    Var_errors_test = np.append(Var_errors_test,(Var_hat_test-Var_test)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat_test = np.sum((Barycenters_Array**3)*(Predicted_Weights_test[x_i]))\n",
    "    Skewness_test = np.mean(np.array(measures_locations_test_list[x_i])**3)\n",
    "    Skewness_errors_test = np.append(Skewness_errors_test,(abs(Skewness_hat_test-Skewness_test))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat_test = np.sum((Barycenters_Array**4)*(Predicted_Weights_test[x_i]))\n",
    "    Kurtosis_test = np.mean(np.array(measures_locations_test_list[x_i])**4)\n",
    "    Kurtosis_errors_test = np.append(Kurtosis_errors_test,(abs(Kurtosis_hat_test-Kurtosis_test))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance_test = np.array([np.min(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test))])\n",
    "Mean_prediction_Performance_test = np.array([np.min(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test))])\n",
    "Var_prediction_Performance_test = np.array([np.min(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test))])\n",
    "Skewness_prediction_Performance_test = np.array([np.min(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test))])\n",
    "Kurtosis_prediction_Performance_test = np.array([np.min(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test))])\n",
    "\n",
    "Type_A_Prediction_test = pd.DataFrame({\"W1\":W1_Performance_test,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance_test,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance_test,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance_test,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance_test},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction_test.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Test.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predictions_mean_test)\n",
    "plt.plot(true_mean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print for Terminal Legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#----------------------#\")\n",
    "print(\"Training-Set Performance\")\n",
    "print(\"#----------------------#\")\n",
    "print(Type_A_Prediction)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"#------------------#\")\n",
    "print(\"Test-Set Performance\")\n",
    "print(\"#------------------#\")\n",
    "print(Type_A_Prediction_test)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facts of Simulation Experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User\n",
    "print(\"====================\")\n",
    "print(\" Experiment's Facts \")\n",
    "print(\"====================\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"=====\")\n",
    "print(\"Model\")\n",
    "print(\"=====\")\n",
    "print(\"\\u2022 N Centers:\",N_Quantizers_to_parameterize)\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"========\")\n",
    "print(\"Training\")\n",
    "print(\"========\")\n",
    "print(\"\\u2022 Data-size:\",(len(x_Grid)*len(t_Grid)))\n",
    "print(\"\\u2022 N Points per training datum:\",N_Monte_Carlo_Samples)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"=======\")\n",
    "print(\"Testing\")\n",
    "print(\"=======\")\n",
    "print(\"\\u2022 Data-size Test:\",(len(x_Grid_test)*len(t_Grid_test)))\n",
    "print(\"\\u2022 N Points per testing datum:\",N_Monte_Carlo_Samples_Test)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
