{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Conditional Laws for Random-Fields - via:\n",
    "\n",
    "## Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$.\n",
    "\n",
    "---\n",
    "\n",
    "By: [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---\n",
    "\n",
    "## What does this code do?\n",
    "1. Learn Heteroskedastic Non-Linear Regression Problem\n",
    "     - $Y\\sim f_{\\text{unkown}}(x) + \\epsilon$ where $f$ is an known function and $\\epsilon\\sim Laplace(0,\\|x\\|)$\n",
    "2. Learn Random Bayesian Network's Law:\n",
    "    - $Y = W_J Y^{J-1}, \\qquad Y^{j}\\triangleq \\sigma\\bullet A^{j}Y^{j-1} + b^{j}, \\qquad Y^0\\triangleq x$\n",
    "\n",
    "3. In the above example if $A_j = M_j\\odot \\tilde{A_j}$ where $\\tilde{A}_j$ is a deterministic matrix and $M_j$ is a \"mask\", that is, a random matrix with binary entries and $\\odot$ is the Hadamard product then we recover the dropout framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode:\n",
    "Software/Hardware Testing or Real-Deal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random DNN\n",
    "f_unknown_mode = \"Heteroskedastic_NonLinear_Regression\"\n",
    "\n",
    "# Random DNN internal noise\n",
    "# f_unknown_mode = \"DNN_with_Random_Weights\"\n",
    "Depth_Bayesian_DNN = 50\n",
    "width = 200\n",
    "\n",
    "# Random Dropout applied to trained DNN\n",
    "# f_unknown_mode = \"DNN_with_Bayesian_Dropout\"\n",
    "Dropout_rate = 0.25\n",
    "\n",
    "# Rough SDE (time 1)\n",
    "# f_unknown_mode = \"Rough_SDE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: *Why the procedure is so computationally efficient*?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rough SDE Meta-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDE with Rough Driver\n",
    "N_Euler_Steps = 10**1\n",
    "Hurst_Exponent = 0.01\n",
    "\n",
    "def alpha(t,x):\n",
    "    output_drift_update = t-x\n",
    "    return output_drift_update\n",
    "\n",
    "def beta(t,x):\n",
    "    output_vol_update = (t+0.001)*np.diag(np.cos(x))\n",
    "    return output_vol_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)\n",
    "- Ratio $\\frac{\\text{Testing Datasize}}{\\text{Training Datasize}}$.\n",
    "- Number of Training Points to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = .2\n",
    "N_train_size = 10**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Monte_Carlo_Samples = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial radis of $\\delta$-bounded random partition of $\\mathcal{X}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "Proportion_per_cluster = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 127.04it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 125.80it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 163.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "==========================================\n",
      "Training Classifer Portion of Type-A Model\n",
      "==========================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8989 - accuracy: 0.0600\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.8923 - accuracy: 0.0600\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8870 - accuracy: 0.0600\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8823 - accuracy: 0.0600\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8773 - accuracy: 0.0700\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8724 - accuracy: 0.0900\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8677 - accuracy: 0.0900\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8632 - accuracy: 0.0900\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8588 - accuracy: 0.0700\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8545 - accuracy: 0.0700\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8501 - accuracy: 0.0700\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8457 - accuracy: 0.0600\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8413 - accuracy: 0.0600\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8367 - accuracy: 0.0600\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8327 - accuracy: 0.0600\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8275 - accuracy: 0.0600\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8230 - accuracy: 0.0700\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8179 - accuracy: 0.0700\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8128 - accuracy: 0.0700\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.8074 - accuracy: 0.0700\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8021 - accuracy: 0.0700\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.7968 - accuracy: 0.0500\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.7914 - accuracy: 0.0300\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.7864 - accuracy: 0.0300\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.7806 - accuracy: 0.0300\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7754 - accuracy: 0.0300\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7694 - accuracy: 0.0300\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.7638 - accuracy: 0.0300\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.7580 - accuracy: 0.0300\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.7519 - accuracy: 0.0300\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.7457 - accuracy: 0.0300\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7403 - accuracy: 0.0300\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.7337 - accuracy: 0.0300\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7278 - accuracy: 0.0300\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.7215 - accuracy: 0.0300\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7150 - accuracy: 0.0300\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7089 - accuracy: 0.0300\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7023 - accuracy: 0.0300\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6959 - accuracy: 0.0300\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6893 - accuracy: 0.0300\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6828 - accuracy: 0.0300\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6763 - accuracy: 0.0300\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6695 - accuracy: 0.0300\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6629 - accuracy: 0.0300\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.6567 - accuracy: 0.0400\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6497 - accuracy: 0.0400\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6430 - accuracy: 0.0500\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6361 - accuracy: 0.0500\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6290 - accuracy: 0.0500\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6218 - accuracy: 0.0400\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "===============================================\n",
      "Training Classifer Portion of Type Model: Done!\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:00<00:00, 166.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 303.98it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 555.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#----------------#\n",
      " Get Test Error(s)\n",
      "#----------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %run Universal_Measure_Valued_Networks_Backend.ipynb\n",
    "exec(open('Universal_Measure_Valued_Networks_Backend.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run: Benchmarks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run: *Pointmass Benchmark(s)*\n",
    "These benchmarks consist of subsets of $C(\\mathbb{R}^d,\\mathbb{R})$ which we lift to models in $C(\\mathbb{R}^d,\\cap_{1\\leq q<\\infty}\\mathscr{P}_{q}(\\mathbb{R}))$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to f(x) \\to \\delta_{f(x)}\\in \\cap_{1\\leq q<\\infty}\\mathcal{P}_{q}(\\mathbb{R}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "--------------\n",
      "Training: ENET\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 720.29it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 631.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "-----------------\n",
      "Training: K-Ridge\n",
      "-----------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.5s finished\n",
      " 43%|████▎     | 43/100 [00:00<00:00, 426.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 504.92it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 566.91it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "--------------\n",
      "Training: GBRF\n",
      "--------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.5s finished\n",
      "100%|██████████| 100/100 [00:00<00:00, 768.75it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 410.17it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "-------------\n",
      "Training: DNN\n",
      "-------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9969 - mse: 1.6241 - mae: 0.9969 - mape: 101.5082\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9969 - mse: 1.6241 - mae: 0.9969 - mape: 101.4691\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9967 - mse: 1.6237 - mae: 0.9967 - mape: 101.3836\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9966 - mse: 1.6235 - mae: 0.9966 - mape: 101.3319\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9966 - mse: 1.6233 - mae: 0.9966 - mape: 101.2751\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9965 - mse: 1.6233 - mae: 0.9965 - mape: 101.2408\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9964 - mse: 1.6231 - mae: 0.9964 - mape: 101.1815\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9963 - mse: 1.6230 - mae: 0.9963 - mape: 101.1398\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9963 - mse: 1.6229 - mae: 0.9963 - mape: 101.0836\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9962 - mse: 1.6227 - mae: 0.9962 - mape: 101.0287\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9961 - mse: 1.6225 - mae: 0.9961 - mape: 100.9767\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9960 - mse: 1.6224 - mae: 0.9960 - mape: 100.9371\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9960 - mse: 1.6224 - mae: 0.9960 - mape: 100.8929\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9959 - mse: 1.6222 - mae: 0.9959 - mape: 100.8489\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9959 - mse: 1.6221 - mae: 0.9959 - mape: 100.8035\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9958 - mse: 1.6220 - mae: 0.9958 - mape: 100.7834\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9958 - mse: 1.6219 - mae: 0.9958 - mape: 100.7638\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9958 - mse: 1.6219 - mae: 0.9958 - mape: 100.7445\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9957 - mse: 1.6218 - mae: 0.9957 - mape: 100.7275\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9957 - mse: 1.6217 - mae: 0.9957 - mape: 100.6879\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9956 - mse: 1.6216 - mae: 0.9956 - mape: 100.6488\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9955 - mse: 1.6215 - mae: 0.9955 - mape: 100.5662\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9954 - mse: 1.6214 - mae: 0.9954 - mape: 100.4911\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9953 - mse: 1.6211 - mae: 0.9953 - mape: 100.4598\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9953 - mse: 1.6211 - mae: 0.9953 - mape: 100.4235\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9952 - mse: 1.6209 - mae: 0.9952 - mape: 100.3881\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9952 - mse: 1.6209 - mae: 0.9952 - mape: 100.3391\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9951 - mse: 1.6208 - mae: 0.9951 - mape: 100.3120\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9951 - mse: 1.6207 - mae: 0.9951 - mape: 100.2767\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9950 - mse: 1.6205 - mae: 0.9950 - mape: 100.2373\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9949 - mse: 1.6205 - mae: 0.9949 - mape: 100.1947\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9949 - mse: 1.6204 - mae: 0.9949 - mape: 100.1544\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9948 - mse: 1.6202 - mae: 0.9948 - mape: 100.1139\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9947 - mse: 1.6201 - mae: 0.9947 - mape: 100.0529\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9946 - mse: 1.6200 - mae: 0.9946 - mape: 100.0032\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9946 - mse: 1.6199 - mae: 0.9946 - mape: 99.9851\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9946 - mse: 1.6198 - mae: 0.9946 - mape: 99.9605\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9945 - mse: 1.6197 - mae: 0.9945 - mape: 99.8898\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9944 - mse: 1.6196 - mae: 0.9944 - mape: 99.8665\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9944 - mse: 1.6196 - mae: 0.9944 - mape: 99.8229\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9943 - mse: 1.6195 - mae: 0.9943 - mape: 99.8027\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9943 - mse: 1.6194 - mae: 0.9943 - mape: 99.7692\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9943 - mse: 1.6194 - mae: 0.9943 - mape: 99.7575\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9943 - mse: 1.6194 - mae: 0.9943 - mape: 99.7536\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9943 - mse: 1.6194 - mae: 0.9943 - mape: 99.7409\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9942 - mse: 1.6192 - mae: 0.9942 - mape: 99.6903\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9941 - mse: 1.6192 - mae: 0.9941 - mape: 99.6712\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9941 - mse: 1.6191 - mae: 0.9941 - mape: 99.6500\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9940 - mse: 1.6190 - mae: 0.9940 - mape: 99.5854\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9939 - mse: 1.6189 - mae: 0.9939 - mape: 99.5412\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 676.97it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 680.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "-----------------------\n",
      "Computing Error Metrics\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "exec(open('CV_Grid.py').read())\n",
    "# Notebook Mode:\n",
    "# %run Evaluation.ipynb\n",
    "# %run Benchmarks_Model_Builder_Pointmass_Based.ipynb\n",
    "# Terminal Mode (Default):\n",
    "exec(open('Evaluation.py').read())\n",
    "exec(open('Benchmarks_Model_Builder_Pointmass_Based.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Mean-Centric Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ENET        kRidge          GBRF          ffNN\n",
      "W1        9.564489e+00  9.428337e+00  1.149899e+01  9.644549e+00\n",
      "Mean      4.177433e+22  4.177433e+22  4.177433e+22  4.177433e+22\n",
      "Var       5.109072e+00  5.109072e+00  5.109072e+00  5.109072e+00\n",
      "Skewness  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
      "Ex_Kur    6.000000e+00  6.000000e+00  6.000000e+00  6.000000e+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>ffNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>9.564489e+00</td>\n",
       "      <td>9.428337e+00</td>\n",
       "      <td>1.149899e+01</td>\n",
       "      <td>9.644549e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>4.177433e+22</td>\n",
       "      <td>4.177433e+22</td>\n",
       "      <td>4.177433e+22</td>\n",
       "      <td>4.177433e+22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>5.109072e+00</td>\n",
       "      <td>5.109072e+00</td>\n",
       "      <td>5.109072e+00</td>\n",
       "      <td>5.109072e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex_Kur</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ENET        kRidge          GBRF          ffNN\n",
       "W1        9.564489e+00  9.428337e+00  1.149899e+01  9.644549e+00\n",
       "Mean      4.177433e+22  4.177433e+22  4.177433e+22  4.177433e+22\n",
       "Var       5.109072e+00  5.109072e+00  5.109072e+00  5.109072e+00\n",
       "Skewness  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
       "Ex_Kur    6.000000e+00  6.000000e+00  6.000000e+00  6.000000e+00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ENET        kRidge          GBRF          ffNN\n",
      "W1        6.484909e+00  6.581567e+00  4.913863e+00  6.499174e+00\n",
      "Mean      4.127114e+22  4.127114e+22  4.127114e+22  4.127114e+22\n",
      "Var       6.021381e+00  6.021381e+00  6.021381e+00  6.021381e+00\n",
      "Skewness  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
      "Ex_Kur    6.000000e+00  6.000000e+00  6.000000e+00  6.000000e+00\n"
     ]
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Complexitie(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        N_Params    T_Time  T_Test/T_test-MC\n",
      "ENET           6  6.866046          0.000851\n",
      "GBRF       72006  1.077835          0.011999\n",
      "kRidge        12  0.914693          0.005726\n",
      "ffNN         101  7.906827          0.586807\n"
     ]
    }
   ],
   "source": [
    "print(Summary_Complexity_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run: *Gaussian Benchmark(s)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bencharm 1: [Gaussian Process Regressor](https://scikit-learn.org/stable/modules/gaussian_process.html)\n",
    "- Benchmark 2: Deep Gaussian Networks:\n",
    "These models train models which assume Gaussianity.  We may view these as models in $\\mathcal{P}_2(\\mathbb{R})$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to (\\hat{\\mu}(x),\\hat{\\sigma}(x))\\triangleq f(x) \\in \\mathbb{R}\\times [0,\\infty) \\to \\frac1{\\hat{\\sigma}(x)\\sqrt{2\\pi}}\\exp\\left(\\frac{-(\\cdot-\\hat{\\mu}(x))^2}{\\hat{\\sigma(x)}^2}\\right) \\in \\mathcal{G}_1\\subset \\mathcal{P}_2(\\mathbb{R});\n",
    "$$\n",
    "where $\\mathcal{G}_1$ is the set of Gaussian measures on $\\mathbb{R}$ equipped with the relative Wasserstein-1 topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Feature Builder - Ready\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.1502s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.3s finished\n",
      "  3%|▎         | 3/100 [00:00<00:03, 25.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering Parameters for Deep Gaussian Network to train on!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 65.18it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Getting Parameters for Deep Gaussian Network!\n",
      "===============================\n",
      "Training Deep Gaussian Network!\n",
      "===============================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9869 - mse: 1.8280 - mae: 0.9869 - mape: 72.4823\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9866 - mse: 1.8270 - mae: 0.9866 - mape: 72.4639\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9862 - mse: 1.8258 - mae: 0.9862 - mape: 72.4777\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9858 - mse: 1.8248 - mae: 0.9858 - mape: 72.4823\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9854 - mse: 1.8237 - mae: 0.9854 - mape: 72.4855\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9851 - mse: 1.8226 - mae: 0.9851 - mape: 72.4836\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9847 - mse: 1.8216 - mae: 0.9847 - mape: 72.4860\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9843 - mse: 1.8206 - mae: 0.9843 - mape: 72.4821\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9839 - mse: 1.8196 - mae: 0.9839 - mape: 72.4930\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9836 - mse: 1.8186 - mae: 0.9836 - mape: 72.4989\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9832 - mse: 1.8175 - mae: 0.9832 - mape: 72.5075\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9828 - mse: 1.8165 - mae: 0.9828 - mape: 72.4949\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9825 - mse: 1.8156 - mae: 0.9825 - mape: 72.5098\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9821 - mse: 1.8145 - mae: 0.9821 - mape: 72.5153\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9818 - mse: 1.8136 - mae: 0.9818 - mape: 72.5039\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9815 - mse: 1.8127 - mae: 0.9815 - mape: 72.5314\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9812 - mse: 1.8118 - mae: 0.9812 - mape: 72.5261\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9808 - mse: 1.8109 - mae: 0.9808 - mape: 72.5276\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9805 - mse: 1.8100 - mae: 0.9805 - mape: 72.5192\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9801 - mse: 1.8089 - mae: 0.9801 - mape: 72.5265\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9797 - mse: 1.8078 - mae: 0.9797 - mape: 72.5283\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9793 - mse: 1.8067 - mae: 0.9793 - mape: 72.5627\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9790 - mse: 1.8056 - mae: 0.9790 - mape: 72.5434\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9785 - mse: 1.8045 - mae: 0.9785 - mape: 72.5346\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9782 - mse: 1.8036 - mae: 0.9782 - mape: 72.5621\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9778 - mse: 1.8025 - mae: 0.9778 - mape: 72.5616\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9774 - mse: 1.8014 - mae: 0.9774 - mape: 72.5717\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9771 - mse: 1.8005 - mae: 0.9771 - mape: 72.5621\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9767 - mse: 1.7994 - mae: 0.9767 - mape: 72.5733\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9763 - mse: 1.7983 - mae: 0.9763 - mape: 72.5822\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9759 - mse: 1.7973 - mae: 0.9759 - mape: 72.5923\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9755 - mse: 1.7961 - mae: 0.9755 - mape: 72.6266\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9751 - mse: 1.7949 - mae: 0.9751 - mape: 72.6647\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9747 - mse: 1.7937 - mae: 0.9747 - mape: 72.7048\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9742 - mse: 1.7924 - mae: 0.9742 - mape: 72.7188\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9738 - mse: 1.7913 - mae: 0.9738 - mape: 72.7354\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9734 - mse: 1.7902 - mae: 0.9734 - mape: 72.7675\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9730 - mse: 1.7890 - mae: 0.9730 - mape: 72.8089\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9726 - mse: 1.7879 - mae: 0.9726 - mape: 72.8168\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9722 - mse: 1.7868 - mae: 0.9722 - mape: 72.8501\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9718 - mse: 1.7857 - mae: 0.9718 - mape: 72.8872\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9714 - mse: 1.7843 - mae: 0.9714 - mape: 72.9100\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9710 - mse: 1.7832 - mae: 0.9710 - mape: 72.9517\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9706 - mse: 1.7820 - mae: 0.9706 - mape: 73.0048\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9702 - mse: 1.7809 - mae: 0.9702 - mape: 73.0713\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9696 - mse: 1.7794 - mae: 0.9696 - mape: 73.1150\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9692 - mse: 1.7782 - mae: 0.9692 - mape: 73.1685\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9688 - mse: 1.7768 - mae: 0.9688 - mape: 73.2272\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9683 - mse: 1.7755 - mae: 0.9683 - mape: 73.3031\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9678 - mse: 1.7741 - mae: 0.9678 - mape: 73.3284\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2110.95it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 1537.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Training Deep Gaussian Network!: END\n",
      "====================================\n",
      "#---------------------------------------#\n",
      " Get Training Errors for: Gaussian Models\n",
      "#---------------------------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#---------------------------------------#\n",
      " Get Testing Errors for: Gaussian Models\n",
      "#---------------------------------------#\n",
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n",
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "--------------------------------------------\n",
      "Computing and Updating Complexity Metrics...\n",
      "--------------------------------------------\n",
      "-----------------------------------------------\n",
      "Updated Complexity Metrics Dataframe and Saved!\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %run Benchmarks_Model_Builder_Mean_Var.ipynb\n",
    "exec(open('Benchmarks_Model_Builder_Mean_Var.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Quality (Updated)\n",
      "                  ENET        kRidge          GBRF          ffNN        GPR  \\\n",
      "W1        6.484909e+00  6.581567e+00  4.913863e+00  6.499174e+00  10.932793   \n",
      "Mean      4.127114e+22  4.127114e+22  4.127114e+22  4.127114e+22   1.788880   \n",
      "Var       6.021381e+00  6.021381e+00  6.021381e+00  6.021381e+00   5.910148   \n",
      "Skewness  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   0.000000   \n",
      "Ex_Kur    6.000000e+00  6.000000e+00  6.000000e+00  6.000000e+00   3.000000   \n",
      "\n",
      "                   DGN  \n",
      "W1        7.204366e+00  \n",
      "Mean      3.917252e+22  \n",
      "Var       4.022202e+00  \n",
      "Skewness  0.000000e+00  \n",
      "Ex_Kur    3.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction Quality (Updated)\")\n",
    "print(Summary_pred_Qual_models_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Complexities Quality (Updated)\n",
      "        N_Params        T_Time  T_Test/T_test-MC\n",
      "ENET         6.0  6.866046e+00          0.000851\n",
      "GBRF     72006.0  1.077835e+00          0.011999\n",
      "kRidge      12.0  9.146926e-01          0.005726\n",
      "ffNN       101.0  7.906827e+00          0.586807\n",
      "GPR          0.0  9.973421e-01          0.013478\n",
      "DGN        101.0  1.619526e+09          0.717878\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Complexities Quality (Updated)\")\n",
    "print(Summary_Complexity_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Final Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# %run WrapUp_Summarizer.ipynb\n",
    "exec(open('WrapUp_Summarizer.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chosen Kernel for GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel_Used_in_GPR: RBF(length_scale=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Kernel_Used_in_GPR: \"+str(GPR_trash.kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Complexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       ENET       GBRF     kRidge       ffNN        GPR  \\\n",
      "N_Params         6.0000E+00 7.2006E+04 1.2000E+01 1.0100E+02 0.0000E+00   \n",
      "T_Time           6.8660E+00 1.0778E+00 9.1469E-01 7.9068E+00 9.9734E-01   \n",
      "T_Test/T_test-MC 8.5103E-04 1.1999E-02 5.7261E-03 5.8681E-01 1.3478E-02   \n",
      "\n",
      "                        DGN        DNM  MC_Oracle  \n",
      "N_Params         1.0100E+02 6.0000E+02 6.0000E+02  \n",
      "T_Time           1.6195E+09 1.3307E-01 1.3307E-01  \n",
      "T_Test/T_test-MC 7.1788E-01 1.0000E+00 1.0000E+00  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>ffNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC_Oracle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N_Params</th>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>7.2006E+04</td>\n",
       "      <td>1.2000E+01</td>\n",
       "      <td>1.0100E+02</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>1.0100E+02</td>\n",
       "      <td>6.0000E+02</td>\n",
       "      <td>6.0000E+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_Time</th>\n",
       "      <td>6.8660E+00</td>\n",
       "      <td>1.0778E+00</td>\n",
       "      <td>9.1469E-01</td>\n",
       "      <td>7.9068E+00</td>\n",
       "      <td>9.9734E-01</td>\n",
       "      <td>1.6195E+09</td>\n",
       "      <td>1.3307E-01</td>\n",
       "      <td>1.3307E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_Test/T_test-MC</th>\n",
       "      <td>8.5103E-04</td>\n",
       "      <td>1.1999E-02</td>\n",
       "      <td>5.7261E-03</td>\n",
       "      <td>5.8681E-01</td>\n",
       "      <td>1.3478E-02</td>\n",
       "      <td>7.1788E-01</td>\n",
       "      <td>1.0000E+00</td>\n",
       "      <td>1.0000E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ENET       GBRF     kRidge       ffNN        GPR  \\\n",
       "N_Params         6.0000E+00 7.2006E+04 1.2000E+01 1.0100E+02 0.0000E+00   \n",
       "T_Time           6.8660E+00 1.0778E+00 9.1469E-01 7.9068E+00 9.9734E-01   \n",
       "T_Test/T_test-MC 8.5103E-04 1.1999E-02 5.7261E-03 5.8681E-01 1.3478E-02   \n",
       "\n",
       "                        DGN        DNM  MC_Oracle  \n",
       "N_Params         1.0100E+02 6.0000E+02 6.0000E+02  \n",
       "T_Time           1.6195E+09 1.3307E-01 1.3307E-01  \n",
       "T_Test/T_test-MC 7.1788E-01 1.0000E+00 1.0000E+00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_Complexity_models)\n",
    "Summary_Complexity_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ENET     kRidge       GBRF       ffNN        GPR        DGN  \\\n",
      "W1       9.5645E+00 9.4283E+00 1.1499E+01 9.6445E+00 4.8804E+00 4.4864E+00   \n",
      "Mean     4.1774E+22 4.1774E+22 4.1774E+22 4.1774E+22 9.8849E-11 4.1271E+22   \n",
      "Var      5.1091E+00 5.1091E+00 5.1091E+00 5.1091E+00 6.0214E+00 4.9336E+00   \n",
      "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00   \n",
      "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00 3.0000E+00 3.0000E+00   \n",
      "\n",
      "          MC-Oracle        DNM  \n",
      "W1       0.0000E+00 5.4902E+00  \n",
      "Mean     1.0691E+00 4.1271E+22  \n",
      "Var      4.2066E+00 2.3189E+00  \n",
      "Skewness 4.0960E-01 7.1518E-02  \n",
      "Ex_Kur   6.4968E+00 5.3704E+00  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>ffNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>DNM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>9.5645E+00</td>\n",
       "      <td>9.4283E+00</td>\n",
       "      <td>1.1499E+01</td>\n",
       "      <td>9.6445E+00</td>\n",
       "      <td>4.8804E+00</td>\n",
       "      <td>4.4864E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>5.4902E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>4.1774E+22</td>\n",
       "      <td>4.1774E+22</td>\n",
       "      <td>4.1774E+22</td>\n",
       "      <td>4.1774E+22</td>\n",
       "      <td>9.8849E-11</td>\n",
       "      <td>4.1271E+22</td>\n",
       "      <td>1.0691E+00</td>\n",
       "      <td>4.1271E+22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>5.1091E+00</td>\n",
       "      <td>5.1091E+00</td>\n",
       "      <td>5.1091E+00</td>\n",
       "      <td>5.1091E+00</td>\n",
       "      <td>6.0214E+00</td>\n",
       "      <td>4.9336E+00</td>\n",
       "      <td>4.2066E+00</td>\n",
       "      <td>2.3189E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>4.0960E-01</td>\n",
       "      <td>7.1518E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex_Kur</th>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>3.0000E+00</td>\n",
       "      <td>3.0000E+00</td>\n",
       "      <td>6.4968E+00</td>\n",
       "      <td>5.3704E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ENET     kRidge       GBRF       ffNN        GPR        DGN  \\\n",
       "W1       9.5645E+00 9.4283E+00 1.1499E+01 9.6445E+00 4.8804E+00 4.4864E+00   \n",
       "Mean     4.1774E+22 4.1774E+22 4.1774E+22 4.1774E+22 9.8849E-11 4.1271E+22   \n",
       "Var      5.1091E+00 5.1091E+00 5.1091E+00 5.1091E+00 6.0214E+00 4.9336E+00   \n",
       "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00   \n",
       "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00 3.0000E+00 3.0000E+00   \n",
       "\n",
       "          MC-Oracle        DNM  \n",
       "W1       0.0000E+00 5.4902E+00  \n",
       "Mean     1.0691E+00 4.1271E+22  \n",
       "Var      4.2066E+00 2.3189E+00  \n",
       "Skewness 4.0960E-01 7.1518E-02  \n",
       "Ex_Kur   6.4968E+00 5.3704E+00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(PredictivePerformance_Metrics_Train)\n",
    "PredictivePerformance_Metrics_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ENET     kRidge       GBRF       ffNN        GPR        DGN  \\\n",
      "W1       6.4849E+00 6.5816E+00 4.9139E+00 6.4992E+00 1.0933E+01 7.2044E+00   \n",
      "Mean     4.1271E+22 4.1271E+22 4.1271E+22 4.1271E+22 1.7889E+00 3.9173E+22   \n",
      "Var      6.0214E+00 6.0214E+00 6.0214E+00 6.0214E+00 5.9101E+00 4.0222E+00   \n",
      "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00   \n",
      "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00 3.0000E+00 3.0000E+00   \n",
      "\n",
      "          MC-Oracle        DNM  \n",
      "W1       0.0000E+00 7.3528E+00  \n",
      "Mean     1.3276E+00 3.9173E+22  \n",
      "Var      7.7468E+00 5.9775E+00  \n",
      "Skewness 2.8721E-01 1.7011E-01  \n",
      "Ex_Kur   5.9728E+00 9.4457E+00  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>ffNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>DNM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>6.4849E+00</td>\n",
       "      <td>6.5816E+00</td>\n",
       "      <td>4.9139E+00</td>\n",
       "      <td>6.4992E+00</td>\n",
       "      <td>1.0933E+01</td>\n",
       "      <td>7.2044E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>7.3528E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>4.1271E+22</td>\n",
       "      <td>4.1271E+22</td>\n",
       "      <td>4.1271E+22</td>\n",
       "      <td>4.1271E+22</td>\n",
       "      <td>1.7889E+00</td>\n",
       "      <td>3.9173E+22</td>\n",
       "      <td>1.3276E+00</td>\n",
       "      <td>3.9173E+22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>6.0214E+00</td>\n",
       "      <td>6.0214E+00</td>\n",
       "      <td>6.0214E+00</td>\n",
       "      <td>6.0214E+00</td>\n",
       "      <td>5.9101E+00</td>\n",
       "      <td>4.0222E+00</td>\n",
       "      <td>7.7468E+00</td>\n",
       "      <td>5.9775E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>2.8721E-01</td>\n",
       "      <td>1.7011E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex_Kur</th>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>3.0000E+00</td>\n",
       "      <td>3.0000E+00</td>\n",
       "      <td>5.9728E+00</td>\n",
       "      <td>9.4457E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ENET     kRidge       GBRF       ffNN        GPR        DGN  \\\n",
       "W1       6.4849E+00 6.5816E+00 4.9139E+00 6.4992E+00 1.0933E+01 7.2044E+00   \n",
       "Mean     4.1271E+22 4.1271E+22 4.1271E+22 4.1271E+22 1.7889E+00 3.9173E+22   \n",
       "Var      6.0214E+00 6.0214E+00 6.0214E+00 6.0214E+00 5.9101E+00 4.0222E+00   \n",
       "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00   \n",
       "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00 3.0000E+00 3.0000E+00   \n",
       "\n",
       "          MC-Oracle        DNM  \n",
       "W1       0.0000E+00 7.3528E+00  \n",
       "Mean     1.3276E+00 3.9173E+22  \n",
       "Var      7.7468E+00 5.9775E+00  \n",
       "Skewness 2.8721E-01 1.7011E-01  \n",
       "Ex_Kur   5.9728E+00 9.4457E+00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(PredictivePerformance_Metrics_Test)\n",
    "PredictivePerformance_Metrics_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n"
     ]
    }
   ],
   "source": [
    "def get_MDN_Means_SubNetwork(height, depth, learning_rate, input_dim, output_dim):\n",
    "    #----------------------------#\n",
    "    # Maximally Interacting Layer #\n",
    "    #-----------------------------#\n",
    "    # Initialize Inputs\n",
    "    input_layer = tf.keras.Input(shape=(input_dim,))\n",
    "   \n",
    "    \n",
    "    #------------------#\n",
    "    #   Core Layers    #\n",
    "    #------------------#\n",
    "    core_layers = fullyConnected_Dense(height)(input_layer)\n",
    "    # Activation\n",
    "    core_layers = tf.nn.swish(core_layers)\n",
    "    # Train additional Depth?\n",
    "    if depth>1:\n",
    "        # Add additional deep layer(s)\n",
    "        for depth_i in range(1,depth):\n",
    "            core_layers = fullyConnected_Dense(height)(core_layers)\n",
    "            # Activation\n",
    "            core_layers = tf.nn.swish(core_layers)\n",
    "    \n",
    "    #------------------#\n",
    "    #  Readout Layers  #\n",
    "    #------------------# \n",
    "    # Gaussian Splitter Layer\n",
    "    output_layers = SD_output(output_dim)(core_layers)  \n",
    "    # Define Input/Output Relationship (Arch.)\n",
    "    trainable_layers_model = tf.keras.Model(input_layer, output_layers)\n",
    "    \n",
    "    \n",
    "    #----------------------------------#\n",
    "    # Define Optimizer & Compile Archs.\n",
    "    #----------------------------------#\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    trainable_layers_model.compile(optimizer=opt, loss=\"mae\", metrics=[\"mse\", \"mae\", \"mape\"])\n",
    "\n",
    "    return trainable_layers_model\n",
    "\n",
    "\n",
    "\n",
    "def build_MDN_Means_SubNetwork(n_folds , n_jobs, n_iter, param_grid_in, X_train, y_train,X_test):\n",
    "    # Update Dictionary\n",
    "    param_grid_in_internal = param_grid_in\n",
    "    param_grid_in_internal['input_dim'] = [(X_train.shape[1])]\n",
    "    \n",
    "    # Deep Feature Network\n",
    "    ffNN_CV = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=get_MDN_Means_SubNetwork, \n",
    "                                                            verbose=True)\n",
    "    \n",
    "    # Randomized CV\n",
    "    ffNN_CVer = RandomizedSearchCV(estimator=ffNN_CV, \n",
    "                                    n_jobs=n_jobs,\n",
    "                                    cv=KFold(n_folds, random_state=2020, shuffle=True),\n",
    "                                    param_distributions=param_grid_in_internal,\n",
    "                                    n_iter=n_iter,\n",
    "                                    return_train_score=True,\n",
    "                                    random_state=2020,\n",
    "                                    verbose=10)\n",
    "    \n",
    "    # Fit Model #\n",
    "    #-----------#\n",
    "    ffNN_CVer.fit(X_train,y_train)\n",
    "\n",
    "    # Write Predictions #\n",
    "    #-------------------#\n",
    "    y_hat_train = ffNN_CVer.predict(X_train)\n",
    "    \n",
    "    eval_time_ffNN = time.time()\n",
    "    y_hat_test = ffNN_CVer.predict(X_test)\n",
    "    eval_time_ffNN = time.time() - eval_time_ffNN\n",
    "    \n",
    "    # Counter number of parameters #\n",
    "    #------------------------------#\n",
    "    # Extract Best Model\n",
    "    best_model = ffNN_CVer.best_estimator_\n",
    "    # Count Number of Parameters\n",
    "    N_params_best_ffNN = np.sum([np.prod(v.get_shape().as_list()) for v in best_model.model.trainable_variables])\n",
    "    \n",
    "    \n",
    "    # Return Values #\n",
    "    #---------------#\n",
    "    return y_hat_train, y_hat_test, N_params_best_ffNN, eval_time_ffNN\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print('Deep Feature Builder - Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9752 - mse: 0.9578 - mae: 0.9752 - mape: 75883752.0000\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9742 - mse: 0.9558 - mae: 0.9742 - mape: 75808392.0000\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9732 - mse: 0.9538 - mae: 0.9732 - mape: 75733296.0000\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9722 - mse: 0.9519 - mae: 0.9722 - mape: 75658608.0000\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9712 - mse: 0.9500 - mae: 0.9712 - mape: 75584408.0000\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9702 - mse: 0.9481 - mae: 0.9702 - mape: 75510368.0000\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9693 - mse: 0.9461 - mae: 0.9693 - mape: 75436400.0000\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9683 - mse: 0.9442 - mae: 0.9683 - mape: 75362752.0000\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9673 - mse: 0.9423 - mae: 0.9673 - mape: 75288984.0000\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9664 - mse: 0.9404 - mae: 0.9664 - mape: 75215472.0000\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9654 - mse: 0.9386 - mae: 0.9654 - mape: 75141856.0000\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9644 - mse: 0.9367 - mae: 0.9644 - mape: 75067968.0000\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9634 - mse: 0.9348 - mae: 0.9634 - mape: 74994224.0000\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9625 - mse: 0.9329 - mae: 0.9625 - mape: 74919832.0000\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9615 - mse: 0.9310 - mae: 0.9615 - mape: 74845664.0000\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9605 - mse: 0.9291 - mae: 0.9605 - mape: 74770312.0000\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9595 - mse: 0.9271 - mae: 0.9595 - mape: 74694984.0000\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9585 - mse: 0.9252 - mae: 0.9585 - mape: 74619312.0000\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9575 - mse: 0.9233 - mae: 0.9575 - mape: 74543160.0000\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9565 - mse: 0.9213 - mae: 0.9565 - mape: 74466208.0000\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9555 - mse: 0.9194 - mae: 0.9555 - mape: 74388936.0000\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9544 - mse: 0.9174 - mae: 0.9544 - mape: 74311232.0000\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9534 - mse: 0.9154 - mae: 0.9534 - mape: 74232840.0000\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9524 - mse: 0.9134 - mae: 0.9524 - mape: 74153648.0000\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9513 - mse: 0.9114 - mae: 0.9513 - mape: 74074008.0000\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9503 - mse: 0.9094 - mae: 0.9503 - mape: 73993688.0000\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9492 - mse: 0.9074 - mae: 0.9492 - mape: 73912584.0000\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9481 - mse: 0.9053 - mae: 0.9481 - mape: 73830912.0000\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9470 - mse: 0.9032 - mae: 0.9470 - mape: 73747928.0000\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9459 - mse: 0.9011 - mae: 0.9459 - mape: 73663920.0000\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9448 - mse: 0.8990 - mae: 0.9448 - mape: 73580056.0000\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9437 - mse: 0.8969 - mae: 0.9437 - mape: 73494864.0000\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9426 - mse: 0.8947 - mae: 0.9426 - mape: 73408400.0000\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9414 - mse: 0.8926 - mae: 0.9414 - mape: 73321408.0000\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9402 - mse: 0.8904 - mae: 0.9402 - mape: 73232944.0000\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9391 - mse: 0.8881 - mae: 0.9391 - mape: 73143440.0000\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9379 - mse: 0.8859 - mae: 0.9379 - mape: 73053336.0000\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9367 - mse: 0.8836 - mae: 0.9367 - mape: 72962160.0000\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9355 - mse: 0.8813 - mae: 0.9355 - mape: 72870192.0000\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9342 - mse: 0.8790 - mae: 0.9342 - mape: 72777576.0000\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9330 - mse: 0.8767 - mae: 0.9330 - mape: 72684088.0000\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9318 - mse: 0.8744 - mae: 0.9318 - mape: 72589464.0000\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9305 - mse: 0.8720 - mae: 0.9305 - mape: 72493280.0000\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9292 - mse: 0.8696 - mae: 0.9292 - mape: 72396640.0000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9279 - mse: 0.8672 - mae: 0.9279 - mape: 72298504.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9266 - mse: 0.8648 - mae: 0.9266 - mape: 72199424.0000\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9253 - mse: 0.8623 - mae: 0.9253 - mape: 72099480.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9239 - mse: 0.8598 - mae: 0.9239 - mape: 71998944.0000\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9226 - mse: 0.8573 - mae: 0.9226 - mape: 71896736.0000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9212 - mse: 0.8548 - mae: 0.9212 - mape: 71794408.0000\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [problem_dim]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_GMM_clusters]\n",
    "\n",
    "\n",
    "# Train simple deep classifier\n",
    "timer_MDN_Means = time.time()\n",
    "MDN_Means_train, MDN_Means_test, N_params_MDN_MeansNet, timer_output_MDN_MeansNet = build_MDN_Means_SubNetwork(n_folds = CV_folds,\n",
    "                                                                                                             n_jobs = n_jobs,\n",
    "                                                                                                             n_iter = n_iter,\n",
    "                                                                                                             param_grid_in=param_grid_Deep_Classifier,\n",
    "                                                                                                             X_train = X_train,\n",
    "                                                                                                             y_train = Y_MDN_targets_train_sd,\n",
    "                                                                                                             X_test = X_test)\n",
    "# Format as float\n",
    "MDN_Means_train = np.array(MDN_Means_train,dtype=float)\n",
    "MDN_Means_test = np.array(MDN_Means_test,dtype=float)\n",
    "timer_MDN_Means = time.time() - timer_MDN_Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
