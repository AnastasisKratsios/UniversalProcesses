{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Conditional Laws for Random-Fields - via:\n",
    "\n",
    "## Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "\n",
    "---\n",
    "\n",
    "By: [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*.\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth:\n",
    "*The build-in Options:*\n",
    "- rSDE \n",
    "- pfBM\n",
    "- 2lnflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth = \"rSDE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 5\n",
    "N_Monte_Carlo_Samples = 10**2\n",
    "N_Monte_Carlo_Samples_Test = 10**1 # How many MC-samples to draw from test-set?\n",
    "\n",
    "# End times for Time-Grid\n",
    "T_end = 1\n",
    "T_end_test = 1.1\n",
    "\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 5\n",
    "Max_Grid = 1\n",
    "\n",
    "# \n",
    "N_Quantizers_to_parameterize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "N_measures_per_center = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP:\n",
    "from operator import itemgetter \n",
    "from itertools import compress\n",
    "# Set Minibatch Size\n",
    "Random_Cover_Mini_Batch_Size = 100\n",
    "# Proportion of Clusters per Minibatch Sample\n",
    "# Quantization_Proportion = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Measure-Valued $2$-Parameter Log-Gaussian Flow\n",
    "$$\n",
    "X_{t,x} \\sim \\log\\text{-}\\mathcal{N}\\left(\\alpha(t,x),\\beta(t,x)\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** *$\\alpha$ and $\\beta$ are specified below in the SDE Example*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Rough SDE\n",
    "Simulate via Euler-M method from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T((1-\\eta)\\beta(s,x)+\\eta\\sigma_s^H)dW_s.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return .1#(.1-.5*(.01**2))*t + np.cos(x)*np.exp(-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rougness = 0.9 # Hurst Parameter\n",
    "Ratio_fBM_to_typical_vol = 0 # $\\eta$ in equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed Fractional Brownian Motion\n",
    "Simulate from:\n",
    "$$\n",
    "X_t^x(\\omega) = f_1(x)f_2(t) + B_t^H(\\omega).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_dirction_x(x):\n",
    "    return x*np.cos(x)\n",
    "\n",
    "def finite_variation_t(t):\n",
    "    return t*(np.sin(math.pi*t) + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "# %run ParaGAN_Backend.ipynb\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of Auxiliary Internal-Variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "measure_weights_test = np.ones(N_Monte_Carlo_Samples_Test)/N_Monte_Carlo_Samples_Test\n",
    "\n",
    "# Get number of centers\n",
    "N_Centers_per_box = max(1,int(round(np.sqrt(N_Quantizers_to_parameterize))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Centers Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grid of Barycenters\n",
    "x_Grid_barycenters = np.arange(start=-Max_Grid,\n",
    "                               stop=Max_Grid,\n",
    "                               step = (2*Max_Grid/N_Centers_per_box))\n",
    "t_Grid_barycenters = np.arange(start=0,\n",
    "                               stop=T_end,\n",
    "                               step = (T_end/N_Centers_per_box))\n",
    "for x_i in range(len(x_Grid_barycenters)):\n",
    "    for t_j in range(len(t_Grid_barycenters)):\n",
    "        new_grid_entry = np.array([t_Grid_barycenters[t_j],x_Grid_barycenters[x_i]]).reshape(1,-1)\n",
    "        if (x_i==0 and t_j ==0):\n",
    "            Grid_Barycenters = new_grid_entry\n",
    "        else:\n",
    "            Grid_Barycenters = np.append(Grid_Barycenters,new_grid_entry,axis=0)\n",
    "\n",
    "# Update Number of Quantizers Generated\n",
    "N_Quantizers_to_parameterize = Grid_Barycenters.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Simulator.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer (Model Type A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $2$-Parameter $\\log$-Gaussian Flow\n",
    "### Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if groud_truth == \"2lnflow\":\n",
    "    # Generate Training Data\n",
    "    for i in range(Grid_Barycenters.shape[0]):\n",
    "        # Get output for center (mu-hat)\n",
    "        center_current, trash = twoparameter_flow_sampler((Grid_Barycenters[i]).reshape(1,2),N_Monte_Carlo_Samples)\n",
    "\n",
    "        # Get random sample in delta ball around ith center\n",
    "        sub_grid_loop = np.random.uniform(0,delta,(N_measures_per_center,2)) + Grid_Barycenters[i]\n",
    "\n",
    "        # Get Measures for this random sample\n",
    "        measures_locations_list_current, measures_weights_list_current = twoparameter_flow_sampler(sub_grid_loop,N_Monte_Carlo_Samples)\n",
    "        ##\n",
    "        measures_locations_list_current = measures_locations_list_current + center_current\n",
    "        measures_weights_list_current = measures_weights_list_current + trash\n",
    "        # Update Classes\n",
    "        Classifer_Wasserstein_Centers_loop = np.zeros([(N_measures_per_center+1),N_Quantizers_to_parameterize]) # The +1 is to account for the center which will be added to the random ball\n",
    "        Classifer_Wasserstein_Centers_loop[:, i] =  1\n",
    "        # Updates Classes\n",
    "        if i==0:\n",
    "            # INITIALIZE: Classifiers\n",
    "            Classifer_Wasserstein_Centers = Classifer_Wasserstein_Centers_loop\n",
    "            # INITIALIZE: Training Data\n",
    "            X_train = np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0)\n",
    "            # INITIALIZE: Barycenters Array\n",
    "            Barycenters_Array = (center_current[0]).reshape(-1,1)\n",
    "            # INITIALIZE: Measures and locations\n",
    "            measures_locations_list = measures_locations_list_current\n",
    "            measures_weights_list = measures_weights_list_current\n",
    "        else:\n",
    "            # UPDATE: Classifer\n",
    "            Classifer_Wasserstein_Centers = np.append(Classifer_Wasserstein_Centers,Classifer_Wasserstein_Centers_loop,axis=0)\n",
    "            # UPDATE: Training Data\n",
    "            X_train = np.append(X_train,np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0),axis=0)\n",
    "            # UPDATE: Populate Barycenters Array\n",
    "            Barycenters_Array = np.append(Barycenters_Array,((center_current[0]).reshape(-1,1)),axis=-1)\n",
    "            # UPDATE: Measures and locations\n",
    "            measures_locations_list = measures_locations_list + measures_locations_list_current\n",
    "            measures_weights_list = measures_locations_list + measures_weights_list_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if groud_truth == \"2lnflow\":\n",
    "    # Generate Testing Dataset (Inputs)\n",
    "    x_tests = np.random.uniform(np.min(X_train[:,0]),np.max(X_train[:,0]),10)\n",
    "    t_tests = np.arange(start=0,\n",
    "                        stop=T_end,\n",
    "                        step = (T_end_test/N_Euler_Maruyama_Steps))\n",
    "\n",
    "    for x_i in range(len(x_tests)):\n",
    "        for t_j in range(len(t_tests)):\n",
    "            test_set_entry = np.array([t_tests[t_j],x_tests[x_i]]).reshape(1,-1)\n",
    "            if (x_i==0 and t_j ==0):\n",
    "                X_test = test_set_entry\n",
    "            else:\n",
    "                X_test = np.append(X_test,test_set_entry,axis=0)\n",
    "\n",
    "    # Generate Testing Dataset (Outputs)\n",
    "    measures_locations_test_list, measures_weights_test_list = twoparameter_flow_sampler(X_test,N_Monte_Carlo_Samples_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough SDE:\n",
    "Simulation of the random-field:\n",
    "$$\n",
    "X_t^x = x + \\int_0^t \\alpha(s,X_t^x)ds + (1-\\eta)\\int_0^t \\beta(s,X_t^x)dW_t + \\int_0^t B_s^H dW_s;\n",
    "$$\n",
    "where: \n",
    " - $(B_t^H)_t$ is a [fractional Brownian Motion](https://arxiv.org/pdf/1406.1956.pdf) with [Hurst exponent](https://en.wikipedia.org/wiki/Hurst_exponent) $H\\in (0,1)$,\n",
    " - $(W_t)_t$ is a [Brownian Motion](https://en.wikipedia.org/wiki/Wiener_process),\n",
    " - $\\alpha$ and $\\beta$ are uniformly [Lipschitz-functions](https://en.wikipedia.org/wiki/Lipschitz_continuity) of appropriate input/output dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Simulator.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if groud_truth == \"rSDE\":\n",
    "    # Initialize position Counter\n",
    "    position_counter = 0\n",
    "    # Iniitalize uniform weights vector\n",
    "    measures_weights_list_loop = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "\n",
    "    # Overrine Number of Centers\n",
    "    N_x = len(x_Grid_barycenters)\n",
    "    N_t = len(t_Grid_barycenters)\n",
    "    N_Quantizers_to_parameterize = N_x*N_t\n",
    "\n",
    "    for x_i in range(N_x):\n",
    "        for t_j in range(N_t):\n",
    "\n",
    "            # Get Current Locations\n",
    "            x_center = x_Grid_barycenters[x_i]\n",
    "            t_center = t_Grid_barycenters[t_j]\n",
    "\n",
    "            current_cover = Euler_Maruyama_Generator(x_0 = x_center,\n",
    "                                                     N_Euler_Maruyama_Steps = N_Euler_Maruyama_Steps,\n",
    "                                                     N_Monte_Carlo_Samples = N_Monte_Carlo_Samples,\n",
    "                                                     T_begin = t_center,\n",
    "                                                     T_end = (t_center+delta),\n",
    "                                                     Hurst = Rougness,\n",
    "                                                     Ratio_fBM_to_typical_vol = Ratio_fBM_to_typical_vol)\n",
    "\n",
    "            barycenter_at_current_location = current_cover[0,:]\n",
    "\n",
    "            measures_locations_list_current = current_cover.tolist()\n",
    "            measures_weights_list_current = list(itertools.repeat(measures_weights_list_loop,N_Monte_Carlo_Samples))\n",
    "\n",
    "            # Get Current Training Data Positions\n",
    "            t_grid_current = (np.linspace(start=t_center,\n",
    "                                          stop=(t_center+delta),\n",
    "                                          num=N_Euler_Maruyama_Steps)).reshape(1,-1)\n",
    "            x_grid_current = (x_center*np.ones(N_Euler_Maruyama_Steps)).reshape(1,-1)\n",
    "\n",
    "            X_train_current = (np.append(x_grid_current,t_grid_current,axis=0)).T\n",
    "\n",
    "            # Get Current Classes\n",
    "            Classifer_Wasserstein_Centers_loop = np.zeros([N_Euler_Maruyama_Steps,N_Quantizers_to_parameterize])\n",
    "            Classifer_Wasserstein_Centers_loop[:, position_counter] =  1\n",
    "\n",
    "\n",
    "            # Updates Classes\n",
    "            if (x_i==0 and t_j==0):\n",
    "                # INITIALIZE: Classifiers\n",
    "                Classifer_Wasserstein_Centers = Classifer_Wasserstein_Centers_loop\n",
    "                # INITIALIZE: Training Data\n",
    "                X_train = X_train_current\n",
    "                # INITIALIZE: Barycenters Array\n",
    "                Barycenters_Array = barycenter_at_current_location.reshape(-1,1)\n",
    "                # INITIALIZE: Measures and locations\n",
    "                measures_locations_list = measures_locations_list_current\n",
    "                measures_weights_list = measures_weights_list_current\n",
    "            else:\n",
    "                # UPDATE: Classifer\n",
    "                Classifer_Wasserstein_Centers = np.append(Classifer_Wasserstein_Centers,Classifer_Wasserstein_Centers_loop,axis=0)\n",
    "                # UPDATE: Training Data\n",
    "                X_train = np.append(X_train,X_train_current,axis=0)\n",
    "                # UPDATE: Populate Barycenters Array\n",
    "                Barycenters_Array = np.append(Barycenters_Array,(barycenter_at_current_location.reshape(-1,1)),axis=-1)\n",
    "                # UPDATE: Measures and locations\n",
    "                measures_locations_list = measures_locations_list + measures_locations_list_current\n",
    "                measures_weights_list = measures_locations_list + measures_weights_list_current\n",
    "\n",
    "            # Update Position\n",
    "            position_counter = position_counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if groud_truth == \"rSDE\":\n",
    "    # Generate Testing Dataset (Inputs)\n",
    "    x_tests = np.random.uniform(np.min(X_train[:,0]),np.max(X_train[:,0]),10)\n",
    "    t_tests = np.arange(start=0,\n",
    "                        stop=T_end,\n",
    "                        step = (T_end_test/N_Euler_Maruyama_Steps))\n",
    "\n",
    "    # Initialize position Counter\n",
    "    position_counter = 0\n",
    "    # Iniitalize uniform weights vector\n",
    "    measures_weights_test_list_loop = np.ones(N_Monte_Carlo_Samples_Test)/N_Monte_Carlo_Samples_Test\n",
    "\n",
    "    # Overrine Number of Centers\n",
    "    N_x_test = len(x_tests)\n",
    "    N_t_test = len(t_tests)\n",
    "\n",
    "    for x_i in range(N_x_test):\n",
    "        for t_j in range(N_t_test):\n",
    "\n",
    "            # Get Current Locations\n",
    "            x_center = x_tests[x_i]\n",
    "            t_center = t_tests[t_j]\n",
    "\n",
    "            current_cover = Euler_Maruyama_Generator(x_0 = x_center,\n",
    "                                                     N_Euler_Maruyama_Steps = N_Euler_Maruyama_Steps,\n",
    "                                                     N_Monte_Carlo_Samples = N_Monte_Carlo_Samples,\n",
    "                                                     T_begin = t_center,\n",
    "                                                     T_end = (t_center+delta),#MAYBE MODIFY OUTOFSAMPLE LENGTH HERE?\n",
    "                                                     Hurst = Rougness,\n",
    "                                                     Ratio_fBM_to_typical_vol = Ratio_fBM_to_typical_vol)\n",
    "\n",
    "            barycenter_at_current_location = current_cover[0,:]\n",
    "\n",
    "            measures_locations_test_list_current = current_cover.tolist()\n",
    "            measures_weights_test_list_current = list(itertools.repeat(measures_weights_test_list_loop,N_Monte_Carlo_Samples_Test))\n",
    "\n",
    "            # Get Current Training Data Positions\n",
    "            t_grid_current_test = (np.linspace(start=t_center,\n",
    "                                               stop=(t_center+delta),\n",
    "                                               num=N_Euler_Maruyama_Steps)).reshape(1,-1)\n",
    "            x_grid_current_test = (x_center*np.ones(N_Euler_Maruyama_Steps)).reshape(1,-1)\n",
    "\n",
    "            X_test_current = (np.append(x_grid_current_test,t_grid_current_test,axis=0)).T\n",
    "\n",
    "\n",
    "            # Updates Classes\n",
    "            if (x_i==0 and t_j==0):\n",
    "                # INITIALIZE: Training Data\n",
    "                X_test = X_test_current\n",
    "                # INITIALIZE: Measures and locations\n",
    "                measures_locations_test_list = measures_locations_test_list_current\n",
    "                measures_weights_test_list = measures_weights_test_list_current\n",
    "            else:\n",
    "                # UPDATE: Training Data\n",
    "                X_test = np.append(X_test,X_test_current,axis=0)\n",
    "                # UPDATE: Measures and locations\n",
    "                measures_locations_test_list = measures_locations_list + measures_locations_test_list_current\n",
    "                measures_weights_test_list = measures_locations_list + measures_weights_test_list_current\n",
    "\n",
    "            # Update Position\n",
    "            position_counter = position_counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1927 - accuracy: 0.2222\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1521 - accuracy: 0.2222\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1203 - accuracy: 0.4000\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0879 - accuracy: 0.5333\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0574 - accuracy: 0.5556\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0283 - accuracy: 0.5333\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9954 - accuracy: 0.5333\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9628 - accuracy: 0.5556\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9276 - accuracy: 0.6444\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8933 - accuracy: 0.6667\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8567 - accuracy: 0.6667\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8194 - accuracy: 0.6667\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7813 - accuracy: 0.6667\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7406 - accuracy: 0.6667\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7008 - accuracy: 0.6667\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6593 - accuracy: 0.6667\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6158 - accuracy: 0.6667\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5721 - accuracy: 0.6667\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5299 - accuracy: 0.6667\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4854 - accuracy: 0.6667\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4420 - accuracy: 0.6667\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3987 - accuracy: 0.6667\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3581 - accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3162 - accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2734 - accuracy: 0.6667\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.2332 - accuracy: 0.6667\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1915 - accuracy: 0.6667\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1529 - accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1117 - accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0718 - accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0332 - accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9937 - accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9162 - accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8803 - accuracy: 0.6667\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8450 - accuracy: 0.6667\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8101 - accuracy: 0.7778\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7778 - accuracy: 0.8889\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6235 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3075 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2083 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1842 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1230 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0753 - accuracy: 1.0000\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [2]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 6827.41it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 2663.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n",
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Format Weights\n",
    "## Train\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): START\")\n",
    "print(\"#---------------------------------------#\")\n",
    "Predicted_Weights = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    b = np.repeat(np.array(predicted_classes_train[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): END\")\n",
    "print(\"#-------------------------------------#\")\n",
    "\n",
    "## Test\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): START\")\n",
    "print(\"#-------------------------------------#\")\n",
    "Predicted_Weights_test = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):\n",
    "    b_test = np.repeat(np.array(predicted_classes_test[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b_test = b_test/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights_test = b_test\n",
    "    else:\n",
    "        Predicted_Weights_test = np.append(Predicted_Weights_test,b_test,axis=1)\n",
    "print(\"#-----------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): END\")\n",
    "print(\"#-----------------------------------#\")\n",
    "        \n",
    "# Format Points of Mass\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: START\")\n",
    "print(\"#-----------------------------#\")\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: END\")\n",
    "print(\"#-----------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/44 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 1688.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>6.193477e-14</td>\n",
       "      <td>0.031626</td>\n",
       "      <td>0.015270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>3.536562e-06</td>\n",
       "      <td>0.101296</td>\n",
       "      <td>0.175159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>2.124155e-05</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.302528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.000399    0.000274         6.193477e-14                0.031626   \n",
       "MAE  0.001347    0.001873         3.536562e-06                0.101296   \n",
       "Max  0.002663    0.004878         2.124155e-05                0.178700   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.015270  \n",
       "MAE              0.175159  \n",
       "Max              0.302528  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Training Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "Skewness_errors = np.array([])\n",
    "Kurtosis_errors = np.array([])\n",
    "predictions_mean = np.array([])\n",
    "true_mean = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measure_weights.reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(np.array(measures_locations_list[x_i]))\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    ## Update Erros\n",
    "    predictions_mean = np.append(predictions_mean,Mu_hat)\n",
    "    true_mean = np.append(true_mean,Mu)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(np.array(measures_locations_list[x_i])**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat = np.sum((Barycenters_Array**3)*(Predicted_Weights[x_i]))\n",
    "    Skewness = np.mean(np.array(measures_locations_list[x_i])**3)\n",
    "    Skewness_errors = np.append(Skewness_errors,(abs(Skewness_hat-Skewness))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat = np.sum((Barycenters_Array**4)*(Predicted_Weights[x_i]))\n",
    "    Kurtosis = np.mean(np.array(measures_locations_list[x_i])**4)\n",
    "    Kurtosis_errors = np.append(Kurtosis_errors,(abs(Kurtosis_hat-Kurtosis))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.min(np.abs(W1_errors)),np.mean(np.abs(W1_errors)),np.max(np.abs(W1_errors))])\n",
    "Mean_prediction_Performance = np.array([np.min(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors)),np.max(np.abs(Mean_errors))])\n",
    "Var_prediction_Performance = np.array([np.min(np.abs(Var_errors)),np.mean(np.abs(Var_errors)),np.max(np.abs(Var_errors))])\n",
    "Skewness_prediction_Performance = np.array([np.min(np.abs(Skewness_errors)),np.mean(np.abs(Skewness_errors)),np.max(np.abs(Skewness_errors))])\n",
    "Kurtosis_prediction_Performance = np.array([np.min(np.abs(Kurtosis_errors)),np.mean(np.abs(Kurtosis_errors)),np.max(np.abs(Kurtosis_errors))])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Train.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f414c515fd0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean,label=\"prediction\",color=\"purple\")\n",
    "plt.plot(true_mean,label=\"true\",color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 963.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Test Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors_test = np.array([])\n",
    "Mean_errors_test = np.array([])\n",
    "Var_errors_test = np.array([])\n",
    "Skewness_errors_test = np.array([])\n",
    "Kurtosis_errors_test = np.array([])\n",
    "# Initialize Prediction Metrics\n",
    "predictions_mean_test = np.array([])\n",
    "true_mean_test = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_test_list))):    \n",
    "    # Get Laws\n",
    "    W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_test_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights_test[x_i,].reshape(-1,),\n",
    "                         (np.array(measures_weights_test_list[x_i])).reshape(-1,))\n",
    "    W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "    # Get Means\n",
    "    Mu_hat_test = np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array))\n",
    "    Mu_test = np.mean(np.array(measures_locations_test_list[x_i]))\n",
    "    Mean_errors_test = np.append(Mean_errors_test,(Mu_hat_test-Mu_test))\n",
    "    ## Update Predictions\n",
    "    predictions_mean_test = np.append(predictions_mean_test,Mu_hat_test)\n",
    "    true_mean_test = np.append(true_mean_test,Mu_test)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat_test = np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))\n",
    "    Var_test = np.mean(np.array(measures_locations_test_list[x_i])**2)\n",
    "    Var_errors_test = np.append(Var_errors_test,(Var_hat_test-Var_test)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat_test = np.sum((Barycenters_Array**3)*(Predicted_Weights_test[x_i]))\n",
    "    Skewness_test = np.mean(np.array(measures_locations_test_list[x_i])**3)\n",
    "    Skewness_errors_test = np.append(Skewness_errors_test,(abs(Skewness_hat_test-Skewness_test))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat_test = np.sum((Barycenters_Array**4)*(Predicted_Weights_test[x_i]))\n",
    "    Kurtosis_test = np.mean(np.array(measures_locations_test_list[x_i])**4)\n",
    "    Kurtosis_errors_test = np.append(Kurtosis_errors_test,(abs(Kurtosis_hat_test-Kurtosis_test))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance_test = np.array([np.min(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test))])\n",
    "Mean_prediction_Performance_test = np.array([np.min(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test))])\n",
    "Var_prediction_Performance_test = np.array([np.min(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test))])\n",
    "Skewness_prediction_Performance_test = np.array([np.min(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test))])\n",
    "Kurtosis_prediction_Performance_test = np.array([np.min(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test))])\n",
    "\n",
    "Type_A_Prediction_test = pd.DataFrame({\"W1\":W1_Performance_test,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance_test,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance_test,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance_test,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance_test},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction_test.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Test.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f414c4f5090>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean_test,color=\"purple\")\n",
    "plt.plot(true_mean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print for Terminal Legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  0.000399    0.000274         6.193477e-14                0.031626   \n",
      "MAE  0.001347    0.001873         3.536562e-06                0.101296   \n",
      "Max  0.002663    0.004878         2.124155e-05                0.178700   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.015270  \n",
      "MAE              0.175159  \n",
      "Max              0.302528  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  0.000449    0.000274         6.193477e-14                0.031626   \n",
      "MAE  0.781368    0.001862         3.497480e-06                0.100487   \n",
      "Max  0.781368    0.001862         3.497480e-06                0.100487   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.015270  \n",
      "MAE              0.173415  \n",
      "Max              0.173415  \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------------#\")\n",
    "print(\"Training-Set Performance\")\n",
    "print(\"#----------------------#\")\n",
    "print(Type_A_Prediction)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"#------------------#\")\n",
    "print(\"Test-Set Performance\")\n",
    "print(\"#------------------#\")\n",
    "print(Type_A_Prediction_test)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>6.193477e-14</td>\n",
       "      <td>0.031626</td>\n",
       "      <td>0.015270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>3.536562e-06</td>\n",
       "      <td>0.101296</td>\n",
       "      <td>0.175159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>2.124155e-05</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.302528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.000399    0.000274         6.193477e-14                0.031626   \n",
       "MAE  0.001347    0.001873         3.536562e-06                0.101296   \n",
       "Max  0.002663    0.004878         2.124155e-05                0.178700   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.015270  \n",
       "MAE              0.175159  \n",
       "Max              0.302528  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>6.193477e-14</td>\n",
       "      <td>0.031626</td>\n",
       "      <td>0.015270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.781368</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>3.497480e-06</td>\n",
       "      <td>0.100487</td>\n",
       "      <td>0.173415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.781368</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>3.497480e-06</td>\n",
       "      <td>0.100487</td>\n",
       "      <td>0.173415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.000449    0.000274         6.193477e-14                0.031626   \n",
       "MAE  0.781368    0.001862         3.497480e-06                0.100487   \n",
       "Max  0.781368    0.001862         3.497480e-06                0.100487   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.015270  \n",
       "MAE              0.173415  \n",
       "Max              0.173415  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
