{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Universal Regular Conditional Expectations:\n",
    "\n",
    "---\n",
    "This implements the universal deep neural model of $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$ [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---\n",
    "\n",
    "## What does this code do?\n",
    "1. Learn Heteroskedastic Non-Linear Regression Problem\n",
    "     - $Y\\sim f_{\\text{unkown}}(x) + \\epsilon$ where $f$ is an known function and $\\epsilon\\sim Laplace(0,\\|x\\|)$\n",
    "2. Learn Random Bayesian Network's Law:\n",
    "    - $Y = W_J Y^{J-1}, \\qquad Y^{j}\\triangleq \\sigma\\bullet A^{j}Y^{j-1} + b^{j}, \\qquad Y^0\\triangleq x$\n",
    "\n",
    "3. In the above example if $A_j = M_j\\odot \\tilde{A_j}$ where $\\tilde{A}_j$ is a deterministic matrix and $M_j$ is a \"mask\", that is, a random matrix with binary entries and $\\odot$ is the Hadamard product then we recover the dropout framework.\n",
    "4. Learn the probability distribution that the unique strong solution to the rough SDE with uniformly Lipschitz drivers driven by a factional Brownian motion with Hurst exponent $H \\in [\\frac1{2},1)$:\n",
    "$$\n",
    "X_t^x = x + \\int_0^t \\alpha(s,X_s^x)ds + \\int_0^t \\beta(s,X_s^x)dB_s^H\n",
    "$$\n",
    "belongs, at time $t=1$, to a ball about the initial point $x$ of random radius given by an independant exponential random-variable with shape parameter $\\lambda=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode:\n",
    "Software/Hardware Testing or Real-Deal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random DNN\n",
    "f_unknown_mode = \"Heteroskedastic_NonLinear_Regression\"\n",
    "\n",
    "# Random DNN internal noise\n",
    "# f_unknown_mode = \"DNN_with_Random_Weights\"\n",
    "Depth_Bayesian_DNN = 2\n",
    "width = 2\n",
    "\n",
    "# Random Dropout applied to trained DNN\n",
    "# f_unknown_mode = \"DNN_with_Bayesian_Dropout\"\n",
    "Dropout_rate = 0.25\n",
    "\n",
    "# Rough SDE (time 1)\n",
    "# f_unknown_mode = \"Rough_SDE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dim = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: *Why the procedure is so computationally efficient*?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rough SDE Meta-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDE with Rough Driver\n",
    "N_Euler_Steps = 10**1\n",
    "Hurst_Exponent = 0.01\n",
    "\n",
    "def alpha(t,x):\n",
    "    output_drift_update = t-x\n",
    "    return output_drift_update\n",
    "\n",
    "def beta(t,x):\n",
    "    output_vol_update = (t+0.001)*np.diag(np.cos(x))\n",
    "    return output_vol_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)\n",
    "- Ratio $\\frac{\\text{Testing Datasize}}{\\text{Training Datasize}}$.\n",
    "- Number of Training Points to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = .2\n",
    "N_train_size = 10**1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Monte_Carlo_Samples = 10**1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial radis of $\\delta$-bounded random partition of $\\mathcal{X}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "Proportion_per_cluster = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 4483.49it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 3646.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 4922.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Running script for main model!\n",
      "------------------------------\n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "==========================================\n",
      "Training Classifer Portion of Type-A Model\n",
      "==========================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.4000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.4000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7051 - accuracy: 0.4000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7019 - accuracy: 0.4000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.4000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6957 - accuracy: 0.4000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.4000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.4000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.4000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.4000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.4000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.4000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.4000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.4000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.4000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.4000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.4000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.4000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.4000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.4000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.4000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.4000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6474 - accuracy: 0.4000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6448 - accuracy: 0.4000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.4000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.7000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.7000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.7000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.8000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.8000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.8000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.8000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 956us/step - loss: 0.6076 - accuracy: 0.8000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6052 - accuracy: 0.8000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.8000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.8000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.8000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5957 - accuracy: 0.8000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5934 - accuracy: 0.8000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.8000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.8000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.8000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.8000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5820 - accuracy: 0.8000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbd5c21c0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1022.20it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 751.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Training Classifer Portion of Type Model: Done!\n",
      "===============================================\n",
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#----------------#\n",
      " Get Test Error(s)\n",
      "#----------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "------------------------------------\n",
      "Done: Running script for main model!\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------\")\n",
    "print(\"Running script for main model!\")\n",
    "print(\"------------------------------\")\n",
    "# %run Universal_Measure_Valued_Networks_Backend.ipynb\n",
    "exec(open('Universal_Measure_Valued_Networks_Backend.py').read())\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Done: Running script for main model!\")\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run: All Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) *Pointmass Benchmark(s)*\n",
    "These benchmarks consist of subsets of $C(\\mathbb{R}^d,\\mathbb{R})$ which we lift to models in $C(\\mathbb{R}^d,\\cap_{1\\leq q<\\infty}\\mathscr{P}_{q}(\\mathbb{R}))$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to f(x) \\to \\delta_{f(x)}\\in \\cap_{1\\leq q<\\infty}\\mathcal{P}_{q}(\\mathbb{R}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "--------------\n",
      "Training: ENET\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1121.02it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 941.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "-----------------\n",
      "Training: K-Ridge\n",
      "-----------------\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0510s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "100%|██████████| 10/10 [00:00<00:00, 812.22it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 240.69it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "--------------\n",
      "Training: GBRF\n",
      "--------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.1434s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "100%|██████████| 10/10 [00:00<00:00, 1179.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1011.28it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "-------------\n",
      "Training: DNN\n",
      "-------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3073 - mse: 1.8254 - mae: 1.3073 - mape: 103.6612\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3072 - mse: 1.8253 - mae: 1.3072 - mape: 103.6587\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3072 - mse: 1.8253 - mae: 1.3072 - mape: 103.6563\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3072 - mse: 1.8252 - mae: 1.3072 - mape: 103.6539\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3071 - mse: 1.8251 - mae: 1.3071 - mape: 103.6515\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3071 - mse: 1.8251 - mae: 1.3071 - mape: 103.6490\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3071 - mse: 1.8250 - mae: 1.3071 - mape: 103.6466\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3071 - mse: 1.8249 - mae: 1.3071 - mape: 103.6441\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3070 - mse: 1.8248 - mae: 1.3070 - mape: 103.6417\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3070 - mse: 1.8248 - mae: 1.3070 - mape: 103.6393\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3070 - mse: 1.8247 - mae: 1.3070 - mape: 103.6369\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3069 - mse: 1.8246 - mae: 1.3069 - mape: 103.6344\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3069 - mse: 1.8245 - mae: 1.3069 - mape: 103.6320\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3069 - mse: 1.8245 - mae: 1.3069 - mape: 103.6296\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3069 - mse: 1.8244 - mae: 1.3069 - mape: 103.6271\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3068 - mse: 1.8243 - mae: 1.3068 - mape: 103.6247\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3068 - mse: 1.8242 - mae: 1.3068 - mape: 103.6223\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3068 - mse: 1.8242 - mae: 1.3068 - mape: 103.6198\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 913us/step - loss: 1.3068 - mse: 1.8241 - mae: 1.3068 - mape: 103.6174\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 854us/step - loss: 1.3067 - mse: 1.8240 - mae: 1.3067 - mape: 103.6150\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3067 - mse: 1.8240 - mae: 1.3067 - mape: 103.6125\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3067 - mse: 1.8239 - mae: 1.3067 - mape: 103.6101\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3066 - mse: 1.8238 - mae: 1.3066 - mape: 103.6077\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3066 - mse: 1.8237 - mae: 1.3066 - mape: 103.6052\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3066 - mse: 1.8237 - mae: 1.3066 - mape: 103.6028\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3066 - mse: 1.8236 - mae: 1.3066 - mape: 103.6003\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3065 - mse: 1.8235 - mae: 1.3065 - mape: 103.5979\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3065 - mse: 1.8234 - mae: 1.3065 - mape: 103.5955\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3065 - mse: 1.8234 - mae: 1.3065 - mape: 103.5930\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3064 - mse: 1.8233 - mae: 1.3064 - mape: 103.5906\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3064 - mse: 1.8232 - mae: 1.3064 - mape: 103.5882\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3064 - mse: 1.8231 - mae: 1.3064 - mape: 103.5857\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3064 - mse: 1.8231 - mae: 1.3064 - mape: 103.5833\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3063 - mse: 1.8230 - mae: 1.3063 - mape: 103.5808\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3063 - mse: 1.8229 - mae: 1.3063 - mape: 103.5784\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3063 - mse: 1.8229 - mae: 1.3063 - mape: 103.5760\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 871us/step - loss: 1.3062 - mse: 1.8228 - mae: 1.3062 - mape: 103.5735\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3062 - mse: 1.8227 - mae: 1.3062 - mape: 103.5711\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3062 - mse: 1.8226 - mae: 1.3062 - mape: 103.5686\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3062 - mse: 1.8226 - mae: 1.3062 - mape: 103.5662\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3061 - mse: 1.8225 - mae: 1.3061 - mape: 103.5638\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3061 - mse: 1.8224 - mae: 1.3061 - mape: 103.5613\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3061 - mse: 1.8223 - mae: 1.3061 - mape: 103.5589\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3060 - mse: 1.8223 - mae: 1.3060 - mape: 103.5564\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3060 - mse: 1.8222 - mae: 1.3060 - mape: 103.5540\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3060 - mse: 1.8221 - mae: 1.3060 - mape: 103.5515\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3060 - mse: 1.8220 - mae: 1.3060 - mape: 103.5491\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3059 - mse: 1.8220 - mae: 1.3059 - mape: 103.5467\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3059 - mse: 1.8219 - mae: 1.3059 - mape: 103.5442\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3059 - mse: 1.8218 - mae: 1.3059 - mape: 103.5418\n",
      "1/1 [==============================] - 0s 841us/step\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1041.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1045.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "-----------------------\n",
      "Computing Error Metrics\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exec(open('CV_Grid.py').read())\n",
    "# Notebook Mode:\n",
    "# %run Evaluation.ipynb\n",
    "# %run Benchmarks_Model_Builder_Pointmass_Based.ipynb\n",
    "# Terminal Mode (Default):\n",
    "exec(open('Evaluation.py').read())\n",
    "exec(open('Benchmarks_Model_Builder_Pointmass_Based.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Point-Mass Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ENET    kRidge      GBRF      ffNN\n",
      "W1        2.619492  2.582876  2.555807  3.363264\n",
      "Mean      1.256631  1.178984  1.183676  0.040922\n",
      "Var       4.728955  4.728955  4.728955  4.728955\n",
      "Skewness  0.000000  0.000000  0.000000  0.000000\n",
      "Ex_Kur    6.000000  6.000000  6.000000  6.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>ffNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>2.619492</td>\n",
       "      <td>2.582876</td>\n",
       "      <td>2.555807</td>\n",
       "      <td>3.363264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>1.256631</td>\n",
       "      <td>1.178984</td>\n",
       "      <td>1.183676</td>\n",
       "      <td>0.040922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>4.728955</td>\n",
       "      <td>4.728955</td>\n",
       "      <td>4.728955</td>\n",
       "      <td>4.728955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex_Kur</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ENET    kRidge      GBRF      ffNN\n",
       "W1        2.619492  2.582876  2.555807  3.363264\n",
       "Mean      1.256631  1.178984  1.183676  0.040922\n",
       "Var       4.728955  4.728955  4.728955  4.728955\n",
       "Skewness  0.000000  0.000000  0.000000  0.000000\n",
       "Ex_Kur    6.000000  6.000000  6.000000  6.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ENET    kRidge      GBRF      ffNN\n",
      "W1        2.493914  2.507653  2.405978  4.206755\n",
      "Mean      1.263991  1.178675  1.263991  0.041852\n",
      "Var       4.299276  4.299276  4.299276  4.299276\n",
      "Skewness  0.000000  0.000000  0.000000  0.000000\n",
      "Ex_Kur    6.000000  6.000000  6.000000  6.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>ffNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>2.493914</td>\n",
       "      <td>2.507653</td>\n",
       "      <td>2.405978</td>\n",
       "      <td>4.206755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>1.263991</td>\n",
       "      <td>1.178675</td>\n",
       "      <td>1.263991</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>4.299276</td>\n",
       "      <td>4.299276</td>\n",
       "      <td>4.299276</td>\n",
       "      <td>4.299276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex_Kur</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ENET    kRidge      GBRF      ffNN\n",
       "W1        2.493914  2.507653  2.405978  4.206755\n",
       "Mean      1.263991  1.178675  1.263991  0.041852\n",
       "Var       4.299276  4.299276  4.299276  4.299276\n",
       "Skewness  0.000000  0.000000  0.000000  0.000000\n",
       "Ex_Kur    6.000000  6.000000  6.000000  6.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Complexitie(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        N_Params    T_Time  T_Test/T_test-MC\n",
      "ENET           4  4.270982          0.032931\n",
      "GBRF        4976  0.302368          0.163400\n",
      "kRidge        10  0.414811          0.161691\n",
      "ffNN          81  5.977831         18.194280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Params</th>\n",
       "      <th>T_Time</th>\n",
       "      <th>T_Test/T_test-MC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENET</th>\n",
       "      <td>4</td>\n",
       "      <td>4.270982</td>\n",
       "      <td>0.032931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBRF</th>\n",
       "      <td>4976</td>\n",
       "      <td>0.302368</td>\n",
       "      <td>0.163400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kRidge</th>\n",
       "      <td>10</td>\n",
       "      <td>0.414811</td>\n",
       "      <td>0.161691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffNN</th>\n",
       "      <td>81</td>\n",
       "      <td>5.977831</td>\n",
       "      <td>18.194280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        N_Params    T_Time  T_Test/T_test-MC\n",
       "ENET           4  4.270982          0.032931\n",
       "GBRF        4976  0.302368          0.163400\n",
       "kRidge        10  0.414811          0.161691\n",
       "ffNN          81  5.977831         18.194280"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_Complexity_models)\n",
    "Summary_Complexity_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) *Gaussian Benchmarks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bencharm 1: [Gaussian Process Regressor](https://scikit-learn.org/stable/modules/gaussian_process.html)\n",
    "- Benchmark 2: Deep Gaussian Networks:\n",
    "These models train models which assume Gaussianity.  We may view these as models in $\\mathcal{P}_2(\\mathbb{R})$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to (\\hat{\\mu}(x),\\hat{\\sigma}(x))\\triangleq f(x) \\in \\mathbb{R}\\times [0,\\infty) \\to \\frac1{\\hat{\\sigma}(x)\\sqrt{2\\pi}}\\exp\\left(\\frac{-(\\cdot-\\hat{\\mu}(x))^2}{\\hat{\\sigma(x)}^2}\\right) \\in \\mathcal{G}_1\\subset \\mathcal{P}_2(\\mathbb{R});\n",
    "$$\n",
    "where $\\mathcal{G}_1$ is the set of Gaussian measures on $\\mathbb{R}$ equipped with the relative Wasserstein-1 topology.\n",
    "\n",
    "Examples of this type of architecture are especially prevalent in uncertainty quantification; see ([Deep Ensembles](https://arxiv.org/abs/1612.01474)] or [NOMU: Neural Optimization-based Model Uncertainty](https://arxiv.org/abs/2102.13640).  Moreover, their universality in $C(\\mathbb{R}^d,\\mathcal{G}_2)$ is known, and has been shown in [Corollary 4.7](https://arxiv.org/abs/2101.05390)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Feature Builder - Ready\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0781s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "100%|██████████| 10/10 [00:00<00:00, 112.87it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering Parameters for Deep Gaussian Network to train on!\n",
      "Done Getting Parameters for Deep Gaussian Network!\n",
      "===============================\n",
      "Training Deep Gaussian Network!\n",
      "===============================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9073 - mse: 1.0322 - mae: 0.9073 - mape: 68.0508\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9073 - mse: 1.0322 - mae: 0.9073 - mape: 68.0495\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9073 - mse: 1.0321 - mae: 0.9073 - mape: 68.0481\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9073 - mse: 1.0321 - mae: 0.9073 - mape: 68.0467\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9072 - mse: 1.0320 - mae: 0.9072 - mape: 68.0453\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9072 - mse: 1.0320 - mae: 0.9072 - mape: 68.0439\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9072 - mse: 1.0320 - mae: 0.9072 - mape: 68.0426\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9072 - mse: 1.0319 - mae: 0.9072 - mape: 68.0412\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9072 - mse: 1.0319 - mae: 0.9072 - mape: 68.0398\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9071 - mse: 1.0318 - mae: 0.9071 - mape: 68.0385\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9071 - mse: 1.0318 - mae: 0.9071 - mape: 68.0371\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9071 - mse: 1.0318 - mae: 0.9071 - mape: 68.0357\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9071 - mse: 1.0317 - mae: 0.9071 - mape: 68.0343\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9071 - mse: 1.0317 - mae: 0.9071 - mape: 68.0329\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9070 - mse: 1.0316 - mae: 0.9070 - mape: 68.0316\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 961us/step - loss: 0.9070 - mse: 1.0316 - mae: 0.9070 - mape: 68.0302\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9070 - mse: 1.0315 - mae: 0.9070 - mape: 68.0288\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9070 - mse: 1.0315 - mae: 0.9070 - mape: 68.0275\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9070 - mse: 1.0315 - mae: 0.9070 - mape: 68.0261\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9069 - mse: 1.0314 - mae: 0.9069 - mape: 68.0247\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9069 - mse: 1.0314 - mae: 0.9069 - mape: 68.0233\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9069 - mse: 1.0313 - mae: 0.9069 - mape: 68.0219\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9069 - mse: 1.0313 - mae: 0.9069 - mape: 68.0206\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9069 - mse: 1.0312 - mae: 0.9069 - mape: 68.0192\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9068 - mse: 1.0312 - mae: 0.9068 - mape: 68.0178\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9068 - mse: 1.0312 - mae: 0.9068 - mape: 68.0165\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9068 - mse: 1.0311 - mae: 0.9068 - mape: 68.0151\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9068 - mse: 1.0311 - mae: 0.9068 - mape: 68.0137\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9068 - mse: 1.0310 - mae: 0.9068 - mape: 68.0123\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9067 - mse: 1.0310 - mae: 0.9067 - mape: 68.0110\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9067 - mse: 1.0309 - mae: 0.9067 - mape: 68.0096\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9067 - mse: 1.0309 - mae: 0.9067 - mape: 68.0082\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9067 - mse: 1.0309 - mae: 0.9067 - mape: 68.0068\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9067 - mse: 1.0308 - mae: 0.9067 - mape: 68.0055\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9066 - mse: 1.0308 - mae: 0.9066 - mape: 68.0041\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9066 - mse: 1.0307 - mae: 0.9066 - mape: 68.0027\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9066 - mse: 1.0307 - mae: 0.9066 - mape: 68.0014\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9066 - mse: 1.0306 - mae: 0.9066 - mape: 68.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9066 - mse: 1.0306 - mae: 0.9066 - mape: 67.9986\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9065 - mse: 1.0306 - mae: 0.9065 - mape: 67.9972\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9065 - mse: 1.0305 - mae: 0.9065 - mape: 67.995 - 0s 1ms/step - loss: 0.9065 - mse: 1.0305 - mae: 0.9065 - mape: 67.9959\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9065 - mse: 1.0305 - mae: 0.9065 - mape: 67.9945\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9065 - mse: 1.0304 - mae: 0.9065 - mape: 67.9931\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9064 - mse: 1.0304 - mae: 0.9064 - mape: 67.9917\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9064 - mse: 1.0304 - mae: 0.9064 - mape: 67.9904\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9064 - mse: 1.0303 - mae: 0.9064 - mape: 67.9890\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9064 - mse: 1.0303 - mae: 0.9064 - mape: 67.9876\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9064 - mse: 1.0302 - mae: 0.9064 - mape: 67.9863\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9063 - mse: 1.0302 - mae: 0.9063 - mape: 67.9849\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9063 - mse: 1.0301 - mae: 0.9063 - mape: 67.9835\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1449.81it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1395.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Training Deep Gaussian Network!: END\n",
      "====================================\n",
      "#---------------------------------------#\n",
      " Get Training Errors for: Gaussian Models\n",
      "#---------------------------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#---------------------------------------#\n",
      " Get Testing Errors for: Gaussian Models\n",
      "#---------------------------------------#\n",
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n",
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "--------------------------------------------\n",
      "Computing and Updating Complexity Metrics...\n",
      "--------------------------------------------\n",
      "-----------------------------------------------\n",
      "Updated Complexity Metrics Dataframe and Saved!\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %run Benchmarks_Model_Builder_Mean_Var.ipynb\n",
    "exec(open('Benchmarks_Model_Builder_Mean_Var.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Quality (Updated)\n",
      "              ENET    kRidge      GBRF      ffNN       GPR       DGN\n",
      "W1        2.493914  2.507653  2.405978  4.206755  2.519180  1.619511\n",
      "Mean      1.263991  1.178675  1.263991  0.041852  0.367858  0.025474\n",
      "Var       4.299276  4.299276  4.299276  4.299276  4.361097  3.703154\n",
      "Skewness  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "Ex_Kur    6.000000  6.000000  6.000000  6.000000  3.000000  3.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>ffNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>2.493914</td>\n",
       "      <td>2.507653</td>\n",
       "      <td>2.405978</td>\n",
       "      <td>4.206755</td>\n",
       "      <td>2.519180</td>\n",
       "      <td>1.619511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>1.263991</td>\n",
       "      <td>1.178675</td>\n",
       "      <td>1.263991</td>\n",
       "      <td>0.041852</td>\n",
       "      <td>0.367858</td>\n",
       "      <td>0.025474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>4.299276</td>\n",
       "      <td>4.299276</td>\n",
       "      <td>4.299276</td>\n",
       "      <td>4.299276</td>\n",
       "      <td>4.361097</td>\n",
       "      <td>3.703154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex_Kur</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ENET    kRidge      GBRF      ffNN       GPR       DGN\n",
       "W1        2.493914  2.507653  2.405978  4.206755  2.519180  1.619511\n",
       "Mean      1.263991  1.178675  1.263991  0.041852  0.367858  0.025474\n",
       "Var       4.299276  4.299276  4.299276  4.299276  4.361097  3.703154\n",
       "Skewness  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "Ex_Kur    6.000000  6.000000  6.000000  6.000000  3.000000  3.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Prediction Quality (Updated)\")\n",
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Complexities Quality (Updated)\n",
      "        N_Params        T_Time  T_Test/T_test-MC\n",
      "ENET         4.0  4.270982e+00          0.032931\n",
      "GBRF      4976.0  3.023679e-01          0.163400\n",
      "kRidge      10.0  4.148109e-01          0.161691\n",
      "ffNN        81.0  5.977831e+00         18.194280\n",
      "GPR          0.0  4.257457e-01          0.171718\n",
      "DGN         81.0  1.619537e+09         33.112352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Params</th>\n",
       "      <th>T_Time</th>\n",
       "      <th>T_Test/T_test-MC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENET</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.270982e+00</td>\n",
       "      <td>0.032931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBRF</th>\n",
       "      <td>4976.0</td>\n",
       "      <td>3.023679e-01</td>\n",
       "      <td>0.163400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kRidge</th>\n",
       "      <td>10.0</td>\n",
       "      <td>4.148109e-01</td>\n",
       "      <td>0.161691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffNN</th>\n",
       "      <td>81.0</td>\n",
       "      <td>5.977831e+00</td>\n",
       "      <td>18.194280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.257457e-01</td>\n",
       "      <td>0.171718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DGN</th>\n",
       "      <td>81.0</td>\n",
       "      <td>1.619537e+09</td>\n",
       "      <td>33.112352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        N_Params        T_Time  T_Test/T_test-MC\n",
       "ENET         4.0  4.270982e+00          0.032931\n",
       "GBRF      4976.0  3.023679e-01          0.163400\n",
       "kRidge      10.0  4.148109e-01          0.161691\n",
       "ffNN        81.0  5.977831e+00         18.194280\n",
       "GPR          0.0  4.257457e-01          0.171718\n",
       "DGN         81.0  1.619537e+09         33.112352"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model Complexities Quality (Updated)\")\n",
    "print(Summary_Complexity_models)\n",
    "Summary_Complexity_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) The natural Universal Benchmark: [Bishop's Mixture Density Network](https://publications.aston.ac.uk/id/eprint/373/1/NCRG_94_004.pdf)\n",
    "\n",
    "This implementation is as follows:\n",
    "- For every $x$ in the trainingdata-set we fit a GMM $\\hat{\\nu}_x$, using the [Expectation-Maximization (EM) algorithm](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm), with the same number of centers as the deep neural model in $\\mathcal{NN}_{1_{\\mathbb{R}^d},\\mathcal{D}}^{\\sigma:\\star}$ which we are evaluating.  \n",
    "- A Mixture density network is then trained to predict the infered parameters; given any $x \\in \\mathbb{R}^d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Preparing Training Outputs for MDNs using EM-Algorithm\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [00:00<00:00, 101.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Prepared Training Outputs for MDNs using EM-Algorithm!\n",
      "======================================================\n",
      "Deep Feature Builder - Ready\n",
      "(0)\n",
      "=====================================================\n",
      "Training Mixture Density Network (MDN): Means: Start!\n",
      "=====================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 935us/step - loss: 1.8106 - mse: 4.5723 - mae: 1.8106 - mape: 99.9172\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8105 - mse: 4.5722 - mae: 1.8105 - mape: 99.9150\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8105 - mse: 4.5722 - mae: 1.8105 - mape: 99.9128\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8105 - mse: 4.5721 - mae: 1.8105 - mape: 99.9106\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8105 - mse: 4.5721 - mae: 1.8105 - mape: 99.9084\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8105 - mse: 4.5720 - mae: 1.8105 - mape: 99.9062\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8105 - mse: 4.5720 - mae: 1.8105 - mape: 99.9040\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8105 - mse: 4.5719 - mae: 1.8105 - mape: 99.9018\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8104 - mse: 4.5719 - mae: 1.8104 - mape: 99.8996\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8104 - mse: 4.5718 - mae: 1.8104 - mape: 99.8974\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8104 - mse: 4.5718 - mae: 1.8104 - mape: 99.8952\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8104 - mse: 4.5717 - mae: 1.8104 - mape: 99.8930\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8104 - mse: 4.5717 - mae: 1.8104 - mape: 99.8908\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8104 - mse: 4.5716 - mae: 1.8104 - mape: 99.8886\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8104 - mse: 4.5716 - mae: 1.8104 - mape: 99.8864\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8103 - mse: 4.5715 - mae: 1.8103 - mape: 99.8842\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8103 - mse: 4.5715 - mae: 1.8103 - mape: 99.8820\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8103 - mse: 4.5714 - mae: 1.8103 - mape: 99.8798\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8103 - mse: 4.5714 - mae: 1.8103 - mape: 99.8776\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8103 - mse: 4.5713 - mae: 1.8103 - mape: 99.8754\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8103 - mse: 4.5713 - mae: 1.8103 - mape: 99.8732\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8103 - mse: 4.5712 - mae: 1.8103 - mape: 99.8710\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8102 - mse: 4.5712 - mae: 1.8102 - mape: 99.8688\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8102 - mse: 4.5712 - mae: 1.8102 - mape: 99.8666\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8102 - mse: 4.5711 - mae: 1.8102 - mape: 99.8644\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8102 - mse: 4.5711 - mae: 1.8102 - mape: 99.8622\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8102 - mse: 4.5710 - mae: 1.8102 - mape: 99.8600\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8102 - mse: 4.5710 - mae: 1.8102 - mape: 99.8577\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8102 - mse: 4.5709 - mae: 1.8102 - mape: 99.8556\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8101 - mse: 4.5709 - mae: 1.8101 - mape: 99.8534\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8101 - mse: 4.5708 - mae: 1.8101 - mape: 99.8512\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8101 - mse: 4.5708 - mae: 1.8101 - mape: 99.8490\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8101 - mse: 4.5707 - mae: 1.8101 - mape: 99.8467\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8101 - mse: 4.5707 - mae: 1.8101 - mape: 99.8446\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8101 - mse: 4.5706 - mae: 1.8101 - mape: 99.8423\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8100 - mse: 4.5706 - mae: 1.8100 - mape: 99.8401\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8100 - mse: 4.5705 - mae: 1.8100 - mape: 99.8380\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8100 - mse: 4.5705 - mae: 1.8100 - mape: 99.8358\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8100 - mse: 4.5704 - mae: 1.8100 - mape: 99.8335\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8100 - mse: 4.5704 - mae: 1.8100 - mape: 99.8313\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8100 - mse: 4.5703 - mae: 1.8100 - mape: 99.8291\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8100 - mse: 4.5703 - mae: 1.8100 - mape: 99.8270\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8099 - mse: 4.5702 - mae: 1.8099 - mape: 99.8248\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8099 - mse: 4.5702 - mae: 1.8099 - mape: 99.8226\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8099 - mse: 4.5701 - mae: 1.8099 - mape: 99.8204\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8099 - mse: 4.5701 - mae: 1.8099 - mape: 99.8182\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8099 - mse: 4.5700 - mae: 1.8099 - mape: 99.8160\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8099 - mse: 4.5700 - mae: 1.8099 - mape: 99.8138\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8099 - mse: 4.5700 - mae: 1.8099 - mape: 99.8116\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8098 - mse: 4.5699 - mae: 1.8098 - mape: 99.8094\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "===================================================\n",
      "Training Mixture Density Network (MDN): Means: END!\n",
      "===================================================\n",
      "(1)\n",
      "===================================================\n",
      "Training Mixture Density Network (MDN): SD: Start!\n",
      "===================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7454 - mse: 0.6886 - mae: 0.7454 - mape: 9608512.0000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7454 - mse: 0.6886 - mae: 0.7454 - mape: 9608247.0000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7454 - mse: 0.6885 - mae: 0.7454 - mape: 9607984.0000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7454 - mse: 0.6885 - mae: 0.7454 - mape: 9607720.0000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7454 - mse: 0.6885 - mae: 0.7454 - mape: 9607454.0000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7454 - mse: 0.6885 - mae: 0.7454 - mape: 9607190.0000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7454 - mse: 0.6885 - mae: 0.7454 - mape: 9606926.0000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7454 - mse: 0.6885 - mae: 0.7454 - mape: 9606662.0000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7453 - mse: 0.6885 - mae: 0.7453 - mape: 9606398.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7453 - mse: 0.6884 - mae: 0.7453 - mape: 9606134.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7453 - mse: 0.6884 - mae: 0.7453 - mape: 9605870.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7453 - mse: 0.6884 - mae: 0.7453 - mape: 9605606.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7453 - mse: 0.6884 - mae: 0.7453 - mape: 9605342.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7453 - mse: 0.6884 - mae: 0.7453 - mape: 9605077.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7453 - mse: 0.6884 - mae: 0.7453 - mape: 9604813.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7453 - mse: 0.6884 - mae: 0.7453 - mape: 9604549.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7453 - mse: 0.6883 - mae: 0.7453 - mape: 9604284.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7453 - mse: 0.6883 - mae: 0.7453 - mape: 9604020.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7453 - mse: 0.6883 - mae: 0.7453 - mape: 9603755.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7452 - mse: 0.6883 - mae: 0.7452 - mape: 9603491.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7452 - mse: 0.6883 - mae: 0.7452 - mape: 9603226.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7452 - mse: 0.6883 - mae: 0.7452 - mape: 9602962.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7452 - mse: 0.6883 - mae: 0.7452 - mape: 9602699.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7452 - mse: 0.6882 - mae: 0.7452 - mape: 9602435.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7452 - mse: 0.6882 - mae: 0.7452 - mape: 9602170.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7452 - mse: 0.6882 - mae: 0.7452 - mape: 9601906.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7452 - mse: 0.6882 - mae: 0.7452 - mape: 9601642.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7452 - mse: 0.6882 - mae: 0.7452 - mape: 9601378.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7452 - mse: 0.6882 - mae: 0.7452 - mape: 9601113.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7452 - mse: 0.6882 - mae: 0.7452 - mape: 9600849.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7451 - mse: 0.6881 - mae: 0.7451 - mape: 9600584.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7451 - mse: 0.6881 - mae: 0.7451 - mape: 9600320.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7451 - mse: 0.6881 - mae: 0.7451 - mape: 9600056.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7451 - mse: 0.6881 - mae: 0.7451 - mape: 9599792.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7451 - mse: 0.6881 - mae: 0.7451 - mape: 9599527.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7451 - mse: 0.6881 - mae: 0.7451 - mape: 9599264.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7451 - mse: 0.6881 - mae: 0.7451 - mape: 9598998.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7451 - mse: 0.6880 - mae: 0.7451 - mape: 9598735.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7451 - mse: 0.6880 - mae: 0.7451 - mape: 9598470.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7451 - mse: 0.6880 - mae: 0.7451 - mape: 9598206.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7451 - mse: 0.6880 - mae: 0.7451 - mape: 9597942.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7450 - mse: 0.6880 - mae: 0.7450 - mape: 9597678.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7450 - mse: 0.6880 - mae: 0.7450 - mape: 9597414.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7450 - mse: 0.6880 - mae: 0.7450 - mape: 9597149.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7450 - mse: 0.6879 - mae: 0.7450 - mape: 9596885.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7450 - mse: 0.6879 - mae: 0.7450 - mape: 9596621.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7450 - mse: 0.6879 - mae: 0.7450 - mape: 9596357.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7450 - mse: 0.6879 - mae: 0.7450 - mape: 9596092.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7450 - mse: 0.6879 - mae: 0.7450 - mape: 9595828.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7450 - mse: 0.6879 - mae: 0.7450 - mape: 9595564.0000\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbd3c62f050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 928us/step\n",
      "=================================================\n",
      "Training Mixture Density Network (MDN): SD: END!\n",
      "=================================================\n",
      "(2)\n",
      "====================================================================\n",
      "Training Mixture Density Network (MDN): Mixture Coefficients: Start!\n",
      "====================================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7748 - accuracy: 0.4000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7708 - accuracy: 0.4000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7669 - accuracy: 0.4000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7630 - accuracy: 0.4000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 0.4000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.4000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7517 - accuracy: 0.4000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7481 - accuracy: 0.4000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7445 - accuracy: 0.4000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7408 - accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7372 - accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.6000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.6000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.6000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.6000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 854us/step - loss: 0.6957 - accuracy: 0.6000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.6000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.6000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 973us/step - loss: 0.6878 - accuracy: 0.6000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.7000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.7000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.7000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.7000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.7000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.7000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.7000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.70 - 0s 1ms/step - loss: 0.6694 - accuracy: 0.7000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.7000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.7000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.7000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.7000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.7000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.7000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.7000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.7000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.7000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.7000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.7000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.7000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.7000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.7000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.7000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbd3c47ec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 947us/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "=================================================================="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Mixture Density Network (MDN): Mixture Coefficients: END!\n",
      "==================================================================\n",
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1102.23it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1440.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------#\n",
      " Get Test Error(s)\n",
      "#--------------------#\n",
      "#---------------------#\n",
      " Get Test Error(s): END\n",
      "#---------------------#\n",
      "#---------------------------#\n",
      " Get Training Error(s): Begin\n",
      "#---------------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------------#\n",
      " Get Testing Error(s): Begin\n",
      "#--------------------------#\n",
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n",
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "--------------------------------------------\n",
      "Computing and Updating Complexity Metrics...\n",
      "--------------------------------------------\n",
      "-----------------------------------------------\n",
      "Updated Complexity Metrics Dataframe and Saved!\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %run Mixture_Density_Network.ipynb\n",
    "exec(open('Mixture_Density_Network.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Final Outputs\n",
    "Now we piece together all the numerical experiments and report a nice summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "Kernel_Used_in_GPR: RBF(length_scale=1)\n"
     ]
    }
   ],
   "source": [
    "# %run WrapUp_Summarizer.ipynb\n",
    "exec(open('WrapUp_Summarizer.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Complexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>ffNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "      <th>MDN</th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC_Oracle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N_Params</th>\n",
       "      <td>4.0000E+00</td>\n",
       "      <td>4.9760E+03</td>\n",
       "      <td>1.0000E+01</td>\n",
       "      <td>8.1000E+01</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>8.1000E+01</td>\n",
       "      <td>3.0600E+02</td>\n",
       "      <td>1.2000E+02</td>\n",
       "      <td>1.2000E+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_Time</th>\n",
       "      <td>4.2710E+00</td>\n",
       "      <td>3.0237E-01</td>\n",
       "      <td>4.1481E-01</td>\n",
       "      <td>5.9778E+00</td>\n",
       "      <td>4.2575E-01</td>\n",
       "      <td>1.6195E+09</td>\n",
       "      <td>1.6195E+09</td>\n",
       "      <td>2.0924E-03</td>\n",
       "      <td>2.0924E-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_Test/T_test-MC</th>\n",
       "      <td>3.2931E-02</td>\n",
       "      <td>1.6340E-01</td>\n",
       "      <td>1.6169E-01</td>\n",
       "      <td>1.8194E+01</td>\n",
       "      <td>1.7172E-01</td>\n",
       "      <td>3.3112E+01</td>\n",
       "      <td>9.2729E+01</td>\n",
       "      <td>1.0000E+00</td>\n",
       "      <td>1.0000E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ENET       GBRF     kRidge       ffNN        GPR  \\\n",
       "N_Params         4.0000E+00 4.9760E+03 1.0000E+01 8.1000E+01 0.0000E+00   \n",
       "T_Time           4.2710E+00 3.0237E-01 4.1481E-01 5.9778E+00 4.2575E-01   \n",
       "T_Test/T_test-MC 3.2931E-02 1.6340E-01 1.6169E-01 1.8194E+01 1.7172E-01   \n",
       "\n",
       "                        DGN        MDN        DNM  MC_Oracle  \n",
       "N_Params         8.1000E+01 3.0600E+02 1.2000E+02 1.2000E+02  \n",
       "T_Time           1.6195E+09 1.6195E+09 2.0924E-03 2.0924E-03  \n",
       "T_Test/T_test-MC 3.3112E+01 9.2729E+01 1.0000E+00 1.0000E+00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summary_Complexity_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>ffNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "      <th>MDN</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>DNM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>2.6195E+00</td>\n",
       "      <td>2.5829E+00</td>\n",
       "      <td>2.5558E+00</td>\n",
       "      <td>3.3633E+00</td>\n",
       "      <td>2.3850E+00</td>\n",
       "      <td>2.5227E+00</td>\n",
       "      <td>1.3370E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>8.1169E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>1.2566E+00</td>\n",
       "      <td>1.1790E+00</td>\n",
       "      <td>1.1837E+00</td>\n",
       "      <td>4.0922E-02</td>\n",
       "      <td>1.9163E-10</td>\n",
       "      <td>2.5087E-02</td>\n",
       "      <td>5.1119E-01</td>\n",
       "      <td>2.2856E-01</td>\n",
       "      <td>1.1708E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>4.7290E+00</td>\n",
       "      <td>4.7290E+00</td>\n",
       "      <td>4.7290E+00</td>\n",
       "      <td>4.7290E+00</td>\n",
       "      <td>4.2993E+00</td>\n",
       "      <td>3.2739E+00</td>\n",
       "      <td>1.9528E+00</td>\n",
       "      <td>2.0240E+00</td>\n",
       "      <td>2.0999E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>4.4696E-01</td>\n",
       "      <td>3.8607E-01</td>\n",
       "      <td>3.3432E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex_Kur</th>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>3.0000E+00</td>\n",
       "      <td>3.0000E+00</td>\n",
       "      <td>2.2262E+00</td>\n",
       "      <td>5.2248E+00</td>\n",
       "      <td>5.1064E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ENET     kRidge       GBRF       ffNN        GPR        DGN  \\\n",
       "W1       2.6195E+00 2.5829E+00 2.5558E+00 3.3633E+00 2.3850E+00 2.5227E+00   \n",
       "Mean     1.2566E+00 1.1790E+00 1.1837E+00 4.0922E-02 1.9163E-10 2.5087E-02   \n",
       "Var      4.7290E+00 4.7290E+00 4.7290E+00 4.7290E+00 4.2993E+00 3.2739E+00   \n",
       "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00   \n",
       "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00 3.0000E+00 3.0000E+00   \n",
       "\n",
       "                MDN  MC-Oracle        DNM  \n",
       "W1       1.3370E+00 0.0000E+00 8.1169E-01  \n",
       "Mean     5.1119E-01 2.2856E-01 1.1708E+00  \n",
       "Var      1.9528E+00 2.0240E+00 2.0999E+00  \n",
       "Skewness 4.4696E-01 3.8607E-01 3.3432E-01  \n",
       "Ex_Kur   2.2262E+00 5.2248E+00 5.1064E+00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictivePerformance_Metrics_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>ffNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "      <th>MDN</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>DNM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>2.4939E+00</td>\n",
       "      <td>2.5077E+00</td>\n",
       "      <td>2.4060E+00</td>\n",
       "      <td>4.2068E+00</td>\n",
       "      <td>2.5192E+00</td>\n",
       "      <td>1.6195E+00</td>\n",
       "      <td>1.3370E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>1.1820E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>1.2640E+00</td>\n",
       "      <td>1.1787E+00</td>\n",
       "      <td>1.2640E+00</td>\n",
       "      <td>4.1852E-02</td>\n",
       "      <td>3.6786E-01</td>\n",
       "      <td>2.5474E-02</td>\n",
       "      <td>2.2354E-01</td>\n",
       "      <td>7.6404E-01</td>\n",
       "      <td>1.2676E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>4.2993E+00</td>\n",
       "      <td>4.2993E+00</td>\n",
       "      <td>4.2993E+00</td>\n",
       "      <td>4.2993E+00</td>\n",
       "      <td>4.3611E+00</td>\n",
       "      <td>3.7032E+00</td>\n",
       "      <td>2.3825E+00</td>\n",
       "      <td>2.4211E+00</td>\n",
       "      <td>1.4205E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>4.3735E-01</td>\n",
       "      <td>3.2575E-01</td>\n",
       "      <td>2.7156E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex_Kur</th>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>3.0000E+00</td>\n",
       "      <td>3.0000E+00</td>\n",
       "      <td>4.2648E+00</td>\n",
       "      <td>5.3651E+00</td>\n",
       "      <td>5.6687E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ENET     kRidge       GBRF       ffNN        GPR        DGN  \\\n",
       "W1       2.4939E+00 2.5077E+00 2.4060E+00 4.2068E+00 2.5192E+00 1.6195E+00   \n",
       "Mean     1.2640E+00 1.1787E+00 1.2640E+00 4.1852E-02 3.6786E-01 2.5474E-02   \n",
       "Var      4.2993E+00 4.2993E+00 4.2993E+00 4.2993E+00 4.3611E+00 3.7032E+00   \n",
       "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00   \n",
       "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00 3.0000E+00 3.0000E+00   \n",
       "\n",
       "                MDN  MC-Oracle        DNM  \n",
       "W1       1.3370E+00 0.0000E+00 1.1820E+00  \n",
       "Mean     2.2354E-01 7.6404E-01 1.2676E-01  \n",
       "Var      2.3825E+00 2.4211E+00 1.4205E+00  \n",
       "Skewness 4.3735E-01 3.2575E-01 2.7156E-01  \n",
       "Ex_Kur   4.2648E+00 5.3651E+00 5.6687E+00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictivePerformance_Metrics_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Terminal Runner(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      "====================================\n",
      "Model Complexity Predictive Quality:\n",
      "====================================\n",
      " \n",
      " \n",
      " \n",
      "                       ENET       GBRF     kRidge       ffNN        GPR  \\\n",
      "N_Params         4.0000E+00 4.9760E+03 1.0000E+01 8.1000E+01 0.0000E+00   \n",
      "T_Time           4.2710E+00 3.0237E-01 4.1481E-01 5.9778E+00 4.2575E-01   \n",
      "T_Test/T_test-MC 3.2931E-02 1.6340E-01 1.6169E-01 1.8194E+01 1.7172E-01   \n",
      "\n",
      "                        DGN        MDN        DNM  MC_Oracle  \n",
      "N_Params         8.1000E+01 3.0600E+02 1.2000E+02 1.2000E+02  \n",
      "T_Time           1.6195E+09 1.6195E+09 2.0924E-03 2.0924E-03  \n",
      "T_Test/T_test-MC 3.3112E+01 9.2729E+01 1.0000E+00 1.0000E+00  \n",
      " \n",
      " \n",
      " \n",
      "============================\n",
      "Training Predictive Quality:\n",
      "============================\n",
      "               ENET     kRidge       GBRF       ffNN        GPR        DGN  \\\n",
      "W1       2.6195E+00 2.5829E+00 2.5558E+00 3.3633E+00 2.3850E+00 2.5227E+00   \n",
      "Mean     1.2566E+00 1.1790E+00 1.1837E+00 4.0922E-02 1.9163E-10 2.5087E-02   \n",
      "Var      4.7290E+00 4.7290E+00 4.7290E+00 4.7290E+00 4.2993E+00 3.2739E+00   \n",
      "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00   \n",
      "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00 3.0000E+00 3.0000E+00   \n",
      "\n",
      "                MDN  MC-Oracle        DNM  \n",
      "W1       1.3370E+00 0.0000E+00 8.1169E-01  \n",
      "Mean     5.1119E-01 2.2856E-01 1.1708E+00  \n",
      "Var      1.9528E+00 2.0240E+00 2.0999E+00  \n",
      "Skewness 4.4696E-01 3.8607E-01 3.3432E-01  \n",
      "Ex_Kur   2.2262E+00 5.2248E+00 5.1064E+00  \n",
      " \n",
      " \n",
      " \n",
      "===========================\n",
      "Testing Predictive Quality:\n",
      "===========================\n",
      "               ENET     kRidge       GBRF       ffNN        GPR        DGN  \\\n",
      "W1       2.4939E+00 2.5077E+00 2.4060E+00 4.2068E+00 2.5192E+00 1.6195E+00   \n",
      "Mean     1.2640E+00 1.1787E+00 1.2640E+00 4.1852E-02 3.6786E-01 2.5474E-02   \n",
      "Var      4.2993E+00 4.2993E+00 4.2993E+00 4.2993E+00 4.3611E+00 3.7032E+00   \n",
      "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00   \n",
      "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00 3.0000E+00 3.0000E+00   \n",
      "\n",
      "                MDN  MC-Oracle        DNM  \n",
      "W1       1.3370E+00 0.0000E+00 1.1820E+00  \n",
      "Mean     2.2354E-01 7.6404E-01 1.2676E-01  \n",
      "Var      2.3825E+00 2.4211E+00 1.4205E+00  \n",
      "Skewness 4.3735E-01 3.2575E-01 2.7156E-01  \n",
      "Ex_Kur   4.2648E+00 5.3651E+00 5.6687E+00  \n",
      "================================\n",
      " \n",
      " \n",
      " \n",
      "Kernel_Used_in_GPR: RBF(length_scale=1)\n",
      "🙃🙃 Have a wonderful day! 🙃🙃\n"
     ]
    }
   ],
   "source": [
    "# For Terminal Running\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"====================================\")\n",
    "print(\"Model Complexity Predictive Quality:\")\n",
    "print(\"====================================\")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(Summary_Complexity_models)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"============================\")\n",
    "print(\"Training Predictive Quality:\")\n",
    "print(\"============================\")\n",
    "print(PredictivePerformance_Metrics_Train)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"===========================\")\n",
    "print(\"Testing Predictive Quality:\")\n",
    "print(\"===========================\")\n",
    "print(PredictivePerformance_Metrics_Test)\n",
    "print(\"================================\")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Kernel_Used_in_GPR: \"+str(GPR_trash.kernel))\n",
    "print(\"🙃🙃 Have a wonderful day! 🙃🙃\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
