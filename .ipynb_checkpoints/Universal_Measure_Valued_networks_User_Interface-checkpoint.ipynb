{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Universal Regular Conditional Expectations:\n",
    "\n",
    "---\n",
    "This implements the universal deep neural model of $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$ [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---\n",
    "\n",
    "## What does this code do?\n",
    "1. Learn Heteroskedastic Non-Linear Regression Problem\n",
    "     - $Y\\sim f_{\\text{unkown}}(x) + \\epsilon$ where $f$ is an known function and $\\epsilon\\sim Laplace(0,\\|x\\|)$\n",
    "2. Learn Random Bayesian Network's Law:\n",
    "    - $Y = W_J Y^{J-1}, \\qquad Y^{j}\\triangleq \\sigma\\bullet A^{j}Y^{j-1} + b^{j}, \\qquad Y^0\\triangleq x$\n",
    "\n",
    "3. In the above example if $A_j = M_j\\odot \\tilde{A_j}$ where $\\tilde{A}_j$ is a deterministic matrix and $M_j$ is a \"mask\", that is, a random matrix with binary entries and $\\odot$ is the Hadamard product then we recover the dropout framework.\n",
    "4. Learn the probability distribution that the unique strong solution to the rough SDE with uniformly Lipschitz drivers driven by a factional Brownian motion with Hurst exponent $H \\in [\\frac1{2},1)$:\n",
    "$$\n",
    "X_t^x = x + \\int_0^t \\alpha(s,X_s^x)ds + \\int_0^t \\beta(s,X_s^x)dB_s^H\n",
    "$$\n",
    "belongs, at time $t=1$, to a ball about the initial point $x$ of random radius given by an independant exponential random-variable with shape parameter $\\lambda=2$\n",
    "5. Train a DNN to predict the returns of bitcoin with GD.  Since this has random initialization then each prediction of a given $x$ is stochastic...We learn the distribution of this conditional RV (conditioned on x in the input space).\n",
    "$$\n",
    "Y_x \\triangleq \\hat{f}_{\\theta_{T}}(x), \\qquad \\theta_{(t+1)}\\triangleq \\theta_{(t)} + \\lambda \\sum_{x \\in \\mathbb{X}} \\nabla_{\\theta}\\|\\hat{f}_{\\theta_t}(x) - f(x)\\|, \\qquad \\theta_0 \\sim N_d(0,1);\n",
    "$$\n",
    "$T\\in \\mathbb{N}$ is a fixed number of \"SGD\" iterations (typically identified by cross-validation on a single SGD trajectory for a single initialization) and where $\\theta \\in \\mathbb{R}^{(d_{J}+1)+\\sum_{j=0}^{J-1} (d_{j+1}d_j + 1)}$ and $d_j$ is the dimension of the \"bias\" vector $b_j$ defining each layer of the DNN with layer dimensions:\n",
    "$$\n",
    "\\hat{f}_{\\theta}(x)\\triangleq A^{(J)}x^{(J)} + b^{(J)},\\qquad x^{(j+1)}\\triangleq \\sigma\\bullet A^{j}x^{(j)} + b^{j},\\qquad x^{(0)}\\triangleq x\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode:\n",
    "Software/Hardware Testing or Real-Deal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random DNN\n",
    "# f_unknown_mode = \"Heteroskedastic_NonLinear_Regression\"\n",
    "\n",
    "# Random DNN internal noise\n",
    "f_unknown_mode = \"DNN_with_Random_Weights\"\n",
    "Depth_Bayesian_DNN = 1\n",
    "width = 5\n",
    "\n",
    "# Random Dropout applied to trained DNN\n",
    "# f_unknown_mode = \"DNN_with_Bayesian_Dropout\"\n",
    "Dropout_rate = 0.1\n",
    "\n",
    "# GD with Randomized Input\n",
    "# f_unknown_mode = \"GD_with_randomized_input\"\n",
    "GD_epochs = 50\n",
    "\n",
    "# SDE with fractional Driver\n",
    "#f_unknown_mode = \"Rough_SDE\"\n",
    "N_Euler_Steps = 10**2\n",
    "Hurst_Exponent = 0.75\n",
    "\n",
    "# f_unknown_mode = \"Rough_SDE_Vanilla\"\n",
    "## Define Process' dynamics in (2) cell(s) below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla fractional SDE:\n",
    "If f_unknown_mode == \"Rough_SDE_Vanilla\" is selected, then we can specify the process's dynamics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------#\n",
    "# Define Process' Dynamics #\n",
    "#--------------------------#\n",
    "drift_constant = 0.1\n",
    "volatility_constant = 0.01\n",
    "\n",
    "# Define DNN Applier\n",
    "def f_unknown_drift_vanilla(x):\n",
    "    x_internal = x\n",
    "    x_internal = drift_constant*x_internal\n",
    "    return x_internal\n",
    "def f_unknown_vol_vanilla(x):\n",
    "    x_internal = volatility_constant*np.diag(np.ones(problem_dim))\n",
    "    return x_internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: *Why the procedure is so computationally efficient*?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)\n",
    "- Ratio $\\frac{\\text{Testing Datasize}}{\\text{Training Datasize}}$.\n",
    "- Number of Training Points to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = .2\n",
    "N_train_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Monte_Carlo_Samples = 10**5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial radis of $\\delta$-bounded random partition of $\\mathcal{X}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.1\n",
    "Proportion_per_cluster = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and Auxiliary Script(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "Deep Feature Builder - Ready\n"
     ]
    }
   ],
   "source": [
    "# %run Loader.ipynb\n",
    "exec(open('Loader.py').read())\n",
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "import time as time #<- Note sure why...but its always seems to need 'its own special loading...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate or Parse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Beginning Data-Parsing/Simulation Phase\n",
      "---------------------------------------\n",
      "Deciding on Which Simulator/Parser To Load\n",
      "Setting/Defining: Internal Parameters\n",
      "Deciding on Which Type of Data to Get/Simulate\n",
      "Simulating Output Data for given input data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:42<00:00,  4.22s/it]\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Done Data-Parsing/Simulation Phase\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %run Data_Simulator_and_Parser.ipynb\n",
    "exec(open('Data_Simulator_and_Parser.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Data\n",
    "This is especially important to avoid exploding gradient problems when training the ML-models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11001.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Running script for main model!\n",
      "------------------------------\n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "==========================================\n",
      "Training Classifer Portion of Type-A Model\n",
      "==========================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0758 - accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0654 - accuracy: 0.2000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0562 - accuracy: 0.3000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0476 - accuracy: 0.3000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0395 - accuracy: 0.3000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0318 - accuracy: 0.3000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0240 - accuracy: 0.3000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0164 - accuracy: 0.3000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0087 - accuracy: 0.3000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0010 - accuracy: 0.3000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9932 - accuracy: 0.3000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9854 - accuracy: 0.3000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9774 - accuracy: 0.3000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9693 - accuracy: 0.3000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9610 - accuracy: 0.3000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9526 - accuracy: 0.3000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9440 - accuracy: 0.3000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9354 - accuracy: 0.1000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9266 - accuracy: 0.3000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9177 - accuracy: 0.3000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9086 - accuracy: 0.3000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8993 - accuracy: 0.3000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8900 - accuracy: 0.3000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8806 - accuracy: 0.3000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8711 - accuracy: 0.3000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8615 - accuracy: 0.3000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8518 - accuracy: 0.3000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8419 - accuracy: 0.3000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8320 - accuracy: 0.3000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8220 - accuracy: 0.3000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8120 - accuracy: 0.3000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8018 - accuracy: 0.3000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7915 - accuracy: 0.3000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7811 - accuracy: 0.3000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7706 - accuracy: 0.3000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7600 - accuracy: 0.3000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7493 - accuracy: 0.3000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7387 - accuracy: 0.3000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7279 - accuracy: 0.3000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7171 - accuracy: 0.3000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7062 - accuracy: 0.3000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6952 - accuracy: 0.3000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6841 - accuracy: 0.3000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6728 - accuracy: 0.3000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6614 - accuracy: 0.3000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6499 - accuracy: 0.3000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6383 - accuracy: 0.3000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6268 - accuracy: 0.3000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6153 - accuracy: 0.3000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6037 - accuracy: 0.3000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5922 - accuracy: 0.3000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5805 - accuracy: 0.3000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5688 - accuracy: 0.3000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5571 - accuracy: 0.3000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5456 - accuracy: 0.3000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5340 - accuracy: 0.3000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5226 - accuracy: 0.3000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5114 - accuracy: 0.3000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5003 - accuracy: 0.3000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4894 - accuracy: 0.3000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4786 - accuracy: 0.3000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4680 - accuracy: 0.3000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4576 - accuracy: 0.3000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4473 - accuracy: 0.3000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4372 - accuracy: 0.3000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4273 - accuracy: 0.3000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4175 - accuracy: 0.3000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4078 - accuracy: 0.3000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3983 - accuracy: 0.3000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3888 - accuracy: 0.3000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3795 - accuracy: 0.3000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3702 - accuracy: 0.3000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3610 - accuracy: 0.3000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3518 - accuracy: 0.3000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3428 - accuracy: 0.3000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3339 - accuracy: 0.3000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3251 - accuracy: 0.4000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3163 - accuracy: 0.4000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3075 - accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2990 - accuracy: 0.6000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2905 - accuracy: 0.6000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2821 - accuracy: 0.6000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2736 - accuracy: 0.6000\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2651 - accuracy: 0.6000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2567 - accuracy: 0.6000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2483 - accuracy: 0.6000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2399 - accuracy: 0.6000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2314 - accuracy: 0.6000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2230 - accuracy: 0.6000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2147 - accuracy: 0.6000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2063 - accuracy: 0.6000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1980 - accuracy: 0.6000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1897 - accuracy: 0.6000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1811 - accuracy: 0.6000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1726 - accuracy: 0.6000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1640 - accuracy: 0.6000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1556 - accuracy: 0.6000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1475 - accuracy: 0.6000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1394 - accuracy: 0.6000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1313 - accuracy: 0.6000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1231 - accuracy: 0.6000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1148 - accuracy: 0.6000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1066 - accuracy: 0.6000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0984 - accuracy: 0.6000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0902 - accuracy: 0.6000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0820 - accuracy: 0.6000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0738 - accuracy: 0.6000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0657 - accuracy: 0.6000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0576 - accuracy: 0.6000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0494 - accuracy: 0.6000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0412 - accuracy: 0.6000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0331 - accuracy: 0.6000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0251 - accuracy: 0.6000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0171 - accuracy: 0.6000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0092 - accuracy: 0.6000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0012 - accuracy: 0.6000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9933 - accuracy: 0.6000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9854 - accuracy: 0.6000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9776 - accuracy: 0.6000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9697 - accuracy: 0.6000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9620 - accuracy: 0.6000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9542 - accuracy: 0.6000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9464 - accuracy: 0.6000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9388 - accuracy: 0.6000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9312 - accuracy: 0.6000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9237 - accuracy: 0.6000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9162 - accuracy: 0.6000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9086 - accuracy: 0.6000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9011 - accuracy: 0.6000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8937 - accuracy: 0.6000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8864 - accuracy: 0.6000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8790 - accuracy: 0.6000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8717 - accuracy: 0.6000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8643 - accuracy: 0.6000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8571 - accuracy: 0.6000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8500 - accuracy: 0.6000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8429 - accuracy: 0.6000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8359 - accuracy: 0.6000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8288 - accuracy: 0.7000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8219 - accuracy: 0.7000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8150 - accuracy: 0.6000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8081 - accuracy: 0.6000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8014 - accuracy: 0.7000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7948 - accuracy: 0.7000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7880 - accuracy: 0.6000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7813 - accuracy: 0.7000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7748 - accuracy: 0.8000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7685 - accuracy: 0.8000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7621 - accuracy: 0.8000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7556 - accuracy: 0.8000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7494 - accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7431 - accuracy: 0.9000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7369 - accuracy: 0.9000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.9000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.9000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7186 - accuracy: 0.9000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.9000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.9000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.9000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6779 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6723 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.9000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.9000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.9000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.9000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.9000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.9000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6198 - accuracy: 0.9000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6148 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.9000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.9000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.9000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.9000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5769 - accuracy: 0.9000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.9000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.9000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.9000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.9000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.9000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.9000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.9000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 965us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Training Classifer Portion of Type Model: Done!\n",
      "===============================================\n",
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.30it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#----------------#\n",
      " Get Test Error(s)\n",
      "#----------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n",
      "                                        DNM  MC-Oracle\n",
      "W1-95L                         7.938964e-07   0.000000\n",
      "W1                             1.531317e-06   0.000000\n",
      "W1-95R                         2.268738e-06   0.000000\n",
      "M-95L                          3.097958e-05   0.000031\n",
      "M                              6.088506e-05   0.000061\n",
      "M-95R                          9.079053e-05   0.000091\n",
      "N_Par                          4.220800e+04   0.000000\n",
      "Train_Time                     1.073255e+01  49.621372\n",
      "Test_Time/MC-Oracle_Test_Time  7.195024e-03   1.000000\n",
      "------------------------------------\n",
      "Done: Running script for main model!\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------\")\n",
    "print(\"Running script for main model!\")\n",
    "print(\"------------------------------\")\n",
    "# %run Universal_Measure_Valued_Networks_Backend.ipynb\n",
    "exec(open('Universal_Measure_Valued_Networks_Backend.py').read())\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Done: Running script for main model!\")\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run: All Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) *Pointmass Benchmark(s)*\n",
    "These benchmarks consist of subsets of $C(\\mathbb{R}^d,\\mathbb{R})$ which we lift to models in $C(\\mathbb{R}^d,\\cap_{1\\leq q<\\infty}\\mathscr{P}_{q}(\\mathbb{R}))$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to f(x) \\to \\delta_{f(x)}\\in \\cap_{1\\leq q<\\infty}\\mathcal{P}_{q}(\\mathbb{R}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "--------------\n",
      "Training: ENET\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 70.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 66.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Training: ENET - Done\n",
      "---------------------\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                        DNM  MC-Oracle          ENET\n",
      "W1-95L                         7.938964e-07   0.000000  3.269980e-03\n",
      "W1                             1.531317e-06   0.000000  3.307251e-03\n",
      "W1-95R                         2.268738e-06   0.000000  3.344523e-03\n",
      "M-95L                          3.097958e-05   0.000031  1.759886e-05\n",
      "M                              6.088506e-05   0.000061  4.789610e-05\n",
      "M-95R                          9.079053e-05   0.000091  7.819334e-05\n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01\n",
      "Train_Time                     1.073255e+01  49.621372  1.620113e+09\n",
      "Test_Time/MC-Oracle_Test_Time  7.195024e-03   1.000000  7.330565e-06\n",
      "-----------------\n",
      "Training: K-Ridge\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0394s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "100%|██████████| 10/10 [00:00<00:00, 63.72it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 60.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle          ENET    KRidge\n",
      "W1-95L                         7.938964e-07   0.000000  3.269980e-03  0.003270\n",
      "W1                             1.531317e-06   0.000000  3.307251e-03  0.003307\n",
      "W1-95R                         2.268738e-06   0.000000  3.344523e-03  0.003345\n",
      "M-95L                          3.097958e-05   0.000031  1.759886e-05  0.000009\n",
      "M                              6.088506e-05   0.000061  4.789610e-05  0.000039\n",
      "M-95R                          9.079053e-05   0.000091  7.819334e-05  0.000068\n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01  0.000000\n",
      "Train_Time                     1.073255e+01  49.621372  1.620113e+09  0.532915\n",
      "Test_Time/MC-Oracle_Test_Time  7.195024e-03   1.000000  7.330565e-06  0.000033\n",
      "--------------\n",
      "Training: GBRF\n",
      "--------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.3s finished\n",
      "100%|██████████| 10/10 [00:00<00:00, 64.72it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 59.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                         7.938964e-07   0.000000  3.269980e-03   \n",
      "W1                             1.531317e-06   0.000000  3.307251e-03   \n",
      "W1-95R                         2.268738e-06   0.000000  3.344523e-03   \n",
      "M-95L                          3.097958e-05   0.000031  1.759886e-05   \n",
      "M                              6.088506e-05   0.000061  4.789610e-05   \n",
      "M-95R                          9.079053e-05   0.000091  7.819334e-05   \n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
      "Train_Time                     1.073255e+01  49.621372  1.620113e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  7.195024e-03   1.000000  7.330565e-06   \n",
      "\n",
      "                                 KRidge         GBRF  \n",
      "W1-95L                         0.003270     0.003270  \n",
      "W1                             0.003307     0.003307  \n",
      "W1-95R                         0.003345     0.003345  \n",
      "M-95L                          0.000009     0.000070  \n",
      "M                              0.000039     0.000100  \n",
      "M-95R                          0.000068     0.000130  \n",
      "N_Par                          0.000000  1000.000000  \n",
      "Train_Time                     0.532915     0.744913  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000033     0.000059  \n",
      "-------------\n",
      "Training: DNN\n",
      "-------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0185 - mse: 3.4188e-04 - mae: 0.0185 - mape: 15215.9717\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 3.3231e-04 - mae: 0.0182 - mape: 15001.8379\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 3.2287e-04 - mae: 0.0180 - mape: 14787.4248\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0177 - mse: 3.1356e-04 - mae: 0.0177 - mape: 14572.8809\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 3.0438e-04 - mae: 0.0174 - mape: 14358.2637\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0172 - mse: 2.9534e-04 - mae: 0.0172 - mape: 14143.5938\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0169 - mse: 2.8643e-04 - mae: 0.0169 - mape: 13928.8877\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 2.7766e-04 - mae: 0.0167 - mape: 13714.1484\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0164 - mse: 2.6902e-04 - mae: 0.0164 - mape: 13499.3887\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 2.6052e-04 - mae: 0.0161 - mape: 13284.6064\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 2.5215e-04 - mae: 0.0159 - mape: 13069.8096\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0156 - mse: 2.4392e-04 - mae: 0.0156 - mape: 12854.9951\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 2.3583e-04 - mae: 0.0153 - mape: 12640.1719\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 2.2787e-04 - mae: 0.0151 - mape: 12425.3369\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 2.2005e-04 - mae: 0.0148 - mape: 12210.4883\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 2.1237e-04 - mae: 0.0146 - mape: 11995.6318\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0143 - mse: 2.0482e-04 - mae: 0.0143 - mape: 11780.7637\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 1.9741e-04 - mae: 0.0140 - mape: 11565.8887\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0138 - mse: 1.9014e-04 - mae: 0.0138 - mape: 11351.0059\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 1.8300e-04 - mae: 0.0135 - mape: 11136.1143\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 1.7600e-04 - mae: 0.0133 - mape: 10921.2129\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0130 - mse: 1.6914e-04 - mae: 0.0130 - mape: 10706.3027\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0127 - mse: 1.6241e-04 - mae: 0.0127 - mape: 10491.3848\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 1.5582e-04 - mae: 0.0125 - mape: 10276.4590\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 1.4937e-04 - mae: 0.0122 - mape: 10061.5244\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 1.4305e-04 - mae: 0.0119 - mape: 9846.5801\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 1.3687e-04 - mae: 0.0117 - mape: 9631.6279\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 1.3083e-04 - mae: 0.0114 - mape: 9416.6621\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 1.2493e-04 - mae: 0.0112 - mape: 9201.6895\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 1.1916e-04 - mae: 0.0109 - mape: 8986.7061\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 1.1352e-04 - mae: 0.0106 - mape: 8771.7129\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 1.0803e-04 - mae: 0.0104 - mape: 8556.7051\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 1.0267e-04 - mae: 0.0101 - mape: 8341.6846\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 9.7448e-05 - mae: 0.0098 - mape: 8126.6523\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 9.2363e-05 - mae: 0.0096 - mape: 7911.6079\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0093 - mse: 8.7414e-05 - mae: 0.0093 - mape: 7696.5518\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 8.2603e-05 - mae: 0.0091 - mape: 7481.4766\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0088 - mse: 7.7929e-05 - mae: 0.0088 - mape: 7266.3906\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 7.3391e-05 - mae: 0.0085 - mape: 7051.2876\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0083 - mse: 6.8990e-05 - mae: 0.0083 - mape: 6836.1670\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 6.4727e-05 - mae: 0.0080 - mape: 6621.0298\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0078 - mse: 6.0600e-05 - mae: 0.0078 - mape: 6405.8774\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 5.6610e-05 - mae: 0.0075 - mape: 6190.7051\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 5.2757e-05 - mae: 0.0072 - mape: 5975.5127\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0070 - mse: 4.9042e-05 - mae: 0.0070 - mape: 5760.2993\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0067 - mse: 4.5463e-05 - mae: 0.0067 - mape: 5545.0654\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 4.2021e-05 - mae: 0.0064 - mape: 5329.8125\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 3.8717e-05 - mae: 0.0062 - mape: 5114.5376\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 3.5550e-05 - mae: 0.0059 - mape: 4899.2393\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 3.2520e-05 - mae: 0.0057 - mape: 4683.9180\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 2.9627e-05 - mae: 0.0054 - mape: 4468.5713\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 2.6871e-05 - mae: 0.0051 - mape: 4253.2007\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 2.4253e-05 - mae: 0.0049 - mape: 4037.8062\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 2.1772e-05 - mae: 0.0046 - mape: 3822.3835\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 1.9429e-05 - mae: 0.0043 - mape: 3606.9321\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 1.7223e-05 - mae: 0.0041 - mape: 3391.4551\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 1.5154e-05 - mae: 0.0038 - mape: 3175.9490\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0036 - mse: 1.3223e-05 - mae: 0.0036 - mape: 2960.4126\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0033 - mse: 1.1429e-05 - mae: 0.0033 - mape: 2744.8464\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0030 - mse: 9.7736e-06 - mae: 0.0030 - mape: 2529.2495\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 8.2555e-06 - mae: 0.0028 - mape: 2313.6196\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 6.8751e-06 - mae: 0.0025 - mape: 2097.9597\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 5.6326e-06 - mae: 0.0022 - mape: 1882.2634\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 4.5279e-06 - mae: 0.0020 - mape: 1666.5355\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 3.5611e-06 - mae: 0.0017 - mape: 1450.7708\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 2.7324e-06 - mae: 0.0015 - mape: 1234.9694\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 2.0417e-06 - mae: 0.0012 - mape: 1019.1332\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6864e-04 - mse: 1.4892e-06 - mae: 9.6864e-04 - mape: 813.7276\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3156e-04 - mse: 1.0459e-06 - mae: 8.3156e-04 - mape: 702.5769\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3663e-04 - mse: 7.0888e-07 - mae: 7.3663e-04 - mape: 612.3617\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2388e-04 - mse: 4.6850e-07 - mae: 6.2388e-04 - mape: 507.0433\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9750e-04 - mse: 3.1694e-07 - mae: 4.9750e-04 - mape: 390.2375\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3534e-04 - mse: 2.4847e-07 - mae: 4.3534e-04 - mape: 322.7559\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2876e-04 - mse: 2.5460e-07 - mae: 4.2876e-04 - mape: 298.7499\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8488e-04 - mse: 3.1249e-07 - mae: 4.8488e-04 - mape: 351.4472\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6209e-04 - mse: 3.9550e-07 - mae: 5.6209e-04 - mape: 425.7333\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2279e-04 - mse: 4.7592e-07 - mae: 6.2279e-04 - mape: 475.8346\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5054e-04 - mse: 5.3859e-07 - mae: 6.5054e-04 - mape: 498.8469\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4866e-04 - mse: 5.7711e-07 - mae: 6.4866e-04 - mape: 497.5036\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4602e-04 - mse: 5.9140e-07 - mae: 6.4602e-04 - mape: 481.7014\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5412e-04 - mse: 5.8155e-07 - mae: 6.5412e-04 - mape: 492.0118\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5313e-04 - mse: 5.4362e-07 - mae: 6.5313e-04 - mape: 496.5859\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2359e-04 - mse: 4.8024e-07 - mae: 6.2359e-04 - mape: 476.2204\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6994e-04 - mse: 3.9883e-07 - mae: 5.6994e-04 - mape: 434.8055\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9574e-04 - mse: 3.0919e-07 - mae: 4.9574e-04 - mape: 375.4744\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0392e-04 - mse: 2.2205e-07 - mae: 4.0392e-04 - mape: 300.8037\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1493e-04 - mse: 1.4826e-07 - mae: 3.1493e-04 - mape: 218.2507\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3286e-04 - mse: 1.0005e-07 - mae: 2.3286e-04 - mape: 133.0051\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0329e-04 - mse: 8.2177e-08 - mae: 2.0329e-04 - mape: 113.9282\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3388e-04 - mse: 9.3878e-08 - mae: 2.3388e-04 - mape: 145.3941\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6609e-04 - mse: 1.1919e-07 - mae: 2.6609e-04 - mape: 179.1147\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9314e-04 - mse: 1.4813e-07 - mae: 2.9314e-04 - mape: 212.5641\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1587e-04 - mse: 1.7252e-07 - mae: 3.1587e-04 - mape: 235.6049\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2350e-04 - mse: 1.8549e-07 - mae: 3.2350e-04 - mape: 249.5626\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3049e-04 - mse: 1.8774e-07 - mae: 3.3049e-04 - mape: 262.8042\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3241e-04 - mse: 1.8017e-07 - mae: 3.3241e-04 - mape: 264.9427\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1603e-04 - mse: 1.6308e-07 - mae: 3.1603e-04 - mape: 249.3970\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8387e-04 - mse: 1.3972e-07 - mae: 2.8387e-04 - mape: 218.1270\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5313e-04 - mse: 1.1795e-07 - mae: 2.5313e-04 - mape: 180.5373\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3315e-04 - mse: 1.0164e-07 - mae: 2.3315e-04 - mape: 153.4001\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2730e-04 - mse: 9.1962e-08 - mae: 2.2730e-04 - mape: 139.5511\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1475e-04 - mse: 8.6223e-08 - mae: 2.1475e-04 - mape: 124.8730\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9907e-04 - mse: 8.4614e-08 - mae: 1.9907e-04 - mape: 108.4800\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0264e-04 - mse: 9.0702e-08 - mae: 2.0264e-04 - mape: 105.6386\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1814e-04 - mse: 1.0009e-07 - mae: 2.1814e-04 - mape: 116.6234\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3268e-04 - mse: 1.0682e-07 - mae: 2.3268e-04 - mape: 132.1147\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3632e-04 - mse: 1.0845e-07 - mae: 2.3632e-04 - mape: 136.1574\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3012e-04 - mse: 1.0480e-07 - mae: 2.3012e-04 - mape: 129.8790\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1505e-04 - mse: 9.7364e-08 - mae: 2.1505e-04 - mape: 114.2922\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0252e-04 - mse: 8.8732e-08 - mae: 2.0252e-04 - mape: 106.6021\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9871e-04 - mse: 8.2864e-08 - mae: 1.9871e-04 - mape: 108.0525\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0438e-04 - mse: 8.1220e-08 - mae: 2.0438e-04 - mape: 115.8241\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0826e-04 - mse: 8.1941e-08 - mae: 2.0826e-04 - mape: 121.1698\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1051e-04 - mse: 8.3852e-08 - mae: 2.1051e-04 - mape: 124.3191\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1585e-04 - mse: 8.6282e-08 - mae: 2.1585e-04 - mape: 126.7934\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1428e-04 - mse: 8.5414e-08 - mae: 2.1428e-04 - mape: 127.6923\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1334e-04 - mse: 8.3195e-08 - mae: 2.1334e-04 - mape: 128.1992\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1277e-04 - mse: 8.1498e-08 - mae: 2.1277e-04 - mape: 127.3932\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1097e-04 - mse: 8.0269e-08 - mae: 2.1097e-04 - mape: 124.9448\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0807e-04 - mse: 7.9675e-08 - mae: 2.0807e-04 - mape: 121.0039\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0416e-04 - mse: 8.0040e-08 - mae: 2.0416e-04 - mape: 115.7099\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9933e-04 - mse: 8.1792e-08 - mae: 1.9933e-04 - mape: 109.1830\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9630e-04 - mse: 8.5438e-08 - mae: 1.9630e-04 - mape: 103.1994\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0075e-04 - mse: 8.8627e-08 - mae: 2.0075e-04 - mape: 104.9742\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0239e-04 - mse: 9.0451e-08 - mae: 2.0239e-04 - mape: 105.3744\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0151e-04 - mse: 9.0681e-08 - mae: 2.0151e-04 - mape: 104.5335\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9832e-04 - mse: 8.9574e-08 - mae: 1.9832e-04 - mape: 102.5646\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9405e-04 - mse: 8.7738e-08 - mae: 1.9405e-04 - mape: 100.6051\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9487e-04 - mse: 8.6800e-08 - mae: 1.9487e-04 - mape: 102.7782\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9605e-04 - mse: 8.5573e-08 - mae: 1.9605e-04 - mape: 105.0338\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9707e-04 - mse: 8.3842e-08 - mae: 1.9707e-04 - mape: 106.5918\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9681e-04 - mse: 8.3329e-08 - mae: 1.9681e-04 - mape: 106.2320\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9522e-04 - mse: 8.3910e-08 - mae: 1.9522e-04 - mape: 104.0924\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9454e-04 - mse: 8.5718e-08 - mae: 1.9454e-04 - mape: 101.5805\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9746e-04 - mse: 8.7711e-08 - mae: 1.9746e-04 - mape: 102.6474\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9803e-04 - mse: 8.8321e-08 - mae: 1.9803e-04 - mape: 102.7731\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9608e-04 - mse: 8.7544e-08 - mae: 1.9608e-04 - mape: 101.6388\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9359e-04 - mse: 8.5825e-08 - mae: 1.9359e-04 - mape: 101.1966\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9452e-04 - mse: 8.4724e-08 - mae: 1.9452e-04 - mape: 103.4447\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9505e-04 - mse: 8.5033e-08 - mae: 1.9505e-04 - mape: 104.2492\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9911e-04 - mse: 8.6471e-08 - mae: 1.9911e-04 - mape: 106.6444\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9398e-04 - mse: 8.5216e-08 - mae: 1.9398e-04 - mape: 102.8571\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9298e-04 - mse: 8.5480e-08 - mae: 1.9298e-04 - mape: 101.0824\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9348e-04 - mse: 8.6064e-08 - mae: 1.9348e-04 - mape: 100.3491\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9545e-04 - mse: 8.6784e-08 - mae: 1.9545e-04 - mape: 101.3880\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9485e-04 - mse: 8.6189e-08 - mae: 1.9485e-04 - mape: 101.2152\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9333e-04 - mse: 8.4494e-08 - mae: 1.9333e-04 - mape: 101.4068\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9431e-04 - mse: 8.3199e-08 - mae: 1.9431e-04 - mape: 103.4776\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9458e-04 - mse: 8.3169e-08 - mae: 1.9458e-04 - mape: 103.9064\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9339e-04 - mse: 8.4210e-08 - mae: 1.9339e-04 - mape: 102.3620\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9192e-04 - mse: 8.6435e-08 - mae: 1.9192e-04 - mape: 99.6485\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9531e-04 - mse: 8.8821e-08 - mae: 1.9531e-04 - mape: 100.6985\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9321e-04 - mse: 8.7476e-08 - mae: 1.9321e-04 - mape: 99.2938\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9267e-04 - mse: 8.5358e-08 - mae: 1.9267e-04 - mape: 99.9300\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9284e-04 - mse: 8.3709e-08 - mae: 1.9284e-04 - mape: 101.2923\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9376e-04 - mse: 8.2388e-08 - mae: 1.9376e-04 - mape: 103.0305\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9368e-04 - mse: 8.2296e-08 - mae: 1.9368e-04 - mape: 102.9537\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9308e-04 - mse: 8.3303e-08 - mae: 1.9308e-04 - mape: 101.4606\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9365e-04 - mse: 8.4265e-08 - mae: 1.9365e-04 - mape: 101.0957\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9269e-04 - mse: 8.3868e-08 - mae: 1.9269e-04 - mape: 100.6446\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9222e-04 - mse: 8.3554e-08 - mae: 1.9222e-04 - mape: 100.7728\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9211e-04 - mse: 8.3370e-08 - mae: 1.9211e-04 - mape: 101.1219\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9124e-04 - mse: 8.4469e-08 - mae: 1.9124e-04 - mape: 99.8594\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9072e-04 - mse: 8.5666e-08 - mae: 1.9072e-04 - mape: 98.9317\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9432e-04 - mse: 8.7004e-08 - mae: 1.9432e-04 - mape: 100.7802\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9085e-04 - mse: 8.4558e-08 - mae: 1.9085e-04 - mape: 99.6678\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9124e-04 - mse: 8.3904e-08 - mae: 1.9124e-04 - mape: 99.8129\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9161e-04 - mse: 8.3525e-08 - mae: 1.9161e-04 - mape: 100.0140\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9183e-04 - mse: 8.3272e-08 - mae: 1.9183e-04 - mape: 100.1757\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9190e-04 - mse: 8.3059e-08 - mae: 1.9190e-04 - mape: 100.3030\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9184e-04 - mse: 8.2845e-08 - mae: 1.9184e-04 - mape: 100.4011\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9165e-04 - mse: 8.2620e-08 - mae: 1.9165e-04 - mape: 100.4694\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9136e-04 - mse: 8.2400e-08 - mae: 1.9136e-04 - mape: 100.5129\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9150e-04 - mse: 8.2219e-08 - mae: 1.9150e-04 - mape: 100.8459\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9068e-04 - mse: 8.3286e-08 - mae: 1.9068e-04 - mape: 99.4158\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9029e-04 - mse: 8.4383e-08 - mae: 1.9029e-04 - mape: 98.3850\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8981e-04 - mse: 8.5542e-08 - mae: 1.8981e-04 - mape: 97.4359\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9145e-04 - mse: 8.6808e-08 - mae: 1.9145e-04 - mape: 97.2839\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8986e-04 - mse: 8.4309e-08 - mae: 1.8986e-04 - mape: 98.1313\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9031e-04 - mse: 8.2508e-08 - mae: 1.9031e-04 - mape: 99.5430\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9073e-04 - mse: 8.2350e-08 - mae: 1.9073e-04 - mape: 99.6320\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9100e-04 - mse: 8.2295e-08 - mae: 1.9100e-04 - mape: 99.7070\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9136e-04 - mse: 8.2244e-08 - mae: 1.9136e-04 - mape: 100.0164\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9158e-04 - mse: 8.0862e-08 - mae: 1.9158e-04 - mape: 101.3764\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9151e-04 - mse: 8.0796e-08 - mae: 1.9151e-04 - mape: 101.3483\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9048e-04 - mse: 8.1911e-08 - mae: 1.9048e-04 - mape: 99.5381\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9079e-04 - mse: 8.2985e-08 - mae: 1.9079e-04 - mape: 98.9575\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8960e-04 - mse: 8.2647e-08 - mae: 1.8960e-04 - mape: 98.4476\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8938e-04 - mse: 8.2519e-08 - mae: 1.8938e-04 - mape: 98.7832\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8834e-04 - mse: 8.3884e-08 - mae: 1.8834e-04 - mape: 97.3653\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9107e-04 - mse: 8.5419e-08 - mae: 1.9107e-04 - mape: 97.5765\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8874e-04 - mse: 8.3019e-08 - mae: 1.8874e-04 - mape: 98.0983\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8884e-04 - mse: 8.2521e-08 - mae: 1.8884e-04 - mape: 97.9719\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8923e-04 - mse: 8.2282e-08 - mae: 1.8923e-04 - mape: 98.0949\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8954e-04 - mse: 8.2141e-08 - mae: 1.8954e-04 - mape: 98.2836\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9000e-04 - mse: 8.0685e-08 - mae: 1.9000e-04 - mape: 99.8848\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8993e-04 - mse: 8.0634e-08 - mae: 1.8993e-04 - mape: 99.8330\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8904e-04 - mse: 8.1851e-08 - mae: 1.8904e-04 - mape: 98.0569\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8984e-04 - mse: 8.3028e-08 - mae: 1.8984e-04 - mape: 97.9156\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8826e-04 - mse: 8.2697e-08 - mae: 1.8826e-04 - mape: 96.9862\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 848us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:00<00:00, 71.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 70.63it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 65.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                        DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                         7.938964e-07   0.000000  3.269980e-03   \n",
      "W1                             1.531317e-06   0.000000  3.307251e-03   \n",
      "W1-95R                         2.268738e-06   0.000000  3.344523e-03   \n",
      "M-95L                          3.097958e-05   0.000031  1.759886e-05   \n",
      "M                              6.088506e-05   0.000061  4.789610e-05   \n",
      "M-95R                          9.079053e-05   0.000091  7.819334e-05   \n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
      "Train_Time                     1.073255e+01  49.621372  1.620113e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  7.195024e-03   1.000000  7.330565e-06   \n",
      "\n",
      "                                 KRidge         GBRF           DNN  \n",
      "W1-95L                         0.003270     0.003270      0.003270  \n",
      "W1                             0.003307     0.003307      0.003307  \n",
      "W1-95R                         0.003345     0.003345      0.003345  \n",
      "M-95L                          0.000009     0.000070      0.000106  \n",
      "M                              0.000039     0.000100      0.000131  \n",
      "M-95R                          0.000068     0.000130      0.000155  \n",
      "N_Par                          0.000000  1000.000000  40801.000000  \n",
      "Train_Time                     0.532915     0.744913      7.635435  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000033     0.000059      0.007206  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exec(open('CV_Grid.py').read())\n",
    "# Notebook Mode:\n",
    "# %run Evaluation.ipynb\n",
    "# %run Benchmarks_Model_Builder_Pointmass_Based.ipynb\n",
    "# Terminal Mode (Default):\n",
    "exec(open('Evaluation.py').read())\n",
    "exec(open('Benchmarks_Model_Builder_Pointmass_Based.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Point-Mass Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                             0.000002   0.000000            -   \n",
      "W1                                 0.000004   0.000000            -   \n",
      "W1-95R                             0.000007   0.000000            -   \n",
      "M-95L                              0.000095   0.000094  0.000123371   \n",
      "M                                  0.000141   0.000141  0.000168421   \n",
      "M-95R                              0.000174   0.000218  0.000228037   \n",
      "N_Par                          42208.000000   0.000000           20   \n",
      "Train_Time                        10.732551  49.621372  1.62011e+09   \n",
      "Test_Time/MC-Oracle_Test_Time      0.007195   1.000000  7.33057e-06   \n",
      "\n",
      "                                    KRidge         GBRF          DNN  \n",
      "W1-95L                                   -            -            -  \n",
      "W1                                       -            -            -  \n",
      "W1-95R                                   -            -            -  \n",
      "M-95L                          8.96305e-05  0.000101662  5.20256e-05  \n",
      "M                              0.000169909  0.000174036  0.000187696  \n",
      "M-95R                          0.000237994  0.000251092  0.000343165  \n",
      "N_Par                                    0         1000        40801  \n",
      "Train_Time                        0.532915     0.744913      7.63544  \n",
      "Test_Time/MC-Oracle_Test_Time  3.26166e-05  5.86148e-05   0.00720621  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000123371</td>\n",
       "      <td>8.96305e-05</td>\n",
       "      <td>0.000101662</td>\n",
       "      <td>5.20256e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000168421</td>\n",
       "      <td>0.000169909</td>\n",
       "      <td>0.000174036</td>\n",
       "      <td>0.000187696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000228037</td>\n",
       "      <td>0.000237994</td>\n",
       "      <td>0.000251092</td>\n",
       "      <td>0.000343165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>42208.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>40801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>10.732551</td>\n",
       "      <td>49.621372</td>\n",
       "      <td>1.62011e+09</td>\n",
       "      <td>0.532915</td>\n",
       "      <td>0.744913</td>\n",
       "      <td>7.63544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>0.007195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.33057e-06</td>\n",
       "      <td>3.26166e-05</td>\n",
       "      <td>5.86148e-05</td>\n",
       "      <td>0.00720621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle         ENET  \\\n",
       "W1-95L                             0.000002   0.000000            -   \n",
       "W1                                 0.000004   0.000000            -   \n",
       "W1-95R                             0.000007   0.000000            -   \n",
       "M-95L                              0.000095   0.000094  0.000123371   \n",
       "M                                  0.000141   0.000141  0.000168421   \n",
       "M-95R                              0.000174   0.000218  0.000228037   \n",
       "N_Par                          42208.000000   0.000000           20   \n",
       "Train_Time                        10.732551  49.621372  1.62011e+09   \n",
       "Test_Time/MC-Oracle_Test_Time      0.007195   1.000000  7.33057e-06   \n",
       "\n",
       "                                    KRidge         GBRF          DNN  \n",
       "W1-95L                                   -            -            -  \n",
       "W1                                       -            -            -  \n",
       "W1-95R                                   -            -            -  \n",
       "M-95L                          8.96305e-05  0.000101662  5.20256e-05  \n",
       "M                              0.000169909  0.000174036  0.000187696  \n",
       "M-95R                          0.000237994  0.000251092  0.000343165  \n",
       "N_Par                                    0         1000        40801  \n",
       "Train_Time                        0.532915     0.744913      7.63544  \n",
       "Test_Time/MC-Oracle_Test_Time  3.26166e-05  5.86148e-05   0.00720621  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                         7.938964e-07   0.000000  3.269980e-03   \n",
      "W1                             1.531317e-06   0.000000  3.307251e-03   \n",
      "W1-95R                         2.268738e-06   0.000000  3.344523e-03   \n",
      "M-95L                          3.097958e-05   0.000031  1.759886e-05   \n",
      "M                              6.088506e-05   0.000061  4.789610e-05   \n",
      "M-95R                          9.079053e-05   0.000091  7.819334e-05   \n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
      "Train_Time                     1.073255e+01  49.621372  1.620113e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  7.195024e-03   1.000000  7.330565e-06   \n",
      "\n",
      "                                 KRidge         GBRF           DNN  \n",
      "W1-95L                         0.003270     0.003270      0.003270  \n",
      "W1                             0.003307     0.003307      0.003307  \n",
      "W1-95R                         0.003345     0.003345      0.003345  \n",
      "M-95L                          0.000009     0.000070      0.000106  \n",
      "M                              0.000039     0.000100      0.000131  \n",
      "M-95R                          0.000068     0.000130      0.000155  \n",
      "N_Par                          0.000000  1000.000000  40801.000000  \n",
      "Train_Time                     0.532915     0.744913      7.635435  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000033     0.000059      0.007206  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>7.938964e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.269980e-03</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.003270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>1.531317e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.307251e-03</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.003307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>2.268738e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.344523e-03</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.003345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>3.097958e-05</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.759886e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>6.088506e-05</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>4.789610e-05</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>9.079053e-05</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>7.819334e-05</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>4.220800e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>40801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.073255e+01</td>\n",
       "      <td>49.621372</td>\n",
       "      <td>1.620113e+09</td>\n",
       "      <td>0.532915</td>\n",
       "      <td>0.744913</td>\n",
       "      <td>7.635435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>7.195024e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.330565e-06</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.007206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle          ENET  \\\n",
       "W1-95L                         7.938964e-07   0.000000  3.269980e-03   \n",
       "W1                             1.531317e-06   0.000000  3.307251e-03   \n",
       "W1-95R                         2.268738e-06   0.000000  3.344523e-03   \n",
       "M-95L                          3.097958e-05   0.000031  1.759886e-05   \n",
       "M                              6.088506e-05   0.000061  4.789610e-05   \n",
       "M-95R                          9.079053e-05   0.000091  7.819334e-05   \n",
       "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
       "Train_Time                     1.073255e+01  49.621372  1.620113e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  7.195024e-03   1.000000  7.330565e-06   \n",
       "\n",
       "                                 KRidge         GBRF           DNN  \n",
       "W1-95L                         0.003270     0.003270      0.003270  \n",
       "W1                             0.003307     0.003307      0.003307  \n",
       "W1-95R                         0.003345     0.003345      0.003345  \n",
       "M-95L                          0.000009     0.000070      0.000106  \n",
       "M                              0.000039     0.000100      0.000131  \n",
       "M-95R                          0.000068     0.000130      0.000155  \n",
       "N_Par                          0.000000  1000.000000  40801.000000  \n",
       "Train_Time                     0.532915     0.744913      7.635435  \n",
       "Test_Time/MC-Oracle_Test_Time  0.000033     0.000059      0.007206  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) *Gaussian Benchmarks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bencharm 1: [Gaussian Process Regressor](https://scikit-learn.org/stable/modules/gaussian_process.html)\n",
    "- Benchmark 2: Deep Gaussian Networks:\n",
    "These models train models which assume Gaussianity.  We may view these as models in $\\mathcal{P}_2(\\mathbb{R})$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to (\\hat{\\mu}(x),\\hat{\\Sigma}(x)\\hat{\\Sigma}^{\\top})\\triangleq f(x) \\in \\mathbb{R}\\times [0,\\infty) \\to \n",
    "(2\\pi)^{-\\frac{d}{2}}\\det(\\hat{\\Sigma}(x))^{-\\frac{1}{2}} \\, e^{ -\\frac{1}{2}(\\cdot - \\hat{\\mu}(x))^{{{\\!\\mathsf{T}}}} \\hat{\\Sigma}(x)^{-1}(\\cdot - \\hat{\\mu}(x)) } \\mu \\in \\mathcal{G}_d\\subset \\mathcal{P}_2(\\mathbb{R});\n",
    "$$\n",
    "where $\\mathcal{G}_1$ is the set of Gaussian measures on $\\mathbb{R}$ equipped with the relative Wasserstein-1 topology.\n",
    "\n",
    "Examples of this type of architecture are especially prevalent in uncertainty quantification; see ([Deep Ensembles](https://arxiv.org/abs/1612.01474)] or [NOMU: Neural Optimization-based Model Uncertainty](https://arxiv.org/abs/2102.13640).  Moreover, their universality in $C(\\mathbb{R}^d,\\mathcal{G}_2)$ is known, and has been shown in [Corollary 4.7](https://arxiv.org/abs/2101.05390)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.9s remaining:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.0s finished\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering Parameters for Deep Gaussian Network to train on!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Getting Parameters for Deep Gaussian Network!\n",
      "===============================\n",
      "Training Deep Gaussian Network!\n",
      "===============================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3777 - mae: 0.4589 - mape: 21172.6445\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3778 - mae: 0.4589 - mape: 21071.3711\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3780 - mae: 0.4589 - mape: 20967.2012\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3782 - mae: 0.4589 - mape: 20861.6152\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3784 - mae: 0.4589 - mape: 20755.1523\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3787 - mae: 0.4589 - mape: 20648.0820\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3789 - mae: 0.4589 - mape: 20540.5664\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3791 - mae: 0.4589 - mape: 20432.7188\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3793 - mae: 0.4589 - mape: 20324.6211\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3795 - mae: 0.4589 - mape: 20216.3320\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4589 - mse: 0.3797 - mae: 0.4589 - mape: 20107.8984\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4588 - mse: 0.3799 - mae: 0.4588 - mape: 19999.3633\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4588 - mse: 0.3801 - mae: 0.4588 - mape: 19890.7539\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3803 - mae: 0.4588 - mape: 19782.1094\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3805 - mae: 0.4588 - mape: 19673.4492\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3807 - mae: 0.4588 - mape: 19564.7969\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3809 - mae: 0.4588 - mape: 19456.1680\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4588 - mse: 0.3811 - mae: 0.4588 - mape: 19347.5898\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3814 - mae: 0.4588 - mape: 19239.0742\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3816 - mae: 0.4588 - mape: 19130.6367\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3818 - mae: 0.4588 - mape: 19022.2930\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3820 - mae: 0.4588 - mape: 18914.0586\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4588 - mse: 0.3822 - mae: 0.4588 - mape: 18805.9434\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4588 - mse: 0.3824 - mae: 0.4588 - mape: 18697.9629\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3826 - mae: 0.4588 - mape: 18590.1211\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3828 - mae: 0.4588 - mape: 18482.4336\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3830 - mae: 0.4588 - mape: 18374.9121\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3832 - mae: 0.4588 - mape: 18267.5625\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4587 - mse: 0.3834 - mae: 0.4587 - mape: 18160.3965\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4587 - mse: 0.3837 - mae: 0.4587 - mape: 18053.4199\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4587 - mse: 0.3839 - mae: 0.4587 - mape: 17946.6426\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4587 - mse: 0.3841 - mae: 0.4587 - mape: 17840.0742\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3843 - mae: 0.4587 - mape: 17733.7188\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3845 - mae: 0.4587 - mape: 17627.5840\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3847 - mae: 0.4587 - mape: 17521.6758\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3849 - mae: 0.4587 - mape: 17416.0039\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4587 - mse: 0.3851 - mae: 0.4587 - mape: 17310.5723\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3853 - mae: 0.4587 - mape: 17205.3809\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4587 - mse: 0.3855 - mae: 0.4587 - mape: 17100.4414\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4587 - mse: 0.3857 - mae: 0.4587 - mape: 16995.7598\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4587 - mse: 0.3859 - mae: 0.4587 - mape: 16891.3379\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3861 - mae: 0.4587 - mape: 16787.1797\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3863 - mae: 0.4587 - mape: 16683.2930\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4587 - mse: 0.3866 - mae: 0.4587 - mape: 16579.6758\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3868 - mae: 0.4587 - mape: 16476.3379\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4587 - mse: 0.3870 - mae: 0.4587 - mape: 16373.2812\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3872 - mae: 0.4587 - mape: 16270.5098\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3874 - mae: 0.4587 - mape: 16168.0264\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4586 - mse: 0.3876 - mae: 0.4586 - mape: 16065.8359\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3878 - mae: 0.4586 - mape: 15963.9404\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3880 - mae: 0.4586 - mape: 15862.3379\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3882 - mae: 0.4586 - mape: 15761.0391\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4586 - mse: 0.3884 - mae: 0.4586 - mape: 15660.0439\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3886 - mae: 0.4586 - mape: 15559.3545\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3888 - mae: 0.4586 - mape: 15458.9736\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4586 - mse: 0.3890 - mae: 0.4586 - mape: 15358.9033\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3892 - mae: 0.4586 - mape: 15259.1504\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3894 - mae: 0.4586 - mape: 15159.7061\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3896 - mae: 0.4586 - mape: 15060.5840\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3898 - mae: 0.4586 - mape: 14961.7783\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3900 - mae: 0.4586 - mape: 14863.2969\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3902 - mae: 0.4586 - mape: 14765.1377\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3904 - mae: 0.4586 - mape: 14667.3066\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3906 - mae: 0.4586 - mape: 14569.8018\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3907 - mae: 0.4586 - mape: 14472.6250\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3909 - mae: 0.4586 - mape: 14375.7793\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3911 - mae: 0.4586 - mape: 14279.2656\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3913 - mae: 0.4586 - mape: 14183.0908\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3915 - mae: 0.4586 - mape: 14087.2471\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3917 - mae: 0.4586 - mape: 13991.7422\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3919 - mae: 0.4586 - mape: 13896.5752\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3921 - mae: 0.4585 - mape: 13801.7480\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3923 - mae: 0.4585 - mape: 13707.2637\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3925 - mae: 0.4585 - mape: 13613.1230\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3927 - mae: 0.4585 - mape: 13519.3252\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3929 - mae: 0.4585 - mape: 13425.8730\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3931 - mae: 0.4585 - mape: 13332.7686\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3932 - mae: 0.4585 - mape: 13240.0127\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3934 - mae: 0.4585 - mape: 13147.6064\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3936 - mae: 0.4585 - mape: 13055.5469\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3938 - mae: 0.4585 - mape: 12963.8418\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3940 - mae: 0.4585 - mape: 12872.4902\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3942 - mae: 0.4585 - mape: 12781.4941\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3944 - mae: 0.4585 - mape: 12690.8535\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3945 - mae: 0.4585 - mape: 12600.5684\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3947 - mae: 0.4585 - mape: 12510.6396\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3949 - mae: 0.4585 - mape: 12421.0684\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3951 - mae: 0.4585 - mape: 12331.8613\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3953 - mae: 0.4585 - mape: 12243.0107\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3955 - mae: 0.4585 - mape: 12154.5215\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3956 - mae: 0.4585 - mape: 12066.3975\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4585 - mse: 0.3958 - mae: 0.4585 - mape: 11978.6357\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3960 - mae: 0.4585 - mape: 11891.2373\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3962 - mae: 0.4585 - mape: 11804.2080\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3964 - mae: 0.4585 - mape: 11717.5420\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3965 - mae: 0.4585 - mape: 11631.2441\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4585 - mse: 0.3967 - mae: 0.4585 - mape: 11545.3145\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3969 - mae: 0.4585 - mape: 11459.7549\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3971 - mae: 0.4585 - mape: 11374.5645\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4585 - mse: 0.3972 - mae: 0.4585 - mape: 11289.7441\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3974 - mae: 0.4585 - mape: 11205.2988\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4585 - mse: 0.3976 - mae: 0.4585 - mape: 11121.2236\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3978 - mae: 0.4585 - mape: 11037.5234\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.3979 - mae: 0.4584 - mape: 10954.1943\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4584 - mse: 0.3981 - mae: 0.4584 - mape: 10871.2441\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4584 - mse: 0.3983 - mae: 0.4584 - mape: 10788.6660\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.3984 - mae: 0.4584 - mape: 10706.4668\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.3986 - mae: 0.4584 - mape: 10624.6426\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4584 - mse: 0.3988 - mae: 0.4584 - mape: 10543.1982\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.3989 - mae: 0.4584 - mape: 10462.1309\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.3991 - mae: 0.4584 - mape: 10381.4424\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.3993 - mae: 0.4584 - mape: 10301.1348\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.3994 - mae: 0.4584 - mape: 10221.2090\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.3996 - mae: 0.4584 - mape: 10141.6631\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.3998 - mae: 0.4584 - mape: 10062.5000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.3999 - mae: 0.4584 - mape: 9983.7197\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4001 - mae: 0.4584 - mape: 9905.3223\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4003 - mae: 0.4584 - mape: 9827.3076\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4004 - mae: 0.4584 - mape: 9749.6777\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4006 - mae: 0.4584 - mape: 9672.4316\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4008 - mae: 0.4584 - mape: 9595.5732\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4009 - mae: 0.4584 - mape: 9519.0986\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4011 - mae: 0.4584 - mape: 9443.0107\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4012 - mae: 0.4584 - mape: 9367.3105\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4014 - mae: 0.4584 - mape: 9291.9980\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4015 - mae: 0.4584 - mape: 9217.0723\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4017 - mae: 0.4584 - mape: 9142.5361\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4019 - mae: 0.4584 - mape: 9068.3867\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4020 - mae: 0.4584 - mape: 8994.6270\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4022 - mae: 0.4584 - mape: 8921.2598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4023 - mae: 0.4584 - mape: 8848.2783\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4025 - mae: 0.4584 - mape: 8775.6885\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4026 - mae: 0.4584 - mape: 8703.4883\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4028 - mae: 0.4584 - mape: 8631.6816\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4029 - mae: 0.4584 - mape: 8560.2617\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4031 - mae: 0.4584 - mape: 8489.2354\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4584 - mse: 0.4032 - mae: 0.4584 - mape: 8418.6006\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4034 - mae: 0.4584 - mape: 8348.3594\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4035 - mae: 0.4584 - mape: 8278.5098\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4037 - mae: 0.4584 - mape: 8209.0498\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4584 - mse: 0.4038 - mae: 0.4584 - mape: 8139.9858\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4040 - mae: 0.4584 - mape: 8071.3125\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4041 - mae: 0.4584 - mape: 8003.0312\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4043 - mae: 0.4584 - mape: 7935.1455\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4584 - mse: 0.4044 - mae: 0.4584 - mape: 7867.6533\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4045 - mae: 0.4584 - mape: 7800.5498\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4047 - mae: 0.4584 - mape: 7733.8438\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4584 - mse: 0.4048 - mae: 0.4584 - mape: 7667.5264\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4584 - mse: 0.4050 - mae: 0.4584 - mape: 7601.6045\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4051 - mae: 0.4584 - mape: 7536.0781\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4052 - mae: 0.4584 - mape: 7470.9429\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4054 - mae: 0.4584 - mape: 7406.2031\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4055 - mae: 0.4584 - mape: 7341.8525\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4057 - mae: 0.4584 - mape: 7277.8975\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4584 - mse: 0.4058 - mae: 0.4584 - mape: 7214.3359\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4059 - mae: 0.4584 - mape: 7151.1655\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4061 - mae: 0.4584 - mape: 7088.3916\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4062 - mae: 0.4584 - mape: 7026.0068\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4583 - mse: 0.4063 - mae: 0.4583 - mape: 6964.0171\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4065 - mae: 0.4583 - mape: 6902.4165\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4066 - mae: 0.4583 - mape: 6841.2119\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4067 - mae: 0.4583 - mape: 6780.3970\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4583 - mse: 0.4068 - mae: 0.4583 - mape: 6719.9741\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4070 - mae: 0.4583 - mape: 6659.9438\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4071 - mae: 0.4583 - mape: 6600.3022\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4072 - mae: 0.4583 - mape: 6541.0522\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4583 - mse: 0.4074 - mae: 0.4583 - mape: 6482.1938\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4583 - mse: 0.4075 - mae: 0.4583 - mape: 6423.7251\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4076 - mae: 0.4583 - mape: 6365.6460\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4077 - mae: 0.4583 - mape: 6307.9546\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4079 - mae: 0.4583 - mape: 6250.6538\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4080 - mae: 0.4583 - mape: 6193.7407\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4081 - mae: 0.4583 - mape: 6137.2158\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4082 - mae: 0.4583 - mape: 6081.0796\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4083 - mae: 0.4583 - mape: 6025.3301\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4085 - mae: 0.4583 - mape: 5969.9653\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4086 - mae: 0.4583 - mape: 5914.9883\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4087 - mae: 0.4583 - mape: 5860.3955\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4583 - mse: 0.4088 - mae: 0.4583 - mape: 5806.1885\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4583 - mse: 0.4089 - mae: 0.4583 - mape: 5752.3647\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4090 - mae: 0.4583 - mape: 5698.9253\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4583 - mse: 0.4092 - mae: 0.4583 - mape: 5645.8691\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4093 - mae: 0.4583 - mape: 5593.1958\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4094 - mae: 0.4583 - mape: 5540.9033\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4583 - mse: 0.4095 - mae: 0.4583 - mape: 5488.9917\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4096 - mae: 0.4583 - mape: 5437.4619\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4097 - mae: 0.4583 - mape: 5386.3105\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4098 - mae: 0.4583 - mape: 5335.5376\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4099 - mae: 0.4583 - mape: 5285.1416\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4100 - mae: 0.4583 - mape: 5235.1245\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4583 - mse: 0.4102 - mae: 0.4583 - mape: 5185.4834\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4103 - mae: 0.4583 - mape: 5136.2188\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4104 - mae: 0.4583 - mape: 5087.3267\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4105 - mae: 0.4583 - mape: 5038.8071\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4106 - mae: 0.4583 - mape: 4990.6636\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4107 - mae: 0.4583 - mape: 4942.8896\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4583 - mse: 0.4108 - mae: 0.4583 - mape: 4895.4873\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4583 - mse: 0.4109 - mae: 0.4583 - mape: 4848.4546\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4583 - mse: 0.4110 - mae: 0.4583 - mape: 4801.7920\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4583 - mse: 0.4111 - mae: 0.4583 - mape: 4755.4951\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f73f8dfc8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Training Deep Gaussian Network!: END\n",
      "====================================\n",
      "#---------------------------------------#\n",
      " Get Training Errors for: Gaussian Models\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 14.16it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------------------------#\n",
      " Get Testing Errors for: Gaussian Models\n",
      "#--------------------------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-33daceb5366a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %run Benchmarks_Model_Builder_Mean_Var.ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Benchmarks_Model_Builder_Mean_Var.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# %run Benchmarks_Model_Builder_Mean_Var.ipynb\n",
    "exec(open('Benchmarks_Model_Builder_Mean_Var.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction Quality (Updated): Test\")\n",
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction Quality (Updated): Train\")\n",
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) The natural Universal Benchmark: [Bishop's Mixture Density Network](https://publications.aston.ac.uk/id/eprint/373/1/NCRG_94_004.pdf)\n",
    "\n",
    "This implementation is as follows:\n",
    "- For every $x$ in the trainingdata-set we fit a GMM $\\hat{\\nu}_x$, using the [Expectation-Maximization (EM) algorithm](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm), with the same number of centers as the deep neural model in $\\mathcal{NN}_{1_{\\mathbb{R}^d},\\mathcal{D}}^{\\sigma:\\star}$ which we are evaluating.  \n",
    "- A Mixture density network is then trained to predict the infered parameters; given any $x \\in \\mathbb{R}^d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_dim == 1:\n",
    "    # %run Mixture_Density_Network.ipynb\n",
    "    exec(open('Mixture_Density_Network.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Final Outputs\n",
    "Now we piece together all the numerical experiments and report a nice summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prasing Quality Metric Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalizing Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write Performance Metrics\n",
    "Summary_pred_Qual_models.to_latex((results_tables_path+\"/Final_Results/\"+\"Performance_metrics_Problem_Type_\"+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS.tex\"),\n",
    "                                 caption=(\"Quality Metrics; d:\"+str(problem_dim)+\", D:\"+str(output_dim)+\", Depth:\"+str(Depth_Bayesian_DNN)+\", Width:\"+str(width)+\", Dropout rate:\"+str(Dropout_rate)+\".\"),\n",
    "                                 float_format=\"{:0.3g}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Terminal Runner(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Terminal Running\n",
    "print(\"===================\")\n",
    "print(\"Predictive Quality:\")\n",
    "print(\"===================\")\n",
    "print(Summary_pred_Qual_models)\n",
    "print(\"===================\")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Kernel_Used_in_GPR: \"+str(GPR_trash.kernel))\n",
    "print(\"🙃🙃 Have a wonderful day! 🙃🙃\")\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
