{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)* by simulating from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T(\\beta(s,x)+\\sigma_s^H)dW_s.\n",
    "$$\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "*This hyperparameter describes the proportion of the data used as sample-barycenters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantization_Proportion = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 10\n",
    "N_Monte_Carlo_Samples = 10*3\n",
    "N_Monte_Carlo_Samples_Test = 10*3 # How many MC-samples to draw from test-set?\n",
    "\n",
    "# Roughness\n",
    "Rougness = 0.1\n",
    "Ratio_fBM_to_typical_vol = 0.1\n",
    "\n",
    "T_end = 1\n",
    "T_end_test = 1.1\n",
    "rough_SDE = False #This hyperparameter determines if we use a Euler-Maryama scheme or if we use something else.  \n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess =10\n",
    "Max_Grid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDE Simulation Hyper-Parameter(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return 0#t*np.sin(math.pi*x) #+ np.exp(-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 1#(1+t) + np.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Martingale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_dirction_x(x):\n",
    "    return np.cos(x)\n",
    "\n",
    "def finite_variation_t(t):\n",
    "    return t*np.sin(math.pi*t) + np.exp(-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "# %run ParaGAN_Backend.ipynb\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Grid\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Grid Instances:  110 and : 738  Testing instances.\n"
     ]
    }
   ],
   "source": [
    "# Get Input Data\n",
    "#----------------------------------------------------------#\n",
    "## Train\n",
    "x_Grid = np.arange(start=-Max_Grid,\n",
    "                   stop=Max_Grid,\n",
    "                   step=(2*Max_Grid/N_Grid_Finess))\n",
    "t_Grid = np.linspace(0,T_end,(1+N_Euler_Maruyama_Steps))\n",
    "## Get Number of Instances in Grid: Training\n",
    "N_Grid_Instances_x = len(x_Grid)\n",
    "N_Grid_Instances_t = len(t_Grid)\n",
    "N_Grid_Instances = N_Grid_Instances_x*N_Grid_Instances_t \n",
    "\n",
    "#----------------------------------------------------------#\n",
    "## Test\n",
    "x_Grid_test = np.sort(np.random.uniform(low=-Max_Grid,\n",
    "                                        high=Max_Grid,\n",
    "                                        size = round(N_Grid_Instances*test_size_ratio)))\n",
    "t_Grid_test = np.linspace(T_end+0.001,T_end_test,(1+round(N_Euler_Maruyama_Steps*test_size_ratio)))\n",
    "# Get Number of Instances in Grid: Test\n",
    "N_Grid_Instances_x_test = len(x_Grid_test)\n",
    "N_Grid_Instances_t_test = len(t_Grid_test)\n",
    "N_Grid_Instances_test = N_Grid_Instances_x_test*N_Grid_Instances_t_test\n",
    "#----------------------------------------------------------#\n",
    "\n",
    "# Updater User\n",
    "print(\"\\u2022 Grid Instances: \", N_Grid_Instances, \"and :\",N_Grid_Instances_test,\" Testing instances.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Counting Parameters\n",
    "Initialize the \"conting\" type parameters which will help us to determine the length of loops and to intialize object's size later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ 8  Centers will be produced; from a total datasize of:  10 !  (That's  0.75  percent).\n",
      "â€¢ Each Wasserstein-1 Ball should contain:  14 elements from the training set.\n"
     ]
    }
   ],
   "source": [
    "# Get Internal (Counting) Parameters\n",
    "N_Quantizers_to_parameterize = round(Quantization_Proportion*N_Grid_Finess)\n",
    "N_Elements_Per_Cluster = int(round(N_Grid_Instances/N_Quantizers_to_parameterize))\n",
    "\n",
    "# Update User\n",
    "print(\"\\u2022\",N_Quantizers_to_parameterize,\" Centers will be produced; from a total datasize of: \",N_Grid_Finess,\n",
    "      \"!  (That's \",Quantization_Proportion,\n",
    "      \" percent).\")\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate from non-Markovian SDE with rough volatility:\n",
    "$d X_t = \\alpha(t,X_t)dt + (\\beta(t,X_t)+\\sigma_t^H)dW_t ;\\qquad X_0 =x$\n",
    "Where $(\\sigma_t^H)_t$ is a fBM with Hurst parameter $H=0.01$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Sampler - Data-Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euler_Maruyama_Generator(x_0,\n",
    "                             N_Euler_Maruyama_Steps = 10,\n",
    "                             N_Monte_Carlo_Samples = 100,\n",
    "                             T = 1,\n",
    "                             Hurst = 0.1,\n",
    "                             Ratio_fBM_to_typical_vol = 0.5): \n",
    "    \n",
    "    #----------------------------#    \n",
    "    # DEFINE INTERNAL PARAMETERS #\n",
    "    #----------------------------#\n",
    "    # Initialize Empirical Measure\n",
    "    X_T_Empirical = np.zeros([N_Euler_Maruyama_Steps,N_Monte_Carlo_Samples])\n",
    "\n",
    "\n",
    "    # Internal Initialization(s)\n",
    "    ## Initialize current state\n",
    "    n_sample = 0\n",
    "    ## Initialize Incriments\n",
    "    dt = T/N_Euler_Maruyama_Steps\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "\n",
    "    #-----------------------------#    \n",
    "    # Generate Monte-Carlo Sample #\n",
    "    #-----------------------------#\n",
    "    while n_sample < N_Monte_Carlo_Samples:\n",
    "        # Reset Step Counter\n",
    "        t = 1\n",
    "        # Initialize Current State \n",
    "        X_current = x_0\n",
    "        # Generate roughness\n",
    "        sigma_rough = FBM(n=N_Euler_Maruyama_Steps, hurst=0.75, length=1, method='daviesharte').fbm()\n",
    "        # Perform Euler-Maruyama Simulation\n",
    "        while t<(N_Euler_Maruyama_Steps-1):\n",
    "            # Update Internal Parameters\n",
    "            ## Get Current Time\n",
    "            t_current = t*(T/N_Euler_Maruyama_Steps)\n",
    "\n",
    "            # Update Generated Path\n",
    "            drift_t = alpha(t_current,X_current)*dt\n",
    "            vol_t = ((1-Ratio_fBM_to_typical_vol)*beta(t_current,X_current)+Ratio_fBM_to_typical_vol*(sigma_rough[t]))*np.random.normal(0,sqrt_dt)\n",
    "            X_current = X_current + drift_t + vol_t\n",
    "\n",
    "            # Update Counter (EM)\n",
    "            t = t+1\n",
    "\n",
    "            # Update Empirical Measure\n",
    "            X_T_Empirical[t,n_sample] = X_current\n",
    "\n",
    "        # Update Counter (MC)\n",
    "        n_sample = n_sample + 1\n",
    "\n",
    "    return X_T_Empirical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List of Barycenters\n",
    "Wasserstein_Barycenters = []\n",
    "# Initialize Terminal-Time Empirical Measures\n",
    "## Training Outputs\n",
    "measures_locations_list = []\n",
    "measures_weights_list = []\n",
    "## Testing Outputs\n",
    "measures_locations_test_list = []\n",
    "measures_weights_test_list = []\n",
    "# Grid (Training and Testing inputs (t,x))\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "measure_weights_test = np.ones(N_Monte_Carlo_Samples_Test)/N_Monte_Carlo_Samples_Test\n",
    "# Initialize Quantizer\n",
    "Init_Quantizer_generic = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $\\{\\hat{\\nu}^{N}_{T,x}\\}_{x \\in \\mathbb{X}}$ Build Wasserstein Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 113.10it/s]\n",
      " 16%|â–ˆâ–Œ        | 13/82 [00:00<00:00, 126.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step:\n",
      "===================================\n",
      "Start Simulation Step: Training Set\n",
      "===================================\n",
      "==================================\n",
      "Done Simulation Step: Training Set\n",
      "==================================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================\n",
      "Start Simulation Step: Test Set\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:00<00:00, 152.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Done Simulation Step: Test Set\n",
      "==============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"Current Monte-Carlo Step:\")\n",
    "if rough_SDE == False:\n",
    "    print(\"===================================\")\n",
    "    print(\"Start Simulation Step: Training Set\")\n",
    "    print(\"===================================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator = FBM(n=N_Euler_Maruyama_Steps, hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid).reshape(-1,1) +field_loop_x\n",
    "        for n_MC in range(N_Monte_Carlo_Samples):\n",
    "            fBM_variation_path_loop = fBM_Generator.fbm().reshape(-1,1)\n",
    "            generated_path_loop = finite_variation_path + fBM_variation_path_loop\n",
    "            if n_MC == 0:\n",
    "                paths_loop = generated_path_loop\n",
    "            else:\n",
    "                paths_loop = np.append(paths_loop,generated_path_loop,axis=-1)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_train_loop = np.append(np.repeat(x_Grid[i],(N_Euler_Maruyama_Steps+1)).reshape(-1,1),\n",
    "                                 t_Grid.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_list = measures_locations_list + measures_locations_loop\n",
    "        measures_weights_list.append(measure_weights)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_train = X_train_loop\n",
    "        else:\n",
    "            X_train = np.append(X_train,X_train_loop,axis=0)\n",
    "    \n",
    "    # Update User\n",
    "    print(\"==================================\")\n",
    "    print(\"Done Simulation Step: Training Set\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "\n",
    "if rough_SDE == False:\n",
    "    print(\"===============================\")\n",
    "    print(\"Start Simulation Step: Test Set\")\n",
    "    print(\"===============================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator_test = FBM(n=(len(t_Grid_test)-1), hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x_test)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid_test[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid_test).reshape(-1,1) +field_loop_x\n",
    "        for n_MC in range(N_Monte_Carlo_Samples_Test):\n",
    "            fBM_variation_path_loop = fBM_Generator_test.fbm().reshape(-1,1)\n",
    "            generated_path_loop = finite_variation_path + fBM_variation_path_loop\n",
    "            if n_MC == 0:\n",
    "                paths_loop = generated_path_loop\n",
    "            else:\n",
    "                paths_loop = np.append(paths_loop,generated_path_loop,axis=-1)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_test_loop = np.append(np.repeat(x_Grid_test[i],len(t_Grid_test)).reshape(-1,1),\n",
    "                                 t_Grid_test.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_test_list = measures_locations_test_list + measures_locations_loop\n",
    "        measures_weights_test_list.append(measure_weights_test)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_test = X_test_loop\n",
    "        else:\n",
    "            X_test = np.append(X_test,X_train_loop,axis=0)\n",
    "    print(\"==============================\")\n",
    "    print(\"Done Simulation Step: Test Set\")\n",
    "    print(\"==============================\")\n",
    "    \n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n"
     ]
    }
   ],
   "source": [
    "if rough_SDE == True:\n",
    "    print(\"Using Euler-Maruyama distritization + Monte-Carlo Sampling.\")\n",
    "    #----------------------------------------------------------------------------------------------#\n",
    "    # Update User\n",
    "    print(\"===================================\")\n",
    "    print(\"Start Simulation Step: Training Set\")\n",
    "    print(\"===================================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator = FBM(n=N_Euler_Maruyama_Steps, hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid).reshape(-1,1) +field_loop_x\n",
    "        # Simulate Paths\n",
    "        paths_loop = Euler_Maruyama_Generator(x_0=x_Grid[i],\n",
    "                                              N_Euler_Maruyama_Steps = N_Euler_Maruyama_Steps,\n",
    "                                              N_Monte_Carlo_Samples = N_Monte_Carlo_Samples,\n",
    "                                              T = T_end,\n",
    "                                              Hurst=Rougness,\n",
    "                                              Ratio_fBM_to_typical_vol=Ratio_fBM_to_typical_vol)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_train_loop = np.append(np.repeat(x_Grid[i],(N_Euler_Maruyama_Steps+1)).reshape(-1,1),\n",
    "                                 t_Grid.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_list = measures_locations_list + measures_locations_loop\n",
    "        measures_weights_list.append(measure_weights)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_train = X_train_loop\n",
    "        else:\n",
    "            X_train = np.append(X_train,X_train_loop,axis=0)\n",
    "    \n",
    "    # Update User\n",
    "    print(\"==================================\")\n",
    "    print(\"Done Simulation Step: Training Set\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "\n",
    "if rough_SDE == True:\n",
    "    print(\"===============================\")\n",
    "    print(\"Start Simulation Step: Test Set\")\n",
    "    print(\"===============================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator_test = FBM(n=(len(t_Grid_test)-1), hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x_test)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid_test[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid_test).reshape(-1,1) +field_loop_x\n",
    "        paths_loop = Euler_Maruyama_Generator(x_0=x_Grid_test[i],\n",
    "                                              N_Euler_Maruyama_Steps = len(t_Grid_test),\n",
    "                                              N_Monte_Carlo_Samples = N_Monte_Carlo_Samples_Test,\n",
    "                                              T = T_end_test,\n",
    "                                              Hurst=Rougness,\n",
    "                                              Ratio_fBM_to_typical_vol=Ratio_fBM_to_typical_vol)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_test_loop = np.append(np.repeat(x_Grid_test[i],len(t_Grid_test)).reshape(-1,1),\n",
    "                                 t_Grid_test.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_test_list = measures_locations_test_list + measures_locations_loop\n",
    "        measures_weights_test_list.append(measure_weights_test)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_test = X_test_loop\n",
    "        else:\n",
    "            X_test = np.append(X_test,X_train_loop,axis=0)\n",
    "    print(\"==============================\")\n",
    "    print(\"Done Simulation Step: Test Set\")\n",
    "    print(\"==============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer (Model Type A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dissimilarity (Distance) Matrix\n",
    "*In this step we build a dissimularity matrix of the dataset on the Wasserstein-1 space.  Namely:*\n",
    "$$\n",
    "\\operatorname{Mat}_{\\# \\mathbb{X},\\# \\mathbb{X}}\\left(\\mathbb{R}\\right)\\ni D; \\text{ where}\\qquad \\, D_{i,j}\\triangleq \\mathcal{W}_1\\left(f(x_i),f(x_j)\\right)\n",
    ";\n",
    "$$\n",
    "*where $f\\in C\\left((\\mathcal{X},\\mathcal{P}_1(\\mathcal{Y})\\right)$ is the \"target\" function we are learning.*\n",
    "\n",
    "**Note**: *Computing the dissimularity matrix is the most costly part of the entire algorithm with a complexity of at-most $\\mathcal{O}\\left(E_{W} \\# \\mathbb{X})^2\\right)$ where $E_W$ denotes the complexity of a single Wasserstein-1 evaluation between two elements of the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 6/110 [00:00<00:01, 57.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜š  Begin Building Distance Matrix  ðŸ˜š\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [00:01<00:00, 82.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜€  Done Building Distance Matrix ðŸ˜€ !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Disimilarity Matrix\n",
    "Dissimilarity_matrix_ot = np.zeros([N_Grid_Instances,N_Grid_Instances])\n",
    "\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Building Distance Matrix\",\" \\U0001F61A\")\n",
    "# Build Disimilarity Matrix\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    for j in range(N_Grid_Instances):\n",
    "        Dissimilarity_matrix_ot[i,j] = ot.emd2_1d(measures_locations_list[j],\n",
    "                                                  measures_locations_list[i])\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Building Distance Matrix\",\"\\U0001F600\",\"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Quantities to Loop Over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\" and Generate Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Locations Matrix (Internal to Loop)\n",
    "measures_locations_list_current = copy.copy(measures_locations_list)\n",
    "Dissimilarity_matrix_ot_current = copy.copy(Dissimilarity_matrix_ot)\n",
    "\n",
    "# Initialize masker vector\n",
    "masker = np.ones(N_Grid_Instances)\n",
    "\n",
    "# Initialize Sorting Reference Vector (This helps us efficiently scroll through the disimularity matrix to identify the barycenter without having to re-compute the dissimultarity matrix of a sub-saple at every iteration (which is the most costly part of the algorithm!))\n",
    "Distances_Loop = Dissimilarity_matrix_ot_current.sum(axis=1)\n",
    "\n",
    "# Initialize Classes (In-Sample)\n",
    "Classifer_Wasserstein_Centers = np.zeros([N_Quantizers_to_parameterize,N_Grid_Instances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/usr/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 5390.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜š  Begin Identifying Sample Barycenters  ðŸ˜š\n",
      "ðŸ˜€  Done Identifying Sample Barycenters ðŸ˜€ !\n",
      "[[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Identifying Sample Barycenters\",\" \\U0001F61A\")\n",
    "\n",
    "# Identify Sample Barycenters\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    # GET BARYCENTER #\n",
    "    #----------------#\n",
    "    ## Identify row with minimum total distance\n",
    "    Barycenter_index = int(Distances_Loop.argsort()[:1][0])\n",
    "    ## Get Barycenter\n",
    "    ## Update Barycenters Array ##\n",
    "    #----------------------------#\n",
    "    ### Get next Barycenter\n",
    "    new_barycenter_loop = np.array(measures_locations_list_current[Barycenter_index]).reshape(-1,1)\n",
    "    ### Update Array of Barycenters\n",
    "    if i == 0:\n",
    "        # Initialize Barycenters Array\n",
    "        Barycenters_Array = new_barycenter_loop\n",
    "    else:\n",
    "        # Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,new_barycenter_loop,axis=-1)\n",
    "\n",
    "    # GET CLUSTER #\n",
    "    #-------------#\n",
    "    # Identify Cluster for this barycenter (which elements are closest to it)\n",
    "    Cluster_indices = (masker*Dissimilarity_matrix_ot_current[:,Barycenter_index]).argsort()[:N_Elements_Per_Cluster]\n",
    "    ## UPDATES Set  M^{(n)}  ##\n",
    "    #-------------------------#\n",
    "    Dissimilarity_matrix_ot_current[Cluster_indices,:] = 0\n",
    "    # Distance-Based Sorting\n",
    "    Distances_Loop[Cluster_indices] = math.inf\n",
    "\n",
    "    # Update Cluster\n",
    "    masker[Cluster_indices] = math.inf\n",
    "    \n",
    "    # Update Classes\n",
    "    Classifer_Wasserstein_Centers[i,Cluster_indices] = 1\n",
    "#     print(Cluster_indices)\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Identifying Sample Barycenters\",\"\\U0001F600\",\"!\")\n",
    "print(Classifer_Wasserstein_Centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1107 - accuracy: 0.1545\n",
      "Epoch 2/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0793 - accuracy: 0.2091\n",
      "Epoch 3/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0496 - accuracy: 0.2545\n",
      "Epoch 4/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0193 - accuracy: 0.2636\n",
      "Epoch 5/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9809 - accuracy: 0.2818\n",
      "Epoch 6/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9386 - accuracy: 0.3000\n",
      "Epoch 7/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8897 - accuracy: 0.2909\n",
      "Epoch 8/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8312 - accuracy: 0.3091\n",
      "Epoch 9/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7749 - accuracy: 0.3091\n",
      "Epoch 10/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7219 - accuracy: 0.3364\n",
      "Epoch 11/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.6723 - accuracy: 0.3636\n",
      "Epoch 12/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.6318 - accuracy: 0.3818\n",
      "Epoch 13/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5841 - accuracy: 0.4818\n",
      "Epoch 14/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5410 - accuracy: 0.5273\n",
      "Epoch 15/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5013 - accuracy: 0.5818\n",
      "Epoch 16/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4544 - accuracy: 0.5727\n",
      "Epoch 17/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4157 - accuracy: 0.6000\n",
      "Epoch 18/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3696 - accuracy: 0.6091\n",
      "Epoch 19/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3291 - accuracy: 0.6182\n",
      "Epoch 20/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3010 - accuracy: 0.5818\n",
      "Epoch 21/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2570 - accuracy: 0.6000\n",
      "Epoch 22/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2100 - accuracy: 0.6364\n",
      "Epoch 23/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1967 - accuracy: 0.6545\n",
      "Epoch 24/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1561 - accuracy: 0.6364\n",
      "Epoch 25/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1208 - accuracy: 0.6000\n",
      "Epoch 26/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1010 - accuracy: 0.6182\n",
      "Epoch 27/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0768 - accuracy: 0.6455\n",
      "Epoch 28/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0359 - accuracy: 0.6455\n",
      "Epoch 29/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0183 - accuracy: 0.6364\n",
      "Epoch 30/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0013 - accuracy: 0.6273\n",
      "Epoch 31/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9682 - accuracy: 0.6545\n",
      "Epoch 32/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9504 - accuracy: 0.6727\n",
      "Epoch 33/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9426 - accuracy: 0.6545\n",
      "Epoch 34/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9081 - accuracy: 0.6727\n",
      "Epoch 35/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8970 - accuracy: 0.6545\n",
      "Epoch 36/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8653 - accuracy: 0.6909\n",
      "Epoch 37/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8481 - accuracy: 0.6818\n",
      "Epoch 38/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8379 - accuracy: 0.6909\n",
      "Epoch 39/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8217 - accuracy: 0.7000\n",
      "Epoch 40/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8000 - accuracy: 0.7091\n",
      "Epoch 41/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7951 - accuracy: 0.7091\n",
      "Epoch 42/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7859 - accuracy: 0.7182\n",
      "Epoch 43/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7522 - accuracy: 0.7545\n",
      "Epoch 44/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.7364\n",
      "Epoch 45/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7201 - accuracy: 0.7364\n",
      "Epoch 46/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7530 - accuracy: 0.7273\n",
      "Epoch 47/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.7727\n",
      "Epoch 48/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.7727\n",
      "Epoch 49/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.7909\n",
      "Epoch 50/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6543 - accuracy: 0.7727\n",
      "Epoch 51/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.7545\n",
      "Epoch 52/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.7818\n",
      "Epoch 53/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.7455\n",
      "Epoch 54/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.7364\n",
      "Epoch 55/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.8091\n",
      "Epoch 56/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.7818\n",
      "Epoch 57/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.8182\n",
      "Epoch 58/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.7636\n",
      "Epoch 59/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.8182\n",
      "Epoch 60/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.8000\n",
      "Epoch 61/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.8273\n",
      "Epoch 62/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.8091\n",
      "Epoch 63/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7818\n",
      "Epoch 64/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.8000\n",
      "Epoch 65/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.8182\n",
      "Epoch 66/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.8364\n",
      "Epoch 67/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.8364\n",
      "Epoch 68/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.8273\n",
      "Epoch 69/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.8273\n",
      "Epoch 70/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.8545\n",
      "Epoch 71/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.8182\n",
      "Epoch 72/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.8273\n",
      "Epoch 73/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7909\n",
      "Epoch 74/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.8273\n",
      "Epoch 75/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.8273\n",
      "Epoch 76/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.8273\n",
      "Epoch 77/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.8364\n",
      "Epoch 78/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8091\n",
      "Epoch 79/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8455\n",
      "Epoch 80/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.8545\n",
      "Epoch 81/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.8455\n",
      "Epoch 82/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7727\n",
      "Epoch 83/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8545\n",
      "Epoch 84/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.8455\n",
      "Epoch 85/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.8273\n",
      "Epoch 86/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8455\n",
      "Epoch 87/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8273\n",
      "Epoch 88/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.8545\n",
      "Epoch 89/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.8273\n",
      "Epoch 90/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.8000\n",
      "Epoch 91/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.8182\n",
      "Epoch 92/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7909\n",
      "Epoch 93/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.8273\n",
      "Epoch 94/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.8091\n",
      "Epoch 95/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.8273\n",
      "Epoch 96/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8364\n",
      "Epoch 97/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.8182\n",
      "Epoch 98/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8273\n",
      "Epoch 99/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7909\n",
      "Epoch 100/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7909\n",
      "Epoch 101/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8364\n",
      "Epoch 102/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8091\n",
      "Epoch 103/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.8182\n",
      "Epoch 104/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.7636\n",
      "Epoch 105/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7242 - accuracy: 0.7091\n",
      "Epoch 106/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7135 - accuracy: 0.8182\n",
      "Epoch 107/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.8273\n",
      "Epoch 108/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.7909\n",
      "Epoch 109/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.8000\n",
      "Epoch 110/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.8182\n",
      "Epoch 111/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8455\n",
      "Epoch 112/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.8182\n",
      "Epoch 113/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.8364\n",
      "Epoch 114/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7818\n",
      "Epoch 115/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.7909\n",
      "Epoch 116/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.7818\n",
      "Epoch 117/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.8091\n",
      "Epoch 118/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.8273\n",
      "Epoch 119/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.8636\n",
      "Epoch 120/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.8364\n",
      "Epoch 121/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7362 - accuracy: 0.7909\n",
      "Epoch 122/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.8000\n",
      "Epoch 123/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.8091\n",
      "Epoch 124/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7909\n",
      "Epoch 125/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.8091\n",
      "Epoch 126/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.8091\n",
      "Epoch 127/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7858 - accuracy: 0.7727\n",
      "Epoch 128/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9193 - accuracy: 0.7273\n",
      "Epoch 129/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7630 - accuracy: 0.7636\n",
      "Epoch 130/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7409 - accuracy: 0.8545\n",
      "Epoch 131/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7799 - accuracy: 0.8273\n",
      "Epoch 132/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8586 - accuracy: 0.7273\n",
      "Epoch 133/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.8182\n",
      "Epoch 134/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2959 - accuracy: 0.7455\n",
      "Epoch 135/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0248 - accuracy: 0.8000\n",
      "Epoch 136/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2042 - accuracy: 0.7091\n",
      "Epoch 137/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2653 - accuracy: 0.7364\n",
      "Epoch 138/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9964 - accuracy: 0.8091\n",
      "Epoch 139/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9401 - accuracy: 0.8000\n",
      "Epoch 140/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4637 - accuracy: 0.7455\n",
      "Epoch 141/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8571 - accuracy: 0.7091\n",
      "Epoch 142/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5552 - accuracy: 0.7182\n",
      "Epoch 143/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1144 - accuracy: 0.6545\n",
      "Epoch 144/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2987 - accuracy: 0.7727\n",
      "Epoch 145/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2254 - accuracy: 0.7727\n",
      "Epoch 146/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8330 - accuracy: 0.7909\n",
      "Epoch 147/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9974 - accuracy: 0.7818\n",
      "Epoch 148/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8807 - accuracy: 0.7727\n",
      "Epoch 149/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.7455\n",
      "Epoch 150/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8909 - accuracy: 0.7182\n",
      "Epoch 151/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2044 - accuracy: 0.6636\n",
      "Epoch 152/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7920 - accuracy: 0.7364\n",
      "Epoch 153/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.4264 - accuracy: 0.7182\n",
      "Epoch 154/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4540 - accuracy: 0.7000\n",
      "Epoch 155/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8701 - accuracy: 0.6545\n",
      "Epoch 156/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1030 - accuracy: 0.7364\n",
      "Epoch 157/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7066 - accuracy: 0.7364\n",
      "Epoch 158/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5802 - accuracy: 0.7455\n",
      "Epoch 159/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5005 - accuracy: 0.7000\n",
      "Epoch 160/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.5569 - accuracy: 0.6364\n",
      "Epoch 161/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.5625 - accuracy: 0.6455\n",
      "Epoch 162/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.0418 - accuracy: 0.6727\n",
      "Epoch 163/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8266 - accuracy: 0.7364\n",
      "Epoch 164/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4.7979 - accuracy: 0.6364\n",
      "Epoch 165/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.5379 - accuracy: 0.6364\n",
      "Epoch 166/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6772 - accuracy: 0.6909\n",
      "Epoch 167/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3432 - accuracy: 0.6818\n",
      "Epoch 168/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8375 - accuracy: 0.6727\n",
      "Epoch 169/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.2111 - accuracy: 0.6909\n",
      "Epoch 170/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6915 - accuracy: 0.6455\n",
      "Epoch 171/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.1800 - accuracy: 0.6636\n",
      "Epoch 172/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.1013 - accuracy: 0.6727\n",
      "Epoch 173/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.5490 - accuracy: 0.6727\n",
      "Epoch 174/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4.0692 - accuracy: 0.6364\n",
      "Epoch 175/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6200 - accuracy: 0.6455\n",
      "Epoch 176/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.5705 - accuracy: 0.6273\n",
      "Epoch 177/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.9539 - accuracy: 0.6636\n",
      "Epoch 178/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.0544 - accuracy: 0.6727\n",
      "Epoch 179/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.9920 - accuracy: 0.5545\n",
      "Epoch 180/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8771 - accuracy: 0.7091\n",
      "Epoch 181/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.2214 - accuracy: 0.6455\n",
      "Epoch 182/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4.4350 - accuracy: 0.6455\n",
      "Epoch 183/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 9.3065 - accuracy: 0.7000\n",
      "Epoch 184/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 7.7687 - accuracy: 0.6455\n",
      "Epoch 185/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 7.3248 - accuracy: 0.5545\n",
      "Epoch 186/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 7.4601 - accuracy: 0.6455\n",
      "Epoch 187/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.5829 - accuracy: 0.6818\n",
      "Epoch 188/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 7.3415 - accuracy: 0.6273\n",
      "Epoch 189/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 17.1165 - accuracy: 0.5545\n",
      "Epoch 190/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 15.9186 - accuracy: 0.6818\n",
      "Epoch 191/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.9481 - accuracy: 0.5545\n",
      "Epoch 192/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 12.6069 - accuracy: 0.6636\n",
      "Epoch 193/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 15.2779 - accuracy: 0.5545\n",
      "Epoch 194/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 17.3431 - accuracy: 0.6273\n",
      "Epoch 195/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 12.0435 - accuracy: 0.5636\n",
      "Epoch 196/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.5849 - accuracy: 0.6636\n",
      "Epoch 197/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 16.7056 - accuracy: 0.5273\n",
      "Epoch 198/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 11.7564 - accuracy: 0.5818\n",
      "Epoch 199/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 17.4526 - accuracy: 0.5364\n",
      "Epoch 200/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 11.8950 - accuracy: 0.6000\n",
      "Epoch 201/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 13.4846 - accuracy: 0.6000\n",
      "Epoch 202/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 20.8731 - accuracy: 0.5273\n",
      "Epoch 203/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 26.6317 - accuracy: 0.4636\n",
      "Epoch 204/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 33.3442 - accuracy: 0.3545\n",
      "Epoch 205/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 27.4959 - accuracy: 0.4818\n",
      "Epoch 206/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 25.1651 - accuracy: 0.5455\n",
      "Epoch 207/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 16.6745 - accuracy: 0.5909\n",
      "Epoch 208/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 15.5513 - accuracy: 0.5636\n",
      "Epoch 209/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 17.6132 - accuracy: 0.5545\n",
      "Epoch 210/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 14.6691 - accuracy: 0.5636\n",
      "Epoch 211/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 13.7443 - accuracy: 0.6000\n",
      "Epoch 212/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 23.4129 - accuracy: 0.6455\n",
      "Epoch 213/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 19.4899 - accuracy: 0.6545\n",
      "Epoch 214/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 17.7816 - accuracy: 0.6000\n",
      "Epoch 215/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 20.4156 - accuracy: 0.6182\n",
      "Epoch 216/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.0493 - accuracy: 0.6182\n",
      "Epoch 217/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 19.2059 - accuracy: 0.5545\n",
      "Epoch 218/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 13.5921 - accuracy: 0.6273\n",
      "Epoch 219/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 16.2583 - accuracy: 0.5636\n",
      "Epoch 220/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 13.5416 - accuracy: 0.6364\n",
      "Epoch 221/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 27.1111 - accuracy: 0.5545\n",
      "Epoch 222/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 31.9122 - accuracy: 0.6091\n",
      "Epoch 223/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 33.4191 - accuracy: 0.4273\n",
      "Epoch 224/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 36.0841 - accuracy: 0.5636\n",
      "Epoch 225/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 63.3990 - accuracy: 0.4818\n",
      "Epoch 226/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 34.7227 - accuracy: 0.5182\n",
      "Epoch 227/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 57.4255 - accuracy: 0.4636\n",
      "Epoch 228/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 37.8332 - accuracy: 0.4455\n",
      "Epoch 229/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 43.4187 - accuracy: 0.4818\n",
      "Epoch 230/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 30.8268 - accuracy: 0.5818\n",
      "Epoch 231/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 25.9699 - accuracy: 0.5545\n",
      "Epoch 232/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 33.2009 - accuracy: 0.4545\n",
      "Epoch 233/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 24.6138 - accuracy: 0.5636\n",
      "Epoch 234/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 17.9644 - accuracy: 0.5364\n",
      "Epoch 235/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 20.2362 - accuracy: 0.5364\n",
      "Epoch 236/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 33.5522 - accuracy: 0.6182\n",
      "Epoch 237/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 43.1638 - accuracy: 0.4909\n",
      "Epoch 238/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 24.4480 - accuracy: 0.5818\n",
      "Epoch 239/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 32.5017 - accuracy: 0.5545\n",
      "Epoch 240/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 42.9816 - accuracy: 0.5455\n",
      "Epoch 241/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 38.2058 - accuracy: 0.5182\n",
      "Epoch 242/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 29.3968 - accuracy: 0.5818\n",
      "Epoch 243/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 21.3572 - accuracy: 0.6727\n",
      "Epoch 244/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 14.1124 - accuracy: 0.6000\n",
      "Epoch 245/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 18.0852 - accuracy: 0.5818\n",
      "Epoch 246/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 16.0383 - accuracy: 0.5455\n",
      "Epoch 247/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 22.6750 - accuracy: 0.6182\n",
      "Epoch 248/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 24.6377 - accuracy: 0.5727\n",
      "Epoch 249/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 22.2441 - accuracy: 0.5636\n",
      "Epoch 250/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 26.8678 - accuracy: 0.5273\n",
      "Epoch 251/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 33.2650 - accuracy: 0.4727\n",
      "Epoch 252/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 23.1156 - accuracy: 0.6000\n",
      "Epoch 253/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 36.8572 - accuracy: 0.5455\n",
      "Epoch 254/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 42.4053 - accuracy: 0.5636\n",
      "Epoch 255/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 57.8657 - accuracy: 0.4091\n",
      "Epoch 256/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 57.2983 - accuracy: 0.3636\n",
      "Epoch 257/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 52.1925 - accuracy: 0.4818\n",
      "Epoch 258/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 37.2460 - accuracy: 0.5727\n",
      "Epoch 259/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 48.6726 - accuracy: 0.4818\n",
      "Epoch 260/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 48.4961 - accuracy: 0.5364\n",
      "Epoch 261/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 51.0311 - accuracy: 0.4545\n",
      "Epoch 262/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 61.5572 - accuracy: 0.4091\n",
      "Epoch 263/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 82.4340 - accuracy: 0.4727\n",
      "Epoch 264/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 128.8022 - accuracy: 0.4000\n",
      "Epoch 265/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 88.2604 - accuracy: 0.4000\n",
      "Epoch 266/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.3840 - accuracy: 0.4091\n",
      "Epoch 267/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 96.5827 - accuracy: 0.4273\n",
      "Epoch 268/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 91.2748 - accuracy: 0.3909\n",
      "Epoch 269/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 87.4182 - accuracy: 0.4455\n",
      "Epoch 270/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 119.8823 - accuracy: 0.4273\n",
      "Epoch 271/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 70.3313 - accuracy: 0.4636\n",
      "Epoch 272/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 105.8342 - accuracy: 0.4091\n",
      "Epoch 273/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 92.1776 - accuracy: 0.5182\n",
      "Epoch 274/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 70.1059 - accuracy: 0.4818\n",
      "Epoch 275/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 63.8533 - accuracy: 0.4909\n",
      "Epoch 276/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 83.8507 - accuracy: 0.4727\n",
      "Epoch 277/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 102.0070 - accuracy: 0.4455\n",
      "Epoch 278/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 77.0770 - accuracy: 0.5636\n",
      "Epoch 279/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 61.7013 - accuracy: 0.5000\n",
      "Epoch 280/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 53.3738 - accuracy: 0.4182\n",
      "Epoch 281/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 62.4804 - accuracy: 0.4545\n",
      "Epoch 282/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 64.0347 - accuracy: 0.5000\n",
      "Epoch 283/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 48.6455 - accuracy: 0.5545\n",
      "Epoch 284/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 28.2876 - accuracy: 0.5455\n",
      "Epoch 285/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 35.1757 - accuracy: 0.6273\n",
      "Epoch 286/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 30.6241 - accuracy: 0.5364\n",
      "Epoch 287/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 34.8708 - accuracy: 0.4909\n",
      "Epoch 288/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 48.7334 - accuracy: 0.5909\n",
      "Epoch 289/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 40.2906 - accuracy: 0.5545\n",
      "Epoch 290/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 114.1735 - accuracy: 0.4545\n",
      "Epoch 291/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 118.9559 - accuracy: 0.4182\n",
      "Epoch 292/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 97.1819 - accuracy: 0.4364\n",
      "Epoch 293/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 96.5807 - accuracy: 0.4273\n",
      "Epoch 294/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 70.9427 - accuracy: 0.4091\n",
      "Epoch 295/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 72.8196 - accuracy: 0.4909\n",
      "Epoch 296/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 81.6719 - accuracy: 0.5091\n",
      "Epoch 297/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 91.5487 - accuracy: 0.4273\n",
      "Epoch 298/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 87.5907 - accuracy: 0.4818\n",
      "Epoch 299/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 68.6643 - accuracy: 0.5000\n",
      "Epoch 300/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 53.9807 - accuracy: 0.5455\n",
      "Epoch 301/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 86.3052 - accuracy: 0.5273\n",
      "Epoch 302/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 106.8783 - accuracy: 0.5364\n",
      "Epoch 303/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 64.5363 - accuracy: 0.5273\n",
      "Epoch 304/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 81.7001 - accuracy: 0.4273\n",
      "Epoch 305/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 53.0518 - accuracy: 0.5273\n",
      "Epoch 306/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 71.8000 - accuracy: 0.5818\n",
      "Epoch 307/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 78.5469 - accuracy: 0.5000\n",
      "Epoch 308/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 115.7105 - accuracy: 0.4273\n",
      "Epoch 309/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 148.3899 - accuracy: 0.4727\n",
      "Epoch 310/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 129.2060 - accuracy: 0.4091\n",
      "Epoch 311/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 139.2097 - accuracy: 0.4091\n",
      "Epoch 312/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 133.1017 - accuracy: 0.4909\n",
      "Epoch 313/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 172.8514 - accuracy: 0.4000\n",
      "Epoch 314/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 118.9167 - accuracy: 0.4909\n",
      "Epoch 315/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 118.7638 - accuracy: 0.4727\n",
      "Epoch 316/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 78.9273 - accuracy: 0.5364\n",
      "Epoch 317/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 94.7441 - accuracy: 0.4364\n",
      "Epoch 318/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 120.1509 - accuracy: 0.4182\n",
      "Epoch 319/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 166.8428 - accuracy: 0.3545\n",
      "Epoch 320/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 188.6017 - accuracy: 0.4364\n",
      "Epoch 321/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 235.6417 - accuracy: 0.4364\n",
      "Epoch 322/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 156.9211 - accuracy: 0.4091\n",
      "Epoch 323/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 206.8457 - accuracy: 0.5364\n",
      "Epoch 324/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 143.7650 - accuracy: 0.5818\n",
      "Epoch 325/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 75.3268 - accuracy: 0.5364\n",
      "Epoch 326/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 91.7579 - accuracy: 0.5545\n",
      "Epoch 327/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 57.1350 - accuracy: 0.4727\n",
      "Epoch 328/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 53.0677 - accuracy: 0.6182\n",
      "Epoch 329/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 61.9709 - accuracy: 0.5636\n",
      "Epoch 330/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 69.9557 - accuracy: 0.5455\n",
      "Epoch 331/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 135.9490 - accuracy: 0.5182\n",
      "Epoch 332/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 198.9159 - accuracy: 0.3818\n",
      "Epoch 333/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 146.9069 - accuracy: 0.4636\n",
      "Epoch 334/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 176.6657 - accuracy: 0.4545\n",
      "Epoch 335/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 167.7838 - accuracy: 0.4455\n",
      "Epoch 336/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 96.3004 - accuracy: 0.4727\n",
      "Epoch 337/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 87.8298 - accuracy: 0.6091\n",
      "Epoch 338/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 63.1318 - accuracy: 0.5545\n",
      "Epoch 339/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 136.0366 - accuracy: 0.4455\n",
      "Epoch 340/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 80.3604 - accuracy: 0.5182\n",
      "Epoch 341/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 97.8726 - accuracy: 0.4727\n",
      "Epoch 342/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 145.5346 - accuracy: 0.4727\n",
      "Epoch 343/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 144.8296 - accuracy: 0.4727\n",
      "Epoch 344/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 78.2570 - accuracy: 0.5182\n",
      "Epoch 345/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 78.0709 - accuracy: 0.5182\n",
      "Epoch 346/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 90.8991 - accuracy: 0.4636\n",
      "Epoch 347/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 85.6339 - accuracy: 0.4455\n",
      "Epoch 348/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 102.3668 - accuracy: 0.5182\n",
      "Epoch 349/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 86.0251 - accuracy: 0.5091\n",
      "Epoch 350/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 79.6569 - accuracy: 0.5273\n",
      "Epoch 351/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 105.3257 - accuracy: 0.5545\n",
      "Epoch 352/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 97.5189 - accuracy: 0.5273\n",
      "Epoch 353/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 147.7538 - accuracy: 0.5364\n",
      "Epoch 354/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 144.9691 - accuracy: 0.4545\n",
      "Epoch 355/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 80.7958 - accuracy: 0.5182\n",
      "Epoch 356/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 84.6700 - accuracy: 0.5182\n",
      "Epoch 357/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 95.4618 - accuracy: 0.5364\n",
      "Epoch 358/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 113.5886 - accuracy: 0.4545\n",
      "Epoch 359/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 140.2218 - accuracy: 0.4727\n",
      "Epoch 360/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 147.4076 - accuracy: 0.4636\n",
      "Epoch 361/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 119.9056 - accuracy: 0.4545\n",
      "Epoch 362/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 168.2970 - accuracy: 0.5091\n",
      "Epoch 363/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 100.4688 - accuracy: 0.5182\n",
      "Epoch 364/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 150.9996 - accuracy: 0.4091\n",
      "Epoch 365/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 218.0614 - accuracy: 0.4818\n",
      "Epoch 366/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 136.4852 - accuracy: 0.4909\n",
      "Epoch 367/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 227.0812 - accuracy: 0.3545\n",
      "Epoch 368/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 217.6068 - accuracy: 0.4455\n",
      "Epoch 369/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 153.8203 - accuracy: 0.3818\n",
      "Epoch 370/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 147.7257 - accuracy: 0.4545\n",
      "Epoch 371/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 133.5330 - accuracy: 0.5909\n",
      "Epoch 372/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 107.7322 - accuracy: 0.4455\n",
      "Epoch 373/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 162.1234 - accuracy: 0.5273\n",
      "Epoch 374/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 116.4851 - accuracy: 0.4727\n",
      "Epoch 375/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 160.7585 - accuracy: 0.5364\n",
      "Epoch 376/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 190.0639 - accuracy: 0.4818\n",
      "Epoch 377/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 141.5819 - accuracy: 0.4455\n",
      "Epoch 378/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 227.8045 - accuracy: 0.5455\n",
      "Epoch 379/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 225.4041 - accuracy: 0.3909\n",
      "Epoch 380/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 203.6639 - accuracy: 0.3545\n",
      "Epoch 381/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 156.7652 - accuracy: 0.5364\n",
      "Epoch 382/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 116.1226 - accuracy: 0.4909\n",
      "Epoch 383/400\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 195.4809 - accuracy: 0.5091\n",
      "Epoch 384/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 146.1139 - accuracy: 0.5273\n",
      "Epoch 385/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 208.1116 - accuracy: 0.4909\n",
      "Epoch 386/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 298.1938 - accuracy: 0.3455\n",
      "Epoch 387/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 279.7941 - accuracy: 0.3909\n",
      "Epoch 388/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 375.0453 - accuracy: 0.3545\n",
      "Epoch 389/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 342.5211 - accuracy: 0.3727\n",
      "Epoch 390/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 266.2794 - accuracy: 0.4364\n",
      "Epoch 391/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 272.9774 - accuracy: 0.3909\n",
      "Epoch 392/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 220.0630 - accuracy: 0.5000\n",
      "Epoch 393/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 293.0036 - accuracy: 0.3909\n",
      "Epoch 394/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 176.6732 - accuracy: 0.4636\n",
      "Epoch 395/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 165.1358 - accuracy: 0.5091\n",
      "Epoch 396/400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 220.2920 - accuracy: 0.3909\n",
      "Epoch 397/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 175.5192 - accuracy: 0.4455\n",
      "Epoch 398/400\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 230.7375 - accuracy: 0.4818\n",
      "Epoch 399/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 288.4961 - accuracy: 0.4364\n",
      "Epoch 400/400\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 289.9236 - accuracy: 0.4273\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 879us/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [2]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers.T,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 5979.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 1175.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n",
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Format Weights\n",
    "## Train\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): START\")\n",
    "print(\"#---------------------------------------#\")\n",
    "Predicted_Weights = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    b = np.repeat(np.array(predicted_classes_train[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): END\")\n",
    "print(\"#-------------------------------------#\")\n",
    "\n",
    "## Test\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): START\")\n",
    "print(\"#-------------------------------------#\")\n",
    "Predicted_Weights_test = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):\n",
    "    b_test = np.repeat(np.array(predicted_classes_test[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b_test = b_test/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights_test = b_test\n",
    "    else:\n",
    "        Predicted_Weights_test = np.append(Predicted_Weights_test,b_test,axis=1)\n",
    "print(\"#-----------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): END\")\n",
    "print(\"#-----------------------------------#\")\n",
    "        \n",
    "# Format Points of Mass\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: START\")\n",
    "print(\"#-----------------------------#\")\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: END\")\n",
    "print(\"#-----------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(measures_weights_list)\n",
    "len(measures_locations_list[x_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:00<00:00, 2288.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "MAE  0.271938    0.162050             0.354213                1.047672   \n",
      "MSE  0.217580    0.050548             0.312230                1.254147   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "MAE              1.354807  \n",
      "MSE              2.017356  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Training Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "Skewness_errors = np.array([])\n",
    "Kurtosis_errors = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measure_weights.reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(np.array(measures_locations_list[x_i]))\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(np.array(measures_locations_list[x_i])**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat = np.sum((Barycenters_Array**3)*(Predicted_Weights[x_i]))\n",
    "    Skewness = np.mean(np.array(measures_locations_list[x_i])**3)\n",
    "    Skewness_errors = np.append(Skewness_errors,(abs(Skewness_hat-Skewness))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat = np.sum((Barycenters_Array**4)*(Predicted_Weights[x_i]))\n",
    "    Kurtosis = np.mean(np.array(measures_locations_list[x_i])**4)\n",
    "    Kurtosis_errors = np.append(Kurtosis_errors,(abs(Kurtosis_hat-Kurtosis))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.mean(np.abs(W1_errors)),np.mean(W1_errors**2)])\n",
    "Mean_prediction_Performance = np.array([np.mean(np.abs(Mean_errors)),np.mean(Mean_errors**2)])\n",
    "Var_prediction_Performance = np.array([np.mean(np.abs(Var_errors)),np.mean(Var_errors**2)])\n",
    "Skewness_prediction_Performance = np.array([np.mean(np.abs(Skewness_errors)),np.mean(Skewness_errors**2)])\n",
    "Kurtosis_prediction_Performance = np.array([np.mean(np.abs(Kurtosis_errors)),np.mean(Kurtosis_errors**2)])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance},index=[\"MAE\",\"MSE\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Train.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "print(Type_A_Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 275/737 [00:00<00:00, 2745.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 737/737 [00:00<00:00, 3075.23it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Test Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors_test = np.array([])\n",
    "Mean_errors_test = np.array([])\n",
    "Var_errors_test = np.array([])\n",
    "Skewness_errors_test = np.array([])\n",
    "Kurtosis_errors_test = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_test_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_test_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights_test[x_i,].reshape(-1,),\n",
    "                         measure_weights_test.reshape(-1,))\n",
    "    W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "    # Get Means\n",
    "    Mu_hat_test = np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array))\n",
    "    Mu_test = np.mean(np.array(measures_locations_test_list[x_i]))\n",
    "    Mean_errors_test =  np.append(Mean_errors_test,(Mu_hat_test-Mu_test))\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat_test = np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))\n",
    "    Var_test = np.mean(np.array(measures_locations_test_list[x_i])**2)\n",
    "    Var_errors_test = np.append(Var_errors_test,(Var_hat_test-Var_test)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat_test = np.sum((Barycenters_Array**3)*(Predicted_Weights_test[x_i]))\n",
    "    Skewness_test = np.mean(np.array(measures_locations_test_list[x_i])**3)\n",
    "    Skewness_errors_test = np.append(Skewness_errors_test,(abs(Skewness_hat_test-Skewness_test))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat_test = np.sum((Barycenters_Array**4)*(Predicted_Weights_test[x_i]))\n",
    "    Kurtosis_test = np.mean(np.array(measures_locations_test_list[x_i])**4)\n",
    "    Kurtosis_errors_test = np.append(Kurtosis_errors_test,(abs(Kurtosis_hat_test-Kurtosis_test))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance_test = np.array([np.mean(np.abs(W1_errors_test)),np.mean(W1_errors_test**2)])\n",
    "Mean_prediction_Performance_test = np.array([np.mean(np.abs(Mean_errors_test)),np.mean(Mean_errors_test**2)])\n",
    "Var_prediction_Performance_test = np.array([np.mean(np.abs(Var_errors_test)),np.mean(Var_errors_test**2)])\n",
    "Skewness_prediction_Performance_test = np.array([np.mean(np.abs(Skewness_errors_test)),np.mean(Skewness_errors_test**2)])\n",
    "Kurtosis_prediction_Performance_test = np.array([np.mean(np.abs(Kurtosis_errors_test)),np.mean(Kurtosis_errors_test**2)])\n",
    "\n",
    "Type_A_Prediction_test = pd.DataFrame({\"W1\":W1_Performance_test,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance_test,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance_test,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance_test,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance_test},index=[\"MAE\",\"MSE\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction_test.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Test.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.271938</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.354213</td>\n",
       "      <td>1.047672</td>\n",
       "      <td>1.354807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.217580</td>\n",
       "      <td>0.050548</td>\n",
       "      <td>0.312230</td>\n",
       "      <td>1.254147</td>\n",
       "      <td>2.017356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "MAE  0.271938    0.162050             0.354213                1.047672   \n",
       "MSE  0.217580    0.050548             0.312230                1.254147   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "MAE              1.354807  \n",
       "MSE              2.017356  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.840013</td>\n",
       "      <td>0.643058</td>\n",
       "      <td>1.930973</td>\n",
       "      <td>1.322353</td>\n",
       "      <td>1.408145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.004965</td>\n",
       "      <td>0.451095</td>\n",
       "      <td>4.614378</td>\n",
       "      <td>1.799255</td>\n",
       "      <td>2.029935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "MAE  0.840013    0.643058             1.930973                1.322353   \n",
       "MSE  1.004965    0.451095             4.614378                1.799255   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "MAE              1.408145  \n",
       "MSE              2.029935  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print for Terminal Legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "MAE  0.271938    0.162050             0.354213                1.047672   \n",
      "MSE  0.217580    0.050548             0.312230                1.254147   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "MAE              1.354807  \n",
      "MSE              2.017356  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "MAE  0.840013    0.643058             1.930973                1.322353   \n",
      "MSE  1.004965    0.451095             4.614378                1.799255   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "MAE              1.408145  \n",
      "MSE              2.029935  \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------------#\")\n",
    "print(\"Training-Set Performance\")\n",
    "print(\"#----------------------#\")\n",
    "print(Type_A_Prediction)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"#------------------#\")\n",
    "print(\"Test-Set Performance\")\n",
    "print(\"#------------------#\")\n",
    "print(Type_A_Prediction_test)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Performance\n",
    "Randomly subsample from output space and visualize empirical measures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adjust if is number of plots to visualizes is larger than number of output distributions (But only if there is not enough data!)\n",
    "# if N_Grid_Instances <= Visualization_Size**2:\n",
    "#         Visualization_Size = int(round(np.sqrt(min(N_Grid_Instances,Visualization_Size**2)))-1)\n",
    "\n",
    "\n",
    "# # Initialize Random Sample of input-output pairs to visualize\n",
    "# plotting_distribution_indices = random.sample(range(N_Grid_Instances), (Visualization_Size)**2)\n",
    "\n",
    "# # Generate Plot\n",
    "# f, axarr = plt.subplots(Visualization_Size,Visualization_Size,figsize=(6, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "# plt.suptitle(\"Sample of Predictions\")\n",
    "# for i in range(Visualization_Size):\n",
    "#     for j in range(Visualization_Size):\n",
    "#         # Get Current (Randomly chosen (uniformly)) Index\n",
    "#         current_index = (i*Visualization_Size + j)\n",
    "#         current_random_index = plotting_distribution_indices[current_index]\n",
    "#         # Generate Current Plot\n",
    "#         axarr[i,j].bar(Barycenters_Array,(Predicted_Weights[current_random_index].reshape(-1,)), alpha=0.5,label=\"Prediction\",color=\"chartreuse\")\n",
    "#         axarr[i,j].bar(measures_locations_list[current_random_index].reshape(-1,),measures_weights_list[current_random_index], alpha=0.5,label=\"Target\",color=\"purple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
