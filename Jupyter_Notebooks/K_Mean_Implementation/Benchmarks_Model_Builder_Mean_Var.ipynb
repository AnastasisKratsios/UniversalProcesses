{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributional Model(s)\n",
    "\n",
    "**Note:** *NB, this means that this script *must* be run after the point-mass benchmarks script!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GPR(X_train_in,X_test_in,y_means_in):\n",
    "    # Initialize Cross-Vlidator of GPR\n",
    "    CV_GPR = RandomizedSearchCV(estimator=GaussianProcessRegressor(),\n",
    "                                n_jobs=n_jobs,\n",
    "                                cv=KFold(2, random_state=2020, shuffle=True),\n",
    "                                param_distributions=param_grid_GAUSSIAN,\n",
    "                                n_iter=n_iter,\n",
    "                                return_train_score=True,\n",
    "                                random_state=2021,\n",
    "                                verbose=10)\n",
    "\n",
    "    CV_GPR.fit(X_train,Y_train_mean_emp)\n",
    "    # Get Best Model\n",
    "    best_GPR = CV_GPR.best_estimator_\n",
    "\n",
    "    # Get Training-Set Prediction\n",
    "    GPR_means = best_GPR.predict(X_train,return_std=True)[0]\n",
    "    GPR_vars = (best_GPR.predict(X_train,return_std=True)[1])**2\n",
    "\n",
    "    # Get Test-Set Predictions\n",
    "    GPR_test_time_prediction = time.time()\n",
    "    GPR_means_test = best_GPR.predict(X_test,return_std=True)[0]\n",
    "    GPR_vars_test = (best_GPR.predict(X_test,return_std=True)[1])**2\n",
    "    GPR_test_time_prediction = time.time() - GPR_test_time_prediction\n",
    "    \n",
    "    # Return Trained Predictions + Model\n",
    "    GPR_means_test = best_GPR.predict(X_test,return_std=True)[0]\n",
    "    return GPR_means,GPR_vars, GPR_means_test, GPR_vars_test, best_GPR, GPR_test_time_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Gaussian DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maps $\\varrho:\\mathbb{R}^d\\ni \\to (\\hat{\\mu},\\sigma)\\in \\mathbb{R}\\times (0,\\infty)$.  \n",
    "\n",
    "Implictly:\n",
    "$\n",
    "\\rho:\\mathbb{R}^d\\ni \\to \\nu\\circ \\varrho(x)\\in \\mathcal{P}_2(\\mathbb{R})\n",
    ".\n",
    "$\n",
    "\n",
    "The universal approximation theorem for this architecture is given in [Corollary 7: Quantitative Rates and Fundamental Obstructions to Non-EuclideanUniversal Approximation with Deep Narrow Feed-Forward Networks](https://arxiv.org/pdf/2101.05390.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian_Splitter(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(fullyConnected_Dense, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def call(self):\n",
    "        return tf.math.pow(self,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ffNN_Gaussian(height, depth, learning_rate, input_dim, output_dim):\n",
    "    #----------------------------#\n",
    "    # Maximally Interacting Layer #\n",
    "    #-----------------------------#\n",
    "    # Initialize Inputs\n",
    "    input_layer = tf.keras.Input(shape=(input_dim,))\n",
    "   \n",
    "    \n",
    "    #------------------#\n",
    "    #   Core Layers    #\n",
    "    #------------------#\n",
    "    core_layers = fullyConnected_Dense(height)(input_layer)\n",
    "    # Activation\n",
    "    core_layers = tf.nn.swish(core_layers)\n",
    "    # Train additional Depth?\n",
    "    if depth>1:\n",
    "        # Add additional deep layer(s)\n",
    "        for depth_i in range(1,depth):\n",
    "            core_layers = fullyConnected_Dense(height)(core_layers)\n",
    "            # Activation\n",
    "            core_layers = tf.nn.swish(core_layers)\n",
    "    core_layers = fullyConnected_Dense(output_dim)(core_layers)  \n",
    "    #------------------#\n",
    "    #  Readout Layers  #\n",
    "    #------------------# \n",
    "    # Gaussian Splitter Layer\n",
    "    output_layers = Gaussian_Splitter(core_layers)\n",
    "    # Define Input/Output Relationship (Arch.)\n",
    "    trainable_layers_model = tf.keras.Model(input_layer, output_layers)\n",
    "    \n",
    "    \n",
    "    #----------------------------------#\n",
    "    # Define Optimizer & Compile Archs.\n",
    "    #----------------------------------#\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    trainable_layers_model.compile(optimizer=opt, loss=\"mae\", metrics=[\"mse\", \"mae\", \"mape\"])\n",
    "\n",
    "    return trainable_layers_model\n",
    "\n",
    "\n",
    "\n",
    "def build_ffNN_Gaussian(n_folds , n_jobs, n_iter, param_grid_in, X_train, y_train,X_test):\n",
    "    # Update Dictionary\n",
    "    param_grid_in_internal = param_grid_in\n",
    "    param_grid_in_internal['input_dim'] = [(X_train.shape[1])]\n",
    "    \n",
    "    # Deep Feature Network\n",
    "    ffNN_CV = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=get_ffNN_Gaussian, \n",
    "                                                            verbose=True)\n",
    "    \n",
    "    # Randomized CV\n",
    "    ffNN_CVer = RandomizedSearchCV(estimator=ffNN_CV, \n",
    "                                    n_jobs=n_jobs,\n",
    "                                    cv=KFold(n_folds, random_state=2020, shuffle=True),\n",
    "                                    param_distributions=param_grid_in_internal,\n",
    "                                    n_iter=n_iter,\n",
    "                                    return_train_score=True,\n",
    "                                    random_state=2020,\n",
    "                                    verbose=10)\n",
    "    \n",
    "    # Fit Model #\n",
    "    #-----------#\n",
    "    ffNN_CVer.fit(X_train,y_train)\n",
    "\n",
    "    # Write Predictions #\n",
    "    #-------------------#\n",
    "    y_hat_train = ffNN_CVer.predict(X_train)\n",
    "    \n",
    "    eval_time_ffNN = time.time()\n",
    "    y_hat_test = ffNN_CVer.predict(X_test)\n",
    "    eval_time_ffNN = time.time() - eval_time_ffNN\n",
    "    \n",
    "    # Counter number of parameters #\n",
    "    #------------------------------#\n",
    "    # Extract Best Model\n",
    "    best_model = ffNN_CVer.best_estimator_\n",
    "    # Count Number of Parameters\n",
    "    N_params_best_ffNN = np.sum([np.prod(v.get_shape().as_list()) for v in best_model.model.trainable_variables])\n",
    "    \n",
    "    \n",
    "    # Return Values #\n",
    "    #---------------#\n",
    "    return y_hat_train, y_hat_test, N_params_best_ffNN, eval_time_ffNN\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print('Deep Feature Builder - Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Output Layer\n",
    "UAP-Preserving\n",
    "$\\rho:\\mathbb{R}^d\\ni x \\mapsto (x_1,\\exp(x_2))\\in \\mathbb{R}\\times (0,\\infty)$; Thus, $\\rho_{\\star}[\\mathcal{NN}_{d,2}^{\\sigma}]$ is dense in $C(\\mathbb{R}^d,\\mathbb{R}\\times [0,\\infty))$ by [this paper's main result.](https://proceedings.neurips.cc/paper/2020/hash/786ab8c4d7ee758f80d57e65582e609d-Abstract.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine Readout post-composed with UAP-preserving readout map to G_d\n",
    "class Gaussian_Splitter(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=16, input_dim=32):\n",
    "        super(Gaussian_Splitter, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name='Weights_ffNN',\n",
    "                                 shape=(input_shape[-1], self.units),\n",
    "                               initializer='random_normal',\n",
    "                               trainable=True)\n",
    "        self.b = self.add_weight(name='bias_ffNN',\n",
    "                                 shape=(self.units,),\n",
    "                               initializer='random_normal',\n",
    "                               trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        parameters = tf.matmul(inputs, self.w) + self.b\n",
    "        mean_and_cov = tf.concat([parameters,tf.math.exp(parameters)],-1)\n",
    "        return mean_and_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implements the above deep network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ffNN_Gaussian(height, depth, learning_rate, input_dim, output_dim):\n",
    "    #----------------------------#\n",
    "    # Maximally Interacting Layer #\n",
    "    #-----------------------------#\n",
    "    # Initialize Inputs\n",
    "    input_layer = tf.keras.Input(shape=(input_dim,))\n",
    "   \n",
    "    \n",
    "    #------------------#\n",
    "    #   Core Layers    #\n",
    "    #------------------#\n",
    "    core_layers = fullyConnected_Dense(height)(input_layer)\n",
    "    # Activation\n",
    "    core_layers = tf.nn.swish(core_layers)\n",
    "    # Train additional Depth?\n",
    "    if depth>1:\n",
    "        # Add additional deep layer(s)\n",
    "        for depth_i in range(1,depth):\n",
    "            core_layers = fullyConnected_Dense(height)(core_layers)\n",
    "            # Activation\n",
    "            core_layers = tf.nn.swish(core_layers)\n",
    "    \n",
    "    #------------------#\n",
    "    #  Readout Layers  #\n",
    "    #------------------# \n",
    "    # Gaussian Splitter Layer\n",
    "    output_layers = Gaussian_Splitter(output_dim)(core_layers)  \n",
    "    # Define Input/Output Relationship (Arch.)\n",
    "    trainable_layers_model = tf.keras.Model(input_layer, output_layers)\n",
    "    \n",
    "    \n",
    "    #----------------------------------#\n",
    "    # Define Optimizer & Compile Archs.\n",
    "    #----------------------------------#\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    trainable_layers_model.compile(optimizer=opt, loss=\"mae\", metrics=[\"mse\", \"mae\", \"mape\"])\n",
    "\n",
    "    return trainable_layers_model\n",
    "\n",
    "\n",
    "\n",
    "def build_ffNN_Gaussian(n_folds , n_jobs, n_iter, param_grid_in, X_train, y_train,X_test):\n",
    "    # Update Dictionary\n",
    "    param_grid_in_internal = param_grid_in\n",
    "    param_grid_in_internal['input_dim'] = [(X_train.shape[1])]\n",
    "    \n",
    "    # Deep Feature Network\n",
    "    ffNN_CV = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=get_ffNN_Gaussian, \n",
    "                                                            verbose=True)\n",
    "    \n",
    "    # Randomized CV\n",
    "    ffNN_CVer = RandomizedSearchCV(estimator=ffNN_CV, \n",
    "                                    n_jobs=n_jobs,\n",
    "                                    cv=KFold(n_folds, random_state=2020, shuffle=True),\n",
    "                                    param_distributions=param_grid_in_internal,\n",
    "                                    n_iter=n_iter,\n",
    "                                    return_train_score=True,\n",
    "                                    random_state=2020,\n",
    "                                    verbose=10)\n",
    "    \n",
    "    # Fit Model #\n",
    "    #-----------#\n",
    "    ffNN_CVer.fit(X_train,y_train)\n",
    "\n",
    "    # Write Predictions #\n",
    "    #-------------------#\n",
    "    y_hat_train = ffNN_CVer.predict(X_train)\n",
    "    \n",
    "    eval_time_ffNN = time.time()\n",
    "    y_hat_test = ffNN_CVer.predict(X_test)\n",
    "    eval_time_ffNN = time.time() - eval_time_ffNN\n",
    "    \n",
    "    # Counter number of parameters #\n",
    "    #------------------------------#\n",
    "    # Extract Best Model\n",
    "    best_model = ffNN_CVer.best_estimator_\n",
    "    # Count Number of Parameters\n",
    "    N_params_best_ffNN = np.sum([np.prod(v.get_shape().as_list()) for v in best_model.model.trainable_variables])\n",
    "    \n",
    "    \n",
    "    # Return Values #\n",
    "    #---------------#\n",
    "    return y_hat_train, y_hat_test, N_params_best_ffNN, eval_time_ffNN\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print('Deep Feature Builder - Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRP_time = time.time()\n",
    "GPR_means, GPR_vars, GPR_means_test, GPR_vars_test, GPR_trash, GPR_test_time_prediction = get_GPR(X_train,X_test,Y_train_mean_emp) \n",
    "GRP_time = time.time() - GRP_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Gaussian Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer Parameters to train on *(for training-set)* for deep Gaussian Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations #\n",
    "#-----------------#\n",
    "print(\"Infering Parameters for Deep Gaussian Network to train on!\")\n",
    "# Start timer:\n",
    "timeBuilding_Training_Set_DGN = time.time()\n",
    "## Dummy Initialized Parameters\n",
    "initParams = [1, 1]\n",
    "## Count Data-set (outputed-samples) size\n",
    "n = Y_train.shape[1]\n",
    "\n",
    "# Get Optimized Parameters to train Deep Gaussian Network On\n",
    "for i in tqdm(range(X_train.shape[0])):\n",
    "    # Define Function Defining log-likelihood of Gaussian dist.\n",
    "    def gaussian_log_like(parameters_in):\n",
    "        mean = parameters_in[0]   \n",
    "        sigma = parameters_in[1]\n",
    "\n",
    "        # Calculate negative log likelihood\n",
    "        negative_log_likelihood = -np.sum(stats.norm.logpdf(Y_train[i,], loc=mean, scale=sigma))\n",
    "\n",
    "        return negative_log_likelihood\n",
    "    # Search for MAE Gaussian Parameters\n",
    "    results_loop = ((minimize(gaussian_log_like, initParams, method='Nelder-Mead')).x).reshape(1,-1)\n",
    "    \n",
    "    # Update Targets #\n",
    "    #----------------#\n",
    "    if i == 0:\n",
    "        Y_train_var_emp = results_loop\n",
    "    else:\n",
    "        Y_train_var_emp = np.append(Y_train_var_emp,results_loop,axis=0)\n",
    "# Stop timer:\n",
    "time.Building_Training_Set_DGN = time.time() - timeBuilding_Training_Set_DGN\n",
    "print(\"Done Getting Parameters for Deep Gaussian Network!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Network on Infered Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===============================\")\n",
    "print(\"Training Deep Gaussian Network!\")\n",
    "print(\"===============================\")\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [problem_dim]\n",
    "param_grid_Deep_Classifier['output_dim'] = [1]\n",
    "\n",
    "# Train simple deep classifier\n",
    "timer_DGP = time.time()\n",
    "Deep_Gaussian_train_parameters, Deep_Gaussian_test_parameters, N_params_deep_Gaussian, timer_output_Deep_Gaussian = build_ffNN_Gaussian(n_folds = CV_folds, \n",
    "                                                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                                                        n_iter = n_iter, \n",
    "                                                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                                                        X_train = X_train, \n",
    "                                                                                                                                        y_train = Y_train_var_emp,\n",
    "                                                                                                                                        X_test = X_test)\n",
    "# Format as float\n",
    "Deep_Gaussian_train_parameters = np.array(Deep_Gaussian_train_parameters,dtype=float)\n",
    "Deep_Gaussian_test_parameters = np.array(Deep_Gaussian_test_parameters,dtype=float)\n",
    "timer_DGP = time.time() - timer_DGP\n",
    "print(\"====================================\")\n",
    "print(\"Training Deep Gaussian Network!: END\")\n",
    "print(\"====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Quality and Prediction Metrics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Bootstraps = N_Boostraps_BCA\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\" Get Training Errors for: Gaussian Models\")\n",
    "print(\"#---------------------------------------#\")\n",
    "for i in tqdm(range((X_train.shape[0]))):    \n",
    "    # Get Samples\n",
    "    ## From: Deep Gaussian Network (DGN)\n",
    "    hat_mu_DGaussianNet = Deep_Gaussian_train_parameters[i,][0]\n",
    "    hat_sd_DGaussianNet = np.sqrt(Deep_Gaussian_train_parameters[i,][1])\n",
    "    sample_DGaussianNet = np.random.normal(hat_mu_DGaussianNet,hat_sd_DGaussianNet,N_Monte_Carlo_Samples)\n",
    "    ## From: Gaussian Process Regressor (GPR)\n",
    "    hat_mu_GRP = GPR_means[i]\n",
    "    hat_sd_GPR = np.sqrt(GPR_vars[i])\n",
    "    sample_GRP = np.random.normal(hat_mu_GRP,hat_sd_GPR,N_Monte_Carlo_Samples)\n",
    "    \n",
    "    # Compute Error(s)\n",
    "    ## W1\n",
    "    ### DGN\n",
    "    W1_loop_DGN = ot.emd2_1d(sample_DGaussianNet,\n",
    "                             np.array(Y_train[i,]).reshape(-1,),\n",
    "                             empirical_weights,\n",
    "                             empirical_weights)\n",
    "    ### GPR\n",
    "    W1_loop_GPR = ot.emd2_1d(sample_GRP,\n",
    "                             np.array(Y_train[i,]).reshape(-1,),\n",
    "                             empirical_weights,\n",
    "                             empirical_weights)\n",
    "    \n",
    "    ## M1\n",
    "    Mu_MC = np.mean(np.array(Y_train[i,]))\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Mu = direct_facts[i,]\n",
    "    else:\n",
    "        Mu = Mu_MC\n",
    "    ### Error(s)\n",
    "    Mean_loop_DGN = (hat_mu_DGaussianNet-Mu)\n",
    "    Mean_loop_GPR = (hat_mu_GRP-Mu_MC)\n",
    "    \n",
    "    ## Variance\n",
    "    Var_loop_DGN = hat_sd_DGaussianNet**2\n",
    "    Var_loop_GPR = hat_sd_GPR**2\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Var = 2*np.sum(X_train[i,]**2)\n",
    "    else:\n",
    "        Var_MC = np.mean(np.array(Y_train[i]-Mu_MC)**2)\n",
    "        Var = Var_MC     \n",
    "    ### Error(s)\n",
    "    Var_loop_DGN = np.abs(Var_loop_DGN-Var)\n",
    "    Var_loop_GPR = np.abs(Mean_loop_GPR-Var)\n",
    "        \n",
    "    # Skewness\n",
    "    Skewness_DGN = 0\n",
    "    Skewness_GPR = 0\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Skewness = 0\n",
    "    else:\n",
    "        Skewness_MC = np.mean((np.array(Y_train[i]-Mu_MC)/Var_MC)**3)\n",
    "        Skewness = Skewness_MC\n",
    "    ### Error(s)\n",
    "    Skewness_loop_DGN = np.abs(Skewness_DGN-Skewness)\n",
    "    Skewness_loop_GPR = np.abs(Skewness_GPR-Skewness)\n",
    "    \n",
    "    # Skewness\n",
    "    Ex_Kurtosis_DGN = 0\n",
    "    Ex_Kurtosis_GPR = 0\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Ex_Kurtosis = 3\n",
    "    else:\n",
    "        Ex_Kurtosis_MC = np.mean((np.array(Y_train[i]-Mu_MC)/Var_MC)**4) - 3\n",
    "        Ex_Kurtosis = Ex_Kurtosis_MC\n",
    "    ### Error(s)\n",
    "    Ex_Kurtosis_loop_DGN = np.abs(Ex_Kurtosis-Ex_Kurtosis_DGN)\n",
    "    Ex_Kurtosis_loop_GPR = np.abs(Ex_Kurtosis-Ex_Kurtosis_GPR)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get Higher Moments Loss\n",
    "#     Higher_momentserrors_loop_GPR,Higher_MC_momentserrors_loop_GPR = Higher_Moments_Loss(sample_GRP,np.array(Y_train[i,]))\n",
    "#     Higher_momentserrors_loop_DGN,Higher_MC_momentserrors_loop_DGN = Higher_Moments_Loss(sample_DGaussianNet,np.array(Y_train[i,]))\n",
    "    \n",
    "    \n",
    "    # Update\n",
    "    if i == 0:\n",
    "        W1_Errors_GPR = W1_loop_GPR\n",
    "        W1_Errors_DGN = W1_loop_DGN\n",
    "        # Moments\n",
    "        ## GPR\n",
    "        Mean_Errors_GPR =  Mean_loop_GPR\n",
    "        Var_Errors_GPR = Var_loop_GPR\n",
    "        Skewness_Errors_GPR = Skewness_loop_GPR\n",
    "        Ex_Kurtosis_Errors_GPR = Ex_Kurtosis_loop_GPR\n",
    "#         Higher_Moments_Errors_GPR = Higher_momentserrors_loop_GPR\n",
    "        ## DGN\n",
    "        Mean_Errors_DGN =  Mean_loop_DGN\n",
    "        Var_Errors_DGN = Var_loop_DGN\n",
    "        Skewness_Errors_DGN = Skewness_loop_DGN\n",
    "        Ex_Kurtosis_Errors_DGN = Ex_Kurtosis_loop_DGN\n",
    "#         Higher_Moments_Errors_DGN = Higher_momentserrors_loop_DGN\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        W1_Errors_GPR = np.append(W1_Errors_GPR,W1_loop_GPR)\n",
    "        W1_Errors_DGN = np.append(W1_Errors_DGN,W1_loop_DGN)\n",
    "        # Moments\n",
    "        ## GPR\n",
    "        Mean_Errors_GPR =  np.append(Mean_Errors_GPR,Mean_loop_GPR)\n",
    "        Var_Errors_GPR = np.append(Var_Errors_GPR,Var_loop_GPR)\n",
    "        Skewness_Errors_GPR = np.append(Skewness_Errors_GPR,Skewness_loop_GPR)\n",
    "        Ex_Kurtosis_Errors_GPR = np.append(Ex_Kurtosis_Errors_GPR,Ex_Kurtosis_loop_GPR)\n",
    "#         Higher_Moments_Errors_GPR = np.append(Higher_Moments_Errors_GPR,Higher_momentserrors_loop_GPR)\n",
    "        ## DGN\n",
    "        Mean_Errors_DGN =  np.append(Mean_Errors_DGN,Mean_loop_DGN)\n",
    "        Var_Errors_DGN = np.append(Var_Errors_DGN,Var_loop_DGN)\n",
    "        Skewness_Errors_DGN = np.append(Skewness_Errors_DGN,Skewness_loop_DGN)\n",
    "        Ex_Kurtosis_Errors_DGN = np.append(Ex_Kurtosis_Errors_DGN,Ex_Kurtosis_loop_DGN)\n",
    "#         Higher_Moments_Errors_DGN = np.append(Higher_Moments_Errors_DGN,Higher_momentserrors_loop_DGN)\n",
    "        \n",
    "    \n",
    "# Compute Error Metrics with Bootstrapped Confidence Intervals\n",
    "W1_Errors_GPR = np.array(bootstrap(np.abs(W1_Errors_GPR),n=N_Bootstraps)(.95))\n",
    "W1_Errors_DGN = np.array(bootstrap(np.abs(W1_Errors_DGN),n=N_Bootstraps)(.95))\n",
    "Mean_Errors_GPR = np.array(bootstrap(np.abs(Mean_Errors_GPR),n=N_Bootstraps)(.95))\n",
    "Mean_Errors_DGN = np.array(bootstrap(np.abs(Mean_Errors_DGN),n=N_Bootstraps)(.95))\n",
    "Var_Errors_GPR = np.array(bootstrap(np.abs(Var_Errors_GPR),n=N_Bootstraps)(.95))\n",
    "Var_Errors_DGN = np.array(bootstrap(np.abs(Var_Errors_DGN),n=N_Bootstraps)(.95))\n",
    "Skewness_Errors_GPR = np.array(bootstrap(np.abs(Skewness_Errors_GPR),n=N_Bootstraps)(.95))\n",
    "Skewness_Errors_DGN = np.array(bootstrap(np.abs(Skewness_Errors_DGN),n=N_Bootstraps)(.95))\n",
    "Ex_Kurtosis_Errors_GPR = np.array(bootstrap(np.abs(Ex_Kurtosis_Errors_GPR),n=N_Bootstraps)(.95))\n",
    "Ex_Kurtosis_Errors_DGN = np.array(bootstrap(np.abs(Ex_Kurtosis_Errors_DGN),n=N_Bootstraps)(.95))\n",
    "#     Higher_Moment_Errors = np.array(bootstrap(np.abs(Higher_Moments_Errors),n=N_Bootstraps)(.95))\n",
    "\n",
    "# Format Error Metrics\n",
    "Summary_pred_Qual_models_DGN_train = np.array([W1_Errors_DGN,\n",
    "                                               Mean_Errors_DGN,\n",
    "                                               Var_Errors_DGN,\n",
    "                                               Skewness_Errors_DGN,\n",
    "                                               Ex_Kurtosis_Errors_DGN])\n",
    "Summary_pred_Qual_models_GPR_train = np.array([W1_Errors_GPR,\n",
    "                                               Mean_Errors_GPR,\n",
    "                                               Var_Errors_GPR,\n",
    "                                               Skewness_Errors_GPR,\n",
    "                                               Ex_Kurtosis_Errors_GPR])\n",
    "print(\"#-------------------------#\")\n",
    "print(\" Get Training Error(s): END\")\n",
    "print(\"#-------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Bootstraps = N_Boostraps_BCA\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\" Get Testing Errors for: Gaussian Models\")\n",
    "print(\"#---------------------------------------#\")\n",
    "for i in tqdm(range((X_test.shape[0]))):    \n",
    "    # Get Samples\n",
    "    ## From: Deep Gaussian Network (DGN)\n",
    "    hat_mu_DGaussianNet_test = Deep_Gaussian_test_parameters[i,][0]\n",
    "    hat_sd_DGaussianNet_test = np.sqrt(Deep_Gaussian_test_parameters[i,][1])\n",
    "    sample_DGaussianNet_test = np.random.normal(hat_mu_DGaussianNet_test,hat_sd_DGaussianNet_test,N_Monte_Carlo_Samples)\n",
    "    ## From: Gaussian Process Regressor (GPR)\n",
    "    hat_mu_GRP_test = GPR_means_test[i]\n",
    "    hat_sd_GPR_test = np.sqrt(GPR_vars_test[i])\n",
    "    sample_GRP_test = np.random.normal(hat_mu_GRP_test,hat_sd_GPR_test,N_Monte_Carlo_Samples)\n",
    "    \n",
    "    # Compute Error(s)\n",
    "    ## W1\n",
    "    ### DGN\n",
    "    W1_loop_DGN_test = ot.emd2_1d(sample_DGaussianNet_test,\n",
    "                             np.array(Y_test[i,]).reshape(-1,),\n",
    "                             empirical_weights,\n",
    "                             empirical_weights)\n",
    "    ### GPR\n",
    "    W1_loop_GPR_test = ot.emd2_1d(sample_GRP_test,\n",
    "                             np.array(Y_test[i,]).reshape(-1,),\n",
    "                             empirical_weights,\n",
    "                             empirical_weights)\n",
    "    \n",
    "    ## M1\n",
    "    Mu_MC_test = np.mean(np.array(Y_test[i,]))\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Mu_test = direct_facts_test[i,]\n",
    "    else:\n",
    "        Mu_test = Mu_MC_test\n",
    "    ### Error(s)\n",
    "    Mean_loop_DGN_test = (hat_mu_DGaussianNet_test-Mu_test)\n",
    "    Mean_loop_GPR_test = (hat_mu_GRP_test-Mu_MC_test)\n",
    "    \n",
    "    ## Variance\n",
    "    Var_loop_DGN_test = hat_sd_DGaussianNet_test**2\n",
    "    Var_loop_GPR_test = hat_sd_GPR_test**2\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Var_test = 2*np.sum(X_test[i,]**2)\n",
    "    else:\n",
    "        Var_MC_test = np.mean(np.array(Y_test[i]-Mu_MC_test)**2)\n",
    "        Var_test = Var_MC_test\n",
    "    ### Error(s)\n",
    "    Var_loop_DGN_test = np.abs(Var_loop_DGN_test-Var_test)\n",
    "    Var_loop_GPR_test = np.abs(Mean_loop_GPR_test-Var_test)\n",
    "        \n",
    "    # Skewness\n",
    "    Skewness_DGN_test = 0\n",
    "    Skewness_GPR_test = 0\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Skewness_test = 0\n",
    "    else:\n",
    "        Skewness_MC_test = np.mean((np.array(Y_test[i]-Mu_MC_test)/Var_MC_test)**3)\n",
    "        Skewness_test = Skewness_MC_test\n",
    "    ### Error(s)\n",
    "    Skewness_loop_DGN = np.abs(Skewness_DGN-Skewness)\n",
    "    Skewness_loop_GPR = np.abs(Skewness_GPR-Skewness)\n",
    "    \n",
    "    # Skewness\n",
    "    Ex_Kurtosis_DGN_test = 0\n",
    "    Ex_Kurtosis_GPR_test = 0\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Ex_Kurtosis_test = 3\n",
    "    else:\n",
    "        Ex_Kurtosis_MC_test = np.mean((np.array(Y_test[i]-Mu_MC)/Var_MC_test)**4) - 3\n",
    "        Ex_Kurtosis_test = Ex_Kurtosis_MC_test\n",
    "    ### Error(s)\n",
    "    Ex_Kurtosis_loop_DGN_test = np.abs(Ex_Kurtosis_test-Ex_Kurtosis_DGN_test)\n",
    "    Ex_Kurtosis_loop_GPR_test = np.abs(Ex_Kurtosis_test-Ex_Kurtosis_GPR_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get Higher Moments Loss\n",
    "#     Higher_momentserrors_loop_GPR,Higher_MC_momentserrors_loop_GPR = Higher_Moments_Loss(sample_GRP,np.array(Y_train[i,]))\n",
    "#     Higher_momentserrors_loop_DGN,Higher_MC_momentserrors_loop_DGN = Higher_Moments_Loss(sample_DGaussianNet,np.array(Y_train[i,]))\n",
    "    \n",
    "    \n",
    "    # Update\n",
    "    if i == 0:\n",
    "        W1_Errors_GPR_test = W1_loop_GPR_test\n",
    "        W1_Errors_DGN_test = W1_loop_DGN_test\n",
    "        # Moments\n",
    "        ## GPR\n",
    "        Mean_Errors_GPR_test =  Mean_loop_GPR_test\n",
    "        Var_Errors_GPR_test = Var_loop_GPR_test\n",
    "        Skewness_Errors_GPR_test = Skewness_GPR_test\n",
    "        Ex_Kurtosis_Errors_GPR_test = Ex_Kurtosis_loop_GPR_test\n",
    "#         Higher_Moments_Errors_GPR = Higher_momentserrors_loop_GPR\n",
    "        ## DGN\n",
    "        Mean_Errors_DGN_test =  Mean_loop_DGN_test\n",
    "        Var_Errors_DGN_test = Var_loop_DGN_test\n",
    "        Skewness_Errors_DGN_test = Skewness_DGN_test\n",
    "        Ex_Kurtosis_Errors_DGN_test = Ex_Kurtosis_loop_DGN_test\n",
    "#         Higher_Moments_Errors_DGN = Higher_momentserrors_loop_DGN\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        W1_Errors_GPR_test = np.append(W1_Errors_GPR_test,W1_loop_GPR_test)\n",
    "        W1_Errors_DGN_test = np.append(W1_Errors_DGN_test,W1_loop_DGN_test)\n",
    "        # Moments\n",
    "        ## GPR\n",
    "        Mean_Errors_GPR_test =  np.append(Mean_Errors_GPR_test,Mean_loop_GPR_test)\n",
    "        Var_Errors_GPR_test = np.append(Var_Errors_GPR_test,Var_loop_GPR_test)\n",
    "        Skewness_Errors_GPR_test = np.append(Skewness_Errors_GPR_test,Skewness_GPR_test)\n",
    "        Ex_Kurtosis_Errors_GPR_test = np.append(Ex_Kurtosis_Errors_GPR_test,Ex_Kurtosis_loop_GPR_test)\n",
    "#         Higher_Moments_Errors_GPR = np.append(Higher_Moments_Errors_GPR,Higher_momentserrors_loop_GPR)\n",
    "        ## DGN\n",
    "        Mean_Errors_DGN_test =  np.append(Mean_Errors_DGN_test,Mean_loop_DGN_test)\n",
    "        Var_Errors_DGN_test = np.append(Var_Errors_DGN_test,Var_loop_DGN_test)\n",
    "        Skewness_Errors_DGN_test = np.append(Skewness_Errors_DGN_test,Skewness_DGN_test)\n",
    "        Ex_Kurtosis_Errors_DGN_test = np.append(Ex_Kurtosis_Errors_DGN_test,Ex_Kurtosis_loop_DGN_test)\n",
    "#         Higher_Moments_Errors_DGN = np.append(Higher_Moments_Errors_DGN,Higher_momentserrors_loop_DGN)\n",
    "        \n",
    "    \n",
    "# Compute Error Metrics with Bootstrapped Confidence Intervals\n",
    "W1_Errors_GPR_test = np.array(bootstrap(np.abs(W1_Errors_GPR_test),n=N_Bootstraps)(.95))\n",
    "W1_Errors_DGN_test = np.array(bootstrap(np.abs(W1_Errors_DGN_test),n=N_Bootstraps)(.95))\n",
    "Mean_Errors_GPR_test = np.array(bootstrap(np.abs(Mean_Errors_GPR_test),n=N_Bootstraps)(.95))\n",
    "Mean_Errors_DGN_test = np.array(bootstrap(np.abs(Mean_Errors_DGN_test),n=N_Bootstraps)(.95))\n",
    "Var_Errors_GPR_test = np.array(bootstrap(np.abs(Var_Errors_GPR_test),n=N_Bootstraps)(.95))\n",
    "Var_Errors_DGN_test = np.array(bootstrap(np.abs(Var_Errors_DGN_test),n=N_Bootstraps)(.95))\n",
    "Skewness_Errors_GPR_test = np.array(bootstrap(np.abs(Skewness_Errors_GPR_test),n=N_Bootstraps)(.95))\n",
    "Skewness_Errors_DGN_test = np.array(bootstrap(np.abs(Skewness_Errors_DGN_test),n=N_Bootstraps)(.95))\n",
    "Ex_Kurtosis_Errors_GPR_test = np.array(bootstrap(np.abs(Ex_Kurtosis_Errors_GPR_test),n=N_Bootstraps)(.95))\n",
    "Ex_Kurtosis_Errors_DGN_test = np.array(bootstrap(np.abs(Ex_Kurtosis_Errors_DGN_test),n=N_Bootstraps)(.95))\n",
    "#     Higher_Moment_Errors = np.array(bootstrap(np.abs(Higher_Moments_Errors),n=N_Bootstraps)(.95))\n",
    "\n",
    "# Format Error Metrics\n",
    "Summary_pred_Qual_models_DGN_test = np.array([W1_Errors_DGN_test,\n",
    "                                              Mean_Errors_DGN_test,\n",
    "                                              Var_Errors_DGN_test,\n",
    "                                              Skewness_Errors_DGN_test,\n",
    "                                              Ex_Kurtosis_Errors_DGN_test])\n",
    "Summary_pred_Qual_models_GPR_test = np.array([W1_Errors_GPR_test,\n",
    "                                              Mean_Errors_GPR_test,\n",
    "                                              Var_Errors_GPR_test,\n",
    "                                              Skewness_Errors_GPR_test,\n",
    "                                              Ex_Kurtosis_Errors_GPR_test])\n",
    "print(\"#------------------------#\")\n",
    "print(\" Get Testing Error(s): END\")\n",
    "print(\"#------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Performance Metrics:\n",
    "NB, this means that this script *must* be run after the point-mass benchmarks script!\n",
    "\n",
    "## Update Prediction-Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------------------------------------------\")\n",
    "print(\"Updating Performance Metrics Dataframe and Saved!\")\n",
    "print(\"-------------------------------------------------\")\n",
    "# Append Gaussian Process Regressor Performance\n",
    "## Train\n",
    "Summary_pred_Qual_models[\"GPR\"] = pd.Series((Summary_pred_Qual_models_GPR_train[:,1]), index=Summary_pred_Qual_models.index)\n",
    "## Test\n",
    "Summary_pred_Qual_models_test[\"GPR\"] = pd.Series((Summary_pred_Qual_models_GPR_test[:,1]), index=Summary_pred_Qual_models_test.index)\n",
    "\n",
    "# Append Deep Gaussian Network Performance\n",
    "## Train\n",
    "Summary_pred_Qual_models[\"DGN\"] = pd.Series((Summary_pred_Qual_models_DGN_train[:,1]), index=Summary_pred_Qual_models.index)\n",
    "## Test\n",
    "Summary_pred_Qual_models_test[\"DGN\"] = pd.Series((Summary_pred_Qual_models_DGN_test[:,1]), index=Summary_pred_Qual_models_test.index)\n",
    "\n",
    "# Update Performance Metrics\n",
    "## Train\n",
    "Summary_pred_Qual_models.to_latex((results_tables_path+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS.tex\"))\n",
    "## Test\n",
    "Summary_pred_Qual_models_test.to_latex((results_tables_path+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS_test.tex\"))\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Updated Performance Metrics Dataframe and Saved!\")\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Model Complexity Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Performance Metrics for GPR and DGN Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------------------\")\n",
    "print(\"Computing and Updating Complexity Metrics...\")\n",
    "print(\"--------------------------------------------\")\n",
    "# Coercion\n",
    "Summary_Complexity_models = Summary_Complexity_models.T\n",
    "# Compute Complexity Metrics for GPR\n",
    "GPR_Facts = np.array([0,GRP_time,GPR_test_time_prediction/Test_Set_PredictionTime_MC])\n",
    "DGN_Facts = np.array([N_params_deep_Gaussian,timer_DGP,timer_output_Deep_Gaussian/Test_Set_PredictionTime_MC])\n",
    "# Update Model Complexities\n",
    "Summary_Complexity_models[\"GPR\"] = pd.Series(GPR_Facts, index=Summary_Complexity_models.index)\n",
    "Summary_Complexity_models[\"DGN\"] = pd.Series(DGN_Facts, index=Summary_Complexity_models.index)\n",
    "# Coercion\n",
    "Summary_Complexity_models = Summary_Complexity_models.T\n",
    "\n",
    "# Save Facts\n",
    "Summary_Complexity_models.to_latex((results_tables_path+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__Complexity_Metrics.tex\"))\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"Updated Complexity Metrics Dataframe and Saved!\")\n",
    "print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
