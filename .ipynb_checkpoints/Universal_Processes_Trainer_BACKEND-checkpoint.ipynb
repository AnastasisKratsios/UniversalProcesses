{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*.\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth:\n",
    "*The build-in Options:*\n",
    "- rSDE \n",
    "- pfBM\n",
    "- 2lnflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth = \"2lnflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 100\n",
    "N_Monte_Carlo_Samples = 10**3\n",
    "N_Monte_Carlo_Samples_Test = 10**3 # How many MC-samples to draw from test-set?\n",
    "\n",
    "# End times for Time-Grid\n",
    "T_end = 1\n",
    "T_end_test = 1.1\n",
    "\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 3\n",
    "Max_Grid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP:\n",
    "from operator import itemgetter \n",
    "from itertools import compress\n",
    "# Set Minibatch Size\n",
    "Random_Cover_Mini_Batch_Size = 25\n",
    "# Proportion of Clusters per Minibatch Sample\n",
    "Quantization_Proportion = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Measure-Valued $2$-Parameter Gaussian Flow\n",
    "$$\n",
    "X_{t,x} \\sim \\mathcal{N}\\left(\\alpha(t,x),\\beta(t,x)\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** *$\\alpha$ and $\\beta$ are specified below in the SDE Example*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Rough SDE\n",
    "Simulate via Euler-M method from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T((1-\\eta)\\beta(s,x)+\\eta\\sigma_s^H)dW_s.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return 1 - .5*(.1**2)#t*np.sin(math.pi*x) + np.exp(-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return .5#(1+t) + np.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rougness = 0.9 # Hurst Parameter\n",
    "Ratio_fBM_to_typical_vol = 0 # $\\eta$ in equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed Fractional Brownian Motion\n",
    "Simulate from:\n",
    "$$\n",
    "X_t^x(\\omega) = f_1(x)f_2(t) + B_t^H(\\omega).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_dirction_x(x):\n",
    "    return x*np.cos(x)\n",
    "\n",
    "def finite_variation_t(t):\n",
    "    return t*(np.sin(math.pi*t) + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "# %run ParaGAN_Backend.ipynb\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Grid\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in each minibatch grid axis:  5\n",
      "â€¢ Grid Instances:  303 and : 1976  Testing instances.\n"
     ]
    }
   ],
   "source": [
    "# Get Input Data\n",
    "#----------------------------------------------------------#\n",
    "## Train\n",
    "x_Grid = np.arange(start=-Max_Grid,\n",
    "                   stop=Max_Grid,\n",
    "                   step=(2*Max_Grid/N_Grid_Finess))\n",
    "t_Grid = np.linspace(0,T_end,(1+N_Euler_Maruyama_Steps))\n",
    "## Get Number of Instances in Grid: Training\n",
    "N_Grid_Instances_x = len(x_Grid)\n",
    "N_Grid_Instances_t = len(t_Grid)\n",
    "N_Grid_Instances = N_Grid_Instances_x*N_Grid_Instances_t \n",
    "\n",
    "#----------------------------------------------------------#\n",
    "## Test\n",
    "x_Grid_test = np.sort(np.random.uniform(low=-Max_Grid,\n",
    "                                        high=Max_Grid,\n",
    "                                        size = round(N_Grid_Instances*test_size_ratio)))\n",
    "t_Grid_test = np.linspace(T_end+0.001,T_end_test,(1+round(N_Euler_Maruyama_Steps*test_size_ratio)))\n",
    "# Get Number of Instances in Grid: Test\n",
    "N_Grid_Instances_x_test = len(x_Grid_test)\n",
    "N_Grid_Instances_t_test = len(t_Grid_test)\n",
    "N_Grid_Instances_test = N_Grid_Instances_x_test*N_Grid_Instances_t_test\n",
    "#----------------------------------------------------------#\n",
    "\n",
    "# Set Minibatch size\n",
    "Covering_Mini_Batch_Size = int(np.max(round(np.sqrt(Random_Cover_Mini_Batch_Size),1)))\n",
    "print(\"Number of points in each minibatch grid axis: \", Covering_Mini_Batch_Size)\n",
    "\n",
    "# Updater User\n",
    "print(\"\\u2022 Grid Instances: \", N_Grid_Instances, \"and :\",N_Grid_Instances_test,\" Testing instances.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Counting Parameters\n",
    "Initialize the \"conting\" type parameters which will help us to determine the length of loops and to intialize object's size later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ 152  Centers will be produced; from a total datasize of:  3 !  (That's  0.5  percent).\n",
      "â€¢ Each Wasserstein-1 Ball should contain:  2 elements from the training set.\n"
     ]
    }
   ],
   "source": [
    "# Get Internal (Counting) Parameters\n",
    "N_Quantizers_to_parameterize = round(Quantization_Proportion*N_Grid_Instances)\n",
    "N_Elements_Per_Cluster = int(round(N_Grid_Instances/N_Quantizers_to_parameterize))\n",
    "\n",
    "# Update User\n",
    "print(\"\\u2022\",N_Quantizers_to_parameterize,\" Centers will be produced; from a total datasize of: \",N_Grid_Finess,\n",
    "      \"!  (That's \",Quantization_Proportion,\n",
    "      \" percent).\")\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate from non-Markovian SDE with rough volatility:\n",
    "$d X_t = \\alpha(t,X_t)dt + ((1-\\eta)\\beta(t,X_t)+\\eta\\sigma_t^H)dW_t ;\\qquad X_0 =x$\n",
    "Where $(\\sigma_t^H)_t$ is a fBM with Hurst parameter $H=0.01$ and $\\eta \\in [0,1]$ controlls the 'abount of long-term memory and roughness in $X_t$'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Sampler - Data-Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euler_Maruyama_Generator(x_0,\n",
    "                             N_Euler_Maruyama_Steps = 10,\n",
    "                             N_Monte_Carlo_Samples = 100,\n",
    "                             T = 1,\n",
    "                             Hurst = 0.1,\n",
    "                             Ratio_fBM_to_typical_vol = 0.5): \n",
    "    \n",
    "    #----------------------------#    \n",
    "    # DEFINE INTERNAL PARAMETERS #\n",
    "    #----------------------------#\n",
    "    # Initialize Empirical Measure\n",
    "    X_T_Empirical = np.zeros([N_Euler_Maruyama_Steps,N_Monte_Carlo_Samples])\n",
    "\n",
    "\n",
    "    # Internal Initialization(s)\n",
    "    ## Initialize current state\n",
    "    n_sample = 0\n",
    "    ## Initialize Incriments\n",
    "    dt = T/N_Euler_Maruyama_Steps\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "\n",
    "    #-----------------------------#    \n",
    "    # Generate Monte-Carlo Sample #\n",
    "    #-----------------------------#\n",
    "    while n_sample < N_Monte_Carlo_Samples:\n",
    "        # Reset Step Counter\n",
    "        t = 1\n",
    "        # Initialize Current State \n",
    "        X_current = x_0\n",
    "        # Generate roughness\n",
    "        sigma_rough = FBM(n=N_Euler_Maruyama_Steps, hurst=0.75, length=1, method='daviesharte').fbm()\n",
    "        # Perform Euler-Maruyama Simulation\n",
    "        while t<(N_Euler_Maruyama_Steps-1):\n",
    "            # Update Internal Parameters\n",
    "            ## Get Current Time\n",
    "            t_current = t*(T/N_Euler_Maruyama_Steps)\n",
    "\n",
    "            # Update Generated Path\n",
    "            drift_t = alpha(t_current,X_current)*dt\n",
    "            vol_t = ((1-Ratio_fBM_to_typical_vol)*beta(t_current,X_current)+Ratio_fBM_to_typical_vol*(sigma_rough[t]))*np.random.normal(0,sqrt_dt)\n",
    "            X_current = X_current + drift_t + vol_t\n",
    "\n",
    "            # Update Counter (EM)\n",
    "            t = t+1\n",
    "\n",
    "            # Update Empirical Measure\n",
    "            X_T_Empirical[t,n_sample] = X_current\n",
    "\n",
    "        # Update Counter (MC)\n",
    "        n_sample = n_sample + 1\n",
    "\n",
    "    return X_T_Empirical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List of Barycenters\n",
    "Wasserstein_Barycenters = []\n",
    "# Initialize Terminal-Time Empirical Measures\n",
    "## Training Outputs\n",
    "measures_locations_list = []\n",
    "measures_weights_list = []\n",
    "## Testing Outputs\n",
    "measures_locations_test_list = []\n",
    "measures_weights_test_list = []\n",
    "# Grid (Training and Testing inputs (t,x))\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "measure_weights_test = np.ones(N_Monte_Carlo_Samples_Test)/N_Monte_Carlo_Samples_Test\n",
    "# Initialize Quantizer\n",
    "Init_Quantizer_generic = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $\\{\\hat{\\nu}^{N}_{T,x}\\}_{x \\in \\mathbb{X}}$ Build Wasserstein Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Training and Testing Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian $2$-Parameter Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 107.43it/s]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct Sampling from Distribution for 2-Parameter Flow.\n",
      "===================================\n",
      "Start Simulation Step: Training Set\n",
      "===================================\n",
      "==================================\n",
      "Done Simulation Step: Training Set\n",
      "==================================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================\n",
      "Start Simulation Step: Test Set\n",
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:00<00:00, 440.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Done Simulation Step: Test Set\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if groud_truth == \"2lnflow\":\n",
    "    print(\"Direct Sampling from Distribution for 2-Parameter Flow.\")\n",
    "    #----------------------------------------------------------------------------------------------#\n",
    "    # Update User\n",
    "    print(\"===================================\")\n",
    "    print(\"Start Simulation Step: Training Set\")\n",
    "    print(\"===================================\")\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x)):\n",
    "        x_loop = x_Grid[i]\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        for j in range(N_Grid_Instances_t):\n",
    "            t_loop = t_Grid[j]\n",
    "            measures_locations_loop = np.random.lognormal(alpha(t_loop,x_loop),\n",
    "                                                          beta(t_loop,x_loop),\n",
    "                                                          N_Monte_Carlo_Samples)\n",
    "        \n",
    "            # Update Inputs\n",
    "            if (i==0 and j==0):\n",
    "                X_train = np.array([t_loop,x_loop]).reshape(1,-1)\n",
    "            else:\n",
    "                X_train = np.append(X_train,np.array([t_loop,x_loop]).reshape(1,-1),axis=0)\n",
    "        \n",
    "            # Append to List\n",
    "            measures_locations_list = measures_locations_list + [measures_locations_loop]\n",
    "            measures_weights_list.append(measure_weights)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Update User\n",
    "    print(\"==================================\")\n",
    "    print(\"Done Simulation Step: Training Set\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "\n",
    "if groud_truth == \"2lnflow\":\n",
    "    print(\"===============================\")\n",
    "    print(\"Start Simulation Step: Test Set\")\n",
    "    print(\"===============================\")\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x_test)):\n",
    "        x_loop = x_Grid_test[i]\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        for j in range(N_Grid_Instances_t_test):\n",
    "            t_loop = t_Grid_test[j]\n",
    "            measures_locations_loop = np.random.lognormal(alpha(t_loop,x_loop),\n",
    "                                                          beta(t_loop,x_loop),\n",
    "                                                          N_Monte_Carlo_Samples_Test)\n",
    "        \n",
    "            # Update Inputs\n",
    "            if (i==0 and j==0):\n",
    "                X_test = np.array([t_loop,x_loop]).reshape(1,-1)\n",
    "            else:\n",
    "                X_test = np.append(X_test,np.array([t_loop,x_loop]).reshape(1,-1),axis=0)\n",
    "        \n",
    "            # Append to List\n",
    "            measures_locations_test_list = measures_locations_test_list + [measures_locations_loop]\n",
    "            measures_weights_test_list.append(measure_weights_test)\n",
    "    print(\"==============================\")\n",
    "    print(\"Done Simulation Step: Test Set\")\n",
    "    print(\"==============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough SDE Simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n"
     ]
    }
   ],
   "source": [
    "if groud_truth == \"rSDE\":\n",
    "    print(\"Using Euler-Maruyama distritization + Monte-Carlo Sampling.\")\n",
    "    #----------------------------------------------------------------------------------------------#\n",
    "    # Update User\n",
    "    print(\"===================================\")\n",
    "    print(\"Start Simulation Step: Training Set\")\n",
    "    print(\"===================================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator = FBM(n=N_Euler_Maruyama_Steps, hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid).reshape(-1,1) +field_loop_x\n",
    "        # Simulate Paths\n",
    "        paths_loop = Euler_Maruyama_Generator(x_0=x_Grid[i],\n",
    "                                              N_Euler_Maruyama_Steps = len(t_Grid),\n",
    "                                              N_Monte_Carlo_Samples = N_Monte_Carlo_Samples,\n",
    "                                              T = T_end,\n",
    "                                              Hurst=Rougness,\n",
    "                                              Ratio_fBM_to_typical_vol=Ratio_fBM_to_typical_vol)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_train_loop = np.append(np.repeat(x_Grid[i],(N_Euler_Maruyama_Steps+1)).reshape(-1,1),\n",
    "                                 t_Grid.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_list = measures_locations_list + measures_locations_loop\n",
    "        measures_weights_list.append(measure_weights)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_train = X_train_loop\n",
    "        else:\n",
    "            X_train = np.append(X_train,X_train_loop,axis=0)\n",
    "    \n",
    "    # Update User\n",
    "    print(\"==================================\")\n",
    "    print(\"Done Simulation Step: Training Set\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "\n",
    "if groud_truth == \"rSDE\":\n",
    "    print(\"===============================\")\n",
    "    print(\"Start Simulation Step: Test Set\")\n",
    "    print(\"===============================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator_test = FBM(n=(len(t_Grid_test)-1), hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x_test)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid_test[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid_test).reshape(-1,1) +field_loop_x\n",
    "        paths_loop = Euler_Maruyama_Generator(x_0=x_Grid_test[i],\n",
    "                                              N_Euler_Maruyama_Steps = len(t_Grid_test),\n",
    "                                              N_Monte_Carlo_Samples = N_Monte_Carlo_Samples_Test,\n",
    "                                              T = T_end_test,\n",
    "                                              Hurst=Rougness,\n",
    "                                              Ratio_fBM_to_typical_vol=Ratio_fBM_to_typical_vol)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_test_loop = np.append(np.repeat(x_Grid_test[i],len(t_Grid_test)).reshape(-1,1),\n",
    "                                 t_Grid_test.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_test_list = measures_locations_test_list + measures_locations_loop\n",
    "        measures_weights_test_list.append(measure_weights_test)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_test = X_test_loop\n",
    "        else:\n",
    "            X_test = np.append(X_test,X_test_loop,axis=0)\n",
    "    print(\"==============================\")\n",
    "    print(\"Done Simulation Step: Test Set\")\n",
    "    print(\"==============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbed fBM Generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step:\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n",
      "===============================--------------------------------------===============================\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"Current Monte-Carlo Step:\")\n",
    "if groud_truth == \"pfBM\":\n",
    "    print(\"===================================\")\n",
    "    print(\"Start Simulation Step: Training Set\")\n",
    "    print(\"===================================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator = FBM(n=N_Euler_Maruyama_Steps, hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid).reshape(-1,1) +field_loop_x\n",
    "        for n_MC in range(N_Monte_Carlo_Samples):\n",
    "            fBM_variation_path_loop = fBM_Generator.fbm().reshape(-1,1)\n",
    "            generated_path_loop = finite_variation_path + fBM_variation_path_loop\n",
    "            if n_MC == 0:\n",
    "                paths_loop = generated_path_loop\n",
    "            else:\n",
    "                paths_loop = np.append(paths_loop,generated_path_loop,axis=-1)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_train_loop = np.append(np.repeat(x_Grid[i],(N_Euler_Maruyama_Steps+1)).reshape(-1,1),\n",
    "                                 t_Grid.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_list = measures_locations_list + measures_locations_loop\n",
    "        measures_weights_list.append(measure_weights)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_train = X_train_loop\n",
    "        else:\n",
    "            X_train = np.append(X_train,X_train_loop,axis=0)\n",
    "    \n",
    "    # Update User\n",
    "    print(\"==================================\")\n",
    "    print(\"Done Simulation Step: Training Set\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "\n",
    "if groud_truth == \"pfBM\":\n",
    "    print(\"===============================\")\n",
    "    print(\"Start Simulation Step: Test Set\")\n",
    "    print(\"===============================\")\n",
    "    # Initialize fBM Generator\n",
    "    fBM_Generator_test = FBM(n=(len(t_Grid_test)-1), hurst=0.75, length=1, method='daviesharte')\n",
    "\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances_x_test)):\n",
    "        # Get x\n",
    "        field_loop_x = field_dirction_x(x_Grid_test[i])\n",
    "        # Get omega and t\n",
    "        # Generate finite-variation path (since it stays unchanged)\n",
    "        finite_variation_path = finite_variation_t(t_Grid_test).reshape(-1,1) +field_loop_x\n",
    "        for n_MC in range(N_Monte_Carlo_Samples_Test):\n",
    "            fBM_variation_path_loop = fBM_Generator_test.fbm().reshape(-1,1)\n",
    "            generated_path_loop = finite_variation_path + fBM_variation_path_loop\n",
    "            if n_MC == 0:\n",
    "                paths_loop = generated_path_loop\n",
    "            else:\n",
    "                paths_loop = np.append(paths_loop,generated_path_loop,axis=-1)\n",
    "        \n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop.tolist()\n",
    "        # Get inputs\n",
    "        X_test_loop = np.append(np.repeat(x_Grid_test[i],len(t_Grid_test)).reshape(-1,1),\n",
    "                                 t_Grid_test.reshape(-1,1),\n",
    "                                 axis=1)\n",
    "        \n",
    "        # Append to List\n",
    "        measures_locations_test_list = measures_locations_test_list + measures_locations_loop\n",
    "        measures_weights_test_list.append(measure_weights_test)\n",
    "        \n",
    "        # Update Inputs\n",
    "        if i==0:\n",
    "            X_test = X_test_loop\n",
    "        else:\n",
    "            X_test = np.append(X_test,X_test_loop,axis=0)\n",
    "    print(\"==============================\")\n",
    "    print(\"Done Simulation Step: Test Set\")\n",
    "    print(\"==============================\")\n",
    "    \n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")\n",
    "print(\"===============================--------------------------------------===============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer (Model Type A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dissimilarity (Distance) Matrix\n",
    "*In this step we build a dissimularity matrix of the dataset on the Wasserstein-1 space.  Namely:*\n",
    "$$\n",
    "\\operatorname{Mat}_{\\# \\mathbb{X},\\# \\mathbb{X}}\\left(\\mathbb{R}\\right)\\ni D; \\text{ where}\\qquad \\, D_{i,j}\\triangleq \\mathcal{W}_1\\left(f(x_i),f(x_j)\\right)\n",
    ";\n",
    "$$\n",
    "*where $f\\in C\\left((\\mathcal{X},\\mathcal{P}_1(\\mathcal{Y})\\right)$ is the \"target\" function we are learning.*\n",
    "\n",
    "**Note**: *Computing the dissimularity matrix is the most costly part of the entire algorithm with a complexity of at-most $\\mathcal{O}\\left(E_{W} \\# \\mathbb{X})^2\\right)$ where $E_W$ denotes the complexity of a single Wasserstein-1 evaluation between two elements of the dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Minibatch Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 412.37it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]/usr/lib/python3.7/site-packages/ipykernel_launcher.py:98: RuntimeWarning: invalid value encountered in multiply\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8418.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 328.96it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 9670.16it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜€  Building Random Covering ðŸ˜€ !\n",
      "Data-Points per Random Sample:  25\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  0\n",
      "Remaining points to cluster:  303\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  1\n",
      "Remaining points to cluster:  298\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  2\n",
      "Remaining points to cluster:  293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 478.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7166.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 396.38it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  3\n",
      "Remaining points to cluster:  288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 6999.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 311.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 6573.94it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  4\n",
      "Remaining points to cluster:  283\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  5\n",
      "Remaining points to cluster:  278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 360.08it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7275.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 554.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8335.96it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 538.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 11414.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 382.00it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  6\n",
      "Remaining points to cluster:  273\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  7\n",
      "Remaining points to cluster:  268\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  8\n",
      "Remaining points to cluster:  263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7353.68it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 448.65it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  9\n",
      "Remaining points to cluster:  258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8220.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 279.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7855.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 418.69it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  10\n",
      "Remaining points to cluster:  253\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  11\n",
      "Remaining points to cluster:  248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8234.75it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 397.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 5747.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 316.49it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  12\n",
      "Remaining points to cluster:  243\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  13\n",
      "Remaining points to cluster:  238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 6516.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 401.42it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  14\n",
      "Remaining points to cluster:  233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7122.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 407.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8478.75it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 440.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7452.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  15\n",
      "Remaining points to cluster:  228\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  16\n",
      "Remaining points to cluster:  223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 572.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7564.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 376.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7309.33it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  17\n",
      "Remaining points to cluster:  218\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  18\n",
      "Remaining points to cluster:  213\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  19\n",
      "Remaining points to cluster:  208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 386.37it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7757.21it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  20\n",
      "Remaining points to cluster:  203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 462.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8356.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 582.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 9330.77it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  21\n",
      "Remaining points to cluster:  198\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  22\n",
      "Remaining points to cluster:  193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 332.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8655.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 290.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 5471.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 336.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8708.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  23\n",
      "Remaining points to cluster:  188\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  24\n",
      "Remaining points to cluster:  183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 324.21it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  25\n",
      "Remaining points to cluster:  178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8351.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 365.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8479.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 343.21it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  26\n",
      "Remaining points to cluster:  173\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  27\n",
      "Remaining points to cluster:  168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7125.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 434.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8821.81it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 422.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8962.57it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  28\n",
      "Remaining points to cluster:  163\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  29\n",
      "Remaining points to cluster:  158\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  30\n",
      "Remaining points to cluster:  153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 307.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8487.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 430.26it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  31\n",
      "Remaining points to cluster:  148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7722.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 416.37it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 9354.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 603.62it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  32\n",
      "Remaining points to cluster:  143\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  33\n",
      "Remaining points to cluster:  138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7238.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 374.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 10303.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 434.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 6463.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 473.69it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  34\n",
      "Remaining points to cluster:  133\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  35\n",
      "Remaining points to cluster:  128\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  36\n",
      "Remaining points to cluster:  123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 9883.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 511.79it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  37\n",
      "Remaining points to cluster:  118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8571.31it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 426.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8859.07it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 499.11it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  38\n",
      "Remaining points to cluster:  113\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  39\n",
      "Remaining points to cluster:  108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 5799.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 468.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 6731.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 287.49it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  40\n",
      "Remaining points to cluster:  103\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  41\n",
      "Remaining points to cluster:  98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 6667.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 403.31it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  42\n",
      "Remaining points to cluster:  93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 4923.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 383.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 5898.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  43\n",
      "Remaining points to cluster:  88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 406.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7889.79it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 393.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8218.72it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  44\n",
      "Remaining points to cluster:  83\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  45\n",
      "Remaining points to cluster:  78\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  46\n",
      "Remaining points to cluster:  73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 433.02it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8655.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 375.92it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  47\n",
      "Remaining points to cluster:  68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 6294.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 339.75it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  48\n",
      "Remaining points to cluster:  63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 5851.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 326.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7674.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 375.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8822.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 538.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7762.69it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  49\n",
      "Remaining points to cluster:  58\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  50\n",
      "Remaining points to cluster:  53\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  51\n",
      "Remaining points to cluster:  48\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  52\n",
      "Remaining points to cluster:  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 374.08it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7176.45it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  53\n",
      "Remaining points to cluster:  38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 320.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8034.56it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  54\n",
      "Remaining points to cluster:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 377.83it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 5791.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 442.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 9922.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 495.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 8964.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 437.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 9188.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 390.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  55\n",
      "Remaining points to cluster:  28\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  56\n",
      "Remaining points to cluster:  23\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  57\n",
      "Remaining points to cluster:  18\n",
      "â¤¢ Current iteration of Mini-Batch Random Covering:  58\n",
      "Remaining points to cluster:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 9294.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 444.38it/s]\n",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  59\n",
      "Remaining points to cluster:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 7694.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤¢ Current iteration of Mini-Batch Random Covering:  60\n",
      "Remaining points to cluster:  3\n",
      "----------------------------------------------------------------------------------------------\n",
      "Average Classes Per Sample Barycenter:  1.0033003300330032\n",
      "Left-Overs: 0\n",
      "----------------------------------------------------------------------------------------------\n",
      "ðŸ˜€  Done Random Covering ðŸ˜€ !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"\\U0001F600\",\" Building Random Covering\",\"\\U0001F600\",\"!\")\n",
    "\n",
    "\n",
    "#-----------------#\n",
    "# Initializations #\n",
    "#-----------------#\n",
    "print(\"Data-Points per Random Sample: \", Covering_Mini_Batch_Size**2)\n",
    "\n",
    "# Initialize Inder for intput/output data\n",
    "index_remaining = np.array(range(len(measures_locations_list)))\n",
    "# Count number of remaining datums to cluster:\n",
    "length_of_sample = len(index_remaining)\n",
    "# Initialize Mini-batch iteration counter\n",
    "mini_batch_iteration_counter = 0\n",
    "# Number of iteration:\n",
    "# len(measures_locations_list)/Covering_Mini_Batch_Size\n",
    "\n",
    "#--------------------#\n",
    "# Build Random-Cover #\n",
    "#--------------------#\n",
    "while length_of_sample >0:\n",
    "    print(\"\\u2922 Current iteration of Mini-Batch Random Covering: \",mini_batch_iteration_counter)\n",
    "    # Update User\n",
    "    print(\"Remaining points to cluster: \",length_of_sample)\n",
    "    \n",
    "    #---------------------------------#\n",
    "    # Get Random Sample for Minibatch #\n",
    "    #---------------------------------#\n",
    "    ## Get indices\n",
    "    which_to_sample = np.random.choice(index_remaining.shape[0], min(Covering_Mini_Batch_Size,length_of_sample), replace=False) \n",
    "    clustering_indices_minibatch = index_remaining[which_to_sample]\n",
    "    ## Get Indices for current sample\n",
    "    indices_to_remove_loop = np.flatnonzero(np.isin(index_remaining,clustering_indices_minibatch))\n",
    "    ## UPDATE: Remove Indices from \"Remaining Data\"\n",
    "    index_remaining = np.delete(index_remaining,indices_to_remove_loop)\n",
    "    ## UPDATE: Length of Sample\n",
    "    length_of_sample = len(index_remaining)\n",
    "    ## UPDATE: Mini-batch iteration counter\n",
    "    mini_batch_iteration_counter = mini_batch_iteration_counter+1\n",
    "    \n",
    "    ## FAILSAFE\n",
    "    if length_of_sample ==0:\n",
    "        break\n",
    "\n",
    "    #---------------------------#\n",
    "    # Build Disimilarity Matrix #\n",
    "    #---------------------------#\n",
    "    Dissimilarity_matrix_ot_current = np.zeros([Covering_Mini_Batch_Size,Covering_Mini_Batch_Size])\n",
    "    # Build Disimilarity Matrix\n",
    "    for i in tqdm(range(Covering_Mini_Batch_Size)):\n",
    "        index_i = indices_to_remove_loop[i]\n",
    "        for j in range(Covering_Mini_Batch_Size):\n",
    "            index_j = indices_to_remove_loop[j]\n",
    "            Dissimilarity_matrix_ot_current[i,j] = ot.emd2_1d(measures_locations_list[index_j],\n",
    "                                                              measures_locations_list[index_i])\n",
    "\n",
    "\n",
    "    #----------------------------#\n",
    "    # Inidialize Looping Indices #\n",
    "    #----------------------------#\n",
    "    # Initialize \"Internal to loop\" subset of measures\n",
    "    measures_locations_list_current = [measures_locations_list[i] for i in indices_to_remove_loop]\n",
    "    # Initialize masker vector\n",
    "    masker = np.ones(Covering_Mini_Batch_Size)\n",
    "    # Initialize Sorting Reference Vector (This helps us efficiently scroll through the disimularity matrix to identify the barycenter without having to re-compute the dissimultarity matrix of a sub-saple at every iteration (which is the most costly part of the algorithm!))\n",
    "    Distances_Loop = Dissimilarity_matrix_ot_current.sum(axis=1)\n",
    "    # Initialize Classes\n",
    "    Classifer_Wasserstein_Centers = np.zeros([N_Quantizers_to_parameterize,N_Grid_Instances])\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------#\n",
    "    # Build Sample Barycenters #\n",
    "    #--------------------------#\n",
    "    # Identify Sample Barycenters\n",
    "    for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "        # GET BARYCENTER #\n",
    "        #----------------#\n",
    "        ## Identify row with minimum total distance\n",
    "        Barycenter_index = int(Distances_Loop.argsort()[:1][0])\n",
    "        ## Get Barycenter\n",
    "        ## Update Barycenters Array ##\n",
    "        #----------------------------#\n",
    "        ### Get next Barycenter\n",
    "        new_barycenter_loop = np.array(measures_locations_list_current[Barycenter_index]).reshape(-1,1)\n",
    "        ### Update Array of Barycenters\n",
    "        if i == 0:\n",
    "            # Initialize Barycenters Array\n",
    "            Barycenters_Array = new_barycenter_loop\n",
    "        else:\n",
    "            # Populate Barycenters Array\n",
    "            Barycenters_Array = np.append(Barycenters_Array,new_barycenter_loop,axis=-1)\n",
    "\n",
    "        # GET CLUSTER #\n",
    "        #-------------#\n",
    "        # Identify Cluster for this barycenter (which elements are closest to it)\n",
    "        Cluster_indices = (masker*Dissimilarity_matrix_ot_current[:,Barycenter_index]).argsort()[:N_Elements_Per_Cluster]\n",
    "        ## UPDATES Set  M^{(n)}  ##\n",
    "        #-------------------------#\n",
    "        Dissimilarity_matrix_ot_current[Cluster_indices,:] = 0\n",
    "        # Distance-Based Sorting\n",
    "        Distances_Loop[Cluster_indices] = math.inf\n",
    "\n",
    "        # Update Cluster\n",
    "        masker[Cluster_indices] = math.inf\n",
    "\n",
    "        # Update Classes\n",
    "        Classifer_Wasserstein_Centers[i,(indices_to_remove_loop[Cluster_indices])] = 1\n",
    "\n",
    "    # pd.DataFrame(Classifer_Wasserstein_Centers)\n",
    "    # print(np.sum(Classifer_Wasserstein_Centers,axis=0))\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Classes Per Sample Barycenter: \", np.mean(np.sum(Classifer_Wasserstein_Centers,axis=0)))\n",
    "print(\"Left-Overs:\",length_of_sample)\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Random Covering\",\"\\U0001F600\",\"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0406 - accuracy: 0.0033\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0405 - accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0407 - accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0406 - accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0406 - accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0406 - accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0407 - accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0407 - accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0406 - accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0407 - accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0407 - accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0407 - accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0407 - accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0408 - accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0409 - accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0410 - accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0411 - accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0411 - accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0412 - accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0411 - accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0412 - accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0416 - accuracy: 0.0033    \n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0417 - accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0417 - accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0418 - accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0420 - accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0422 - accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0423 - accuracy: 0.0033\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0427 - accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0426 - accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0428 - accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0429 - accuracy: 0.0033\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0433 - accuracy: 0.0066 \n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0427 - accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0430 - accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0441 - accuracy: 0.0033 \n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0438 - accuracy: 0.0198 \n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0460 - accuracy: 0.0594    \n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0440 - accuracy: 0.0330    \n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0442 - accuracy: 0.0495\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0523 - accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0591 - accuracy: 0.1056 \n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0698 - accuracy: 0.0990    \n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.0706 - accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.1102 - accuracy: 0.1023    \n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.1268 - accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.1965 - accuracy: 0.0990    \n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.2698 - accuracy: 0.0495\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.3591 - accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.3678 - accuracy: 0.1056    \n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.3542 - accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.3139 - accuracy: 0.1056    \n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.3656 - accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.3892 - accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.3935 - accuracy: 0.1056 \n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.4413 - accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.5873 - accuracy: 0.0066    \n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.6757 - accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.6556 - accuracy: 0.1023\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8041 - accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.9199 - accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9864 - accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.0100 - accuracy: 0.1023\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0446 - accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0727 - accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.1545 - accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.0365 - accuracy: 0.1023    \n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9908 - accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8009 - accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.6285 - accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.6062 - accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.6084 - accuracy: 0.1056\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.6069 - accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8036 - accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7569 - accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.6617 - accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.6328 - accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7799 - accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8560 - accuracy: 0.0000e+00\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8218 - accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7373 - accuracy: 0.0429\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.8002 - accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.7592 - accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9474 - accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9045 - accuracy: 0.0099\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0196 - accuracy: 0.1056    \n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0913 - accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.3821 - accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.3693 - accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.6319 - accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.8199 - accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.9144 - accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.0017 - accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.0611 - accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.3532 - accuracy: 0.1023\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.2060 - accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.0655 - accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.1692 - accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.4546 - accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.4857 - accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.5811 - accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.9518 - accuracy: 0.1023\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.2624 - accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.4377 - accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.5480 - accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.4133 - accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.4361 - accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.3851 - accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.4747 - accuracy: 0.1056    \n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.4950 - accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.7465 - accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9.7765 - accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 9.9444 - accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 9.9121 - accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.0060 - accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.1372 - accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.3911 - accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.4335 - accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.7000 - accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11.1708 - accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.8893 - accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 10.4155 - accuracy: 0.1056\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.5727 - accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.8472 - accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 11.9464 - accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.1792 - accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 11.7377 - accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12.1168 - accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.3494 - accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.9583 - accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.0241 - accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.0143 - accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.8735 - accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.9742 - accuracy: 0.0033   \n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.5944 - accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14.4316 - accuracy: 0.1023   \n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.8727 - accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.4185 - accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14.0665 - accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 13.5975 - accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.2644 - accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 13.6173 - accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14.7943 - accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14.8853 - accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.4567 - accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.1516 - accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.1616 - accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14.7955 - accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 14.7695 - accuracy: 0.0858\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 14.9054 - accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14.8474 - accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 15.2799 - accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 16.1348 - accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 16.1466 - accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 16.2927 - accuracy: 0.0033\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 16.4057 - accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 17.2142 - accuracy: 0.0000e+00\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 17.8616 - accuracy: 0.0495\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 18.2667 - accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18.6673 - accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 19.1188 - accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19.4336 - accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20.2090 - accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 19.6873 - accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20.3807 - accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20.6609 - accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20.3789 - accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 20.5783 - accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.0254 - accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.6061 - accuracy: 0.1056\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.4393 - accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.6765 - accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.8386 - accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.6874 - accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 21.6898 - accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22.4078 - accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22.6618 - accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22.5282 - accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 22.7765 - accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23.1670 - accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23.9959 - accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24.2311 - accuracy: 0.0033\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25.4761 - accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25.3714 - accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25.9514 - accuracy: 0.1056\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26.1996 - accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26.6153 - accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 26.3180 - accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27.0713 - accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 27.3957 - accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24.9191 - accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23.9151 - accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23.4606 - accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23.0209 - accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24.2815 - accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24.2612 - accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25.3831 - accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 25.6279 - accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24.8104 - accuracy: 0.1056   \n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 24.6833 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "62/62 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [2]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers.T,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:06<00:00, 23.21it/s]\n",
      "  3%|â–Ž         | 5/152 [00:00<00:02, 49.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:38<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Format Weights\n",
    "## Train\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): START\")\n",
    "print(\"#---------------------------------------#\")\n",
    "Predicted_Weights = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    b = np.repeat(np.array(predicted_classes_train[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): END\")\n",
    "print(\"#-------------------------------------#\")\n",
    "\n",
    "## Test\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): START\")\n",
    "print(\"#-------------------------------------#\")\n",
    "Predicted_Weights_test = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):\n",
    "    b_test = np.repeat(np.array(predicted_classes_test[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b_test = b_test/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights_test = b_test\n",
    "    else:\n",
    "        Predicted_Weights_test = np.append(Predicted_Weights_test,b_test,axis=1)\n",
    "print(\"#-----------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): END\")\n",
    "print(\"#-----------------------------------#\")\n",
    "        \n",
    "# Format Points of Mass\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: START\")\n",
    "print(\"#-----------------------------#\")\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: END\")\n",
    "print(\"#-----------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/302 [00:00<00:12, 24.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 302/302 [00:08<00:00, 34.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>3.119004e-13</td>\n",
       "      <td>2.298051e-12</td>\n",
       "      <td>9.020263e-24</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.020820e-03</td>\n",
       "      <td>1.260660e-02</td>\n",
       "      <td>1.252172e-03</td>\n",
       "      <td>0.355492</td>\n",
       "      <td>0.553699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>4.673603e-03</td>\n",
       "      <td>5.662444e-02</td>\n",
       "      <td>1.841653e-02</td>\n",
       "      <td>0.656278</td>\n",
       "      <td>0.880603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               W1    E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  3.119004e-13  2.298051e-12         9.020263e-24                0.000243   \n",
       "MAE  1.020820e-03  1.260660e-02         1.252172e-03                0.355492   \n",
       "Max  4.673603e-03  5.662444e-02         1.841653e-02                0.656278   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.002610  \n",
       "MAE              0.553699  \n",
       "Max              0.880603  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Training Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "Skewness_errors = np.array([])\n",
    "Kurtosis_errors = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measure_weights.reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(np.array(measures_locations_list[x_i]))\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(np.array(measures_locations_list[x_i])**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat = np.sum((Barycenters_Array**3)*(Predicted_Weights[x_i]))\n",
    "    Skewness = np.mean(np.array(measures_locations_list[x_i])**3)\n",
    "    Skewness_errors = np.append(Skewness_errors,(abs(Skewness_hat-Skewness))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat = np.sum((Barycenters_Array**4)*(Predicted_Weights[x_i]))\n",
    "    Kurtosis = np.mean(np.array(measures_locations_list[x_i])**4)\n",
    "    Kurtosis_errors = np.append(Kurtosis_errors,(abs(Kurtosis_hat-Kurtosis))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.min(np.abs(W1_errors)),np.mean(np.abs(W1_errors)),np.max(np.abs(W1_errors))])\n",
    "Mean_prediction_Performance = np.array([np.min(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors)),np.max(np.abs(Mean_errors))])\n",
    "Var_prediction_Performance = np.array([np.min(np.abs(Var_errors)),np.mean(np.abs(Var_errors)),np.max(np.abs(Var_errors))])\n",
    "Skewness_prediction_Performance = np.array([np.min(np.abs(Skewness_errors)),np.mean(np.abs(Skewness_errors)),np.max(np.abs(Skewness_errors))])\n",
    "Kurtosis_prediction_Performance = np.array([np.min(np.abs(Kurtosis_errors)),np.mean(np.abs(Kurtosis_errors)),np.max(np.abs(Kurtosis_errors))])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Train.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1975 [00:00<01:06, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1975/1975 [00:56<00:00, 34.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.102132e-09</td>\n",
       "      <td>0.036213</td>\n",
       "      <td>0.115493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.012947</td>\n",
       "      <td>1.226930e-03</td>\n",
       "      <td>0.357281</td>\n",
       "      <td>0.550203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.061044</td>\n",
       "      <td>1.692666e-02</td>\n",
       "      <td>0.624823</td>\n",
       "      <td>0.854867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.000230    0.000003         1.102132e-09                0.036213   \n",
       "MAE  0.000999    0.012947         1.226930e-03                0.357281   \n",
       "Max  0.004806    0.061044         1.692666e-02                0.624823   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.115493  \n",
       "MAE              0.550203  \n",
       "Max              0.854867  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Test Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors_test = np.array([])\n",
    "Mean_errors_test = np.array([])\n",
    "Var_errors_test = np.array([])\n",
    "Skewness_errors_test = np.array([])\n",
    "Kurtosis_errors_test = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_test_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_test_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights_test[x_i,].reshape(-1,),\n",
    "                         measure_weights_test.reshape(-1,))\n",
    "    W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "    # Get Means\n",
    "    Mu_hat_test = np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array))\n",
    "    Mu_test = np.mean(np.array(measures_locations_test_list[x_i]))\n",
    "    Mean_errors_test =  np.append(Mean_errors_test,(Mu_hat_test-Mu_test))\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat_test = np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))\n",
    "    Var_test = np.mean(np.array(measures_locations_test_list[x_i])**2)\n",
    "    Var_errors_test = np.append(Var_errors_test,(Var_hat_test-Var_test)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat_test = np.sum((Barycenters_Array**3)*(Predicted_Weights_test[x_i]))\n",
    "    Skewness_test = np.mean(np.array(measures_locations_test_list[x_i])**3)\n",
    "    Skewness_errors_test = np.append(Skewness_errors_test,(abs(Skewness_hat_test-Skewness_test))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat_test = np.sum((Barycenters_Array**4)*(Predicted_Weights_test[x_i]))\n",
    "    Kurtosis_test = np.mean(np.array(measures_locations_test_list[x_i])**4)\n",
    "    Kurtosis_errors_test = np.append(Kurtosis_errors_test,(abs(Kurtosis_hat_test-Kurtosis_test))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance_test = np.array([np.min(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test)),np.max(np.abs(W1_errors_test))])\n",
    "Mean_prediction_Performance_test = np.array([np.min(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test)),np.max(np.abs(Mean_errors_test))])\n",
    "Var_prediction_Performance_test = np.array([np.min(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test)),np.max(np.abs(Var_errors_test))])\n",
    "Skewness_prediction_Performance_test = np.array([np.min(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test)),np.max(np.abs(Skewness_errors_test))])\n",
    "Kurtosis_prediction_Performance_test = np.array([np.min(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test)),np.max(np.abs(Kurtosis_errors_test))])\n",
    "\n",
    "Type_A_Prediction_test = pd.DataFrame({\"W1\":W1_Performance_test,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance_test,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance_test,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance_test,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance_test},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction_test.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Test.tex\"))\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print for Terminal Legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "               W1    E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  3.119004e-13  2.298051e-12         9.020263e-24                0.000243   \n",
      "MAE  1.020820e-03  1.260660e-02         1.252172e-03                0.355492   \n",
      "Max  4.673603e-03  5.662444e-02         1.841653e-02                0.656278   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.002610  \n",
      "MAE              0.553699  \n",
      "Max              0.880603  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  0.000230    0.000003         1.102132e-09                0.036213   \n",
      "MAE  0.000999    0.012947         1.226930e-03                0.357281   \n",
      "Max  0.004806    0.061044         1.692666e-02                0.624823   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.115493  \n",
      "MAE              0.550203  \n",
      "Max              0.854867  \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------------#\")\n",
    "print(\"Training-Set Performance\")\n",
    "print(\"#----------------------#\")\n",
    "print(Type_A_Prediction)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"#------------------#\")\n",
    "print(\"Test-Set Performance\")\n",
    "print(\"#------------------#\")\n",
    "print(Type_A_Prediction_test)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facts of Simulation Experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      " Experiment's Facts \n",
      "====================\n",
      "------------------------------------------------------\n",
      "=====\n",
      "Model\n",
      "=====\n",
      "â€¢ N Centers: 152\n",
      "â€¢ Each Wasserstein-1 Ball should contain:  2 elements from the training set.\n",
      "------------------------------------------------------\n",
      "========\n",
      "Training\n",
      "========\n",
      "â€¢ Data-size: 303\n",
      "â€¢ N Points per training datum: 1000\n",
      "------------------------------------------------------\n",
      "=======\n",
      "Testing\n",
      "=======\n",
      "â€¢ Data-size Test: 1976\n",
      "â€¢ N Points per testing datum: 1000\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"====================\")\n",
    "print(\" Experiment's Facts \")\n",
    "print(\"====================\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"=====\")\n",
    "print(\"Model\")\n",
    "print(\"=====\")\n",
    "print(\"\\u2022 N Centers:\",N_Quantizers_to_parameterize)\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"========\")\n",
    "print(\"Training\")\n",
    "print(\"========\")\n",
    "print(\"\\u2022 Data-size:\",(len(x_Grid)*len(t_Grid)))\n",
    "print(\"\\u2022 N Points per training datum:\",N_Monte_Carlo_Samples)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"=======\")\n",
    "print(\"Testing\")\n",
    "print(\"=======\")\n",
    "print(\"\\u2022 Data-size Test:\",(len(x_Grid_test)*len(t_Grid_test)))\n",
    "print(\"\\u2022 N Points per testing datum:\",N_Monte_Carlo_Samples_Test)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>3.119004e-13</td>\n",
       "      <td>2.298051e-12</td>\n",
       "      <td>9.020263e-24</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.020820e-03</td>\n",
       "      <td>1.260660e-02</td>\n",
       "      <td>1.252172e-03</td>\n",
       "      <td>0.355492</td>\n",
       "      <td>0.553699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>4.673603e-03</td>\n",
       "      <td>5.662444e-02</td>\n",
       "      <td>1.841653e-02</td>\n",
       "      <td>0.656278</td>\n",
       "      <td>0.880603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               W1    E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  3.119004e-13  2.298051e-12         9.020263e-24                0.000243   \n",
       "MAE  1.020820e-03  1.260660e-02         1.252172e-03                0.355492   \n",
       "Max  4.673603e-03  5.662444e-02         1.841653e-02                0.656278   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.002610  \n",
       "MAE              0.553699  \n",
       "Max              0.880603  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.102132e-09</td>\n",
       "      <td>0.036213</td>\n",
       "      <td>0.115493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.012947</td>\n",
       "      <td>1.226930e-03</td>\n",
       "      <td>0.357281</td>\n",
       "      <td>0.550203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.061044</td>\n",
       "      <td>1.692666e-02</td>\n",
       "      <td>0.624823</td>\n",
       "      <td>0.854867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.000230    0.000003         1.102132e-09                0.036213   \n",
       "MAE  0.000999    0.012947         1.226930e-03                0.357281   \n",
       "Max  0.004806    0.061044         1.692666e-02                0.624823   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.115493  \n",
       "MAE              0.550203  \n",
       "Max              0.854867  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Testing Predictions\n",
    "# Mu_hat = np.array([])\n",
    "# Mu = np.array([])\n",
    "# # Populate Error Distribution\n",
    "# for x_i in tqdm(range(len(measures_locations_list)-1)):    \n",
    "#     # Get Laws\n",
    "#     Mu_hat = np.append(Mu_hat,np.sum((Predicted_Weights[x_i])*(Barycenters_Array)))\n",
    "#     Mu = np.append(Mu,np.mean(np.array(measures_locations_list[x_i])))\n",
    "\n",
    "# # Get Training Predictions\n",
    "# Mu_hat_test = np.array([])\n",
    "# Mu_test = np.array([])\n",
    "# Var_hat_test = np.array([])\n",
    "# # Populate Error Distribution\n",
    "# for x_i in tqdm(range(len(measures_locations_test_list)-1)):    \n",
    "#     # Get Laws\n",
    "#     Mu_hat_test = np.append(Mu_hat_test,np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array)))\n",
    "#     Mu_test = np.append(Mu_test,np.mean(np.array(measures_locations_test_list[x_i])))\n",
    "#     ## Error Bands\n",
    "#     Var_hat_test = np.append(Var_hat_test,np.sqrt(np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
