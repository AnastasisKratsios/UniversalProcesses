{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Conditional Laws for Random-Fields - via:\n",
    "\n",
    "## Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "\n",
    "---\n",
    "\n",
    "By: [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*.\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth:\n",
    "*The build-in Options:*\n",
    "- rSDE \n",
    "- pfBM\n",
    "- 2lnflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "# groud_truth = \"rSDE\"\n",
    "# Option 2:\n",
    "groud_truth = \"2lnflow\"\n",
    "## Option 3:\n",
    "# groud_truth = \"pfBM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 10\n",
    "N_Monte_Carlo_Samples = 10**3\n",
    "N_Monte_Carlo_Samples_Test = 10**3 # How many MC-samples to draw from test-set?\n",
    "\n",
    "# End times for Time-Grid\n",
    "T_end = 1\n",
    "T_end_test = 1.1\n",
    "\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 10\n",
    "Max_Grid = 1\n",
    "\n",
    "# Number of Centers (\\hat{\\mu}_s)\n",
    "N_Quantizers_to_parameterize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "N_measures_per_center = 10*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP:\n",
    "from operator import itemgetter \n",
    "from itertools import compress\n",
    "# Set Minibatch Size\n",
    "Random_Cover_Mini_Batch_Size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Rough SDE\n",
    "Simulate via Euler-M method from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T((1-\\eta)\\beta(s,x)+\\eta\\sigma_s^H)dW_s.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return .1*(.1-.5*(.01**2))*t + np.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 0.01+t*np.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rougness = 0.9 # Hurst Parameter\n",
    "Ratio_fBM_to_typical_vol = 0 # $\\eta$ in equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Measure-Valued $2$-Parameter Log-Gaussian Flow\n",
    "$$\n",
    "X_{t,x} \\sim \\log\\text{-}\\mathcal{N}\\left(\\alpha(t,x),\\beta(t,x)\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** *$\\alpha$ and $\\beta$ are specified below in the SDE Example*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed Fractional Brownian Motion\n",
    "Simulate from:\n",
    "$$\n",
    "X_t^x(\\omega) = f_1(x)f_2(t) + B_t^H(\\omega).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_dirction_x(x):\n",
    "    return x*np.cos(x)\n",
    "\n",
    "def finite_variation_t(t):\n",
    "    return t*(np.sin(math.pi*t) + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of Auxiliary Internal-Variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "measure_weights_test = np.ones(N_Monte_Carlo_Samples_Test)/N_Monte_Carlo_Samples_Test\n",
    "\n",
    "# Get number of centers\n",
    "N_Centers_per_box = max(1,int(round(np.sqrt(N_Quantizers_to_parameterize))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Centers Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get x and t grid of \"centers\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Coordinates Grid\n",
    "\n",
    "*We separate the case of a $2$-parameter measure-valued flow from the SDE example as follows:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grid of Barycenters\n",
    "x_Grid_barycenters = np.arange(start=-Max_Grid,\n",
    "                               stop=Max_Grid,\n",
    "                               step = (2*Max_Grid/N_Centers_per_box))\n",
    "if groud_truth == \"2lnflow\":\n",
    "    t_Grid_barycenters = np.arange(start=0,\n",
    "                                   stop=T_end,\n",
    "                                   step = (T_end/N_Centers_per_box))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If we do not consider the 2-paramter (probability) measure-valued flow model; then we start all time points at the same place; so as to ensure that the \"test set\" consists exactly of future times corresponding to trained initial states!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(groud_truth == \"2lnflow\"):\n",
    "    t_Grid_barycenters = np.arange(start=0,\n",
    "                               stop=T_end,\n",
    "                               step = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Full-Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_i in range(len(x_Grid_barycenters)):\n",
    "    for t_j in range(len(t_Grid_barycenters)):\n",
    "        new_grid_entry = np.array([t_Grid_barycenters[t_j],x_Grid_barycenters[x_i]]).reshape(1,-1)\n",
    "        if (x_i==0 and t_j ==0):\n",
    "            Grid_Barycenters = new_grid_entry\n",
    "        else:\n",
    "            Grid_Barycenters = np.append(Grid_Barycenters,new_grid_entry,axis=0)\n",
    "\n",
    "# Update Number of Quantizers Generated\n",
    "N_Quantizers_to_parameterize = Grid_Barycenters.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD Simulator (Backend)\n",
    "# %run Simulator.ipynb\n",
    "exec(open('Simulator.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer (Model Type A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $2$-Parameter $\\log$-Gaussian Flow\n",
    "Generate data by sampling from a random-field $(X_t^x)_{t,x}$ distributed according to:\n",
    "$$\n",
    "X_{t,x} \\sim \\log\\text{-}\\mathcal{N}\\left(\\alpha(t,x),\\beta(t,x)\\right).\n",
    "$$\n",
    "\n",
    "### Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 520.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set - 2-logNormal Ground-Truth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if groud_truth == \"2lnflow\":\n",
    "    print(\"Building Training Set - 2-logNormal Ground-Truth\")\n",
    "    # Generate Training Data\n",
    "    for i in tqdm(range(Grid_Barycenters.shape[0])):\n",
    "        # Get output for center (mu-hat)\n",
    "        center_current, trash = twoparameter_flow_sampler((Grid_Barycenters[i]).reshape(1,2),N_Monte_Carlo_Samples)\n",
    "\n",
    "        # Get random sample in delta ball around ith center\n",
    "        sub_grid_loop = np.random.uniform(0,delta,(N_measures_per_center,2)) + Grid_Barycenters[i]\n",
    "\n",
    "        # Get Measures for this random sample\n",
    "        measures_locations_list_current, measures_weights_list_current = twoparameter_flow_sampler(sub_grid_loop,N_Monte_Carlo_Samples)\n",
    "        ##\n",
    "        measures_locations_list_current = measures_locations_list_current + center_current\n",
    "        measures_weights_list_current = measures_weights_list_current + trash\n",
    "        # Update Classes\n",
    "        Classifer_Wasserstein_Centers_loop = np.zeros([(N_measures_per_center+1),N_Quantizers_to_parameterize]) # The +1 is to account for the center which will be added to the random ball\n",
    "        Classifer_Wasserstein_Centers_loop[:, i] =  1\n",
    "        # Updates Classes\n",
    "        if i==0:\n",
    "            # INITIALIZE: Classifiers\n",
    "            Classifer_Wasserstein_Centers = Classifer_Wasserstein_Centers_loop\n",
    "            # INITIALIZE: Training Data\n",
    "            X_train = np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0)\n",
    "            # INITIALIZE: Barycenters Array\n",
    "            Barycenters_Array = (center_current[0]).reshape(-1,1)\n",
    "            # INITIALIZE: Measures and locations\n",
    "            measures_locations_list = measures_locations_list_current\n",
    "            measures_weights_list = measures_weights_list_current\n",
    "        else:\n",
    "            # UPDATE: Classifer\n",
    "            Classifer_Wasserstein_Centers = np.append(Classifer_Wasserstein_Centers,Classifer_Wasserstein_Centers_loop,axis=0)\n",
    "            # UPDATE: Training Data\n",
    "            X_train = np.append(X_train,np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0),axis=0)\n",
    "            # UPDATE: Populate Barycenters Array\n",
    "            Barycenters_Array = np.append(Barycenters_Array,((center_current[0]).reshape(-1,1)),axis=-1)\n",
    "            # UPDATE: Measures and locations\n",
    "            measures_locations_list = measures_locations_list + measures_locations_list_current\n",
    "            measures_weights_list = measures_locations_list + measures_weights_list_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 6028.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set - 2-logNormal Ground-Truth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if groud_truth == \"2lnflow\":\n",
    "    print(\"Building Test Set - 2-logNormal Ground-Truth\")\n",
    "    # Generate Testing Dataset (Inputs)\n",
    "    x_tests = np.random.uniform(np.min(X_train[:,0]),np.max(X_train[:,0]),10)\n",
    "    t_tests = np.arange(start=0,\n",
    "                        stop=T_end,\n",
    "                        step = (T_end_test/N_Euler_Maruyama_Steps))\n",
    "    for x_i in tqdm(range(len(x_tests))):\n",
    "        for t_j in range(len(t_tests)):\n",
    "            test_set_entry = np.array([t_tests[t_j],x_tests[x_i]]).reshape(1,-1)\n",
    "            if (x_i==0 and t_j ==0):\n",
    "                X_test = test_set_entry\n",
    "            else:\n",
    "                X_test = np.append(X_test,test_set_entry,axis=0)\n",
    "\n",
    "    # Generate Testing Dataset (Outputs)\n",
    "    measures_locations_test_list, measures_weights_test_list = twoparameter_flow_sampler(X_test,N_Monte_Carlo_Samples_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough SDE:\n",
    "Simulation of the random-field:\n",
    "$$\n",
    "X_t^x = x + \\int_0^t \\alpha(s,X_t^x)ds + (1-\\eta)\\int_0^t \\beta(s,X_t^x)dW_t + \\int_0^t B_s^H dW_s;\n",
    "$$\n",
    "where: \n",
    " - $(B_t^H)_t$ is a [fractional Brownian Motion](https://arxiv.org/pdf/1406.1956.pdf) with [Hurst exponent](https://en.wikipedia.org/wiki/Hurst_exponent) $H\\in (0,1)$,\n",
    " - $(W_t)_t$ is a [Brownian Motion](https://en.wikipedia.org/wiki/Wiener_process),\n",
    " - $\\alpha$ and $\\beta$ are uniformly [Lipschitz-functions](https://en.wikipedia.org/wiki/Lipschitz_continuity) of appropriate input/output dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD Simulator (Backend)\n",
    "# %run Simulator.ipynb\n",
    "exec(open('Simulator.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW?\n",
    "if groud_truth == \"rSDE\":\n",
    "    print(\"Building Training + Testing Set - rough-SDE Ground-Truth\")\n",
    "    \n",
    "    # Initialize position Counter\n",
    "    position_counter = 0\n",
    "    # Iniitalize uniform weights vector\n",
    "    measures_weights_list_loop = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "\n",
    "    # For simplicity override:\n",
    "    N_Monte_Carlo_Samples_Test = N_Monte_Carlo_Samples\n",
    "    \n",
    "    # Overrine Number of Centers\n",
    "    N_x = len(x_Grid_barycenters)\n",
    "    N_t = len(t_Grid_barycenters)\n",
    "    N_Quantizers_to_parameterize = N_x*N_t\n",
    "    \n",
    "    # Initialize number of training and testing to grab from each initial condition\n",
    "    N_train = int(N_Euler_Maruyama_Steps*(1-test_size_ratio))\n",
    "    N_test = N_Euler_Maruyama_Steps - N_train\n",
    "\n",
    "    for x_i in tqdm(range(N_x)):\n",
    "        for t_j in range(N_t):\n",
    "\n",
    "            # Get Current Locations\n",
    "            x_center = x_Grid_barycenters[x_i]\n",
    "            t_center = t_Grid_barycenters[t_j]\n",
    "\n",
    "            current_cover = Euler_Maruyama_Generator(x_0 = x_center,\n",
    "                                                     N_Euler_Maruyama_Steps = N_Euler_Maruyama_Steps,\n",
    "                                                     N_Monte_Carlo_Samples = N_Monte_Carlo_Samples,\n",
    "                                                     T_begin = t_center,\n",
    "                                                     T_end = (t_center+delta),\n",
    "                                                     Hurst = Rougness,\n",
    "                                                     Ratio_fBM_to_typical_vol = Ratio_fBM_to_typical_vol)\n",
    "            # Get Barycenter\n",
    "            barycenter_at_current_location = current_cover[0,:]\n",
    "            \n",
    "            # Subset\n",
    "            ## Measure Location(s)\n",
    "            measures_locations_list_current_train = (current_cover[:N_train]).tolist()\n",
    "            measures_locations_list_current_test = (current_cover[:-N_train]).tolist()\n",
    "            ## Measure Weight(s)\n",
    "            measures_weights_list_current = list(itertools.repeat(measures_weights_list_loop,N_Monte_Carlo_Samples))\n",
    "\n",
    "            \n",
    "            # Get Current Training Data Positions\n",
    "            t_grid_current = (np.linspace(start=t_center,\n",
    "                                          stop=(t_center+delta),\n",
    "                                          num=N_Euler_Maruyama_Steps)).reshape(1,-1)\n",
    "            x_grid_current = (x_center*np.ones(N_Euler_Maruyama_Steps)).reshape(1,-1)\n",
    "\n",
    "            X_train_current = (np.append(x_grid_current,t_grid_current,axis=0)).T\n",
    "            ## Subset\n",
    "            X_train_updater = X_train_current[:N_train,:] # Get top of array (including center)\n",
    "            X_test_updater = X_train_current[-N_test:,:] # Get bottom of array (exclusing center)\n",
    "\n",
    "            # Get Current Classes\n",
    "            Classifer_Wasserstein_Centers_loop = np.zeros([N_train,N_Quantizers_to_parameterize])\n",
    "            Classifer_Wasserstein_Centers_loop[:, position_counter] =  1\n",
    "\n",
    "\n",
    "            # Updates Classes\n",
    "            if (x_i==0 and t_j==0):\n",
    "                # INITIALIZE: Classifiers\n",
    "                Classifer_Wasserstein_Centers = Classifer_Wasserstein_Centers_loop\n",
    "                # INITIALIZE: Training Data\n",
    "                X_train = X_train_updater\n",
    "                X_test = X_test_updater\n",
    "                # INITIALIZE: Barycenters Array\n",
    "                Barycenters_Array = barycenter_at_current_location.reshape(-1,1)\n",
    "                # INITIALIZE: Measures and locations\n",
    "                measures_locations_list = measures_locations_list_current_train\n",
    "                measures_locations_test_list = measures_locations_list_current_test\n",
    "                measures_weights_list = measures_weights_list_current\n",
    "                measures_weights_test_list = measures_weights_list_current\n",
    "            else:\n",
    "                # UPDATE: Classifer\n",
    "                Classifer_Wasserstein_Centers = np.append(Classifer_Wasserstein_Centers,Classifer_Wasserstein_Centers_loop,axis=0)\n",
    "                # UPDATE: Training Data\n",
    "                X_train = np.append(X_train,X_train_updater,axis=0)\n",
    "                X_test = np.append(X_test,X_test_updater,axis=0)\n",
    "                # UPDATE: Populate Barycenters Array\n",
    "                Barycenters_Array = np.append(Barycenters_Array,(barycenter_at_current_location.reshape(-1,1)),axis=-1)\n",
    "                # UPDATE: Measures and locations\n",
    "                ## Train\n",
    "                measures_locations_list = measures_locations_list + measures_locations_list_current_train\n",
    "                measures_weights_list = measures_locations_list + measures_weights_list_current\n",
    "                ## Test\n",
    "                measures_locations_test_list = measures_locations_test_list + measures_locations_list_current_test\n",
    "                measures_weights_test_list = measures_locations_test_list + measures_weights_list_current\n",
    "\n",
    "            # Update Position\n",
    "            position_counter = position_counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   35.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   35.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 4.4844 - accuracy: 0.0248\n",
      "Epoch 2/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 3.7986 - accuracy: 0.0576\n",
      "Epoch 3/400\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.0455 - accuracy: 0.1610\n",
      "Epoch 4/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.4744 - accuracy: 0.2971\n",
      "Epoch 5/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.0761 - accuracy: 0.3962\n",
      "Epoch 6/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.7643 - accuracy: 0.5048\n",
      "Epoch 7/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.5159 - accuracy: 0.5910\n",
      "Epoch 8/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3258 - accuracy: 0.6619\n",
      "Epoch 9/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1496 - accuracy: 0.7114\n",
      "Epoch 10/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0066 - accuracy: 0.7800\n",
      "Epoch 11/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.8784 - accuracy: 0.8110\n",
      "Epoch 12/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.7547 - accuracy: 0.8681\n",
      "Epoch 13/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.8995\n",
      "Epoch 14/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.9324\n",
      "Epoch 15/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.9352\n",
      "Epoch 16/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.9667\n",
      "Epoch 17/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.9667\n",
      "Epoch 18/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.9657\n",
      "Epoch 19/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.9829\n",
      "Epoch 20/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9924\n",
      "Epoch 21/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9929\n",
      "Epoch 22/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9981\n",
      "Epoch 23/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9967\n",
      "Epoch 24/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9990\n",
      "Epoch 25/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9995\n",
      "Epoch 26/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 1.0000\n",
      "Epoch 27/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 1.0000\n",
      "Epoch 28/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 1.0000\n",
      "Epoch 29/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 1.0000\n",
      "Epoch 30/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 1.0000\n",
      "Epoch 31/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 1.0000\n",
      "Epoch 32/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 1.0000\n",
      "Epoch 33/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 1.0000\n",
      "Epoch 34/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 1.0000\n",
      "Epoch 35/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 36/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 37/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 38/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 39/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 40/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 41/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 42/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 43/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 44/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 45/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 46/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 47/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 48/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 49/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 50/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 51/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 52/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 53/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 54/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 55/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 56/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 57/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 58/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 59/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 60/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 61/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 62/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 63/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 64/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 65/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 66/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 67/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 68/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 69/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 70/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 71/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 72/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 73/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 74/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 75/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 76/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 77/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 78/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 79/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 80/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 81/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 82/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 83/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 84/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 85/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 86/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 87/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 88/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 89/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 90/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 91/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 92/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 93/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 94/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.5407e-04 - accuracy: 1.0000\n",
      "Epoch 95/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.0542e-04 - accuracy: 1.0000\n",
      "Epoch 96/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.6818e-04 - accuracy: 1.0000\n",
      "Epoch 97/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.2502e-04 - accuracy: 1.0000\n",
      "Epoch 98/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.9300e-04 - accuracy: 1.0000\n",
      "Epoch 99/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.5705e-04 - accuracy: 1.0000\n",
      "Epoch 100/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.2695e-04 - accuracy: 1.0000\n",
      "Epoch 101/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.9500e-04 - accuracy: 1.0000\n",
      "Epoch 102/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.6465e-04 - accuracy: 1.0000\n",
      "Epoch 103/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.3865e-04 - accuracy: 1.0000\n",
      "Epoch 104/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.1198e-04 - accuracy: 1.0000\n",
      "Epoch 105/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.8747e-04 - accuracy: 1.0000\n",
      "Epoch 106/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.6373e-04 - accuracy: 1.0000\n",
      "Epoch 107/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.3812e-04 - accuracy: 1.0000\n",
      "Epoch 108/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.2079e-04 - accuracy: 1.0000\n",
      "Epoch 109/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.9605e-04 - accuracy: 1.0000\n",
      "Epoch 110/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.7405e-04 - accuracy: 1.0000\n",
      "Epoch 111/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.5252e-04 - accuracy: 1.0000\n",
      "Epoch 112/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.3966e-04 - accuracy: 1.0000\n",
      "Epoch 113/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.2253e-04 - accuracy: 1.0000\n",
      "Epoch 114/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.0420e-04 - accuracy: 1.0000\n",
      "Epoch 115/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.8380e-04 - accuracy: 1.0000\n",
      "Epoch 116/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.7185e-04 - accuracy: 1.0000\n",
      "Epoch 117/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.5562e-04 - accuracy: 1.0000\n",
      "Epoch 118/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.3939e-04 - accuracy: 1.0000\n",
      "Epoch 119/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.2706e-04 - accuracy: 1.0000\n",
      "Epoch 120/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.1333e-04 - accuracy: 1.0000\n",
      "Epoch 121/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.0154e-04 - accuracy: 1.0000\n",
      "Epoch 122/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.8951e-04 - accuracy: 1.0000\n",
      "Epoch 123/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.7778e-04 - accuracy: 1.0000\n",
      "Epoch 124/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.6745e-04 - accuracy: 1.0000\n",
      "Epoch 125/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.5556e-04 - accuracy: 1.0000\n",
      "Epoch 126/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.4872e-04 - accuracy: 1.0000\n",
      "Epoch 127/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.3580e-04 - accuracy: 1.0000\n",
      "Epoch 128/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.2694e-04 - accuracy: 1.0000\n",
      "Epoch 129/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.1833e-04 - accuracy: 1.0000\n",
      "Epoch 130/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.1227e-04 - accuracy: 1.0000\n",
      "Epoch 131/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9870e-04 - accuracy: 1.0000\n",
      "Epoch 132/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9704e-04 - accuracy: 1.0000\n",
      "Epoch 133/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.8425e-04 - accuracy: 1.0000\n",
      "Epoch 134/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7945e-04 - accuracy: 1.0000\n",
      "Epoch 135/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7186e-04 - accuracy: 1.0000\n",
      "Epoch 136/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.6581e-04 - accuracy: 1.0000\n",
      "Epoch 137/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.5957e-04 - accuracy: 1.0000\n",
      "Epoch 138/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.5216e-04 - accuracy: 1.0000\n",
      "Epoch 139/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4683e-04 - accuracy: 1.0000\n",
      "Epoch 140/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4017e-04 - accuracy: 1.0000\n",
      "Epoch 141/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3576e-04 - accuracy: 1.0000\n",
      "Epoch 142/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2956e-04 - accuracy: 1.0000\n",
      "Epoch 143/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2448e-04 - accuracy: 1.0000\n",
      "Epoch 144/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2074e-04 - accuracy: 1.0000\n",
      "Epoch 145/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1516e-04 - accuracy: 1.0000\n",
      "Epoch 146/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1157e-04 - accuracy: 1.0000\n",
      "Epoch 147/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0683e-04 - accuracy: 1.0000\n",
      "Epoch 148/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0202e-04 - accuracy: 1.0000\n",
      "Epoch 149/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.8835e-05 - accuracy: 1.0000\n",
      "Epoch 150/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.5502e-05 - accuracy: 1.0000\n",
      "Epoch 151/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.1350e-05 - accuracy: 1.0000\n",
      "Epoch 152/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.8726e-05 - accuracy: 1.0000\n",
      "Epoch 153/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.3868e-05 - accuracy: 1.0000\n",
      "Epoch 154/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.1930e-05 - accuracy: 1.0000\n",
      "Epoch 155/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.8013e-05 - accuracy: 1.0000\n",
      "Epoch 156/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.4677e-05 - accuracy: 1.0000\n",
      "Epoch 157/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.2920e-05 - accuracy: 1.0000\n",
      "Epoch 158/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.9620e-05 - accuracy: 1.0000\n",
      "Epoch 159/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.6763e-05 - accuracy: 1.0000\n",
      "Epoch 160/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.3843e-05 - accuracy: 1.0000\n",
      "Epoch 161/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step - loss: 6.1409e-05 - accuracy: 1.0000\n",
      "Epoch 162/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.9489e-05 - accuracy: 1.0000\n",
      "Epoch 163/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.8590e-05 - accuracy: 1.0000\n",
      "Epoch 164/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.4885e-05 - accuracy: 1.0000\n",
      "Epoch 165/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.3284e-05 - accuracy: 1.0000\n",
      "Epoch 166/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.1109e-05 - accuracy: 1.0000\n",
      "Epoch 167/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.9305e-05 - accuracy: 1.0000\n",
      "Epoch 168/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.7312e-05 - accuracy: 1.0000\n",
      "Epoch 169/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.5920e-05 - accuracy: 1.0000\n",
      "Epoch 170/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.4115e-05 - accuracy: 1.0000\n",
      "Epoch 171/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.2177e-05 - accuracy: 1.0000\n",
      "Epoch 172/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.0092e-05 - accuracy: 1.0000\n",
      "Epoch 173/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.9194e-05 - accuracy: 1.0000\n",
      "Epoch 174/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.7583e-05 - accuracy: 1.0000\n",
      "Epoch 175/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.6119e-05 - accuracy: 1.0000\n",
      "Epoch 176/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 3.4542e-05 - accuracy: 1.0000\n",
      "Epoch 177/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.3268e-05 - accuracy: 1.0000\n",
      "Epoch 178/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.2099e-05 - accuracy: 1.0000\n",
      "Epoch 179/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.1215e-05 - accuracy: 1.0000\n",
      "Epoch 180/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.0028e-05 - accuracy: 1.0000\n",
      "Epoch 181/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.8722e-05 - accuracy: 1.0000\n",
      "Epoch 182/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.7806e-05 - accuracy: 1.0000\n",
      "Epoch 183/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.6819e-05 - accuracy: 1.0000\n",
      "Epoch 184/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.6199e-05 - accuracy: 1.0000\n",
      "Epoch 185/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.4847e-05 - accuracy: 1.0000\n",
      "Epoch 186/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.3665e-05 - accuracy: 1.0000\n",
      "Epoch 187/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.3044e-05 - accuracy: 1.0000\n",
      "Epoch 188/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.2256e-05 - accuracy: 1.0000\n",
      "Epoch 189/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.1292e-05 - accuracy: 1.0000\n",
      "Epoch 190/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.0793e-05 - accuracy: 1.0000\n",
      "Epoch 191/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9773e-05 - accuracy: 1.0000\n",
      "Epoch 192/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9030e-05 - accuracy: 1.0000\n",
      "Epoch 193/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.8427e-05 - accuracy: 1.0000\n",
      "Epoch 194/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7588e-05 - accuracy: 1.0000\n",
      "Epoch 195/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7110e-05 - accuracy: 1.0000\n",
      "Epoch 196/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.6381e-05 - accuracy: 1.0000\n",
      "Epoch 197/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.5759e-05 - accuracy: 1.0000\n",
      "Epoch 198/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.5274e-05 - accuracy: 1.0000\n",
      "Epoch 199/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4669e-05 - accuracy: 1.0000\n",
      "Epoch 200/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4153e-05 - accuracy: 1.0000\n",
      "Epoch 201/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3545e-05 - accuracy: 1.0000\n",
      "Epoch 202/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3031e-05 - accuracy: 1.0000\n",
      "Epoch 203/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2667e-05 - accuracy: 1.0000\n",
      "Epoch 204/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2104e-05 - accuracy: 1.0000\n",
      "Epoch 205/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1735e-05 - accuracy: 1.0000\n",
      "Epoch 206/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1236e-05 - accuracy: 1.0000\n",
      "Epoch 207/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0959e-05 - accuracy: 1.0000\n",
      "Epoch 208/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0398e-05 - accuracy: 1.0000\n",
      "Epoch 209/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0166e-05 - accuracy: 1.0000\n",
      "Epoch 210/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.7599e-06 - accuracy: 1.0000\n",
      "Epoch 211/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.3359e-06 - accuracy: 1.0000\n",
      "Epoch 212/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.0245e-06 - accuracy: 1.0000\n",
      "Epoch 213/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.7559e-06 - accuracy: 1.0000\n",
      "Epoch 214/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.4626e-06 - accuracy: 1.0000\n",
      "Epoch 215/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.1180e-06 - accuracy: 1.0000\n",
      "Epoch 216/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.7880e-06 - accuracy: 1.0000\n",
      "Epoch 217/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.5881e-06 - accuracy: 1.0000\n",
      "Epoch 218/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.2886e-06 - accuracy: 1.0000\n",
      "Epoch 219/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.9764e-06 - accuracy: 1.0000\n",
      "Epoch 220/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.6843e-06 - accuracy: 1.0000\n",
      "Epoch 221/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.4988e-06 - accuracy: 1.0000\n",
      "Epoch 222/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.3463e-06 - accuracy: 1.0000\n",
      "Epoch 223/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.0278e-06 - accuracy: 1.0000\n",
      "Epoch 224/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.9094e-06 - accuracy: 1.0000\n",
      "Epoch 225/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.6312e-06 - accuracy: 1.0000\n",
      "Epoch 226/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.4144e-06 - accuracy: 1.0000\n",
      "Epoch 227/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.3188e-06 - accuracy: 1.0000\n",
      "Epoch 228/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.0784e-06 - accuracy: 1.0000\n",
      "Epoch 229/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.9063e-06 - accuracy: 1.0000\n",
      "Epoch 230/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.6982e-06 - accuracy: 1.0000\n",
      "Epoch 231/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.5483e-06 - accuracy: 1.0000\n",
      "Epoch 232/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.3603e-06 - accuracy: 1.0000\n",
      "Epoch 233/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.2306e-06 - accuracy: 1.0000\n",
      "Epoch 234/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.0189e-06 - accuracy: 1.0000\n",
      "Epoch 235/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 3.9133e-06 - accuracy: 1.0000\n",
      "Epoch 236/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.7952e-06 - accuracy: 1.0000\n",
      "Epoch 237/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.6088e-06 - accuracy: 1.0000\n",
      "Epoch 238/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.4739e-06 - accuracy: 1.0000\n",
      "Epoch 239/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step - loss: 3.3731e-06 - accuracy: 1.0000\n",
      "Epoch 240/400\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 3.2471e-06 - accuracy: 1.0000\n",
      "Epoch 241/400\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 3.1399e-06 - accuracy: 1.0000\n",
      "Epoch 242/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.0280e-06 - accuracy: 1.0000\n",
      "Epoch 243/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.9261e-06 - accuracy: 1.0000\n",
      "Epoch 244/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.8375e-06 - accuracy: 1.0000\n",
      "Epoch 245/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.7136e-06 - accuracy: 1.0000\n",
      "Epoch 246/400\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 2.6361e-06 - accuracy: 1.0000\n",
      "Epoch 247/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.5444e-06 - accuracy: 1.0000\n",
      "Epoch 248/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.4465e-06 - accuracy: 1.0000\n",
      "Epoch 249/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.3859e-06 - accuracy: 1.0000\n",
      "Epoch 250/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.2718e-06 - accuracy: 1.0000\n",
      "Epoch 251/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.2275e-06 - accuracy: 1.0000\n",
      "Epoch 252/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.1273e-06 - accuracy: 1.0000\n",
      "Epoch 253/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.0457e-06 - accuracy: 1.0000\n",
      "Epoch 254/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9696e-06 - accuracy: 1.0000\n",
      "Epoch 255/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9080e-06 - accuracy: 1.0000\n",
      "Epoch 256/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.8686e-06 - accuracy: 1.0000\n",
      "Epoch 257/400\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 1.7675e-06 - accuracy: 1.0000\n",
      "Epoch 258/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7351e-06 - accuracy: 1.0000\n",
      "Epoch 259/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.6563e-06 - accuracy: 1.0000\n",
      "Epoch 260/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.5849e-06 - accuracy: 1.0000\n",
      "Epoch 261/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.5440e-06 - accuracy: 1.0000\n",
      "Epoch 262/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4827e-06 - accuracy: 1.0000\n",
      "Epoch 263/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4335e-06 - accuracy: 1.0000\n",
      "Epoch 264/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3886e-06 - accuracy: 1.0000\n",
      "Epoch 265/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3454e-06 - accuracy: 1.0000\n",
      "Epoch 266/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2878e-06 - accuracy: 1.0000\n",
      "Epoch 267/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2582e-06 - accuracy: 1.0000\n",
      "Epoch 268/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2134e-06 - accuracy: 1.0000\n",
      "Epoch 269/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1780e-06 - accuracy: 1.0000\n",
      "Epoch 270/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1281e-06 - accuracy: 1.0000\n",
      "Epoch 271/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0957e-06 - accuracy: 1.0000\n",
      "Epoch 272/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0634e-06 - accuracy: 1.0000\n",
      "Epoch 273/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0248e-06 - accuracy: 1.0000\n",
      "Epoch 274/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.9869e-07 - accuracy: 1.0000\n",
      "Epoch 275/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.4976e-07 - accuracy: 1.0000\n",
      "Epoch 276/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.1002e-07 - accuracy: 1.0000\n",
      "Epoch 277/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.7982e-07 - accuracy: 1.0000\n",
      "Epoch 278/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.5626e-07 - accuracy: 1.0000\n",
      "Epoch 279/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.3129e-07 - accuracy: 1.0000\n",
      "Epoch 280/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.0665e-07 - accuracy: 1.0000\n",
      "Epoch 281/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.6907e-07 - accuracy: 1.0000\n",
      "Epoch 282/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.5346e-07 - accuracy: 1.0000\n",
      "Epoch 283/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.2088e-07 - accuracy: 1.0000\n",
      "Epoch 284/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.0197e-07 - accuracy: 1.0000\n",
      "Epoch 285/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.7302e-07 - accuracy: 1.0000\n",
      "Epoch 286/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.5242e-07 - accuracy: 1.0000\n",
      "Epoch 287/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.3067e-07 - accuracy: 1.0000\n",
      "Epoch 288/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.0950e-07 - accuracy: 1.0000\n",
      "Epoch 289/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.9043e-07 - accuracy: 1.0000\n",
      "Epoch 290/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.6579e-07 - accuracy: 1.0000\n",
      "Epoch 291/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.5086e-07 - accuracy: 1.0000\n",
      "Epoch 292/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.3207e-07 - accuracy: 1.0000\n",
      "Epoch 293/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.1430e-07 - accuracy: 1.0000\n",
      "Epoch 294/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.0153e-07 - accuracy: 1.0000\n",
      "Epoch 295/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.7985e-07 - accuracy: 1.0000\n",
      "Epoch 296/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.7144e-07 - accuracy: 1.0000\n",
      "Epoch 297/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.5169e-07 - accuracy: 1.0000\n",
      "Epoch 298/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.3205e-07 - accuracy: 1.0000\n",
      "Epoch 299/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.2433e-07 - accuracy: 1.0000\n",
      "Epoch 300/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.0350e-07 - accuracy: 1.0000\n",
      "Epoch 301/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.9560e-07 - accuracy: 1.0000\n",
      "Epoch 302/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.8181e-07 - accuracy: 1.0000\n",
      "Epoch 303/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.7137e-07 - accuracy: 1.0000\n",
      "Epoch 304/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 3.5757e-07 - accuracy: 1.0000\n",
      "Epoch 305/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.4968e-07 - accuracy: 1.0000\n",
      "Epoch 306/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.3776e-07 - accuracy: 1.0000\n",
      "Epoch 307/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.2391e-07 - accuracy: 1.0000\n",
      "Epoch 308/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.1204e-07 - accuracy: 1.0000\n",
      "Epoch 309/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.0637e-07 - accuracy: 1.0000\n",
      "Epoch 310/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.9252e-07 - accuracy: 1.0000\n",
      "Epoch 311/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.8656e-07 - accuracy: 1.0000\n",
      "Epoch 312/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.7662e-07 - accuracy: 1.0000\n",
      "Epoch 313/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.7061e-07 - accuracy: 1.0000\n",
      "Epoch 314/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.5937e-07 - accuracy: 1.0000\n",
      "Epoch 315/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.5108e-07 - accuracy: 1.0000\n",
      "Epoch 316/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.4211e-07 - accuracy: 1.0000\n",
      "Epoch 317/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step - loss: 2.3643e-07 - accuracy: 1.0000\n",
      "Epoch 318/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.2854e-07 - accuracy: 1.0000\n",
      "Epoch 319/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.2218e-07 - accuracy: 1.0000\n",
      "Epoch 320/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.1458e-07 - accuracy: 1.0000\n",
      "Epoch 321/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.1009e-07 - accuracy: 1.0000\n",
      "Epoch 322/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.0453e-07 - accuracy: 1.0000\n",
      "Epoch 323/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9828e-07 - accuracy: 1.0000\n",
      "Epoch 324/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9028e-07 - accuracy: 1.0000\n",
      "Epoch 325/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.8591e-07 - accuracy: 1.0000\n",
      "Epoch 326/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7978e-07 - accuracy: 1.0000\n",
      "Epoch 327/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7649e-07 - accuracy: 1.0000\n",
      "Epoch 328/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7251e-07 - accuracy: 1.0000\n",
      "Epoch 329/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.6701e-07 - accuracy: 1.0000\n",
      "Epoch 330/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.6110e-07 - accuracy: 1.0000\n",
      "Epoch 331/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.5787e-07 - accuracy: 1.0000\n",
      "Epoch 332/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.5463e-07 - accuracy: 1.0000\n",
      "Epoch 333/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4969e-07 - accuracy: 1.0000\n",
      "Epoch 334/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4731e-07 - accuracy: 1.0000\n",
      "Epoch 335/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4282e-07 - accuracy: 1.0000\n",
      "Epoch 336/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4050e-07 - accuracy: 1.0000\n",
      "Epoch 337/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3726e-07 - accuracy: 1.0000\n",
      "Epoch 338/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3482e-07 - accuracy: 1.0000\n",
      "Epoch 339/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3249e-07 - accuracy: 1.0000\n",
      "Epoch 340/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2863e-07 - accuracy: 1.0000\n",
      "Epoch 341/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2835e-07 - accuracy: 1.0000\n",
      "Epoch 342/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2523e-07 - accuracy: 1.0000\n",
      "Epoch 343/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2472e-07 - accuracy: 1.0000\n",
      "Epoch 344/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2262e-07 - accuracy: 1.0000\n",
      "Epoch 345/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2063e-07 - accuracy: 1.0000\n",
      "Epoch 346/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1858e-07 - accuracy: 1.0000\n",
      "Epoch 347/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2403e-07 - accuracy: 1.0000\n",
      "Epoch 348/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1597e-07 - accuracy: 1.0000\n",
      "Epoch 349/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1296e-07 - accuracy: 1.0000\n",
      "Epoch 350/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1143e-07 - accuracy: 1.0000\n",
      "Epoch 351/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1166e-07 - accuracy: 1.0000\n",
      "Epoch 352/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1450e-07 - accuracy: 1.0000\n",
      "Epoch 353/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1064e-07 - accuracy: 1.0000\n",
      "Epoch 354/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0655e-07 - accuracy: 1.0000\n",
      "Epoch 355/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2602e-07 - accuracy: 1.0000\n",
      "Epoch 356/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.3985 - accuracy: 0.7967\n",
      "Epoch 357/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9976\n",
      "Epoch 358/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7187e-04 - accuracy: 1.0000\n",
      "Epoch 359/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0938e-04 - accuracy: 1.0000\n",
      "Epoch 360/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.3885e-05 - accuracy: 1.0000\n",
      "Epoch 361/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.8189e-05 - accuracy: 1.0000\n",
      "Epoch 362/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.7744e-05 - accuracy: 1.0000\n",
      "Epoch 363/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 5.0196e-05 - accuracy: 1.0000\n",
      "Epoch 364/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 4.4246e-05 - accuracy: 1.0000\n",
      "Epoch 365/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.9593e-05 - accuracy: 1.0000\n",
      "Epoch 366/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.5836e-05 - accuracy: 1.0000\n",
      "Epoch 367/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.2662e-05 - accuracy: 1.0000\n",
      "Epoch 368/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 3.0008e-05 - accuracy: 1.0000\n",
      "Epoch 369/400\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.7707e-05 - accuracy: 1.0000\n",
      "Epoch 370/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.5738e-05 - accuracy: 1.0000\n",
      "Epoch 371/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.4006e-05 - accuracy: 1.0000\n",
      "Epoch 372/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.2465e-05 - accuracy: 1.0000\n",
      "Epoch 373/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 2.1104e-05 - accuracy: 1.0000\n",
      "Epoch 374/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.9880e-05 - accuracy: 1.0000\n",
      "Epoch 375/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.8782e-05 - accuracy: 1.0000\n",
      "Epoch 376/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.7785e-05 - accuracy: 1.0000\n",
      "Epoch 377/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.6863e-05 - accuracy: 1.0000\n",
      "Epoch 378/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.6033e-05 - accuracy: 1.0000\n",
      "Epoch 379/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.5271e-05 - accuracy: 1.0000\n",
      "Epoch 380/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.4565e-05 - accuracy: 1.0000\n",
      "Epoch 381/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3911e-05 - accuracy: 1.0000\n",
      "Epoch 382/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.3309e-05 - accuracy: 1.0000\n",
      "Epoch 383/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2746e-05 - accuracy: 1.0000\n",
      "Epoch 384/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.2221e-05 - accuracy: 1.0000\n",
      "Epoch 385/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1732e-05 - accuracy: 1.0000\n",
      "Epoch 386/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.1278e-05 - accuracy: 1.0000\n",
      "Epoch 387/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0844e-05 - accuracy: 1.0000\n",
      "Epoch 388/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0436e-05 - accuracy: 1.0000\n",
      "Epoch 389/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 1.0056e-05 - accuracy: 1.0000\n",
      "Epoch 390/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.6956e-06 - accuracy: 1.0000\n",
      "Epoch 391/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.3541e-06 - accuracy: 1.0000\n",
      "Epoch 392/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 9.0328e-06 - accuracy: 1.0000\n",
      "Epoch 393/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.7265e-06 - accuracy: 1.0000\n",
      "Epoch 394/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 8.4398e-06 - accuracy: 1.0000\n",
      "Epoch 395/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step - loss: 8.1652e-06 - accuracy: 1.0000\n",
      "Epoch 396/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.8994e-06 - accuracy: 1.0000\n",
      "Epoch 397/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.6503e-06 - accuracy: 1.0000\n",
      "Epoch 398/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.4105e-06 - accuracy: 1.0000\n",
      "Epoch 399/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 7.1847e-06 - accuracy: 1.0000\n",
      "Epoch 400/400\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 6.9649e-06 - accuracy: 1.0000\n",
      "66/66 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "print(\"==========================================\")\n",
    "print(\"Training Classifer Portion of Type-A Model\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [2]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers,\n",
    "                                                                                                        X_test = X_test)\n",
    "\n",
    "print(\"=================================================\")\n",
    "print(\"Training Classifer Portion of Type-A Model: Done!\")\n",
    "print(\"=================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:03, 29.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:26<00:00,  3.81it/s]\n",
      " 27%|██▋       | 27/100 [00:00<00:00, 266.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 118.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Format Weights\n",
    "## Train\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): START\")\n",
    "print(\"#---------------------------------------#\")\n",
    "Predicted_Weights = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    b = np.repeat(np.array(predicted_classes_train[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): END\")\n",
    "print(\"#-------------------------------------#\")\n",
    "\n",
    "## Test\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): START\")\n",
    "print(\"#-------------------------------------#\")\n",
    "Predicted_Weights_test = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):\n",
    "    b_test = np.repeat(np.array(predicted_classes_test[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b_test = b_test/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights_test = b_test\n",
    "    else:\n",
    "        Predicted_Weights_test = np.append(Predicted_Weights_test,b_test,axis=1)\n",
    "print(\"#-----------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): END\")\n",
    "print(\"#-----------------------------------#\")\n",
    "        \n",
    "# Format Points of Mass\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: START\")\n",
    "print(\"#-----------------------------#\")\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: END\")\n",
    "print(\"#-----------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2099 [00:00<00:55, 37.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2099/2099 [00:43<00:00, 48.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.001669</td>\n",
       "      <td>2.407174e-09</td>\n",
       "      <td>4.552322e-17</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.016975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.573796</td>\n",
       "      <td>4.270876e-02</td>\n",
       "      <td>2.462486e+00</td>\n",
       "      <td>1.433613</td>\n",
       "      <td>2.404198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>40.481232</td>\n",
       "      <td>4.139603e-01</td>\n",
       "      <td>2.077592e+02</td>\n",
       "      <td>11.109448</td>\n",
       "      <td>19.603060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            W1    E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min   0.001669  2.407174e-09         4.552322e-17                0.002861   \n",
       "MAE   6.573796  4.270876e-02         2.462486e+00                1.433613   \n",
       "Max  40.481232  4.139603e-01         2.077592e+02               11.109448   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.016975  \n",
       "MAE              2.404198  \n",
       "Max             19.603060  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Training Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "Skewness_errors = np.array([])\n",
    "Kurtosis_errors = np.array([])\n",
    "predictions_mean = np.array([])\n",
    "true_mean = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         (np.array(measures_weights_list[x_i])).reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(np.array(measures_locations_list[x_i]))\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    ## Update Erros\n",
    "    predictions_mean = np.append(predictions_mean,Mu_hat)\n",
    "    true_mean = np.append(true_mean,Mu)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(np.array(measures_locations_list[x_i])**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat = np.sum((Barycenters_Array**3)*(Predicted_Weights[x_i]))\n",
    "    Skewness = np.mean(np.array(measures_locations_list[x_i])**3)\n",
    "    Skewness_errors = np.append(Skewness_errors,(abs(Skewness_hat-Skewness))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat = np.sum((Barycenters_Array**4)*(Predicted_Weights[x_i]))\n",
    "    Kurtosis = np.mean(np.array(measures_locations_list[x_i])**4)\n",
    "    Kurtosis_errors = np.append(Kurtosis_errors,(abs(Kurtosis_hat-Kurtosis))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.min(np.abs(W1_errors)),np.mean(np.abs(W1_errors)),np.max(np.abs(W1_errors))])\n",
    "Mean_prediction_Performance = np.array([np.min(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors)),np.max(np.abs(Mean_errors))])\n",
    "Var_prediction_Performance = np.array([np.min(np.abs(Var_errors)),np.mean(np.abs(Var_errors)),np.max(np.abs(Var_errors))])\n",
    "Skewness_prediction_Performance = np.array([np.min(np.abs(Skewness_errors)),np.mean(np.abs(Skewness_errors)),np.max(np.abs(Skewness_errors))])\n",
    "Kurtosis_prediction_Performance = np.array([np.min(np.abs(Kurtosis_errors)),np.mean(np.abs(Kurtosis_errors)),np.max(np.abs(Kurtosis_errors))])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Train.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:00<00:02, 37.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 46.69it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Test Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors_test = np.array([])\n",
    "Mean_errors_test = np.array([])\n",
    "Var_errors_test = np.array([])\n",
    "Skewness_errors_test = np.array([])\n",
    "Kurtosis_errors_test = np.array([])\n",
    "# Initialize Prediction Metrics\n",
    "predictions_mean_test = np.array([])\n",
    "true_mean_test = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_test_list))):    \n",
    "    # Get Laws\n",
    "    W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_test_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights_test[x_i,].reshape(-1,),\n",
    "                         (np.array(measures_weights_test_list[x_i])).reshape(-1,))\n",
    "    W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "    # Get Means\n",
    "    Mu_hat_test = np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array))\n",
    "    Mu_test = np.mean(np.array(measures_locations_test_list[x_i]))\n",
    "    Mean_errors_test = np.append(Mean_errors_test,(Mu_hat_test-Mu_test))\n",
    "    ## Update Predictions\n",
    "    predictions_mean_test = np.append(predictions_mean_test,Mu_hat_test)\n",
    "    true_mean_test = np.append(true_mean_test,Mu_test)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat_test = np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))\n",
    "    Var_test = np.mean(np.array(measures_locations_test_list[x_i])**2)\n",
    "    Var_errors_test = np.append(Var_errors_test,(Var_hat_test-Var_test)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat_test = np.sum((Barycenters_Array**3)*(Predicted_Weights_test[x_i]))\n",
    "    Skewness_test = np.mean(np.array(measures_locations_test_list[x_i])**3)\n",
    "    Skewness_errors_test = np.append(Skewness_errors_test,(abs(Skewness_hat_test-Skewness_test))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat_test = np.sum((Barycenters_Array**4)*(Predicted_Weights_test[x_i]))\n",
    "    Kurtosis_test = np.mean(np.array(measures_locations_test_list[x_i])**4)\n",
    "    Kurtosis_errors_test = np.append(Kurtosis_errors_test,(abs(Kurtosis_hat_test-Kurtosis_test))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance_test = np.array([np.min(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test))])\n",
    "Mean_prediction_Performance_test = np.array([np.min(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test))])\n",
    "Var_prediction_Performance_test = np.array([np.min(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test))])\n",
    "Skewness_prediction_Performance_test = np.array([np.min(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test))])\n",
    "Kurtosis_prediction_Performance_test = np.array([np.min(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test))])\n",
    "\n",
    "Type_A_Prediction_test = pd.DataFrame({\"W1\":W1_Performance_test,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance_test,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance_test,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance_test,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance_test},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction_test.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Test.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7993000c50>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean,label=\"prediction\",color=\"purple\")\n",
    "plt.plot(true_mean,label=\"true\",color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7940701910>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean_test,color=\"purple\")\n",
    "plt.plot(true_mean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print for Terminal Legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "            W1    E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min   0.001669  2.407174e-09         4.552322e-17                0.002861   \n",
      "MAE   6.573796  4.270876e-02         2.462486e+00                1.433613   \n",
      "Max  40.481232  4.139603e-01         2.077592e+02               11.109448   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.016975  \n",
      "MAE              2.404198  \n",
      "Max             19.603060  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  0.024850    0.130777             0.355226                0.691216   \n",
      "MAE  1.867726    0.601342           104.437530                3.258045   \n",
      "Max  1.867726    0.601342           104.437530                3.258045   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              1.459013  \n",
      "MAE              4.405871  \n",
      "Max              4.405871  \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------------#\")\n",
    "print(\"Training-Set Performance\")\n",
    "print(\"#----------------------#\")\n",
    "print(Type_A_Prediction)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"#------------------#\")\n",
    "print(\"Test-Set Performance\")\n",
    "print(\"#------------------#\")\n",
    "print(Type_A_Prediction_test)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.001669</td>\n",
       "      <td>2.407174e-09</td>\n",
       "      <td>4.552322e-17</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.016975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.573796</td>\n",
       "      <td>4.270876e-02</td>\n",
       "      <td>2.462486e+00</td>\n",
       "      <td>1.433613</td>\n",
       "      <td>2.404198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>40.481232</td>\n",
       "      <td>4.139603e-01</td>\n",
       "      <td>2.077592e+02</td>\n",
       "      <td>11.109448</td>\n",
       "      <td>19.603060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            W1    E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min   0.001669  2.407174e-09         4.552322e-17                0.002861   \n",
       "MAE   6.573796  4.270876e-02         2.462486e+00                1.433613   \n",
       "Max  40.481232  4.139603e-01         2.077592e+02               11.109448   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.016975  \n",
       "MAE              2.404198  \n",
       "Max             19.603060  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.024850</td>\n",
       "      <td>0.130777</td>\n",
       "      <td>0.355226</td>\n",
       "      <td>0.691216</td>\n",
       "      <td>1.459013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.867726</td>\n",
       "      <td>0.601342</td>\n",
       "      <td>104.437530</td>\n",
       "      <td>3.258045</td>\n",
       "      <td>4.405871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>1.867726</td>\n",
       "      <td>0.601342</td>\n",
       "      <td>104.437530</td>\n",
       "      <td>3.258045</td>\n",
       "      <td>4.405871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.024850    0.130777             0.355226                0.691216   \n",
       "MAE  1.867726    0.601342           104.437530                3.258045   \n",
       "Max  1.867726    0.601342           104.437530                3.258045   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              1.459013  \n",
       "MAE              4.405871  \n",
       "Max              4.405871  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
