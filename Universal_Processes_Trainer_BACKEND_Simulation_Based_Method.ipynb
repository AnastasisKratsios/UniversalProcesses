{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Conditional Laws for Random-Fields - via:\n",
    "\n",
    "## Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "\n",
    "---\n",
    "\n",
    "By: [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*.\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth:\n",
    "*The build-in Options:*\n",
    "- rSDE \n",
    "- pfBM\n",
    "- 2lnflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth = \"2lnflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 5\n",
    "N_Monte_Carlo_Samples = 10**2\n",
    "N_Monte_Carlo_Samples_Test = 10**1 # How many MC-samples to draw from test-set?\n",
    "\n",
    "# End times for Time-Grid\n",
    "T_end = 1\n",
    "T_end_test = 1.1\n",
    "\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 5\n",
    "Max_Grid = 1\n",
    "\n",
    "# \n",
    "N_Quantizers_to_parameterize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "N_measures_per_center = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP:\n",
    "from operator import itemgetter \n",
    "from itertools import compress\n",
    "# Set Minibatch Size\n",
    "Random_Cover_Mini_Batch_Size = 100\n",
    "# Proportion of Clusters per Minibatch Sample\n",
    "# Quantization_Proportion = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Measure-Valued $2$-Parameter Log-Gaussian Flow\n",
    "$$\n",
    "X_{t,x} \\sim \\log\\text{-}\\mathcal{N}\\left(\\alpha(t,x),\\beta(t,x)\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** *$\\alpha$ and $\\beta$ are specified below in the SDE Example*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Rough SDE\n",
    "Simulate via Euler-M method from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T((1-\\eta)\\beta(s,x)+\\eta\\sigma_s^H)dW_s.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return (.1-.5*(.01**2))*t + np.cos(x)*np.exp(-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rougness = 0.9 # Hurst Parameter\n",
    "Ratio_fBM_to_typical_vol = 0 # $\\eta$ in equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed Fractional Brownian Motion\n",
    "Simulate from:\n",
    "$$\n",
    "X_t^x(\\omega) = f_1(x)f_2(t) + B_t^H(\\omega).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_dirction_x(x):\n",
    "    return x*np.cos(x)\n",
    "\n",
    "def finite_variation_t(t):\n",
    "    return t*(np.sin(math.pi*t) + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "# %run ParaGAN_Backend.ipynb\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of Auxiliary Internal-Variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "measure_weights_test = np.ones(N_Monte_Carlo_Samples_Test)/N_Monte_Carlo_Samples_Test\n",
    "\n",
    "# Get number of centers\n",
    "N_Centers_per_box = max(1,int(round(np.sqrt(N_Quantizers_to_parameterize))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Centers Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grid of Barycenters\n",
    "x_Grid_barycenters = np.arange(start=-Max_Grid,\n",
    "                               stop=Max_Grid,\n",
    "                               step = (2*Max_Grid/N_Centers_per_box))\n",
    "t_Grid_barycenters = np.arange(start=0,\n",
    "                               stop=T_end,\n",
    "                               step = (T_end/N_Centers_per_box))\n",
    "for x_i in range(len(x_Grid_barycenters)):\n",
    "    for t_j in range(len(t_Grid_barycenters)):\n",
    "        new_grid_entry = np.array([t_Grid_barycenters[t_j],x_Grid_barycenters[x_i]]).reshape(1,-1)\n",
    "        if (x_i==0 and t_j ==0):\n",
    "            Grid_Barycenters = new_grid_entry\n",
    "        else:\n",
    "            Grid_Barycenters = np.append(Grid_Barycenters,new_grid_entry,axis=0)\n",
    "\n",
    "# Update Number of Quantizers Generated\n",
    "N_Quantizers_to_parameterize = Grid_Barycenters.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Simulator.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer (Model Type A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $2$-Parameter $\\log$-Gaussian Flow\n",
    "### Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if groud_truth == \"2lnflow\":\n",
    "    # Generate Training Data\n",
    "    for i in range(Grid_Barycenters.shape[0]):\n",
    "        # Get output for center (mu-hat)\n",
    "        center_current, trash = twoparameter_flow_sampler((Grid_Barycenters[i]).reshape(1,2),N_Monte_Carlo_Samples)\n",
    "\n",
    "        # Get random sample in delta ball around ith center\n",
    "        sub_grid_loop = np.random.uniform(0,delta,(N_measures_per_center,2)) + Grid_Barycenters[i]\n",
    "\n",
    "        # Get Measures for this random sample\n",
    "        measures_locations_list_current, measures_weights_list_current = twoparameter_flow_sampler(sub_grid_loop,N_Monte_Carlo_Samples)\n",
    "        ##\n",
    "        measures_locations_list_current = measures_locations_list_current + center_current\n",
    "        measures_weights_list_current = measures_weights_list_current + trash\n",
    "        # Update Classes\n",
    "        Classifer_Wasserstein_Centers_loop = np.zeros([(N_measures_per_center+1),N_Quantizers_to_parameterize]) # The +1 is to account for the center which will be added to the random ball\n",
    "        Classifer_Wasserstein_Centers_loop[:, i] =  1\n",
    "        # Updates Classes\n",
    "        if i==0:\n",
    "            # INITIALIZE: Classifiers\n",
    "            Classifer_Wasserstein_Centers = Classifer_Wasserstein_Centers_loop\n",
    "            # INITIALIZE: Training Data\n",
    "            X_train = np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0)\n",
    "            # INITIALIZE: Barycenters Array\n",
    "            Barycenters_Array = (center_current[0]).reshape(-1,1)\n",
    "            # INITIALIZE: Measures and locations\n",
    "            measures_locations_list = measures_locations_list_current\n",
    "            measures_weights_list = measures_weights_list_current\n",
    "        else:\n",
    "            # UPDATE: Classifer\n",
    "            Classifer_Wasserstein_Centers = np.append(Classifer_Wasserstein_Centers,Classifer_Wasserstein_Centers_loop,axis=0)\n",
    "            # UPDATE: Training Data\n",
    "            X_train = np.append(X_train,np.append((Grid_Barycenters[i]).reshape(1,2),sub_grid_loop,axis=0),axis=0)\n",
    "            # UPDATE: Populate Barycenters Array\n",
    "            Barycenters_Array = np.append(Barycenters_Array,((center_current[0]).reshape(-1,1)),axis=-1)\n",
    "            # UPDATE: Measures and locations\n",
    "            measures_locations_list = measures_locations_list + measures_locations_list_current\n",
    "            measures_weights_list = measures_locations_list + measures_weights_list_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if groud_truth == \"2lnflow\":\n",
    "    # Generate Testing Dataset (Inputs)\n",
    "    x_tests = np.random.uniform(np.min(X_train[:,0]),np.max(X_train[:,0]),10)\n",
    "    t_tests = np.arange(start=0,\n",
    "                        stop=T_end,\n",
    "                        step = (T_end_test/N_Euler_Maruyama_Steps))\n",
    "\n",
    "    for x_i in range(len(x_tests)):\n",
    "        for t_j in range(len(t_tests)):\n",
    "            test_set_entry = np.array([t_tests[t_j],x_tests[x_i]]).reshape(1,-1)\n",
    "            if (x_i==0 and t_j ==0):\n",
    "                X_test = test_set_entry\n",
    "            else:\n",
    "                X_test = np.append(X_test,test_set_entry,axis=0)\n",
    "\n",
    "    # Generate Testing Dataset (Outputs)\n",
    "    measures_locations_test_list, measures_weights_test_list = twoparameter_flow_sampler(X_test,N_Monte_Carlo_Samples_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough SDE:\n",
    "Simulation of the random-field:\n",
    "$$\n",
    "X_t^x = x + \\int_0^t \\alpha(s,X_t^x)ds + (1-\\eta)\\int_0^t \\beta(s,X_t^x)dW_t + \\int_0^t B_s^H dW_s;\n",
    "$$\n",
    "where: \n",
    " - $(B_t^H)_t$ is a [fractional Brownian Motion](https://arxiv.org/pdf/1406.1956.pdf) with [Hurst exponent](https://en.wikipedia.org/wiki/Hurst_exponent) $H\\in (0,1)$,\n",
    " - $(W_t)_t$ is a [Brownian Motion](https://en.wikipedia.org/wiki/Wiener_process),\n",
    " - $\\alpha$ and $\\beta$ are uniformly [Lipschitz-functions](https://en.wikipedia.org/wiki/Lipschitz_continuity) of appropriate input/output dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Simulator.ipynb\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if groud_truth == \"rSDE\":\n",
    "    # Initialize position Counter\n",
    "    position_counter = 0\n",
    "    # Iniitalize uniform weights vector\n",
    "    measures_weights_list_loop = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "\n",
    "    # Overrine Number of Centers\n",
    "    N_x = len(x_Grid_barycenters)\n",
    "    N_t = len(t_Grid_barycenters)\n",
    "    N_Quantizers_to_parameterize = N_x*N_t\n",
    "\n",
    "    for x_i in range(N_x):\n",
    "        for t_j in range(N_t):\n",
    "\n",
    "            # Get Current Locations\n",
    "            x_center = x_Grid_barycenters[x_i]\n",
    "            t_center = t_Grid_barycenters[t_j]\n",
    "\n",
    "            current_cover = Euler_Maruyama_Generator(x_0 = x_center,\n",
    "                                                     N_Euler_Maruyama_Steps = N_Euler_Maruyama_Steps,\n",
    "                                                     N_Monte_Carlo_Samples = N_Monte_Carlo_Samples,\n",
    "                                                     T_begin = t_center,\n",
    "                                                     T_end = (t_center+delta),\n",
    "                                                     Hurst = 0.1,\n",
    "                                                     Ratio_fBM_to_typical_vol = 0.5)\n",
    "\n",
    "            barycenter_at_current_location = current_cover[0,:]\n",
    "\n",
    "            measures_locations_list_current = current_cover.tolist()\n",
    "            measures_weights_list_current = list(itertools.repeat(measures_weights_list_loop,N_Monte_Carlo_Samples))\n",
    "\n",
    "            # Get Current Training Data Positions\n",
    "            t_grid_current = (np.linspace(start=t_center,\n",
    "                                          stop=(t_center+delta),\n",
    "                                          num=N_Euler_Maruyama_Steps)).reshape(1,-1)\n",
    "            x_grid_current = (x_center*np.ones(N_Euler_Maruyama_Steps)).reshape(1,-1)\n",
    "\n",
    "            X_train_current = (np.append(x_grid_current,t_grid_current,axis=0)).T\n",
    "\n",
    "            # Get Current Classes\n",
    "            Classifer_Wasserstein_Centers_loop = np.zeros([N_Euler_Maruyama_Steps,N_Quantizers_to_parameterize])\n",
    "            Classifer_Wasserstein_Centers_loop[:, position_counter] =  1\n",
    "\n",
    "\n",
    "            # Updates Classes\n",
    "            if (x_i==0 and t_j==0):\n",
    "                # INITIALIZE: Classifiers\n",
    "                Classifer_Wasserstein_Centers = Classifer_Wasserstein_Centers_loop\n",
    "                # INITIALIZE: Training Data\n",
    "                X_train = X_train_current\n",
    "                # INITIALIZE: Barycenters Array\n",
    "                Barycenters_Array = barycenter_at_current_location.reshape(-1,1)\n",
    "                # INITIALIZE: Measures and locations\n",
    "                measures_locations_list = measures_locations_list_current\n",
    "                measures_weights_list = measures_weights_list_current\n",
    "            else:\n",
    "                # UPDATE: Classifer\n",
    "                Classifer_Wasserstein_Centers = np.append(Classifer_Wasserstein_Centers,Classifer_Wasserstein_Centers_loop,axis=0)\n",
    "                # UPDATE: Training Data\n",
    "                X_train = np.append(X_train,X_train_current,axis=0)\n",
    "                # UPDATE: Populate Barycenters Array\n",
    "                Barycenters_Array = np.append(Barycenters_Array,(barycenter_at_current_location.reshape(-1,1)),axis=-1)\n",
    "                # UPDATE: Measures and locations\n",
    "                measures_locations_list = measures_locations_list + measures_locations_list_current\n",
    "                measures_weights_list = measures_locations_list + measures_weights_list_current\n",
    "\n",
    "            # Update Position\n",
    "            position_counter = position_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP\n",
    "X_test = X_train\n",
    "measures_locations_test_list = measures_locations_list\n",
    "measures_weights_test_list = measures_weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8\n",
       "0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "5   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "6   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "7   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "8   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "9   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "10  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "11  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "12  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "13  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "14  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "15  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "16  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "17  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "18  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "19  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "20  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "21  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "22  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "23  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "24  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "25  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "26  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "27  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "28  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "29  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "30  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "31  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "32  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "33  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "34  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "35  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "36  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "37  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "38  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "39  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "40  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "41  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "42  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "43  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "44  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Classifer_Wasserstein_Centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1927 - accuracy: 0.2222\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1521 - accuracy: 0.2222\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1203 - accuracy: 0.4000\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0879 - accuracy: 0.5333\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0574 - accuracy: 0.5556\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0283 - accuracy: 0.5333\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9954 - accuracy: 0.5333\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9628 - accuracy: 0.5556\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9276 - accuracy: 0.6444\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8933 - accuracy: 0.6667\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8567 - accuracy: 0.6667\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8194 - accuracy: 0.6667\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7813 - accuracy: 0.6667\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7406 - accuracy: 0.6667\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7008 - accuracy: 0.6667\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6593 - accuracy: 0.6667\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6158 - accuracy: 0.6667\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5721 - accuracy: 0.6667\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5299 - accuracy: 0.6667\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4854 - accuracy: 0.6667\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4420 - accuracy: 0.6667\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3987 - accuracy: 0.6667\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3581 - accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3162 - accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2734 - accuracy: 0.6667\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2332 - accuracy: 0.6667\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1915 - accuracy: 0.6667\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1529 - accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1117 - accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0718 - accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0332 - accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9937 - accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9162 - accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8803 - accuracy: 0.6667\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8450 - accuracy: 0.6667\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8101 - accuracy: 0.7778\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7778 - accuracy: 0.8889\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7105 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6528 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2916 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2083 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1375 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 1.0000\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [2]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers,\n",
    "                                                                                                        X_test = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 5891.80it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 8105.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n",
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Format Weights\n",
    "## Train\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): START\")\n",
    "print(\"#---------------------------------------#\")\n",
    "Predicted_Weights = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    b = np.repeat(np.array(predicted_classes_train[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): END\")\n",
    "print(\"#-------------------------------------#\")\n",
    "\n",
    "## Test\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): START\")\n",
    "print(\"#-------------------------------------#\")\n",
    "Predicted_Weights_test = np.array([])\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):\n",
    "    b_test = np.repeat(np.array(predicted_classes_test[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b_test = b_test/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights_test = b_test\n",
    "    else:\n",
    "        Predicted_Weights_test = np.append(Predicted_Weights_test,b_test,axis=1)\n",
    "print(\"#-----------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): END\")\n",
    "print(\"#-----------------------------------#\")\n",
    "        \n",
    "# Format Points of Mass\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: START\")\n",
    "print(\"#-----------------------------#\")\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)\n",
    "print(\"#-----------------------------#\")\n",
    "print(\"Building Barycenters Set: END\")\n",
    "print(\"#-----------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 1384.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>6.383252e-12</td>\n",
       "      <td>0.042147</td>\n",
       "      <td>0.027361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>1.478954e-05</td>\n",
       "      <td>0.126438</td>\n",
       "      <td>0.197643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.011591</td>\n",
       "      <td>5.650396e-05</td>\n",
       "      <td>0.205281</td>\n",
       "      <td>0.319574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.000400    0.000008         6.383252e-12                0.042147   \n",
       "MAE  0.001366    0.003526         1.478954e-05                0.126438   \n",
       "Max  0.002674    0.011591         5.650396e-05                0.205281   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.027361  \n",
       "MAE              0.197643  \n",
       "Max              0.319574  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building Training Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "Skewness_errors = np.array([])\n",
    "Kurtosis_errors = np.array([])\n",
    "predictions_mean = np.array([])\n",
    "true_mean = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_list)-1)):    \n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         measure_weights.reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(np.array(measures_locations_list[x_i]))\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    ## Update Erros\n",
    "    predictions_mean = np.append(predictions_mean,Mu_hat)\n",
    "    true_mean = np.append(true_mean,Mu)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(np.array(measures_locations_list[x_i])**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat = np.sum((Barycenters_Array**3)*(Predicted_Weights[x_i]))\n",
    "    Skewness = np.mean(np.array(measures_locations_list[x_i])**3)\n",
    "    Skewness_errors = np.append(Skewness_errors,(abs(Skewness_hat-Skewness))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat = np.sum((Barycenters_Array**4)*(Predicted_Weights[x_i]))\n",
    "    Kurtosis = np.mean(np.array(measures_locations_list[x_i])**4)\n",
    "    Kurtosis_errors = np.append(Kurtosis_errors,(abs(Kurtosis_hat-Kurtosis))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.min(np.abs(W1_errors)),np.mean(np.abs(W1_errors)),np.max(np.abs(W1_errors))])\n",
    "Mean_prediction_Performance = np.array([np.min(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors)),np.max(np.abs(Mean_errors))])\n",
    "Var_prediction_Performance = np.array([np.min(np.abs(Var_errors)),np.mean(np.abs(Var_errors)),np.max(np.abs(Var_errors))])\n",
    "Skewness_prediction_Performance = np.array([np.min(np.abs(Skewness_errors)),np.mean(np.abs(Skewness_errors)),np.max(np.abs(Skewness_errors))])\n",
    "Kurtosis_prediction_Performance = np.array([np.min(np.abs(Kurtosis_errors)),np.mean(np.abs(Kurtosis_errors)),np.max(np.abs(Kurtosis_errors))])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Train.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f863060fbd0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean,label=\"prediction\",color=\"purple\")\n",
    "plt.plot(true_mean,label=\"true\",color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 1403.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Test Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors_test = np.array([])\n",
    "Mean_errors_test = np.array([])\n",
    "Var_errors_test = np.array([])\n",
    "Skewness_errors_test = np.array([])\n",
    "Kurtosis_errors_test = np.array([])\n",
    "# Initialize Prediction Metrics\n",
    "predictions_mean_test = np.array([])\n",
    "true_mean_test = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(len(measures_locations_test_list))):    \n",
    "    # Get Laws\n",
    "    W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(measures_locations_test_list[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights_test[x_i,].reshape(-1,),\n",
    "                         (np.array(measures_weights_test_list[x_i])).reshape(-1,))\n",
    "    W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "    # Get Means\n",
    "    Mu_hat_test = np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array))\n",
    "    Mu_test = np.mean(np.array(measures_locations_test_list[x_i]))\n",
    "    Mean_errors_test = np.append(Mean_errors_test,(Mu_hat_test-Mu_test))\n",
    "    ## Update Predictions\n",
    "    predictions_mean_test = np.append(predictions_mean_test,Mu_hat_test)\n",
    "    true_mean_test = np.append(true_mean_test,Mu_test)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat_test = np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))\n",
    "    Var_test = np.mean(np.array(measures_locations_test_list[x_i])**2)\n",
    "    Var_errors_test = np.append(Var_errors_test,(Var_hat_test-Var_test)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat_test = np.sum((Barycenters_Array**3)*(Predicted_Weights_test[x_i]))\n",
    "    Skewness_test = np.mean(np.array(measures_locations_test_list[x_i])**3)\n",
    "    Skewness_errors_test = np.append(Skewness_errors_test,(abs(Skewness_hat_test-Skewness_test))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat_test = np.sum((Barycenters_Array**4)*(Predicted_Weights_test[x_i]))\n",
    "    Kurtosis_test = np.mean(np.array(measures_locations_test_list[x_i])**4)\n",
    "    Kurtosis_errors_test = np.append(Kurtosis_errors_test,(abs(Kurtosis_hat_test-Kurtosis_test))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance_test = np.array([np.min(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test))])\n",
    "Mean_prediction_Performance_test = np.array([np.min(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test))])\n",
    "Var_prediction_Performance_test = np.array([np.min(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test))])\n",
    "Skewness_prediction_Performance_test = np.array([np.min(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test))])\n",
    "Kurtosis_prediction_Performance_test = np.array([np.min(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test))])\n",
    "\n",
    "Type_A_Prediction_test = pd.DataFrame({\"W1\":W1_Performance_test,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance_test,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance_test,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance_test,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance_test},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction_test.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+str(\"__RatiofBM_\")+str(Ratio_fBM_to_typical_vol)+\n",
    " \"__TypeAPrediction_Test.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f86305908d0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions_mean_test,color=\"purple\")\n",
    "plt.plot(true_mean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print for Terminal Legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  0.000400    0.000008         6.383252e-12                0.042147   \n",
      "MAE  0.001366    0.003526         1.478954e-05                0.126438   \n",
      "Max  0.002674    0.011591         5.650396e-05                0.205281   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.027361  \n",
      "MAE              0.197643  \n",
      "Max              0.319574  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min  0.000449    0.000008         6.383252e-12                0.042147   \n",
      "MAE  0.779824    0.003567         1.468450e-05                0.126429   \n",
      "Max  0.779824    0.003567         1.468450e-05                0.126429   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min              0.027361  \n",
      "MAE              0.197143  \n",
      "Max              0.197143  \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------------#\")\n",
    "print(\"Training-Set Performance\")\n",
    "print(\"#----------------------#\")\n",
    "print(Type_A_Prediction)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"#------------------#\")\n",
    "print(\"Test-Set Performance\")\n",
    "print(\"#------------------#\")\n",
    "print(Type_A_Prediction_test)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>6.383252e-12</td>\n",
       "      <td>0.042147</td>\n",
       "      <td>0.027361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>1.478954e-05</td>\n",
       "      <td>0.126438</td>\n",
       "      <td>0.197643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.011591</td>\n",
       "      <td>5.650396e-05</td>\n",
       "      <td>0.205281</td>\n",
       "      <td>0.319574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.000400    0.000008         6.383252e-12                0.042147   \n",
       "MAE  0.001366    0.003526         1.478954e-05                0.126438   \n",
       "Max  0.002674    0.011591         5.650396e-05                0.205281   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.027361  \n",
       "MAE              0.197643  \n",
       "Max              0.319574  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>6.383252e-12</td>\n",
       "      <td>0.042147</td>\n",
       "      <td>0.027361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.779824</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>1.468450e-05</td>\n",
       "      <td>0.126429</td>\n",
       "      <td>0.197143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.779824</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>1.468450e-05</td>\n",
       "      <td>0.126429</td>\n",
       "      <td>0.197143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min  0.000449    0.000008         6.383252e-12                0.042147   \n",
       "MAE  0.779824    0.003567         1.468450e-05                0.126429   \n",
       "Max  0.779824    0.003567         1.468450e-05                0.126429   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min              0.027361  \n",
       "MAE              0.197143  \n",
       "Max              0.197143  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
