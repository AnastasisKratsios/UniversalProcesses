{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Universal Regular Conditional Expectations:\n",
    "\n",
    "---\n",
    "This implements the universal deep neural model of $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$ [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---\n",
    "\n",
    "## What does this code do?\n",
    "1. Learn Heteroskedastic Non-Linear Regression Problem\n",
    "     - $Y\\sim f_{\\text{unkown}}(x) + \\epsilon$ where $f$ is an known function and $\\epsilon\\sim Laplace(0,\\|x\\|)$\n",
    "2. Learn Random Bayesian Network's Law:\n",
    "    - $Y = W_J Y^{J-1}, \\qquad Y^{j}\\triangleq \\sigma\\bullet A^{j}Y^{j-1} + b^{j}, \\qquad Y^0\\triangleq x$\n",
    "\n",
    "3. In the above example if $A_j = M_j\\odot \\tilde{A_j}$ where $\\tilde{A}_j$ is a deterministic matrix and $M_j$ is a \"mask\", that is, a random matrix with binary entries and $\\odot$ is the Hadamard product then we recover the dropout framework.\n",
    "4. Learn the probability distribution that the unique strong solution to the rough SDE with uniformly Lipschitz drivers driven by a factional Brownian motion with Hurst exponent $H \\in [\\frac1{2},1)$:\n",
    "$$\n",
    "X_t^x = x + \\int_0^t \\alpha(s,X_s^x)ds + \\int_0^t \\beta(s,X_s^x)dB_s^H\n",
    "$$\n",
    "belongs, at time $t=1$, to a ball about the initial point $x$ of random radius given by an independant exponential random-variable with shape parameter $\\lambda=2$\n",
    "5. Train a DNN to predict the returns of bitcoin with GD.  Since this has random initialization then each prediction of a given $x$ is stochastic...We learn the distribution of this conditional RV (conditioned on x in the input space).\n",
    "$$\n",
    "Y_x \\triangleq \\hat{f}_{\\theta_{T}}(x), \\qquad \\theta_{(t+1)}\\triangleq \\theta_{(t)} + \\lambda \\sum_{x \\in \\mathbb{X}} \\nabla_{\\theta}\\|\\hat{f}_{\\theta_t}(x) - f(x)\\|, \\qquad \\theta_0 \\sim N_d(0,1);\n",
    "$$\n",
    "$T\\in \\mathbb{N}$ is a fixed number of \"SGD\" iterations (typically identified by cross-validation on a single SGD trajectory for a single initialization) and where $\\theta \\in \\mathbb{R}^{(d_{J}+1)+\\sum_{j=0}^{J-1} (d_{j+1}d_j + 1)}$ and $d_j$ is the dimension of the \"bias\" vector $b_j$ defining each layer of the DNN with layer dimensions:\n",
    "$$\n",
    "\\hat{f}_{\\theta}(x)\\triangleq A^{(J)}x^{(J)} + b^{(J)},\\qquad x^{(j+1)}\\triangleq \\sigma\\bullet A^{j}x^{(j)} + b^{j},\\qquad x^{(0)}\\triangleq x\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode:\n",
    "Software/Hardware Testing or Real-Deal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random DNN\n",
    "# f_unknown_mode = \"Heteroskedastic_NonLinear_Regression\"\n",
    "\n",
    "# Random DNN internal noise\n",
    "#f_unknown_mode = \"DNN_with_Random_Weights\"\n",
    "Depth_Bayesian_DNN = 2\n",
    "width = 10\n",
    "\n",
    "# Random Dropout applied to trained DNN\n",
    "# f_unknown_mode = \"DNN_with_Bayesian_Dropout\"\n",
    "Dropout_rate = 0.1\n",
    "\n",
    "# GD with Randomized Input\n",
    "f_unknown_mode = \"GD_with_randomized_input\"\n",
    "GD_epochs = 50\n",
    "# dataset_option = 'SnP'\n",
    "dataset_option = 'crypto'\n",
    "\n",
    "# SDE with fractional Driver\n",
    "# f_unknown_mode = \"Rough_SDE\"\n",
    "N_Euler_Steps = 10**2\n",
    "Hurst_Exponent = 0.75\n",
    "\n",
    "# f_unknown_mode = \"Rough_SDE_Vanilla\"\n",
    "## Define Process' dynamics in (2) cell(s) below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dim = 1\n",
    "width = int(2*(problem_dim+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla fractional SDE:\n",
    "If f_unknown_mode == \"Rough_SDE_Vanilla\" is selected, then we can specify the process's dynamics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------#\n",
    "# Define Process' Dynamics #\n",
    "#--------------------------#\n",
    "drift_constant = 0.1\n",
    "volatility_constant = 0.01\n",
    "\n",
    "# Define DNN Applier\n",
    "def f_unknown_drift_vanilla(x):\n",
    "    x_internal = x\n",
    "    x_internal = drift_constant*x_internal\n",
    "    return x_internal\n",
    "def f_unknown_vol_vanilla(x):\n",
    "    x_internal = volatility_constant*np.diag(np.ones(problem_dim))\n",
    "    return x_internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: *Why the procedure is so computationally efficient*?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)\n",
    "- Ratio $\\frac{\\text{Testing Datasize}}{\\text{Training Datasize}}$.\n",
    "- Number of Training Points to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = .2\n",
    "N_train_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Monte_Carlo_Samples = 10**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial radis of $\\delta$-bounded random partition of $\\mathcal{X}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.1\n",
    "Proportion_per_cluster = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and Auxiliary Script(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "Deep Feature Builder - Ready\n"
     ]
    }
   ],
   "source": [
    "# %run Loader.ipynb\n",
    "exec(open('Loader.py').read())\n",
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "import time as time #<- Note sure why...but its always seems to need 'its own special loading...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate or Parse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Beginning Data-Parsing/Simulation Phase\n",
      "---------------------------------------\n",
      "Deciding on Which Simulator/Parser To Load\n",
      "Setting/Defining: Internal Parameters\n",
      "Deciding on Which Type of Data to Get/Simulate\n",
      "#================================================#\n",
      " Training Datasize: 170 and test datasize: 42.  \n",
      "#================================================#\n",
      "Simulating Output Data for given input data\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 474.7037 - mse: 528289.9375 - mae: 474.7037\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.7028 - mse: 528289.1875 - mae: 474.7028\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.7021 - mse: 528288.6250 - mae: 474.7021\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.7012 - mse: 528287.5000 - mae: 474.7012\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.7002 - mse: 528286.5625 - mae: 474.7002\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 474.6992 - mse: 528285.4375 - mae: 474.6992\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.6975 - mse: 528283.1250 - mae: 474.6975\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 474.6952 - mse: 528279.3125 - mae: 474.6952\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.6917 - mse: 528273.5000 - mae: 474.6917\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.6874 - mse: 528266.1875 - mae: 474.6874\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.6810 - mse: 528255.5000 - mae: 474.6810\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 474.6733 - mse: 528240.6250 - mae: 474.6733\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.6638 - mse: 528224.5625 - mae: 474.6638\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.6507 - mse: 528199.8750 - mae: 474.6507\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.6350 - mse: 528170.1250 - mae: 474.6350\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 474.6155 - mse: 528134.1875 - mae: 474.6155\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.5913 - mse: 528087.9375 - mae: 474.5913\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.5649 - mse: 528042.5625 - mae: 474.5649\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.5321 - mse: 527977.6875 - mae: 474.5321\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.5002 - mse: 527921.0000 - mae: 474.5002\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 474.4588 - mse: 527843.5000 - mae: 474.4588\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 474.4153 - mse: 527764.8750 - mae: 474.4153\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.3653 - mse: 527670.0000 - mae: 474.3653\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.3103 - mse: 527566.7500 - mae: 474.3103\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.2448 - mse: 527442.0625 - mae: 474.2448\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.1780 - mse: 527326.9375 - mae: 474.1780\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.0996 - mse: 527184.2500 - mae: 474.0996\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 474.0162 - mse: 527021.6875 - mae: 474.0162\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 473.9242 - mse: 526841.5000 - mae: 473.9242\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 473.8319 - mse: 526676.0000 - mae: 473.8319\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 473.7267 - mse: 526486.9375 - mae: 473.7267\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 473.6114 - mse: 526276.2500 - mae: 473.6114\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 473.4909 - mse: 526042.0625 - mae: 473.4909\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 473.3620 - mse: 525805.3750 - mae: 473.3620\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 473.2247 - mse: 525565.8125 - mae: 473.2247\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 473.0654 - mse: 525245.8125 - mae: 473.0654\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 472.9139 - mse: 524994.0000 - mae: 472.9139\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 472.7410 - mse: 524671.8750 - mae: 472.7410\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 472.5547 - mse: 524296.0625 - mae: 472.5547\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 472.3718 - mse: 523942.1250 - mae: 472.3718\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 472.1838 - mse: 523649.0000 - mae: 472.1838\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 471.9394 - mse: 523147.9375 - mae: 471.9394\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 471.7276 - mse: 522762.9062 - mae: 471.7276\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 471.4876 - mse: 522321.8438 - mae: 471.4876\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 471.2404 - mse: 521879.9062 - mae: 471.2404\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 470.9716 - mse: 521395.2812 - mae: 470.9716\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 470.7087 - mse: 520943.7188 - mae: 470.7087\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 470.4190 - mse: 520414.5938 - mae: 470.4190\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 470.1039 - mse: 519815.1875 - mae: 470.1039\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 469.8061 - mse: 519309.9375 - mae: 469.8061\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 469.5092 - mse: 518751.9062 - mae: 469.5092\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 469.1832 - mse: 518190.1250 - mae: 469.1832\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 468.8170 - mse: 517496.1562 - mae: 468.8170\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 468.4773 - mse: 516878.4062 - mae: 468.4773\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 468.1159 - mse: 516183.0000 - mae: 468.1159\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 467.7450 - mse: 515578.3438 - mae: 467.7450\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 467.3521 - mse: 514856.7500 - mae: 467.3521\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 466.9179 - mse: 514052.7188 - mae: 466.9179\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 466.4649 - mse: 513225.6562 - mae: 466.4649\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 466.0407 - mse: 512485.3750 - mae: 466.0407\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 465.5484 - mse: 511644.3438 - mae: 465.5484\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 465.0789 - mse: 510732.6562 - mae: 465.0789\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 464.5967 - mse: 509939.3750 - mae: 464.5967\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 464.0427 - mse: 508923.1562 - mae: 464.0427\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 463.5073 - mse: 507954.7188 - mae: 463.5073\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 462.9476 - mse: 506968.0000 - mae: 462.9476\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 462.3419 - mse: 505868.6250 - mae: 462.3419\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 461.7566 - mse: 504907.6250 - mae: 461.7566\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 461.0933 - mse: 503660.2812 - mae: 461.0933\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 460.5175 - mse: 502693.1250 - mae: 460.5175\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 459.8428 - mse: 501505.7812 - mae: 459.8428\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 459.2200 - mse: 500440.1875 - mae: 459.2200\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 458.5570 - mse: 499242.3125 - mae: 458.5570\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 457.8837 - mse: 498056.5312 - mae: 457.8837\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 457.1472 - mse: 496746.2500 - mae: 457.1472\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 456.4759 - mse: 495663.6562 - mae: 456.4759\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 455.7593 - mse: 494402.5938 - mae: 455.7593\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 455.0306 - mse: 493053.3125 - mae: 455.0306\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 454.2972 - mse: 491663.6250 - mae: 454.2972\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 453.5868 - mse: 490461.8750 - mae: 453.5868\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 452.8096 - mse: 489152.9375 - mae: 452.8096\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 452.0210 - mse: 487759.0000 - mae: 452.0210\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 451.2233 - mse: 486284.1875 - mae: 451.2233\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 450.3991 - mse: 484892.1562 - mae: 450.3991\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 449.5864 - mse: 483551.4375 - mae: 449.5864\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 448.6544 - mse: 481809.7812 - mae: 448.6544\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 447.8477 - mse: 480530.6875 - mae: 447.8477\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 446.9300 - mse: 478951.0000 - mae: 446.9300\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 446.0030 - mse: 477211.8438 - mae: 446.0031\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 445.1104 - mse: 475649.0312 - mae: 445.1104\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 444.2530 - mse: 474418.5938 - mae: 444.2530\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 443.1642 - mse: 472333.9375 - mae: 443.1642\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 442.2259 - mse: 470752.7188 - mae: 442.2259\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 441.1699 - mse: 469010.1250 - mae: 441.1699\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 440.1711 - mse: 467355.0938 - mae: 440.1711\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 439.1185 - mse: 465581.4688 - mae: 439.1185\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 438.1484 - mse: 464025.0000 - mae: 438.1484\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 437.0967 - mse: 462224.8438 - mae: 437.0967\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 435.9931 - mse: 460235.7500 - mae: 435.9931\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 434.9607 - mse: 458647.7188 - mae: 434.9607\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 433.9671 - mse: 456955.0000 - mae: 433.9671\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 432.9862 - mse: 455305.0312 - mae: 432.9862\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 431.8356 - mse: 453326.1250 - mae: 431.8356\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 430.8886 - mse: 451678.4375 - mae: 430.8886\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 429.8439 - mse: 449822.9688 - mae: 429.8439\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 428.8352 - mse: 448249.0312 - mae: 428.8352\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 427.7617 - mse: 446415.8438 - mae: 427.7617\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 426.6247 - mse: 444470.0312 - mae: 426.6247\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 425.4471 - mse: 442517.7500 - mae: 425.4471\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 424.3749 - mse: 440832.0000 - mae: 424.3749\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 423.1608 - mse: 438955.6250 - mae: 423.1608\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 422.0005 - mse: 436991.9062 - mae: 422.0005\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 420.8129 - mse: 435267.9375 - mae: 420.8129\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 419.4512 - mse: 433091.0938 - mae: 419.4512\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6b5c16c9b3d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %run Data_Simulator_and_Parser.ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data_Simulator_and_Parser.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mf_unknown\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3167\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0mrelaxation\u001b[0m \u001b[0mretracing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3168\u001b[0m     \"\"\"\n\u001b[0;32m-> 3169\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3170\u001b[0m       args, kwargs = self._function_spec.canonicalize_function_inputs(\n\u001b[1;32m   3171\u001b[0m           *args, **kwargs)\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36minput_signature\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2838\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2840\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2841\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minput_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;34m\"\"\"Returns the input signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %run Data_Simulator_and_Parser.ipynb\n",
    "exec(open('Data_Simulator_and_Parser.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Data\n",
    "This is especially important to avoid exploding gradient problems when training the ML-models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 13352.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Running script for main model!\n",
      "------------------------------\n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "==========================================\n",
      "Training Classifer Portion of Type-A Model\n",
      "==========================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    7.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0695 - accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0600 - accuracy: 0.1000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0515 - accuracy: 0.1000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0436 - accuracy: 0.1000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0362 - accuracy: 0.1000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0293 - accuracy: 0.1000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0228 - accuracy: 0.1000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0163 - accuracy: 0.1000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0099 - accuracy: 0.1000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0035 - accuracy: 0.1000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9971 - accuracy: 0.1000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9907 - accuracy: 0.1000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9842 - accuracy: 0.1000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9776 - accuracy: 0.1000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9709 - accuracy: 0.1000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9641 - accuracy: 0.2000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9572 - accuracy: 0.2000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9502 - accuracy: 0.3000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9431 - accuracy: 0.3000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9360 - accuracy: 0.3000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9288 - accuracy: 0.3000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9213 - accuracy: 0.3000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9137 - accuracy: 0.3000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9060 - accuracy: 0.3000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8982 - accuracy: 0.4000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8902 - accuracy: 0.4000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8822 - accuracy: 0.4000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8740 - accuracy: 0.4000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8655 - accuracy: 0.4000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8569 - accuracy: 0.4000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8481 - accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8390 - accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8297 - accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8203 - accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8106 - accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8007 - accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7906 - accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7802 - accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7697 - accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7588 - accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7475 - accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7361 - accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7243 - accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7122 - accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6999 - accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6873 - accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6745 - accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6613 - accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6478 - accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6340 - accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6199 - accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6056 - accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5910 - accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5762 - accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5613 - accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5462 - accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5311 - accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5158 - accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5004 - accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4850 - accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4696 - accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4541 - accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4385 - accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4231 - accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4079 - accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3928 - accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3777 - accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3628 - accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3481 - accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3336 - accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3193 - accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3053 - accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2913 - accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2776 - accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2639 - accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2506 - accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2375 - accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2248 - accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2120 - accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1995 - accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1872 - accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1750 - accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1629 - accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1512 - accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1396 - accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1281 - accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1169 - accuracy: 0.6000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1057 - accuracy: 0.6000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0946 - accuracy: 0.6000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0839 - accuracy: 0.6000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0733 - accuracy: 0.6000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0628 - accuracy: 0.6000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0525 - accuracy: 0.6000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0423 - accuracy: 0.6000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0323 - accuracy: 0.6000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0225 - accuracy: 0.6000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0129 - accuracy: 0.6000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0035 - accuracy: 0.6000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9941 - accuracy: 0.6000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9849 - accuracy: 0.6000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.6000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9670 - accuracy: 0.6000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9583 - accuracy: 0.6000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9497 - accuracy: 0.6000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9413 - accuracy: 0.6000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9331 - accuracy: 0.6000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9248 - accuracy: 0.6000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9168 - accuracy: 0.6000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9089 - accuracy: 0.6000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9010 - accuracy: 0.7000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8933 - accuracy: 0.7000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8856 - accuracy: 0.7000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8781 - accuracy: 0.7000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8708 - accuracy: 0.7000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8635 - accuracy: 0.7000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8563 - accuracy: 0.7000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8493 - accuracy: 0.7000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8423 - accuracy: 0.7000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8354 - accuracy: 0.7000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8285 - accuracy: 0.8000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8218 - accuracy: 0.8000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8152 - accuracy: 0.8000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8086 - accuracy: 0.8000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8021 - accuracy: 0.8000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7957 - accuracy: 0.8000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7893 - accuracy: 0.8000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7829 - accuracy: 0.8000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7769 - accuracy: 0.8000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7708 - accuracy: 0.8000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7648 - accuracy: 0.8000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7588 - accuracy: 0.8000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7528 - accuracy: 0.8000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7470 - accuracy: 0.8000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7412 - accuracy: 0.8000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7355 - accuracy: 0.8000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7297 - accuracy: 0.8000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7242 - accuracy: 0.8000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7186 - accuracy: 0.8000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.8000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7076 - accuracy: 0.8000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7019 - accuracy: 0.8000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.8000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.8000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.8000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.8000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.8000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.8000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.8000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.8000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.8000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.8000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.8000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.8000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.8000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.8000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.9000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6099 - accuracy: 0.9000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.9000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.9000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5956 - accuracy: 0.9000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5909 - accuracy: 0.9000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.9000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.9000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.9000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.9000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.9000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.9000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.9000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.9000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.9000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.9000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.9000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.9000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.9000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.9000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.9000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.9000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5137 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4620 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4535 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 438.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 255.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Training Classifer Portion of Type Model: Done!\n",
      "===============================================\n",
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#----------------#\n",
      " Get Test Error(s)\n",
      "#----------------#\n",
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n",
      "                                        DNM  MC-Oracle\n",
      "W1-95L                         5.252696e-07   0.000000\n",
      "W1                             5.252696e-07   0.000000\n",
      "W1-95R                         5.252696e-07   0.000000\n",
      "M-95L                          5.834706e-05   0.000000\n",
      "M                              5.834706e-05   0.000000\n",
      "M-95R                          5.834706e-05   0.000000\n",
      "N_Par                          4.220800e+04   0.000000\n",
      "Train_Time                     1.115808e+01   1.814789\n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000\n",
      "------------------------------------\n",
      "Done: Running script for main model!\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------\")\n",
    "print(\"Running script for main model!\")\n",
    "print(\"------------------------------\")\n",
    "# %run Universal_Measure_Valued_Networks_Backend.ipynb\n",
    "exec(open('Universal_Measure_Valued_Networks_Backend.py').read())\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Done: Running script for main model!\")\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run: All Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) *Pointmass Benchmark(s)*\n",
    "These benchmarks consist of subsets of $C(\\mathbb{R}^d,\\mathbb{R})$ which we lift to models in $C(\\mathbb{R}^d,\\cap_{1\\leq q<\\infty}\\mathscr{P}_{q}(\\mathbb{R}))$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to f(x) \\to \\delta_{f(x)}\\in \\cap_{1\\leq q<\\infty}\\mathcal{P}_{q}(\\mathbb{R}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "--------------\n",
      "Training: ENET\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1690.23it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 986.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Training: ENET - Done\n",
      "---------------------\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                        DNM  MC-Oracle         ENET KRidge  \\\n",
      "W1-95L                         5.252696e-07   0.000000            -      -   \n",
      "W1                             5.252696e-07   0.000000            -      -   \n",
      "W1-95R                         5.252696e-07   0.000000            -      -   \n",
      "M-95L                          5.834706e-05   0.000000  6.30167e-06    NaN   \n",
      "M                              5.834706e-05   0.000000   1.1343e-05    NaN   \n",
      "M-95R                          5.834706e-05   0.000000  2.14257e-05    NaN   \n",
      "N_Par                          4.220800e+04   0.000000           20    NaN   \n",
      "Train_Time                     1.115808e+01   1.814789  1.62012e+09    NaN   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694    NaN   \n",
      "\n",
      "                              GBRF  DNN  \n",
      "W1-95L                           -    -  \n",
      "W1                               -    -  \n",
      "W1-95R                           -    -  \n",
      "M-95L                          NaN  NaN  \n",
      "M                              NaN  NaN  \n",
      "M-95R                          NaN  NaN  \n",
      "N_Par                          NaN  NaN  \n",
      "Train_Time                     NaN  NaN  \n",
      "Test_Time/MC-Oracle_Test_Time  NaN  NaN  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "-----------------\n",
      "Training: K-Ridge\n",
      "-----------------\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0571s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.5s finished\n",
      "100%|██████████| 10/10 [00:00<00:00, 1108.72it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 286.23it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000            -   \n",
      "W1                             5.252696e-07   0.000000            -   \n",
      "W1-95R                         5.252696e-07   0.000000            -   \n",
      "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
      "M                              5.834706e-05   0.000000   1.1343e-05   \n",
      "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
      "N_Par                          4.220800e+04   0.000000           20   \n",
      "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
      "\n",
      "                                    KRidge GBRF  DNN  \n",
      "W1-95L                                   -    -    -  \n",
      "W1                                       -    -    -  \n",
      "W1-95R                                   -    -    -  \n",
      "M-95L                           5.9994e-05  NaN  NaN  \n",
      "M                              7.12614e-05  NaN  NaN  \n",
      "M-95R                          8.80365e-05  NaN  NaN  \n",
      "N_Par                                    0  NaN  NaN  \n",
      "Train_Time                        0.574352  NaN  NaN  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000849836  NaN  NaN  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "--------------\n",
      "Training: GBRF\n",
      "--------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.4s finished\n",
      "100%|██████████| 10/10 [00:00<00:00, 2143.01it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1518.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000            -   \n",
      "W1                             5.252696e-07   0.000000            -   \n",
      "W1-95R                         5.252696e-07   0.000000            -   \n",
      "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
      "M                              5.834706e-05   0.000000   1.1343e-05   \n",
      "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
      "N_Par                          4.220800e+04   0.000000           20   \n",
      "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
      "\n",
      "                                    KRidge         GBRF  DNN  \n",
      "W1-95L                                   -            -    -  \n",
      "W1                                       -            -    -  \n",
      "W1-95R                                   -            -    -  \n",
      "M-95L                           5.9994e-05  6.30167e-06  NaN  \n",
      "M                              7.12614e-05   1.1343e-05  NaN  \n",
      "M-95R                          8.80365e-05  2.14257e-05  NaN  \n",
      "N_Par                                    0         1000  NaN  \n",
      "Train_Time                        0.574352      0.66944  NaN  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629  NaN  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "-------------\n",
      "Training: DNN\n",
      "-------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0186 - mse: 3.4521e-04 - mae: 0.0186 - mape: 16726221.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0183 - mse: 3.3560e-04 - mae: 0.0183 - mape: 16491434.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0180 - mse: 3.2611e-04 - mae: 0.0180 - mape: 16256339.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0178 - mse: 3.1676e-04 - mae: 0.0178 - mape: 16021107.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 3.0753e-04 - mae: 0.0175 - mape: 15785795.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 2.9845e-04 - mae: 0.0173 - mape: 15550426.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0170 - mse: 2.8949e-04 - mae: 0.0170 - mape: 15315014.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 2.8068e-04 - mae: 0.0167 - mape: 15079568.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 2.7199e-04 - mae: 0.0165 - mape: 14844098.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 2.6345e-04 - mae: 0.0162 - mape: 14608608.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 2.5504e-04 - mae: 0.0160 - mape: 14373099.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 2.4676e-04 - mae: 0.0157 - mape: 14137573.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 2.3863e-04 - mae: 0.0154 - mape: 13902034.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 2.3063e-04 - mae: 0.0152 - mape: 13666480.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 2.2276e-04 - mae: 0.0149 - mape: 13430914.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 2.1503e-04 - mae: 0.0146 - mape: 13195337.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 2.0744e-04 - mae: 0.0144 - mape: 12959750.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141 - mse: 1.9999e-04 - mae: 0.0141 - mape: 12724153.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 1.9267e-04 - mae: 0.0139 - mape: 12488544.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 1.8549e-04 - mae: 0.0136 - mape: 12252929.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 1.7844e-04 - mae: 0.0133 - mape: 12017304.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 1.7153e-04 - mae: 0.0131 - mape: 11781664.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 1.6476e-04 - mae: 0.0128 - mape: 11546019.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0126 - mse: 1.5813e-04 - mae: 0.0126 - mape: 11310362.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0123 - mse: 1.5163e-04 - mae: 0.0123 - mape: 11074695.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 1.4527e-04 - mae: 0.0120 - mape: 10839019.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 1.3905e-04 - mae: 0.0118 - mape: 10603331.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0115 - mse: 1.3296e-04 - mae: 0.0115 - mape: 10367632.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 1.2701e-04 - mae: 0.0112 - mape: 10131920.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0110 - mse: 1.2119e-04 - mae: 0.0110 - mape: 9896196.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 1.1552e-04 - mae: 0.0107 - mape: 9660460.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 1.0998e-04 - mae: 0.0105 - mape: 9424710.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 1.0457e-04 - mae: 0.0102 - mape: 9188944.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 9.9306e-05 - mae: 0.0099 - mape: 8953164.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 9.4177e-05 - mae: 0.0097 - mape: 8717368.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 8.9184e-05 - mae: 0.0094 - mape: 8481559.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 8.4328e-05 - mae: 0.0091 - mape: 8245731.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 7.9609e-05 - mae: 0.0089 - mape: 8009889.5000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 7.5026e-05 - mae: 0.0086 - mape: 7774027.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 7.0581e-05 - mae: 0.0084 - mape: 7538145.5000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 6.6273e-05 - mae: 0.0081 - mape: 7302246.5000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 6.2101e-05 - mae: 0.0078 - mape: 7066326.5000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 5.8067e-05 - mae: 0.0076 - mape: 6830385.5000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 5.4170e-05 - mae: 0.0073 - mape: 6594421.5000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 5.0409e-05 - mae: 0.0071 - mape: 6358435.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 4.6786e-05 - mae: 0.0068 - mape: 6122425.5000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 4.3300e-05 - mae: 0.0065 - mape: 5886392.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 3.9951e-05 - mae: 0.0063 - mape: 5650335.5000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 3.6739e-05 - mae: 0.0060 - mape: 5414249.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 3.3664e-05 - mae: 0.0057 - mape: 5178141.5000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0055 - mse: 3.0727e-05 - mae: 0.0055 - mape: 4942003.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 2.7926e-05 - mae: 0.0052 - mape: 4705835.5000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0050 - mse: 2.5263e-05 - mae: 0.0050 - mape: 4469641.5000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 2.2738e-05 - mae: 0.0047 - mape: 4233416.5000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 2.0350e-05 - mae: 0.0044 - mape: 3997162.5000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 1.8099e-05 - mae: 0.0042 - mape: 3760875.5000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 1.5986e-05 - mae: 0.0039 - mape: 3524556.7500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 1.4010e-05 - mae: 0.0036 - mape: 3288202.5000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 1.2172e-05 - mae: 0.0034 - mape: 3051818.5000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 1.0471e-05 - mae: 0.0031 - mape: 2815396.5000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 8.9086e-06 - mae: 0.0029 - mape: 2578940.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 7.4835e-06 - mae: 0.0026 - mape: 2342444.7500\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 6.1962e-06 - mae: 0.0023 - mape: 2105914.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 5.0468e-06 - mae: 0.0021 - mape: 1869344.3750\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 4.0354e-06 - mae: 0.0018 - mape: 1632735.2500\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0015 - mse: 3.1619e-06 - mae: 0.0015 - mape: 1396087.3750\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 2.4265e-06 - mae: 0.0013 - mape: 1159396.1250\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0010 - mse: 1.8292e-06 - mae: 0.0010 - mape: 922665.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.2052e-04 - mse: 1.3702e-06 - mae: 8.2052e-04 - mape: 751081.8750\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1876e-04 - mse: 9.9705e-07 - mae: 7.1876e-04 - mape: 674606.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5211e-04 - mse: 7.1560e-07 - mae: 6.5211e-04 - mape: 631856.5625\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8807e-04 - mse: 5.1796e-07 - mae: 5.8807e-04 - mape: 586242.9375\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7777e-04 - mse: 3.9293e-07 - mae: 5.7777e-04 - mape: 556590.8750\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4582e-04 - mse: 3.2300e-07 - mae: 5.4582e-04 - mape: 507781.5625\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9511e-04 - mse: 2.9699e-07 - mae: 4.9511e-04 - mape: 442472.8125\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0043e-04 - mse: 3.0844e-07 - mae: 5.0043e-04 - mape: 435237.1875\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3509e-04 - mse: 3.4376e-07 - mae: 5.3509e-04 - mape: 460509.9375\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6979e-04 - mse: 3.8313e-07 - mae: 5.6979e-04 - mape: 489437.4062\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8849e-04 - mse: 4.1439e-07 - mae: 5.8849e-04 - mape: 505611.5625\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0062e-04 - mse: 4.3321e-07 - mae: 6.0062e-04 - mape: 517820.5625\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9422e-04 - mse: 4.3447e-07 - mae: 5.9422e-04 - mape: 513840.0625\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8791e-04 - mse: 4.1670e-07 - mae: 5.8791e-04 - mape: 511680.5625\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6303e-04 - mse: 3.8038e-07 - mae: 5.6303e-04 - mape: 492503.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2855e-04 - mse: 3.2959e-07 - mae: 5.2855e-04 - mape: 465104.8438\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.8390e-04 - mse: 2.6885e-07 - mae: 4.8390e-04 - mape: 428347.6562\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2351e-04 - mse: 2.0492e-07 - mae: 4.2351e-04 - mape: 376554.7500\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4943e-04 - mse: 1.4571e-07 - mae: 3.4943e-04 - mape: 311695.5000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6341e-04 - mse: 9.9640e-08 - mae: 2.6341e-04 - mape: 235450.5469\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1315e-04 - mse: 7.5043e-08 - mae: 2.1315e-04 - mape: 195445.0469\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2363e-04 - mse: 7.7808e-08 - mae: 2.2363e-04 - mape: 215302.8438\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4053e-04 - mse: 1.0005e-07 - mae: 2.4053e-04 - mape: 240100.5781\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7110e-04 - mse: 1.3338e-07 - mae: 2.7110e-04 - mape: 264963.2812\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9392e-04 - mse: 1.6165e-07 - mae: 2.9392e-04 - mape: 284127.9375\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9991e-04 - mse: 1.8001e-07 - mae: 2.9991e-04 - mape: 289068.8125\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9601e-04 - mse: 1.8954e-07 - mae: 2.9601e-04 - mape: 285980.5625\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8799e-04 - mse: 1.9089e-07 - mae: 2.8799e-04 - mape: 280458.4375\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8095e-04 - mse: 1.8501e-07 - mae: 2.8095e-04 - mape: 276972.9062\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8154e-04 - mse: 1.7055e-07 - mae: 2.8154e-04 - mape: 281432.6250\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8110e-04 - mse: 1.5318e-07 - mae: 2.8110e-04 - mape: 277610.2812\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7241e-04 - mse: 1.3287e-07 - mae: 2.7241e-04 - mape: 266200.0312\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5634e-04 - mse: 1.1107e-07 - mae: 2.5634e-04 - mape: 247994.9531\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3858e-04 - mse: 9.0178e-08 - mae: 2.3858e-04 - mape: 228630.4531\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2566e-04 - mse: 7.3853e-08 - mae: 2.2566e-04 - mape: 214127.6250\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1313e-04 - mse: 6.2897e-08 - mae: 2.1313e-04 - mape: 200044.7656\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0803e-04 - mse: 5.7349e-08 - mae: 2.0803e-04 - mape: 192933.4844\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0212e-04 - mse: 5.6487e-08 - mae: 2.0212e-04 - mape: 184583.7188\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0262e-04 - mse: 5.9890e-08 - mae: 2.0262e-04 - mape: 182258.9688\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1365e-04 - mse: 6.5858e-08 - mae: 2.1365e-04 - mape: 190821.6719\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2340e-04 - mse: 7.0304e-08 - mae: 2.2340e-04 - mape: 199168.8750\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2577e-04 - mse: 7.1353e-08 - mae: 2.2577e-04 - mape: 201085.8281\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2147e-04 - mse: 6.8844e-08 - mae: 2.2147e-04 - mape: 197207.5156\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1119e-04 - mse: 6.3838e-08 - mae: 2.1119e-04 - mape: 188119.5469\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0086e-04 - mse: 5.8232e-08 - mae: 2.0086e-04 - mape: 179687.3125\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9600e-04 - mse: 5.4637e-08 - mae: 1.9600e-04 - mape: 176640.2812\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9814e-04 - mse: 5.3107e-08 - mae: 1.9814e-04 - mape: 179772.8281\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9872e-04 - mse: 5.2688e-08 - mae: 1.9872e-04 - mape: 180603.2031\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0096e-04 - mse: 5.2900e-08 - mae: 2.0096e-04 - mape: 182436.9688\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0333e-04 - mse: 5.3230e-08 - mae: 2.0333e-04 - mape: 184295.0312\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0355e-04 - mse: 5.3084e-08 - mae: 2.0355e-04 - mape: 183928.6562\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0183e-04 - mse: 5.2383e-08 - mae: 2.0183e-04 - mape: 181553.5312\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9836e-04 - mse: 5.1418e-08 - mae: 1.9836e-04 - mape: 177355.6250\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9331e-04 - mse: 5.0745e-08 - mae: 1.9331e-04 - mape: 171511.7031\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8912e-04 - mse: 5.1091e-08 - mae: 1.8912e-04 - mape: 166475.1562\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9280e-04 - mse: 5.2498e-08 - mae: 1.9280e-04 - mape: 170017.2500\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9524e-04 - mse: 5.4067e-08 - mae: 1.9524e-04 - mape: 172422.6250\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9652e-04 - mse: 5.5137e-08 - mae: 1.9652e-04 - mape: 173760.5625\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9673e-04 - mse: 5.5412e-08 - mae: 1.9673e-04 - mape: 174126.6250\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9600e-04 - mse: 5.4861e-08 - mae: 1.9600e-04 - mape: 173615.5469\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9440e-04 - mse: 5.3646e-08 - mae: 1.9440e-04 - mape: 172311.4219\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9201e-04 - mse: 5.2062e-08 - mae: 1.9201e-04 - mape: 170282.5781\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8890e-04 - mse: 5.0499e-08 - mae: 1.8890e-04 - mape: 167599.4531\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8734e-04 - mse: 4.9402e-08 - mae: 1.8734e-04 - mape: 166511.0312\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9034e-04 - mse: 4.9118e-08 - mae: 1.9034e-04 - mape: 169246.1719\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9184e-04 - mse: 4.9155e-08 - mae: 1.9184e-04 - mape: 170371.6094\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9118e-04 - mse: 4.9074e-08 - mae: 1.9118e-04 - mape: 169243.0469\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8858e-04 - mse: 4.8936e-08 - mae: 1.8858e-04 - mape: 166072.9062\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8770e-04 - mse: 4.9161e-08 - mae: 1.8770e-04 - mape: 164539.3906\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8660e-04 - mse: 4.9626e-08 - mae: 1.8660e-04 - mape: 163518.6250\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8779e-04 - mse: 5.0014e-08 - mae: 1.8779e-04 - mape: 164865.2500\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8789e-04 - mse: 4.9987e-08 - mae: 1.8789e-04 - mape: 165207.2188\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8700e-04 - mse: 4.9495e-08 - mae: 1.8700e-04 - mape: 164637.2188\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8523e-04 - mse: 4.8693e-08 - mae: 1.8523e-04 - mape: 163245.2188\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8316e-04 - mse: 4.7881e-08 - mae: 1.8316e-04 - mape: 161618.4219\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8471e-04 - mse: 4.7436e-08 - mae: 1.8471e-04 - mape: 164234.9531\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8496e-04 - mse: 4.7337e-08 - mae: 1.8496e-04 - mape: 165321.1406\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8463e-04 - mse: 4.7179e-08 - mae: 1.8463e-04 - mape: 165007.1406\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8389e-04 - mse: 4.6968e-08 - mae: 1.8389e-04 - mape: 163568.1562\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8133e-04 - mse: 4.7024e-08 - mae: 1.8133e-04 - mape: 160227.1562\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8220e-04 - mse: 4.7238e-08 - mae: 1.8220e-04 - mape: 161081.781 - 0s 2ms/step - loss: 1.8220e-04 - mse: 4.7238e-08 - mae: 1.8220e-04 - mape: 161081.7812\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8242e-04 - mse: 4.7239e-08 - mae: 1.8242e-04 - mape: 161391.2031\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8162e-04 - mse: 4.6922e-08 - mae: 1.8162e-04 - mape: 160759.9531\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8010e-04 - mse: 4.6420e-08 - mae: 1.8010e-04 - mape: 159495.8438\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8072e-04 - mse: 4.6176e-08 - mae: 1.8072e-04 - mape: 159611.4844\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8133e-04 - mse: 4.6223e-08 - mae: 1.8133e-04 - mape: 159613.0938\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8056e-04 - mse: 4.6130e-08 - mae: 1.8056e-04 - mape: 159003.2812\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7958e-04 - mse: 4.6004e-08 - mae: 1.7958e-04 - mape: 158864.2969\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7956e-04 - mse: 4.5778e-08 - mae: 1.7956e-04 - mape: 159704.2031\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7921e-04 - mse: 4.5620e-08 - mae: 1.7921e-04 - mape: 159378.2969\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7864e-04 - mse: 4.5525e-08 - mae: 1.7864e-04 - mape: 158074.9531\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7858e-04 - mse: 4.5293e-08 - mae: 1.7858e-04 - mape: 157464.2500\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7812e-04 - mse: 4.5024e-08 - mae: 1.7812e-04 - mape: 157213.8438\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7734e-04 - mse: 4.4743e-08 - mae: 1.7734e-04 - mape: 157329.8438\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7703e-04 - mse: 4.4592e-08 - mae: 1.7703e-04 - mape: 157075.9844\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7694e-04 - mse: 4.4546e-08 - mae: 1.7694e-04 - mape: 156264.0938\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7639e-04 - mse: 4.4465e-08 - mae: 1.7639e-04 - mape: 155792.2500\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7640e-04 - mse: 4.4394e-08 - mae: 1.7640e-04 - mape: 156586.7969\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7724e-04 - mse: 4.4193e-08 - mae: 1.7724e-04 - mape: 158245.6719\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7676e-04 - mse: 4.3990e-08 - mae: 1.7676e-04 - mape: 157729.7969\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7501e-04 - mse: 4.3814e-08 - mae: 1.7501e-04 - mape: 155163.4219\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7525e-04 - mse: 4.3570e-08 - mae: 1.7525e-04 - mape: 154779.9688\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7508e-04 - mse: 4.3322e-08 - mae: 1.7508e-04 - mape: 154781.0156\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7433e-04 - mse: 4.3289e-08 - mae: 1.7433e-04 - mape: 154026.7188\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7425e-04 - mse: 4.3297e-08 - mae: 1.7425e-04 - mape: 154682.7031\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7468e-04 - mse: 4.3172e-08 - mae: 1.7468e-04 - mape: 155885.1250\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7405e-04 - mse: 4.3049e-08 - mae: 1.7405e-04 - mape: 155158.8438\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7389e-04 - mse: 4.2988e-08 - mae: 1.7389e-04 - mape: 154121.8125\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7308e-04 - mse: 4.2760e-08 - mae: 1.7308e-04 - mape: 152627.5781\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7272e-04 - mse: 4.2504e-08 - mae: 1.7272e-04 - mape: 152397.4219\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7180e-04 - mse: 4.2219e-08 - mae: 1.7180e-04 - mape: 152343.5156\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7275e-04 - mse: 4.1882e-08 - mae: 1.7275e-04 - mape: 154188.9062\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7248e-04 - mse: 4.1632e-08 - mae: 1.7248e-04 - mape: 153918.7188\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7157e-04 - mse: 4.1552e-08 - mae: 1.7157e-04 - mape: 152854.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7046e-04 - mse: 4.1601e-08 - mae: 1.7046e-04 - mape: 150795.3438\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7159e-04 - mse: 4.1578e-08 - mae: 1.7159e-04 - mape: 151168.5938\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7113e-04 - mse: 4.1423e-08 - mae: 1.7113e-04 - mape: 150804.9688\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6975e-04 - mse: 4.1173e-08 - mae: 1.6975e-04 - mape: 150270.6094\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6958e-04 - mse: 4.0827e-08 - mae: 1.6958e-04 - mape: 150977.0312\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6912e-04 - mse: 4.0594e-08 - mae: 1.6912e-04 - mape: 150486.6406\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6890e-04 - mse: 4.0482e-08 - mae: 1.6890e-04 - mape: 149409.7188\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6860e-04 - mse: 4.0340e-08 - mae: 1.6860e-04 - mape: 149119.8594\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6766e-04 - mse: 4.0157e-08 - mae: 1.6766e-04 - mape: 148961.2344\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6737e-04 - mse: 4.0104e-08 - mae: 1.6737e-04 - mape: 148549.8750\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6653e-04 - mse: 3.9841e-08 - mae: 1.6653e-04 - mape: 147711.7812\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6795e-04 - mse: 3.9778e-08 - mae: 1.6795e-04 - mape: 148290.9062\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6763e-04 - mse: 3.9620e-08 - mae: 1.6763e-04 - mape: 148012.3906\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6568e-04 - mse: 3.9364e-08 - mae: 1.6568e-04 - mape: 146882.9688\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6786e-04 - mse: 3.9382e-08 - mae: 1.6786e-04 - mape: 150584.4844\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6843e-04 - mse: 3.9518e-08 - mae: 1.6843e-04 - mape: 151700.1094\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6718e-04 - mse: 3.9501e-08 - mae: 1.6718e-04 - mape: 150080.2812\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6712e-04 - mse: 3.9541e-08 - mae: 1.6712e-04 - mape: 148848.5156\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [00:00<00:00, 1367.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:00<00:00, 308.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000            -   \n",
      "W1                             5.252696e-07   0.000000            -   \n",
      "W1-95R                         5.252696e-07   0.000000            -   \n",
      "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
      "M                              5.834706e-05   0.000000   1.1343e-05   \n",
      "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
      "N_Par                          4.220800e+04   0.000000           20   \n",
      "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
      "\n",
      "                                    KRidge         GBRF          DNN  \n",
      "W1-95L                                   -            -            -  \n",
      "W1                                       -            -            -  \n",
      "W1-95R                                   -            -            -  \n",
      "M-95L                           5.9994e-05  6.30167e-06  0.000196334  \n",
      "M                              7.12614e-05   1.1343e-05  0.000203166  \n",
      "M-95R                          8.80365e-05  2.14257e-05  0.000240146  \n",
      "N_Par                                    0         1000        40801  \n",
      "Train_Time                        0.574352      0.66944      9.68545  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629     0.150841  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exec(open('CV_Grid.py').read())\n",
    "# Notebook Mode:\n",
    "# %run Evaluation.ipynb\n",
    "# %run Benchmarks_Model_Builder_Pointmass_Based.ipynb\n",
    "# Terminal Mode (Default):\n",
    "exec(open('Evaluation.py').read())\n",
    "exec(open('Benchmarks_Model_Builder_Pointmass_Based.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Point-Mass Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000            -   \n",
      "W1                             5.252696e-07   0.000000            -   \n",
      "W1-95R                         5.252696e-07   0.000000            -   \n",
      "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
      "M                              5.834706e-05   0.000000   1.1343e-05   \n",
      "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
      "N_Par                          4.220800e+04   0.000000           20   \n",
      "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
      "\n",
      "                                    KRidge         GBRF          DNN  \n",
      "W1-95L                                   -            -            -  \n",
      "W1                                       -            -            -  \n",
      "W1-95R                                   -            -            -  \n",
      "M-95L                           5.9994e-05  6.30167e-06  0.000196334  \n",
      "M                              7.12614e-05   1.1343e-05  0.000203166  \n",
      "M-95R                          8.80365e-05  2.14257e-05  0.000240146  \n",
      "N_Par                                    0         1000        40801  \n",
      "Train_Time                        0.574352      0.66944      9.68545  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629     0.150841  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.30167e-06</td>\n",
       "      <td>5.9994e-05</td>\n",
       "      <td>6.30167e-06</td>\n",
       "      <td>0.000196334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.1343e-05</td>\n",
       "      <td>7.12614e-05</td>\n",
       "      <td>1.1343e-05</td>\n",
       "      <td>0.000203166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.14257e-05</td>\n",
       "      <td>8.80365e-05</td>\n",
       "      <td>2.14257e-05</td>\n",
       "      <td>0.000240146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>4.220800e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>40801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.115808e+01</td>\n",
       "      <td>1.814789</td>\n",
       "      <td>1.62012e+09</td>\n",
       "      <td>0.574352</td>\n",
       "      <td>0.66944</td>\n",
       "      <td>9.68545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>1.942113e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00021694</td>\n",
       "      <td>0.000849836</td>\n",
       "      <td>0.00244629</td>\n",
       "      <td>0.150841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle         ENET  \\\n",
       "W1-95L                         5.252696e-07   0.000000            -   \n",
       "W1                             5.252696e-07   0.000000            -   \n",
       "W1-95R                         5.252696e-07   0.000000            -   \n",
       "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
       "M                              5.834706e-05   0.000000   1.1343e-05   \n",
       "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
       "N_Par                          4.220800e+04   0.000000           20   \n",
       "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
       "\n",
       "                                    KRidge         GBRF          DNN  \n",
       "W1-95L                                   -            -            -  \n",
       "W1                                       -            -            -  \n",
       "W1-95R                                   -            -            -  \n",
       "M-95L                           5.9994e-05  6.30167e-06  0.000196334  \n",
       "M                              7.12614e-05   1.1343e-05  0.000203166  \n",
       "M-95R                          8.80365e-05  2.14257e-05  0.000240146  \n",
       "N_Par                                    0         1000        40801  \n",
       "Train_Time                        0.574352      0.66944      9.68545  \n",
       "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629     0.150841  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000  3.971106e-11   \n",
      "W1                             5.252696e-07   0.000000  3.971106e-11   \n",
      "W1-95R                         5.252696e-07   0.000000  3.971106e-11   \n",
      "M-95L                          5.834706e-05   0.000000  6.301671e-06   \n",
      "M                              5.834706e-05   0.000000  6.301671e-06   \n",
      "M-95R                          5.834706e-05   0.000000  6.301671e-06   \n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
      "Train_Time                     1.115808e+01   1.814789  1.620119e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000  2.169400e-04   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \n",
      "W1-95L                         3.599282e-09  3.971106e-11  3.854703e-08  \n",
      "W1                             4.145635e-09  3.971106e-11  4.132317e-08  \n",
      "W1-95R                         4.691989e-09  3.971106e-11  4.409930e-08  \n",
      "M-95L                          5.999402e-05  6.301671e-06  1.963340e-04  \n",
      "M                              6.424605e-05  6.301671e-06  2.031662e-04  \n",
      "M-95R                          6.849809e-05  6.301671e-06  2.099983e-04  \n",
      "N_Par                          0.000000e+00  1.000000e+03  4.080100e+04  \n",
      "Train_Time                     5.743520e-01  6.694398e-01  9.685448e+00  \n",
      "Test_Time/MC-Oracle_Test_Time  8.498361e-04  2.446292e-03  1.508413e-01  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>3.599282e-09</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>3.854703e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>4.145635e-09</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>4.132317e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>4.691989e-09</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>4.409930e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>5.999402e-05</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>1.963340e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>6.424605e-05</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>2.031662e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>6.849809e-05</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>2.099983e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>4.220800e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>4.080100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.115808e+01</td>\n",
       "      <td>1.814789</td>\n",
       "      <td>1.620119e+09</td>\n",
       "      <td>5.743520e-01</td>\n",
       "      <td>6.694398e-01</td>\n",
       "      <td>9.685448e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>1.942113e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.169400e-04</td>\n",
       "      <td>8.498361e-04</td>\n",
       "      <td>2.446292e-03</td>\n",
       "      <td>1.508413e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle          ENET  \\\n",
       "W1-95L                         5.252696e-07   0.000000  3.971106e-11   \n",
       "W1                             5.252696e-07   0.000000  3.971106e-11   \n",
       "W1-95R                         5.252696e-07   0.000000  3.971106e-11   \n",
       "M-95L                          5.834706e-05   0.000000  6.301671e-06   \n",
       "M                              5.834706e-05   0.000000  6.301671e-06   \n",
       "M-95R                          5.834706e-05   0.000000  6.301671e-06   \n",
       "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
       "Train_Time                     1.115808e+01   1.814789  1.620119e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000  2.169400e-04   \n",
       "\n",
       "                                     KRidge          GBRF           DNN  \n",
       "W1-95L                         3.599282e-09  3.971106e-11  3.854703e-08  \n",
       "W1                             4.145635e-09  3.971106e-11  4.132317e-08  \n",
       "W1-95R                         4.691989e-09  3.971106e-11  4.409930e-08  \n",
       "M-95L                          5.999402e-05  6.301671e-06  1.963340e-04  \n",
       "M                              6.424605e-05  6.301671e-06  2.031662e-04  \n",
       "M-95R                          6.849809e-05  6.301671e-06  2.099983e-04  \n",
       "N_Par                          0.000000e+00  1.000000e+03  4.080100e+04  \n",
       "Train_Time                     5.743520e-01  6.694398e-01  9.685448e+00  \n",
       "Test_Time/MC-Oracle_Test_Time  8.498361e-04  2.446292e-03  1.508413e-01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) *Gaussian Benchmarks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bencharm 1: [Gaussian Process Regressor](https://scikit-learn.org/stable/modules/gaussian_process.html)\n",
    "- Benchmark 2: Deep Gaussian Networks:\n",
    "These models train models which assume Gaussianity.  We may view these as models in $\\mathcal{P}_2(\\mathbb{R})$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to (\\hat{\\mu}(x),\\hat{\\Sigma}(x)\\hat{\\Sigma}^{\\top})\\triangleq f(x) \\in \\mathbb{R}\\times [0,\\infty) \\to \n",
    "(2\\pi)^{-\\frac{d}{2}}\\det(\\hat{\\Sigma}(x))^{-\\frac{1}{2}} \\, e^{ -\\frac{1}{2}(\\cdot - \\hat{\\mu}(x))^{{{\\!\\mathsf{T}}}} \\hat{\\Sigma}(x)^{-1}(\\cdot - \\hat{\\mu}(x)) } \\mu \\in \\mathcal{G}_d\\subset \\mathcal{P}_2(\\mathbb{R});\n",
    "$$\n",
    "where $\\mathcal{G}_1$ is the set of Gaussian measures on $\\mathbb{R}$ equipped with the relative Wasserstein-1 topology.\n",
    "\n",
    "Examples of this type of architecture are especially prevalent in uncertainty quantification; see ([Deep Ensembles](https://arxiv.org/abs/1612.01474)] or [NOMU: Neural Optimization-based Model Uncertainty](https://arxiv.org/abs/2102.13640).  Moreover, their universality in $C(\\mathbb{R}^d,\\mathcal{G}_2)$ is known, and has been shown in [Corollary 4.7](https://arxiv.org/abs/2101.05390)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.1340s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.5s finished\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering Parameters for Deep Gaussian Network to train on!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.84it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Getting Parameters for Deep Gaussian Network!\n",
      "===============================\n",
      "Training Deep Gaussian Network!\n",
      "===============================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5005 - mse: 0.4579 - mae: 0.5005 - mape: 450463840.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5005 - mse: 0.4581 - mae: 0.5005 - mape: 450459200.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5005 - mse: 0.4583 - mae: 0.5005 - mape: 450454368.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5004 - mse: 0.4585 - mae: 0.5004 - mape: 450449504.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5004 - mse: 0.4587 - mae: 0.5004 - mape: 450444704.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5004 - mse: 0.4589 - mae: 0.5004 - mape: 450439840.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5004 - mse: 0.4591 - mae: 0.5004 - mape: 450434976.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5004 - mse: 0.4593 - mae: 0.5004 - mape: 450430144.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5004 - mse: 0.4596 - mae: 0.5004 - mape: 450425344.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5004 - mse: 0.4598 - mae: 0.5004 - mape: 450420544.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5004 - mse: 0.4600 - mae: 0.5004 - mape: 450415776.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5004 - mse: 0.4602 - mae: 0.5004 - mape: 450411008.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5004 - mse: 0.4604 - mae: 0.5004 - mape: 450406240.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5004 - mse: 0.4607 - mae: 0.5004 - mape: 450401536.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5004 - mse: 0.4609 - mae: 0.5004 - mape: 450396864.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5004 - mse: 0.4611 - mae: 0.5004 - mape: 450392256.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5004 - mse: 0.4613 - mae: 0.5004 - mape: 450387648.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5004 - mse: 0.4615 - mae: 0.5004 - mape: 450383008.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5004 - mse: 0.4618 - mae: 0.5004 - mape: 450378496.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5004 - mse: 0.4620 - mae: 0.5004 - mape: 450373952.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5004 - mse: 0.4622 - mae: 0.5004 - mape: 450369440.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5004 - mse: 0.4624 - mae: 0.5004 - mape: 450364992.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - mse: 0.4626 - mae: 0.5003 - mape: 450360512.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - mse: 0.4629 - mae: 0.5003 - mape: 450356160.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5003 - mse: 0.4631 - mae: 0.5003 - mape: 450351808.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - mse: 0.4633 - mae: 0.5003 - mape: 450347456.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5003 - mse: 0.4635 - mae: 0.5003 - mape: 450343168.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - mse: 0.4637 - mae: 0.5003 - mape: 450338912.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5003 - mse: 0.4640 - mae: 0.5003 - mape: 450334720.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5003 - mse: 0.4642 - mae: 0.5003 - mape: 450330528.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5003 - mse: 0.4644 - mae: 0.5003 - mape: 450326336.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5003 - mse: 0.4646 - mae: 0.5003 - mape: 450322240.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5003 - mse: 0.4648 - mae: 0.5003 - mape: 450318144.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5003 - mse: 0.4650 - mae: 0.5003 - mape: 450314080.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5003 - mse: 0.4653 - mae: 0.5003 - mape: 450310080.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5003 - mse: 0.4655 - mae: 0.5003 - mape: 450306112.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5003 - mse: 0.4657 - mae: 0.5003 - mape: 450302144.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - mse: 0.4659 - mae: 0.5003 - mape: 450298272.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5003 - mse: 0.4661 - mae: 0.5003 - mape: 450294432.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5003 - mse: 0.4663 - mae: 0.5003 - mape: 450290592.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5003 - mse: 0.4666 - mae: 0.5003 - mape: 450286784.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5003 - mse: 0.4668 - mae: 0.5003 - mape: 450283008.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5003 - mse: 0.4670 - mae: 0.5003 - mape: 450279328.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - mse: 0.4672 - mae: 0.5003 - mape: 450275648.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5003 - mse: 0.4674 - mae: 0.5003 - mape: 450271936.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4676 - mae: 0.5002 - mape: 450268352.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4678 - mae: 0.5002 - mape: 450264768.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5002 - mse: 0.4680 - mae: 0.5002 - mape: 450261248.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4683 - mae: 0.5002 - mape: 450257760.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5002 - mse: 0.4685 - mae: 0.5002 - mape: 450254240.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5002 - mse: 0.4687 - mae: 0.5002 - mape: 450250848.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4689 - mae: 0.5002 - mape: 450247424.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4691 - mae: 0.5002 - mape: 450244032.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4693 - mae: 0.5002 - mape: 450240704.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5002 - mse: 0.4695 - mae: 0.5002 - mape: 450237440.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4697 - mae: 0.5002 - mape: 450234176.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4699 - mae: 0.5002 - mape: 450230944.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5002 - mse: 0.4701 - mae: 0.5002 - mape: 450227776.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4703 - mae: 0.5002 - mape: 450224576.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4705 - mae: 0.5002 - mape: 450221472.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5002 - mse: 0.4707 - mae: 0.5002 - mape: 450218400.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4709 - mae: 0.5002 - mape: 450215328.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4712 - mae: 0.5002 - mape: 450212288.0000\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5002 - mse: 0.4714 - mae: 0.5002 - mape: 450209280.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5002 - mse: 0.4716 - mae: 0.5002 - mape: 450206304.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4718 - mae: 0.5002 - mape: 450203392.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5002 - mse: 0.4720 - mae: 0.5002 - mape: 450200512.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5002 - mse: 0.4722 - mae: 0.5002 - mape: 450197664.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4724 - mae: 0.5002 - mape: 450194784.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4726 - mae: 0.5002 - mape: 450192032.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - mse: 0.4728 - mae: 0.5002 - mape: 450189248.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5002 - mse: 0.4729 - mae: 0.5002 - mape: 450186496.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5002 - mse: 0.4731 - mae: 0.5002 - mape: 450183840.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5002 - mse: 0.4733 - mae: 0.5002 - mape: 450181184.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - mse: 0.4735 - mae: 0.5001 - mape: 450178496.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5001 - mse: 0.4737 - mae: 0.5001 - mape: 450175904.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - mse: 0.4739 - mae: 0.5001 - mape: 450173344.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5001 - mse: 0.4741 - mae: 0.5001 - mape: 450170784.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4743 - mae: 0.5001 - mape: 450168256.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5001 - mse: 0.4745 - mae: 0.5001 - mape: 450165760.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5001 - mse: 0.4747 - mae: 0.5001 - mape: 450163296.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5001 - mse: 0.4749 - mae: 0.5001 - mape: 450160832.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5001 - mse: 0.4751 - mae: 0.5001 - mape: 450158496.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5001 - mse: 0.4753 - mae: 0.5001 - mape: 450156128.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - mse: 0.4754 - mae: 0.5001 - mape: 450153792.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4756 - mae: 0.5001 - mape: 450151424.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4758 - mae: 0.5001 - mape: 450149184.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4760 - mae: 0.5001 - mape: 450146912.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - mse: 0.4762 - mae: 0.5001 - mape: 450144672.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4764 - mae: 0.5001 - mape: 450142528.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5001 - mse: 0.4766 - mae: 0.5001 - mape: 450140320.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - mse: 0.4767 - mae: 0.5001 - mape: 450138176.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5001 - mse: 0.4769 - mae: 0.5001 - mape: 450136064.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - mse: 0.4771 - mae: 0.5001 - mape: 450133952.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5001 - mse: 0.4773 - mae: 0.5001 - mape: 450131904.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - mse: 0.4775 - mae: 0.5001 - mape: 450129824.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5001 - mse: 0.4777 - mae: 0.5001 - mape: 450127808.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5001 - mse: 0.4778 - mae: 0.5001 - mape: 450125824.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4780 - mae: 0.5001 - mape: 450123840.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4782 - mae: 0.5001 - mape: 450121920.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4784 - mae: 0.5001 - mape: 450120032.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5001 - mse: 0.4785 - mae: 0.5001 - mape: 450118144.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5001 - mse: 0.4787 - mae: 0.5001 - mape: 450116288.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5001 - mse: 0.4789 - mae: 0.5001 - mape: 450114464.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4791 - mae: 0.5001 - mape: 450112672.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5001 - mse: 0.4792 - mae: 0.5001 - mape: 450110880.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5001 - mse: 0.4794 - mae: 0.5001 - mape: 450109024.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4796 - mae: 0.5001 - mape: 450107328.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - mse: 0.4797 - mae: 0.5001 - mape: 450105600.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - mse: 0.4799 - mae: 0.5001 - mape: 450103904.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4801 - mae: 0.5001 - mape: 450102208.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4803 - mae: 0.5001 - mape: 450100640.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5001 - mse: 0.4804 - mae: 0.5001 - mape: 450099008.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4806 - mae: 0.5001 - mape: 450097344.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5001 - mse: 0.4808 - mae: 0.5001 - mape: 450095776.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4809 - mae: 0.5001 - mape: 450094240.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5001 - mse: 0.4811 - mae: 0.5001 - mape: 450092736.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - mse: 0.4812 - mae: 0.5001 - mape: 450091200.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4814 - mae: 0.5000 - mape: 450089664.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4816 - mae: 0.5000 - mape: 450088256.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4817 - mae: 0.5000 - mape: 450086752.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4819 - mae: 0.5000 - mape: 450085376.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4820 - mae: 0.5000 - mape: 450083936.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4822 - mae: 0.5000 - mape: 450082560.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4824 - mae: 0.5000 - mape: 450081184.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5000 - mse: 0.4825 - mae: 0.5000 - mape: 450079840.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4827 - mae: 0.5000 - mape: 450078528.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4828 - mae: 0.5000 - mape: 450077248.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4830 - mae: 0.5000 - mape: 450075968.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4831 - mae: 0.5000 - mape: 450074624.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4833 - mae: 0.5000 - mape: 450073408.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - mse: 0.4834 - mae: 0.5000 - mape: 450072160.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4836 - mae: 0.5000 - mape: 450070944.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4837 - mae: 0.5000 - mape: 450069760.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4839 - mae: 0.5000 - mape: 450068576.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - mse: 0.4840 - mae: 0.5000 - mape: 450067456.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4842 - mae: 0.5000 - mape: 450066336.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4843 - mae: 0.5000 - mape: 450065152.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4845 - mae: 0.5000 - mape: 450064064.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4846 - mae: 0.5000 - mape: 450063008.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4848 - mae: 0.5000 - mape: 450061888.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - mse: 0.4849 - mae: 0.5000 - mape: 450060864.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4851 - mae: 0.5000 - mape: 450059840.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4852 - mae: 0.5000 - mape: 450058816.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - mse: 0.4853 - mae: 0.5000 - mape: 450057792.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4855 - mae: 0.5000 - mape: 450056800.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4856 - mae: 0.5000 - mape: 450055776.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4858 - mae: 0.5000 - mape: 450054848.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4859 - mae: 0.5000 - mape: 450053952.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4860 - mae: 0.5000 - mape: 450053024.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4862 - mae: 0.5000 - mape: 450052096.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4863 - mae: 0.5000 - mape: 450051168.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4864 - mae: 0.5000 - mape: 450050304.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4866 - mae: 0.5000 - mape: 450049472.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4867 - mae: 0.5000 - mape: 450048608.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - mse: 0.4868 - mae: 0.5000 - mape: 450047744.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4870 - mae: 0.5000 - mape: 450046912.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4871 - mae: 0.5000 - mape: 450046144.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4872 - mae: 0.5000 - mape: 450045344.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4874 - mae: 0.5000 - mape: 450044576.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4875 - mae: 0.5000 - mape: 450043808.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4876 - mae: 0.5000 - mape: 450043040.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4877 - mae: 0.5000 - mape: 450042272.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4879 - mae: 0.5000 - mape: 450041536.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4880 - mae: 0.5000 - mape: 450040896.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4881 - mae: 0.5000 - mape: 450040128.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4882 - mae: 0.5000 - mape: 450039456.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4884 - mae: 0.5000 - mape: 450038784.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4885 - mae: 0.5000 - mape: 450038080.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4886 - mae: 0.5000 - mape: 450037408.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4887 - mae: 0.5000 - mape: 450036832.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5000 - mse: 0.4888 - mae: 0.5000 - mape: 450036160.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5000 - mse: 0.4890 - mae: 0.5000 - mape: 450035520.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4891 - mae: 0.5000 - mape: 450034944.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5000 - mse: 0.4892 - mae: 0.5000 - mape: 450034336.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4893 - mae: 0.5000 - mape: 450033728.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4894 - mae: 0.5000 - mape: 450033152.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4895 - mae: 0.5000 - mape: 450032576.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4896 - mae: 0.5000 - mape: 450032032.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4897 - mae: 0.5000 - mape: 450031456.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4899 - mae: 0.5000 - mape: 450030944.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4900 - mae: 0.5000 - mape: 450030400.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4901 - mae: 0.5000 - mape: 450029888.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4902 - mae: 0.5000 - mape: 450029376.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4903 - mae: 0.5000 - mape: 450028864.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4904 - mae: 0.5000 - mape: 450028384.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4905 - mae: 0.5000 - mape: 450027936.0000\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4906 - mae: 0.5000 - mape: 450027456.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4907 - mae: 0.5000 - mape: 450027008.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4908 - mae: 0.5000 - mape: 450026560.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4909 - mae: 0.5000 - mape: 450026080.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4910 - mae: 0.5000 - mape: 450025664.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4911 - mae: 0.5000 - mape: 450025280.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4912 - mae: 0.5000 - mape: 450024864.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4913 - mae: 0.5000 - mape: 450024448.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4914 - mae: 0.5000 - mape: 450024032.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4915 - mae: 0.5000 - mape: 450023616.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5000 - mse: 0.4916 - mae: 0.5000 - mape: 450023232.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - mse: 0.4917 - mae: 0.5000 - mape: 450022848.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - mse: 0.4918 - mae: 0.5000 - mape: 450022496.0000\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Training Deep Gaussian Network!: END\n",
      "====================================\n",
      "#---------------------------------------#\n",
      " Get Training Errors for: Gaussian Models\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 646.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 275.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------------------------#\n",
      " Get Testing Errors for: Gaussian Models\n",
      "#--------------------------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000            -   \n",
      "W1                             5.252696e-07   0.000000            -   \n",
      "W1-95R                         5.252696e-07   0.000000            -   \n",
      "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
      "M                              5.834706e-05   0.000000   1.1343e-05   \n",
      "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
      "N_Par                          4.220800e+04   0.000000           20   \n",
      "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
      "\n",
      "                                    KRidge         GBRF          DNN  \\\n",
      "W1-95L                                   -            -            -   \n",
      "W1                                       -            -            -   \n",
      "W1-95R                                   -            -            -   \n",
      "M-95L                           5.9994e-05  6.30167e-06  0.000196334   \n",
      "M                              7.12614e-05   1.1343e-05  0.000203166   \n",
      "M-95R                          8.80365e-05  2.14257e-05  0.000240146   \n",
      "N_Par                                    0         1000        40801   \n",
      "Train_Time                        0.574352      0.66944      9.68545   \n",
      "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629     0.150841   \n",
      "\n",
      "                                    GPR           DGN  \n",
      "W1-95L                         0.000010      1.003425  \n",
      "W1                             0.000010      1.009751  \n",
      "W1-95R                         0.000010      1.016077  \n",
      "M-95L                          0.000000      0.007965  \n",
      "M                              0.000006      0.008116  \n",
      "M-95R                          0.000032      0.008211  \n",
      "N_Par                          0.000000  40801.000000  \n",
      "Train_Time                     0.590494      6.833113  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000962      0.150610  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %run Benchmarks_Model_Builder_Mean_Var.ipynb\n",
    "exec(open('Benchmarks_Model_Builder_Mean_Var.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Quality (Updated): Test\n",
      "                                        DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000  3.971106e-11   \n",
      "W1                             5.252696e-07   0.000000  3.971106e-11   \n",
      "W1-95R                         5.252696e-07   0.000000  3.971106e-11   \n",
      "M-95L                          5.834706e-05   0.000000  6.301671e-06   \n",
      "M                              5.834706e-05   0.000000  6.301671e-06   \n",
      "M-95R                          5.834706e-05   0.000000  6.301671e-06   \n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
      "Train_Time                     1.115808e+01   1.814789  1.620119e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000  2.169400e-04   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \\\n",
      "W1-95L                         3.599282e-09  3.971106e-11  3.854703e-08   \n",
      "W1                             4.145635e-09  3.971106e-11  4.132317e-08   \n",
      "W1-95R                         4.691989e-09  3.971106e-11  4.409930e-08   \n",
      "M-95L                          5.999402e-05  6.301671e-06  1.963340e-04   \n",
      "M                              6.424605e-05  6.301671e-06  2.031662e-04   \n",
      "M-95R                          6.849809e-05  6.301671e-06  2.099983e-04   \n",
      "N_Par                          0.000000e+00  1.000000e+03  4.080100e+04   \n",
      "Train_Time                     5.743520e-01  6.694398e-01  9.685448e+00   \n",
      "Test_Time/MC-Oracle_Test_Time  8.498361e-04  2.446292e-03  1.508413e-01   \n",
      "\n",
      "                                    GPR           DGN  \n",
      "W1-95L                         0.000009      1.003425  \n",
      "W1                             0.000010      1.009751  \n",
      "W1-95R                         0.000010      1.016077  \n",
      "M-95L                          0.000000      0.007883  \n",
      "M                              0.000000      0.007884  \n",
      "M-95R                          0.000000      0.007885  \n",
      "N_Par                          0.000000  40801.000000  \n",
      "Train_Time                     0.590494      6.833113  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000962      0.150610  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>3.599282e-09</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>3.854703e-08</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>4.145635e-09</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>4.132317e-08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.009751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>4.691989e-09</td>\n",
       "      <td>3.971106e-11</td>\n",
       "      <td>4.409930e-08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.016077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>5.999402e-05</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>1.963340e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>6.424605e-05</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>2.031662e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>6.849809e-05</td>\n",
       "      <td>6.301671e-06</td>\n",
       "      <td>2.099983e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>4.220800e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>4.080100e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.115808e+01</td>\n",
       "      <td>1.814789</td>\n",
       "      <td>1.620119e+09</td>\n",
       "      <td>5.743520e-01</td>\n",
       "      <td>6.694398e-01</td>\n",
       "      <td>9.685448e+00</td>\n",
       "      <td>0.590494</td>\n",
       "      <td>6.833113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>1.942113e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.169400e-04</td>\n",
       "      <td>8.498361e-04</td>\n",
       "      <td>2.446292e-03</td>\n",
       "      <td>1.508413e-01</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.150610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle          ENET  \\\n",
       "W1-95L                         5.252696e-07   0.000000  3.971106e-11   \n",
       "W1                             5.252696e-07   0.000000  3.971106e-11   \n",
       "W1-95R                         5.252696e-07   0.000000  3.971106e-11   \n",
       "M-95L                          5.834706e-05   0.000000  6.301671e-06   \n",
       "M                              5.834706e-05   0.000000  6.301671e-06   \n",
       "M-95R                          5.834706e-05   0.000000  6.301671e-06   \n",
       "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
       "Train_Time                     1.115808e+01   1.814789  1.620119e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000  2.169400e-04   \n",
       "\n",
       "                                     KRidge          GBRF           DNN  \\\n",
       "W1-95L                         3.599282e-09  3.971106e-11  3.854703e-08   \n",
       "W1                             4.145635e-09  3.971106e-11  4.132317e-08   \n",
       "W1-95R                         4.691989e-09  3.971106e-11  4.409930e-08   \n",
       "M-95L                          5.999402e-05  6.301671e-06  1.963340e-04   \n",
       "M                              6.424605e-05  6.301671e-06  2.031662e-04   \n",
       "M-95R                          6.849809e-05  6.301671e-06  2.099983e-04   \n",
       "N_Par                          0.000000e+00  1.000000e+03  4.080100e+04   \n",
       "Train_Time                     5.743520e-01  6.694398e-01  9.685448e+00   \n",
       "Test_Time/MC-Oracle_Test_Time  8.498361e-04  2.446292e-03  1.508413e-01   \n",
       "\n",
       "                                    GPR           DGN  \n",
       "W1-95L                         0.000009      1.003425  \n",
       "W1                             0.000010      1.009751  \n",
       "W1-95R                         0.000010      1.016077  \n",
       "M-95L                          0.000000      0.007883  \n",
       "M                              0.000000      0.007884  \n",
       "M-95R                          0.000000      0.007885  \n",
       "N_Par                          0.000000  40801.000000  \n",
       "Train_Time                     0.590494      6.833113  \n",
       "Test_Time/MC-Oracle_Test_Time  0.000962      0.150610  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Prediction Quality (Updated): Test\")\n",
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Quality (Updated): Train\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000            -   \n",
      "W1                             5.252696e-07   0.000000            -   \n",
      "W1-95R                         5.252696e-07   0.000000            -   \n",
      "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
      "M                              5.834706e-05   0.000000   1.1343e-05   \n",
      "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
      "N_Par                          4.220800e+04   0.000000           20   \n",
      "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
      "\n",
      "                                    KRidge         GBRF          DNN  \\\n",
      "W1-95L                                   -            -            -   \n",
      "W1                                       -            -            -   \n",
      "W1-95R                                   -            -            -   \n",
      "M-95L                           5.9994e-05  6.30167e-06  0.000196334   \n",
      "M                              7.12614e-05   1.1343e-05  0.000203166   \n",
      "M-95R                          8.80365e-05  2.14257e-05  0.000240146   \n",
      "N_Par                                    0         1000        40801   \n",
      "Train_Time                        0.574352      0.66944      9.68545   \n",
      "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629     0.150841   \n",
      "\n",
      "                                    GPR           DGN  \n",
      "W1-95L                         0.000010      1.003425  \n",
      "W1                             0.000010      1.009751  \n",
      "W1-95R                         0.000010      1.016077  \n",
      "M-95L                          0.000000      0.007965  \n",
      "M                              0.000006      0.008116  \n",
      "M-95R                          0.000032      0.008211  \n",
      "N_Par                          0.000000  40801.000000  \n",
      "Train_Time                     0.590494      6.833113  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000962      0.150610  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.009751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.016077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.30167e-06</td>\n",
       "      <td>5.9994e-05</td>\n",
       "      <td>6.30167e-06</td>\n",
       "      <td>0.000196334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.1343e-05</td>\n",
       "      <td>7.12614e-05</td>\n",
       "      <td>1.1343e-05</td>\n",
       "      <td>0.000203166</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.008116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.14257e-05</td>\n",
       "      <td>8.80365e-05</td>\n",
       "      <td>2.14257e-05</td>\n",
       "      <td>0.000240146</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.008211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>4.220800e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>40801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.115808e+01</td>\n",
       "      <td>1.814789</td>\n",
       "      <td>1.62012e+09</td>\n",
       "      <td>0.574352</td>\n",
       "      <td>0.66944</td>\n",
       "      <td>9.68545</td>\n",
       "      <td>0.590494</td>\n",
       "      <td>6.833113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>1.942113e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00021694</td>\n",
       "      <td>0.000849836</td>\n",
       "      <td>0.00244629</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.150610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle         ENET  \\\n",
       "W1-95L                         5.252696e-07   0.000000            -   \n",
       "W1                             5.252696e-07   0.000000            -   \n",
       "W1-95R                         5.252696e-07   0.000000            -   \n",
       "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
       "M                              5.834706e-05   0.000000   1.1343e-05   \n",
       "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
       "N_Par                          4.220800e+04   0.000000           20   \n",
       "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
       "\n",
       "                                    KRidge         GBRF          DNN  \\\n",
       "W1-95L                                   -            -            -   \n",
       "W1                                       -            -            -   \n",
       "W1-95R                                   -            -            -   \n",
       "M-95L                           5.9994e-05  6.30167e-06  0.000196334   \n",
       "M                              7.12614e-05   1.1343e-05  0.000203166   \n",
       "M-95R                          8.80365e-05  2.14257e-05  0.000240146   \n",
       "N_Par                                    0         1000        40801   \n",
       "Train_Time                        0.574352      0.66944      9.68545   \n",
       "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629     0.150841   \n",
       "\n",
       "                                    GPR           DGN  \n",
       "W1-95L                         0.000010      1.003425  \n",
       "W1                             0.000010      1.009751  \n",
       "W1-95R                         0.000010      1.016077  \n",
       "M-95L                          0.000000      0.007965  \n",
       "M                              0.000006      0.008116  \n",
       "M-95R                          0.000032      0.008211  \n",
       "N_Par                          0.000000  40801.000000  \n",
       "Train_Time                     0.590494      6.833113  \n",
       "Test_Time/MC-Oracle_Test_Time  0.000962      0.150610  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Prediction Quality (Updated): Train\")\n",
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) The natural Universal Benchmark: [Bishop's Mixture Density Network](https://publications.aston.ac.uk/id/eprint/373/1/NCRG_94_004.pdf)\n",
    "\n",
    "This implementation is as follows:\n",
    "- For every $x$ in the trainingdata-set we fit a GMM $\\hat{\\nu}_x$, using the [Expectation-Maximization (EM) algorithm](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm), with the same number of centers as the deep neural model in $\\mathcal{NN}_{1_{\\mathbb{R}^d},\\mathcal{D}}^{\\sigma:\\star}$ which we are evaluating.  \n",
    "- A Mixture density network is then trained to predict the infered parameters; given any $x \\in \\mathbb{R}^d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Preparing Training Outputs for MDNs using EM-Algorithm\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.29it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Prepared Training Outputs for MDNs using EM-Algorithm!\n",
      "======================================================\n",
      "Deep Feature Builder - Ready\n",
      "(0)\n",
      "=====================================================\n",
      "Training Mixture Density Network (MDN): Means: Start!\n",
      "=====================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    8.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0401 - mse: 0.0032 - mae: 0.0401 - mape: 38817964.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0400 - mse: 0.0032 - mae: 0.0400 - mape: 38702960.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0399 - mse: 0.0032 - mae: 0.0399 - mape: 38587612.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0398 - mse: 0.0032 - mae: 0.0398 - mape: 38472920.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0397 - mse: 0.0032 - mae: 0.0397 - mape: 38358172.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0396 - mse: 0.0031 - mae: 0.0396 - mape: 38247840.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0031 - mae: 0.0394 - mape: 38139744.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0393 - mse: 0.0031 - mae: 0.0393 - mape: 38033960.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0392 - mse: 0.0031 - mae: 0.0392 - mape: 37929672.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0391 - mse: 0.0031 - mae: 0.0391 - mape: 37824828.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0390 - mse: 0.0031 - mae: 0.0390 - mape: 37719704.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0389 - mse: 0.0031 - mae: 0.0389 - mape: 37614616.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0031 - mae: 0.0388 - mape: 37509192.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0387 - mse: 0.0031 - mae: 0.0387 - mape: 37403800.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0031 - mae: 0.0386 - mape: 37299088.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0030 - mae: 0.0385 - mape: 37194188.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0030 - mae: 0.0384 - mape: 37089504.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0383 - mse: 0.0030 - mae: 0.0383 - mape: 36984568.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 0.0030 - mae: 0.0382 - mape: 36879384.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0030 - mae: 0.0381 - mape: 36774008.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0380 - mse: 0.0030 - mae: 0.0380 - mape: 36668852.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0379 - mse: 0.0030 - mae: 0.0379 - mape: 36563596.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0378 - mse: 0.0030 - mae: 0.0378 - mape: 36458248.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0376 - mse: 0.0030 - mae: 0.0376 - mape: 36352840.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0375 - mse: 0.0029 - mae: 0.0375 - mape: 36247460.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0374 - mse: 0.0029 - mae: 0.0374 - mape: 36142144.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 0.0029 - mae: 0.0373 - mape: 36037736.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0372 - mse: 0.0029 - mae: 0.0372 - mape: 35933576.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0371 - mse: 0.0029 - mae: 0.0371 - mape: 35829144.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0370 - mse: 0.0029 - mae: 0.0370 - mape: 35724328.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0369 - mse: 0.0029 - mae: 0.0369 - mape: 35619456.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0368 - mse: 0.0029 - mae: 0.0368 - mape: 35514220.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0367 - mse: 0.0029 - mae: 0.0367 - mape: 35408800.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0029 - mae: 0.0366 - mape: 35303760.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0365 - mse: 0.0028 - mae: 0.0365 - mape: 35198704.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0028 - mae: 0.0364 - mape: 35093520.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0363 - mse: 0.0028 - mae: 0.0363 - mape: 34988228.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0362 - mse: 0.0028 - mae: 0.0362 - mape: 34882836.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0361 - mse: 0.0028 - mae: 0.0361 - mape: 34777556.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0028 - mae: 0.0360 - mape: 34672232.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0028 - mae: 0.0358 - mape: 34567560.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0357 - mse: 0.0028 - mae: 0.0357 - mape: 34462804.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0356 - mse: 0.0028 - mae: 0.0356 - mape: 34357604.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0355 - mse: 0.0028 - mae: 0.0355 - mape: 34252084.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0354 - mse: 0.0027 - mae: 0.0354 - mape: 34146808.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0353 - mse: 0.0027 - mae: 0.0353 - mape: 34041384.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0027 - mae: 0.0352 - mape: 33935908.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0351 - mse: 0.0027 - mae: 0.0351 - mape: 33830628.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0350 - mse: 0.0027 - mae: 0.0350 - mape: 33725628.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0027 - mae: 0.0349 - mape: 33620432.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0348 - mse: 0.0027 - mae: 0.0348 - mape: 33515168.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0027 - mae: 0.0347 - mape: 33409824.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0346 - mse: 0.0027 - mae: 0.0346 - mape: 33304442.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0345 - mse: 0.0027 - mae: 0.0345 - mape: 33199040.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0344 - mse: 0.0026 - mae: 0.0344 - mape: 33093546.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0343 - mse: 0.0026 - mae: 0.0343 - mape: 32988292.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0342 - mse: 0.0026 - mae: 0.0342 - mape: 32883146.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0026 - mae: 0.0340 - mape: 32777636.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0339 - mse: 0.0026 - mae: 0.0339 - mape: 32672156.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0338 - mse: 0.0026 - mae: 0.0338 - mape: 32566772.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0337 - mse: 0.0026 - mae: 0.0337 - mape: 32461172.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0336 - mse: 0.0026 - mae: 0.0336 - mape: 32355936.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0335 - mse: 0.0026 - mae: 0.0335 - mape: 32250564.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0334 - mse: 0.0026 - mae: 0.0334 - mape: 32144972.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0025 - mae: 0.0333 - mape: 32039460.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0332 - mse: 0.0025 - mae: 0.0332 - mape: 31933836.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0331 - mse: 0.0025 - mae: 0.0331 - mape: 31828454.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0025 - mae: 0.0330 - mape: 31722960.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0329 - mse: 0.0025 - mae: 0.0329 - mape: 31617334.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0025 - mae: 0.0328 - mape: 31511642.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0025 - mae: 0.0327 - mape: 31406394.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0025 - mae: 0.0326 - mape: 31300922.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0325 - mse: 0.0025 - mae: 0.0325 - mape: 31195130.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0025 - mae: 0.0323 - mape: 31089338.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0025 - mae: 0.0322 - mape: 30983926.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0321 - mse: 0.0024 - mae: 0.0321 - mape: 30878304.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0024 - mae: 0.0320 - mape: 30772502.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0024 - mae: 0.0319 - mape: 30666988.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0024 - mae: 0.0318 - mape: 30561238.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0317 - mse: 0.0024 - mae: 0.0317 - mape: 30455372.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0316 - mse: 0.0024 - mae: 0.0316 - mape: 30349702.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0024 - mae: 0.0315 - mape: 30243884.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0314 - mse: 0.0024 - mae: 0.0314 - mape: 30138336.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0313 - mse: 0.0024 - mae: 0.0313 - mape: 30032460.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0024 - mae: 0.0312 - mape: 29926588.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0024 - mae: 0.0311 - mape: 29820774.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0310 - mse: 0.0024 - mae: 0.0310 - mape: 29714828.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0309 - mse: 0.0023 - mae: 0.0309 - mape: 29608940.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0023 - mae: 0.0308 - mape: 29503114.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0306 - mse: 0.0023 - mae: 0.0306 - mape: 29397264.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0305 - mse: 0.0023 - mae: 0.0305 - mape: 29291612.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0304 - mse: 0.0023 - mae: 0.0304 - mape: 29185786.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0023 - mae: 0.0303 - mape: 29079578.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0302 - mse: 0.0023 - mae: 0.0302 - mape: 28973492.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0301 - mse: 0.0023 - mae: 0.0301 - mape: 28867658.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0023 - mae: 0.0300 - mape: 28761492.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0299 - mse: 0.0023 - mae: 0.0299 - mape: 28655424.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0298 - mse: 0.0023 - mae: 0.0298 - mape: 28549446.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0023 - mae: 0.0297 - mape: 28443380.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0022 - mae: 0.0296 - mape: 28337238.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0022 - mae: 0.0295 - mape: 28231068.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0294 - mse: 0.0022 - mae: 0.0294 - mape: 28124938.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0293 - mse: 0.0022 - mae: 0.0293 - mape: 28019270.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0292 - mse: 0.0022 - mae: 0.0292 - mape: 27913062.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0291 - mse: 0.0022 - mae: 0.0291 - mape: 27813910.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0022 - mae: 0.0290 - mape: 27719962.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 0.0022 - mae: 0.0289 - mape: 27626106.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0288 - mse: 0.0022 - mae: 0.0288 - mape: 27529722.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0287 - mse: 0.0022 - mae: 0.0287 - mape: 27431210.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0286 - mse: 0.0022 - mae: 0.0286 - mape: 27330768.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 0.0022 - mae: 0.0285 - mape: 27228300.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0284 - mse: 0.0021 - mae: 0.0284 - mape: 27124928.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0282 - mse: 0.0021 - mae: 0.0282 - mape: 27022652.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0021 - mae: 0.0281 - mape: 26922784.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0280 - mse: 0.0021 - mae: 0.0280 - mape: 26826454.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0279 - mse: 0.0021 - mae: 0.0279 - mape: 26730198.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0021 - mae: 0.0278 - mape: 26633322.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0021 - mae: 0.0278 - mape: 26535394.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0276 - mse: 0.0021 - mae: 0.0276 - mape: 26436340.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0275 - mse: 0.0021 - mae: 0.0275 - mape: 26337620.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0274 - mse: 0.0021 - mae: 0.0274 - mape: 26237908.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0273 - mse: 0.0021 - mae: 0.0273 - mape: 26137062.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0272 - mse: 0.0021 - mae: 0.0272 - mape: 26039044.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0272 - mse: 0.0020 - mae: 0.0272 - mape: 25946102.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0271 - mse: 0.0020 - mae: 0.0271 - mape: 25853786.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0020 - mae: 0.0270 - mape: 25762192.0000\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0269 - mse: 0.0020 - mae: 0.0269 - mape: 25671510.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0020 - mae: 0.0268 - mape: 25581152.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0267 - mse: 0.0020 - mae: 0.0267 - mape: 25489606.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0266 - mse: 0.0020 - mae: 0.0266 - mape: 25398128.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0020 - mae: 0.0265 - mape: 25308304.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0264 - mse: 0.0020 - mae: 0.0264 - mape: 25220286.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0020 - mae: 0.0263 - mape: 25131642.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0262 - mse: 0.0020 - mae: 0.0262 - mape: 25042340.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0261 - mse: 0.0020 - mae: 0.0261 - mape: 24952288.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0020 - mae: 0.0260 - mape: 24861994.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0019 - mae: 0.0260 - mape: 24771562.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0259 - mse: 0.0019 - mae: 0.0259 - mape: 24680278.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0258 - mse: 0.0019 - mae: 0.0258 - mape: 24589484.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0257 - mse: 0.0019 - mae: 0.0257 - mape: 24498130.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0256 - mse: 0.0019 - mae: 0.0256 - mape: 24406756.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0255 - mse: 0.0019 - mae: 0.0255 - mape: 24315856.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0019 - mae: 0.0254 - mape: 24224896.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0253 - mse: 0.0019 - mae: 0.0253 - mape: 24134180.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0019 - mae: 0.0252 - mape: 24043634.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0251 - mse: 0.0019 - mae: 0.0251 - mape: 23954006.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0250 - mse: 0.0019 - mae: 0.0250 - mape: 23864138.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0249 - mse: 0.0019 - mae: 0.0249 - mape: 23774280.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0248 - mse: 0.0019 - mae: 0.0248 - mape: 23683542.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0248 - mse: 0.0019 - mae: 0.0248 - mape: 23592566.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0247 - mse: 0.0018 - mae: 0.0247 - mape: 23501900.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0246 - mse: 0.0018 - mae: 0.0246 - mape: 23411936.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0018 - mae: 0.0245 - mape: 23321884.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0244 - mse: 0.0018 - mae: 0.0244 - mape: 23231884.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0243 - mse: 0.0018 - mae: 0.0243 - mape: 23141426.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0242 - mse: 0.0018 - mae: 0.0242 - mape: 23051108.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0018 - mae: 0.0241 - mape: 22960932.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0240 - mse: 0.0018 - mae: 0.0240 - mape: 22871932.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0239 - mse: 0.0018 - mae: 0.0239 - mape: 22785262.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0018 - mae: 0.0238 - mape: 22699224.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0238 - mse: 0.0018 - mae: 0.0238 - mape: 22613184.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0237 - mse: 0.0018 - mae: 0.0237 - mape: 22526596.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0236 - mse: 0.0018 - mae: 0.0236 - mape: 22440174.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0235 - mse: 0.0018 - mae: 0.0235 - mape: 22353430.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0017 - mae: 0.0234 - mape: 22267080.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0017 - mae: 0.0233 - mape: 22180656.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0017 - mae: 0.0232 - mape: 22094576.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0231 - mse: 0.0017 - mae: 0.0231 - mape: 22008252.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0017 - mae: 0.0231 - mape: 21921568.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0017 - mae: 0.0230 - mape: 21835264.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0017 - mae: 0.0229 - mape: 21748742.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0228 - mse: 0.0017 - mae: 0.0228 - mape: 21662458.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0227 - mse: 0.0017 - mae: 0.0227 - mape: 21575950.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0017 - mae: 0.0226 - mape: 21489228.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0017 - mae: 0.0225 - mape: 21402752.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0017 - mae: 0.0224 - mape: 21317220.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0224 - mse: 0.0017 - mae: 0.0224 - mape: 21232032.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0223 - mse: 0.0017 - mae: 0.0223 - mape: 21146022.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0222 - mse: 0.0017 - mae: 0.0222 - mape: 21059782.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0016 - mae: 0.0221 - mape: 20974052.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0220 - mse: 0.0016 - mae: 0.0220 - mape: 20888044.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0016 - mae: 0.0219 - mape: 20801708.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0016 - mae: 0.0218 - mape: 20715174.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0016 - mae: 0.0217 - mape: 20630060.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0016 - mae: 0.0217 - mape: 20559898.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0016 - mae: 0.0216 - mape: 20493392.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0215 - mse: 0.0016 - mae: 0.0215 - mape: 20423174.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0016 - mae: 0.0215 - mape: 20353126.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0214 - mse: 0.0016 - mae: 0.0214 - mape: 20282560.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0016 - mae: 0.0213 - mape: 20209122.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0016 - mae: 0.0212 - mape: 20134014.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0016 - mae: 0.0211 - mape: 20056382.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0016 - mae: 0.0211 - mape: 19977548.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0210 - mse: 0.0015 - mae: 0.0210 - mape: 19899798.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0209 - mse: 0.0015 - mae: 0.0209 - mape: 19826686.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0015 - mae: 0.0208 - mape: 19758846.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0208 - mse: 0.0015 - mae: 0.0208 - mape: 19691206.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0015 - mae: 0.0207 - mape: 19622290.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0206 - mse: 0.0015 - mae: 0.0206 - mape: 19550820.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0206 - mse: 0.0015 - mae: 0.0206 - mape: 19477636.0000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 979us/step\n",
      "===================================================\n",
      "Training Mixture Density Network (MDN): Means: END!\n",
      "===================================================\n",
      "(1)\n",
      "===================================================\n",
      "Training Mixture Density Network (MDN): SD: Start!\n",
      "===================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9828 - mse: 0.9679 - mae: 0.9828 - mape: 98277712.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9827 - mse: 0.9677 - mae: 0.9827 - mape: 98266328.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9826 - mse: 0.9675 - mae: 0.9826 - mape: 98254912.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9825 - mse: 0.9672 - mae: 0.9825 - mape: 98243480.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9823 - mse: 0.9670 - mae: 0.9823 - mape: 98232048.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9822 - mse: 0.9668 - mae: 0.9822 - mape: 98220600.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9821 - mse: 0.9666 - mae: 0.9821 - mape: 98209160.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9820 - mse: 0.9663 - mae: 0.9820 - mape: 98197712.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9819 - mse: 0.9661 - mae: 0.9819 - mape: 98186264.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9818 - mse: 0.9659 - mae: 0.9818 - mape: 98174808.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9817 - mse: 0.9657 - mae: 0.9817 - mape: 98163360.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9815 - mse: 0.9654 - mae: 0.9815 - mape: 98151904.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9814 - mse: 0.9652 - mae: 0.9814 - mape: 98140456.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9813 - mse: 0.9650 - mae: 0.9813 - mape: 98129000.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9812 - mse: 0.9648 - mae: 0.9812 - mape: 98117552.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9811 - mse: 0.9645 - mae: 0.9811 - mape: 98106096.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9810 - mse: 0.9643 - mae: 0.9810 - mape: 98094648.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9809 - mse: 0.9641 - mae: 0.9809 - mape: 98083184.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9807 - mse: 0.9639 - mae: 0.9807 - mape: 98071736.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9806 - mse: 0.9636 - mae: 0.9806 - mape: 98060288.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9805 - mse: 0.9634 - mae: 0.9805 - mape: 98048840.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9804 - mse: 0.9632 - mae: 0.9804 - mape: 98037392.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9803 - mse: 0.9630 - mae: 0.9803 - mape: 98025936.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9802 - mse: 0.9627 - mae: 0.9802 - mape: 98014480.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9801 - mse: 0.9625 - mae: 0.9801 - mape: 98003032.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9799 - mse: 0.9623 - mae: 0.9799 - mape: 97991584.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9798 - mse: 0.9621 - mae: 0.9798 - mape: 97980128.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9797 - mse: 0.9618 - mae: 0.9797 - mape: 97968680.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9796 - mse: 0.9616 - mae: 0.9796 - mape: 97957232.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9795 - mse: 0.9614 - mae: 0.9795 - mape: 97945792.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9794 - mse: 0.9611 - mae: 0.9794 - mape: 97934336.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9793 - mse: 0.9609 - mae: 0.9793 - mape: 97922888.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9791 - mse: 0.9607 - mae: 0.9791 - mape: 97911440.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9790 - mse: 0.9605 - mae: 0.9790 - mape: 97899984.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9789 - mse: 0.9602 - mae: 0.9789 - mape: 97888544.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9788 - mse: 0.9600 - mae: 0.9788 - mape: 97877096.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9787 - mse: 0.9598 - mae: 0.9787 - mape: 97865640.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9786 - mse: 0.9596 - mae: 0.9786 - mape: 97854200.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9785 - mse: 0.9593 - mae: 0.9785 - mape: 97842752.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9783 - mse: 0.9591 - mae: 0.9783 - mape: 97831296.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9782 - mse: 0.9589 - mae: 0.9782 - mape: 97819856.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9781 - mse: 0.9587 - mae: 0.9781 - mape: 97808400.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9780 - mse: 0.9585 - mae: 0.9780 - mape: 97796952.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9779 - mse: 0.9582 - mae: 0.9779 - mape: 97785504.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9778 - mse: 0.9580 - mae: 0.9778 - mape: 97774048.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9777 - mse: 0.9578 - mae: 0.9777 - mape: 97762600.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9775 - mse: 0.9576 - mae: 0.9775 - mape: 97751152.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9774 - mse: 0.9573 - mae: 0.9774 - mape: 97739696.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9773 - mse: 0.9571 - mae: 0.9773 - mape: 97728240.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9772 - mse: 0.9569 - mae: 0.9772 - mape: 97716784.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9771 - mse: 0.9567 - mae: 0.9771 - mape: 97705328.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9770 - mse: 0.9564 - mae: 0.9770 - mape: 97693872.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9768 - mse: 0.9562 - mae: 0.9768 - mape: 97682416.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9767 - mse: 0.9560 - mae: 0.9767 - mape: 97670960.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9766 - mse: 0.9558 - mae: 0.9766 - mape: 97659504.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9765 - mse: 0.9555 - mae: 0.9765 - mape: 97648040.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9764 - mse: 0.9553 - mae: 0.9764 - mape: 97636584.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9763 - mse: 0.9551 - mae: 0.9763 - mape: 97625112.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9762 - mse: 0.9549 - mae: 0.9762 - mape: 97613648.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9760 - mse: 0.9546 - mae: 0.9760 - mape: 97602192.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9759 - mse: 0.9544 - mae: 0.9759 - mape: 97590720.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9758 - mse: 0.9542 - mae: 0.9758 - mape: 97579248.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9757 - mse: 0.9540 - mae: 0.9757 - mape: 97567784.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9756 - mse: 0.9537 - mae: 0.9756 - mape: 97556304.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9755 - mse: 0.9535 - mae: 0.9755 - mape: 97544832.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9754 - mse: 0.9533 - mae: 0.9754 - mape: 97533360.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9752 - mse: 0.9531 - mae: 0.9752 - mape: 97521880.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9751 - mse: 0.9528 - mae: 0.9751 - mape: 97510400.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9750 - mse: 0.9526 - mae: 0.9750 - mape: 97498928.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9749 - mse: 0.9524 - mae: 0.9749 - mape: 97487440.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9748 - mse: 0.9522 - mae: 0.9748 - mape: 97475952.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9747 - mse: 0.9519 - mae: 0.9747 - mape: 97464472.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9746 - mse: 0.9517 - mae: 0.9746 - mape: 97452976.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9744 - mse: 0.9515 - mae: 0.9744 - mape: 97441488.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9743 - mse: 0.9513 - mae: 0.9743 - mape: 97430000.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9742 - mse: 0.9510 - mae: 0.9742 - mape: 97418504.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9741 - mse: 0.9508 - mae: 0.9741 - mape: 97407008.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9740 - mse: 0.9506 - mae: 0.9740 - mape: 97395504.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9739 - mse: 0.9504 - mae: 0.9739 - mape: 97384000.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9738 - mse: 0.9501 - mae: 0.9738 - mape: 97372496.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9736 - mse: 0.9499 - mae: 0.9736 - mape: 97360984.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9735 - mse: 0.9497 - mae: 0.9735 - mape: 97349480.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9734 - mse: 0.9495 - mae: 0.9734 - mape: 97337960.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9733 - mse: 0.9492 - mae: 0.9733 - mape: 97326448.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9732 - mse: 0.9490 - mae: 0.9732 - mape: 97314920.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9731 - mse: 0.9488 - mae: 0.9731 - mape: 97303400.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9729 - mse: 0.9486 - mae: 0.9729 - mape: 97291880.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9728 - mse: 0.9483 - mae: 0.9728 - mape: 97280344.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9727 - mse: 0.9481 - mae: 0.9727 - mape: 97268816.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9726 - mse: 0.9479 - mae: 0.9726 - mape: 97257280.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9725 - mse: 0.9477 - mae: 0.9725 - mape: 97245744.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9724 - mse: 0.9474 - mae: 0.9724 - mape: 97234200.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9723 - mse: 0.9472 - mae: 0.9723 - mape: 97222656.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9721 - mse: 0.9470 - mae: 0.9721 - mape: 97211112.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9720 - mse: 0.9468 - mae: 0.9720 - mape: 97199568.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9719 - mse: 0.9465 - mae: 0.9719 - mape: 97188008.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9718 - mse: 0.9463 - mae: 0.9718 - mape: 97176448.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9717 - mse: 0.9461 - mae: 0.9717 - mape: 97164888.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9716 - mse: 0.9459 - mae: 0.9716 - mape: 97153328.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9714 - mse: 0.9456 - mae: 0.9714 - mape: 97141752.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9713 - mse: 0.9454 - mae: 0.9713 - mape: 97130192.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9712 - mse: 0.9452 - mae: 0.9712 - mape: 97118608.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9711 - mse: 0.9450 - mae: 0.9711 - mape: 97107032.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9710 - mse: 0.9447 - mae: 0.9710 - mape: 97095440.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9709 - mse: 0.9445 - mae: 0.9709 - mape: 97083856.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9707 - mse: 0.9443 - mae: 0.9707 - mape: 97072272.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9706 - mse: 0.9441 - mae: 0.9706 - mape: 97060672.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9705 - mse: 0.9438 - mae: 0.9705 - mape: 97049072.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9704 - mse: 0.9436 - mae: 0.9704 - mape: 97037464.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9703 - mse: 0.9434 - mae: 0.9703 - mape: 97025856.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9702 - mse: 0.9432 - mae: 0.9702 - mape: 97014248.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9701 - mse: 0.9429 - mae: 0.9701 - mape: 97002640.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9699 - mse: 0.9427 - mae: 0.9699 - mape: 96991016.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9698 - mse: 0.9425 - mae: 0.9698 - mape: 96979392.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9697 - mse: 0.9423 - mae: 0.9697 - mape: 96967768.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9696 - mse: 0.9420 - mae: 0.9696 - mape: 96956136.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9695 - mse: 0.9418 - mae: 0.9695 - mape: 96944496.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9694 - mse: 0.9416 - mae: 0.9694 - mape: 96932856.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9692 - mse: 0.9413 - mae: 0.9692 - mape: 96921216.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9691 - mse: 0.9411 - mae: 0.9691 - mape: 96909560.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9690 - mse: 0.9409 - mae: 0.9690 - mape: 96897904.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9689 - mse: 0.9407 - mae: 0.9689 - mape: 96886240.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9688 - mse: 0.9404 - mae: 0.9688 - mape: 96874576.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9687 - mse: 0.9402 - mae: 0.9687 - mape: 96862912.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9685 - mse: 0.9400 - mae: 0.9685 - mape: 96851240.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9684 - mse: 0.9398 - mae: 0.9684 - mape: 96839552.0000\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9683 - mse: 0.9395 - mae: 0.9683 - mape: 96827880.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9682 - mse: 0.9393 - mae: 0.9682 - mape: 96816184.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9681 - mse: 0.9391 - mae: 0.9681 - mape: 96804488.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9680 - mse: 0.9389 - mae: 0.9680 - mape: 96792792.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9678 - mse: 0.9386 - mae: 0.9678 - mape: 96781080.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9677 - mse: 0.9384 - mae: 0.9677 - mape: 96769384.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9676 - mse: 0.9382 - mae: 0.9676 - mape: 96757672.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9675 - mse: 0.9379 - mae: 0.9675 - mape: 96745952.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9674 - mse: 0.9377 - mae: 0.9674 - mape: 96734224.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9673 - mse: 0.9375 - mae: 0.9673 - mape: 96722496.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9671 - mse: 0.9373 - mae: 0.9671 - mape: 96710768.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9670 - mse: 0.9370 - mae: 0.9670 - mape: 96699024.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9669 - mse: 0.9368 - mae: 0.9669 - mape: 96687280.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9668 - mse: 0.9366 - mae: 0.9668 - mape: 96675520.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9667 - mse: 0.9363 - mae: 0.9667 - mape: 96663768.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9665 - mse: 0.9361 - mae: 0.9665 - mape: 96652008.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9664 - mse: 0.9359 - mae: 0.9664 - mape: 96640240.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9663 - mse: 0.9357 - mae: 0.9663 - mape: 96628464.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9662 - mse: 0.9354 - mae: 0.9662 - mape: 96616688.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9661 - mse: 0.9352 - mae: 0.9661 - mape: 96604904.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9660 - mse: 0.9350 - mae: 0.9660 - mape: 96593112.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9658 - mse: 0.9348 - mae: 0.9658 - mape: 96581320.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9657 - mse: 0.9345 - mae: 0.9657 - mape: 96569520.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9656 - mse: 0.9343 - mae: 0.9656 - mape: 96557712.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9655 - mse: 0.9341 - mae: 0.9655 - mape: 96545896.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9654 - mse: 0.9338 - mae: 0.9654 - mape: 96534072.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9652 - mse: 0.9336 - mae: 0.9652 - mape: 96522256.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9651 - mse: 0.9334 - mae: 0.9651 - mape: 96510424.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9650 - mse: 0.9332 - mae: 0.9650 - mape: 96498584.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9649 - mse: 0.9329 - mae: 0.9649 - mape: 96486736.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9648 - mse: 0.9327 - mae: 0.9648 - mape: 96474896.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9647 - mse: 0.9325 - mae: 0.9647 - mape: 96463040.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9645 - mse: 0.9322 - mae: 0.9645 - mape: 96451176.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9644 - mse: 0.9320 - mae: 0.9644 - mape: 96439304.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9643 - mse: 0.9318 - mae: 0.9643 - mape: 96427432.000 - 0s 3ms/step - loss: 0.9643 - mse: 0.9318 - mae: 0.9643 - mape: 96427432.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9642 - mse: 0.9315 - mae: 0.9642 - mape: 96415552.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9641 - mse: 0.9313 - mae: 0.9641 - mape: 96403664.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9639 - mse: 0.9311 - mae: 0.9639 - mape: 96391760.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9638 - mse: 0.9309 - mae: 0.9638 - mape: 96379864.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9637 - mse: 0.9306 - mae: 0.9637 - mape: 96367952.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9636 - mse: 0.9304 - mae: 0.9636 - mape: 96356040.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9635 - mse: 0.9302 - mae: 0.9635 - mape: 96344120.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9633 - mse: 0.9299 - mae: 0.9633 - mape: 96332192.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9632 - mse: 0.9297 - mae: 0.9632 - mape: 96320256.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9631 - mse: 0.9295 - mae: 0.9631 - mape: 96308320.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9630 - mse: 0.9292 - mae: 0.9630 - mape: 96296368.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9629 - mse: 0.9290 - mae: 0.9629 - mape: 96284416.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9627 - mse: 0.9288 - mae: 0.9627 - mape: 96272456.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9626 - mse: 0.9286 - mae: 0.9626 - mape: 96260480.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9625 - mse: 0.9283 - mae: 0.9625 - mape: 96248512.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9624 - mse: 0.9281 - mae: 0.9624 - mape: 96236528.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9623 - mse: 0.9279 - mae: 0.9623 - mape: 96224536.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9622 - mse: 0.9276 - mae: 0.9622 - mape: 96212544.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9620 - mse: 0.9274 - mae: 0.9620 - mape: 96200536.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9619 - mse: 0.9272 - mae: 0.9619 - mape: 96188528.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9618 - mse: 0.9269 - mae: 0.9618 - mape: 96176496.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9617 - mse: 0.9267 - mae: 0.9617 - mape: 96164480.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9615 - mse: 0.9265 - mae: 0.9615 - mape: 96152440.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9614 - mse: 0.9262 - mae: 0.9614 - mape: 96140400.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9613 - mse: 0.9260 - mae: 0.9613 - mape: 96128360.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9612 - mse: 0.9258 - mae: 0.9612 - mape: 96116304.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9611 - mse: 0.9255 - mae: 0.9611 - mape: 96104240.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9609 - mse: 0.9253 - mae: 0.9609 - mape: 96092168.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9608 - mse: 0.9251 - mae: 0.9608 - mape: 96080096.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9607 - mse: 0.9248 - mae: 0.9607 - mape: 96068008.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9606 - mse: 0.9246 - mae: 0.9606 - mape: 96055912.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9605 - mse: 0.9244 - mae: 0.9605 - mape: 96043816.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9603 - mse: 0.9241 - mae: 0.9603 - mape: 96031704.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9602 - mse: 0.9239 - mae: 0.9602 - mape: 96019584.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9601 - mse: 0.9237 - mae: 0.9601 - mape: 96007464.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9600 - mse: 0.9234 - mae: 0.9600 - mape: 95995328.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9599 - mse: 0.9232 - mae: 0.9599 - mape: 95983192.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9597 - mse: 0.9230 - mae: 0.9597 - mape: 95971040.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9596 - mse: 0.9227 - mae: 0.9596 - mape: 95958880.0000\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7bc0fe5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 951us/step\n",
      "1/1 [==============================] - 0s 949us/step\n",
      "=================================================\n",
      "Training Mixture Density Network (MDN): SD: END!\n",
      "=================================================\n",
      "(2)\n",
      "====================================================================\n",
      "Training Mixture Density Network (MDN): Mixture Coefficients: Start!\n",
      "====================================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0800 - accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0328 - accuracy: 0.4000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9885 - accuracy: 0.9000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9471 - accuracy: 0.9000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9068 - accuracy: 0.9000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8684 - accuracy: 0.9000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8303 - accuracy: 0.9000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7932 - accuracy: 0.9000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7557 - accuracy: 0.9000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7167 - accuracy: 0.9000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6766 - accuracy: 0.9000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6352 - accuracy: 0.9000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5924 - accuracy: 0.9000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5480 - accuracy: 0.9000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5018 - accuracy: 0.9000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4540 - accuracy: 0.9000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4047 - accuracy: 0.9000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3543 - accuracy: 0.9000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3031 - accuracy: 0.9000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2514 - accuracy: 0.9000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1996 - accuracy: 0.9000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1479 - accuracy: 0.9000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0967 - accuracy: 0.9000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0465 - accuracy: 0.9000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9976 - accuracy: 0.9000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9504 - accuracy: 0.9000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9052 - accuracy: 0.9000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8623 - accuracy: 0.9000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8218 - accuracy: 0.9000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7839 - accuracy: 0.9000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7488 - accuracy: 0.9000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.9000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.9000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.9000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.9000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6135 - accuracy: 0.9000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.9000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5760 - accuracy: 0.9000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.9000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.9000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.9000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.9000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5111 - accuracy: 0.9000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.9000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.9000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.9000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.9000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.9000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.9000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.9000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.9000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.9000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.9000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.9000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.9000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.9000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.9000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.9000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4082 - accuracy: 0.9000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.9000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.9000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.9000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.9000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.9000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.9000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.9000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.9000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.9000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.9000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.9000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.9000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.9000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.9000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.9000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.9000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.9000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.9000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.9000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.9000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.9000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.9000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3581 - accuracy: 0.9000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.9000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.9000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3555 - accuracy: 0.9000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.9000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3538 - accuracy: 0.9000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.9000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.9000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.9000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.9000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.9000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.9000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.9000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.9000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.9000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.9000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.9000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3464 - accuracy: 0.9000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.9000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.9000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3452 - accuracy: 0.9000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.9000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.9000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.9000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.9000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.9000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.9000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3427 - accuracy: 0.9000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.9000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.9000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3418 - accuracy: 0.9000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.9000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.9000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.9000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.9000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3405 - accuracy: 0.9000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.9000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3400 - accuracy: 0.9000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.9000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.9000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.9000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.9000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.9000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.9000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3386 - accuracy: 0.9000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.9000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.9000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.9000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.9000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.9000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.9000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.9000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.9000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.9000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.9000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.9000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.9000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.9000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.9000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.9000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.9000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.9000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.9000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.9000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.9000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.9000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.9000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.9000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.9000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.9000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.9000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.9000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.9000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.9000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.9000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.9000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.9000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.9000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.9000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.9000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.9000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.9000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.9000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3332 - accuracy: 0.9000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.9000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.9000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.9000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.9000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.9000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.9000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.9000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.9000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.9000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.9000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.9000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.9000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.9000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.9000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.9000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.9000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.9000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3314 - accuracy: 0.9000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.9000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.9000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.9000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.9000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.9000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.9000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.9000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.9000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.9000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.9000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.9000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.9000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.9000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.9000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.9000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3300 - accuracy: 0.9000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe794797830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 780us/step\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "Training Mixture Density Network (MDN): Mixture Coefficients: END!\n",
      "==================================================================\n",
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 298.38it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 160.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------#\n",
      " Get Test Error(s)\n",
      "#--------------------#\n",
      "#---------------------#\n",
      " Get Test Error(s): END\n",
      "#---------------------#\n",
      "#---------------------------#\n",
      " Get Training Error(s): Begin\n",
      "#---------------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------------#\n",
      " Get Testing Error(s): Begin\n",
      "#--------------------------#\n",
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n",
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "Updated DataFrame\n",
      "-------------------------------------------------\n",
      "Train\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000            -   \n",
      "W1                             5.252696e-07   0.000000            -   \n",
      "W1-95R                         5.252696e-07   0.000000            -   \n",
      "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
      "M                              5.834706e-05   0.000000   1.1343e-05   \n",
      "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
      "N_Par                          4.220800e+04   0.000000           20   \n",
      "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
      "\n",
      "                                    KRidge         GBRF          DNN  \\\n",
      "W1-95L                                   -            -            -   \n",
      "W1                                       -            -            -   \n",
      "W1-95R                                   -            -            -   \n",
      "M-95L                           5.9994e-05  6.30167e-06  0.000196334   \n",
      "M                              7.12614e-05   1.1343e-05  0.000203166   \n",
      "M-95R                          8.80365e-05  2.14257e-05  0.000240146   \n",
      "N_Par                                    0         1000        40801   \n",
      "Train_Time                        0.574352      0.66944      9.68545   \n",
      "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629     0.150841   \n",
      "\n",
      "                                    GPR           DGN  \n",
      "W1-95L                         0.000010      1.003425  \n",
      "W1                             0.000010      1.009751  \n",
      "W1-95R                         0.000010      1.016077  \n",
      "M-95L                          0.000000      0.007965  \n",
      "M                              0.000006      0.008116  \n",
      "M-95R                          0.000032      0.008211  \n",
      "N_Par                          0.000000  40801.000000  \n",
      "Train_Time                     0.590494      6.833113  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000962      0.150610  \n",
      "-------------------------------------------------\n",
      "Test\n",
      "                                        DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000  3.971106e-11   \n",
      "W1                             5.252696e-07   0.000000  3.971106e-11   \n",
      "W1-95R                         5.252696e-07   0.000000  3.971106e-11   \n",
      "M-95L                          5.834706e-05   0.000000  6.301671e-06   \n",
      "M                              5.834706e-05   0.000000  6.301671e-06   \n",
      "M-95R                          5.834706e-05   0.000000  6.301671e-06   \n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
      "Train_Time                     1.115808e+01   1.814789  1.620119e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000  2.169400e-04   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \\\n",
      "W1-95L                         3.599282e-09  3.971106e-11  3.854703e-08   \n",
      "W1                             4.145635e-09  3.971106e-11  4.132317e-08   \n",
      "W1-95R                         4.691989e-09  3.971106e-11  4.409930e-08   \n",
      "M-95L                          5.999402e-05  6.301671e-06  1.963340e-04   \n",
      "M                              6.424605e-05  6.301671e-06  2.031662e-04   \n",
      "M-95R                          6.849809e-05  6.301671e-06  2.099983e-04   \n",
      "N_Par                          0.000000e+00  1.000000e+03  4.080100e+04   \n",
      "Train_Time                     5.743520e-01  6.694398e-01  9.685448e+00   \n",
      "Test_Time/MC-Oracle_Test_Time  8.498361e-04  2.446292e-03  1.508413e-01   \n",
      "\n",
      "                                    GPR           DGN            MDN  \n",
      "W1-95L                         0.000009      1.003425       1.020663  \n",
      "W1                             0.000010      1.009751       1.038546  \n",
      "W1-95R                         0.000010      1.016077       1.056430  \n",
      "M-95L                          0.000000      0.007883       0.028093  \n",
      "M                              0.000000      0.007884       0.047301  \n",
      "M-95R                          0.000000      0.007885       0.066510  \n",
      "N_Par                          0.000000  40801.000000  126624.000000  \n",
      "Train_Time                     0.590494      6.833113       0.230019  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000962      0.150610      72.465969  \n",
      "-------------------------------------------------\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000            -   \n",
      "W1                             5.252696e-07   0.000000            -   \n",
      "W1-95R                         5.252696e-07   0.000000            -   \n",
      "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
      "M                              5.834706e-05   0.000000   1.1343e-05   \n",
      "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
      "N_Par                          4.220800e+04   0.000000           20   \n",
      "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
      "\n",
      "                                    KRidge         GBRF          DNN  \\\n",
      "W1-95L                                   -            -            -   \n",
      "W1                                       -            -            -   \n",
      "W1-95R                                   -            -            -   \n",
      "M-95L                           5.9994e-05  6.30167e-06  0.000196334   \n",
      "M                              7.12614e-05   1.1343e-05  0.000203166   \n",
      "M-95R                          8.80365e-05  2.14257e-05  0.000240146   \n",
      "N_Par                                    0         1000        40801   \n",
      "Train_Time                        0.574352      0.66944      9.68545   \n",
      "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629     0.150841   \n",
      "\n",
      "                                    GPR           DGN            MDN  \n",
      "W1-95L                         0.000010      1.003425       1.020663  \n",
      "W1                             0.000010      1.009751       1.038546  \n",
      "W1-95R                         0.000010      1.016077       1.056430  \n",
      "M-95L                          0.000000      0.007965       0.028093  \n",
      "M                              0.000006      0.008116       0.047301  \n",
      "M-95R                          0.000032      0.008211       0.066510  \n",
      "N_Par                          0.000000  40801.000000  126624.000000  \n",
      "Train_Time                     0.590494      6.833113       0.230019  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000962      0.150610      72.465969  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "Have a jolly old day!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if output_dim == 1:\n",
    "    # %run Mixture_Density_Network.ipynb\n",
    "    exec(open('Mixture_Density_Network.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Final Outputs\n",
    "Now we piece together all the numerical experiments and report a nice summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prasing Quality Metric Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalizing Saving\n",
    "**Note:** *We do it in two steps since the grid sometimes does not want to write nicely...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write Performance Metrics\n",
    "### Incase caption breaks\n",
    "Summary_pred_Qual_models.to_latex((results_tables_path+\"/Final_Results/\"+\"Performance_metrics_Problem_Type_\"+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS.tex\"),\n",
    "                                 float_format=\"{:0.3g}\".format)\n",
    "text_file = open((results_tables_path+\"/Final_Results/\"+\"ZZZ_CAPTION_Performance_metrics_Problem_Type_\"+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS___CAPTION.tex\"), \"w\")\n",
    "text_file.write(\"Quality Metrics; d:\"+str(problem_dim)+\", D:\"+str(output_dim)+\", Depth:\"+str(Depth_Bayesian_DNN)+\", Width:\"+str(width)+\", Dropout rate:\"+str(Dropout_rate)+\".\")\n",
    "text_file.close()\n",
    "\n",
    "\n",
    "### Incase caption does not break\n",
    "Summary_pred_Qual_models.to_latex((results_tables_path+\"/Final_Results/\"+\"Performance_metrics_Problem_Type_\"+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS.tex\"),\n",
    "                                 caption=(\"Quality Metrics; d:\"+str(problem_dim)+\", D:\"+str(output_dim)+\", Depth:\"+str(Depth_Bayesian_DNN)+\", Width:\"+str(width)+\", Dropout rate:\"+str(Dropout_rate)+\".\"),\n",
    "                                 float_format=\"{:0.3g}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Terminal Runner(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Predictive Quality:\n",
      "===================\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                         5.252696e-07   0.000000            -   \n",
      "W1                             5.252696e-07   0.000000            -   \n",
      "W1-95R                         5.252696e-07   0.000000            -   \n",
      "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
      "M                              5.834706e-05   0.000000   1.1343e-05   \n",
      "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
      "N_Par                          4.220800e+04   0.000000           20   \n",
      "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
      "\n",
      "                                    KRidge         GBRF          DNN  \\\n",
      "W1-95L                                   -            -            -   \n",
      "W1                                       -            -            -   \n",
      "W1-95R                                   -            -            -   \n",
      "M-95L                           5.9994e-05  6.30167e-06  0.000196334   \n",
      "M                              7.12614e-05   1.1343e-05  0.000203166   \n",
      "M-95R                          8.80365e-05  2.14257e-05  0.000240146   \n",
      "N_Par                                    0         1000        40801   \n",
      "Train_Time                        0.574352      0.66944      9.68545   \n",
      "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629     0.150841   \n",
      "\n",
      "                                    GPR           DGN            MDN  \n",
      "W1-95L                         0.000010      1.003425       1.020663  \n",
      "W1                             0.000010      1.009751       1.038546  \n",
      "W1-95R                         0.000010      1.016077       1.056430  \n",
      "M-95L                          0.000000      0.007965       0.028093  \n",
      "M                              0.000006      0.008116       0.047301  \n",
      "M-95R                          0.000032      0.008211       0.066510  \n",
      "N_Par                          0.000000  40801.000000  126624.000000  \n",
      "Train_Time                     0.590494      6.833113       0.230019  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000962      0.150610      72.465969  \n",
      "===================\n",
      " \n",
      " \n",
      " \n",
      "Kernel_Used_in_GPR: WhiteKernel(noise_level=1)\n",
      "🙃🙃 Have a wonderful day! 🙃🙃\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "      <th>MDN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.003425</td>\n",
       "      <td>1.020663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.009751</td>\n",
       "      <td>1.038546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>5.252696e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.016077</td>\n",
       "      <td>1.056430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.30167e-06</td>\n",
       "      <td>5.9994e-05</td>\n",
       "      <td>6.30167e-06</td>\n",
       "      <td>0.000196334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>0.028093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.1343e-05</td>\n",
       "      <td>7.12614e-05</td>\n",
       "      <td>1.1343e-05</td>\n",
       "      <td>0.000203166</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.047301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>5.834706e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.14257e-05</td>\n",
       "      <td>8.80365e-05</td>\n",
       "      <td>2.14257e-05</td>\n",
       "      <td>0.000240146</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.066510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>4.220800e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>40801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40801.000000</td>\n",
       "      <td>126624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.115808e+01</td>\n",
       "      <td>1.814789</td>\n",
       "      <td>1.62012e+09</td>\n",
       "      <td>0.574352</td>\n",
       "      <td>0.66944</td>\n",
       "      <td>9.68545</td>\n",
       "      <td>0.590494</td>\n",
       "      <td>6.833113</td>\n",
       "      <td>0.230019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>1.942113e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00021694</td>\n",
       "      <td>0.000849836</td>\n",
       "      <td>0.00244629</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.150610</td>\n",
       "      <td>72.465969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle         ENET  \\\n",
       "W1-95L                         5.252696e-07   0.000000            -   \n",
       "W1                             5.252696e-07   0.000000            -   \n",
       "W1-95R                         5.252696e-07   0.000000            -   \n",
       "M-95L                          5.834706e-05   0.000000  6.30167e-06   \n",
       "M                              5.834706e-05   0.000000   1.1343e-05   \n",
       "M-95R                          5.834706e-05   0.000000  2.14257e-05   \n",
       "N_Par                          4.220800e+04   0.000000           20   \n",
       "Train_Time                     1.115808e+01   1.814789  1.62012e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  1.942113e-01   1.000000   0.00021694   \n",
       "\n",
       "                                    KRidge         GBRF          DNN  \\\n",
       "W1-95L                                   -            -            -   \n",
       "W1                                       -            -            -   \n",
       "W1-95R                                   -            -            -   \n",
       "M-95L                           5.9994e-05  6.30167e-06  0.000196334   \n",
       "M                              7.12614e-05   1.1343e-05  0.000203166   \n",
       "M-95R                          8.80365e-05  2.14257e-05  0.000240146   \n",
       "N_Par                                    0         1000        40801   \n",
       "Train_Time                        0.574352      0.66944      9.68545   \n",
       "Test_Time/MC-Oracle_Test_Time  0.000849836   0.00244629     0.150841   \n",
       "\n",
       "                                    GPR           DGN            MDN  \n",
       "W1-95L                         0.000010      1.003425       1.020663  \n",
       "W1                             0.000010      1.009751       1.038546  \n",
       "W1-95R                         0.000010      1.016077       1.056430  \n",
       "M-95L                          0.000000      0.007965       0.028093  \n",
       "M                              0.000006      0.008116       0.047301  \n",
       "M-95R                          0.000032      0.008211       0.066510  \n",
       "N_Par                          0.000000  40801.000000  126624.000000  \n",
       "Train_Time                     0.590494      6.833113       0.230019  \n",
       "Test_Time/MC-Oracle_Test_Time  0.000962      0.150610      72.465969  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Terminal Running\n",
    "print(\"===================\")\n",
    "print(\"Predictive Quality:\")\n",
    "print(\"===================\")\n",
    "print(Summary_pred_Qual_models)\n",
    "print(\"===================\")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Kernel_Used_in_GPR: \"+str(GPR_trash.kernel))\n",
    "print(\"🙃🙃 Have a wonderful day! 🙃🙃\")\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
