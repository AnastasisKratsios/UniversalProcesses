{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Conditional Laws for Random-Fields - via:\n",
    "\n",
    "## Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$.\n",
    "\n",
    "---\n",
    "\n",
    "By: [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---\n",
    "\n",
    "## What does this code do?\n",
    "1. Learn Heteroskedastic Non-Linear Regression Problem\n",
    "     - $Y\\sim f_{\\text{unkown}}(x) + \\epsilon$ where $f$ is an known function and $\\epsilon\\sim Laplace(0,\\|x\\|)$\n",
    "2. Learn Random Bayesian Network's Law:\n",
    "    - $Y = W_J Y^{J-1}, \\qquad Y^{j}\\triangleq \\sigma\\bullet A^{j}Y^{j-1} + b^{j}, \\qquad Y^0\\triangleq x$\n",
    "\n",
    "3. In the above example if $A_j = M_j\\odot \\tilde{A_j}$ where $\\tilde{A}_j$ is a deterministic matrix and $M_j$ is a \"mask\", that is, a random matrix with binary entries and $\\odot$ is the Hadamard product then we recover the dropout framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode:\n",
    "Software/Hardware Testing or Real-Deal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random DNN\n",
    "f_unknown_mode = \"Heteroskedastic_NonLinear_Regression\"\n",
    "\n",
    "# Random DNN internal noise\n",
    "# f_unknown_mode = \"DNN_with_Random_Weights\"\n",
    "Depth_Bayesian_DNN = 10\n",
    "width = 20\n",
    "\n",
    "# Random Dropout applied to trained DNN\n",
    "# f_unknown_mode = \"DNN_with_Bayesian_Dropout\"\n",
    "Dropout_rate = 0.1\n",
    "\n",
    "# Rough SDE (time 1)\n",
    "# f_unknown_mode = \"Rough_SDE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rough SDE Meta-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDE with Rough Driver\n",
    "N_Euler_Steps = 10**1\n",
    "Hurst_Exponent = 0.01\n",
    "\n",
    "def alpha(t,x):\n",
    "    output_drift_update = t-x\n",
    "    return output_drift_update\n",
    "\n",
    "def beta(t,x):\n",
    "    output_vol_update = (t+0.001)*np.diag(np.cos(x))\n",
    "    return output_vol_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "- Random $\\delta$-bounded partition on input space,\n",
    "- Train deep classifier on infered classes.\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Auxiliaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "\n",
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\"\n",
    "\n",
    "\n",
    "### Set Seed\n",
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)\n",
    "- Ratio $\\frac{\\text{Testing Datasize}}{\\text{Training Datasize}}$.\n",
    "- Number of Training Points to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = .2\n",
    "N_train_size = 10**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Monte_Carlo_Samples = 10**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial radis of $\\delta$-bounded random partition of $\\mathcal{X}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "Proportion_per_cluster = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate from: $Y=f(X,W)$ \n",
    "- Random DNN (internal noise): \n",
    "    - $f(X,W) = f_{\\text{unknown}}(X+U)$\n",
    "- Random DNN: \n",
    "    - $f(X,W) = f_{\\text{unknown}}(X)+W$\n",
    "    \n",
    "*Non-linear dependance on exhaugenous noise.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heteroskedastic Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "    #-----------#\n",
    "    # Build DNN #\n",
    "    #-----------#\n",
    "    W_feature = np.random.uniform(size=np.array([width,problem_dim]),low=-.5,high=.5)\n",
    "    W_readout = np.random.uniform(size=np.array([1,width]),low=-.5,high=.5)\n",
    "    # Generate Matrices\n",
    "    for i_weights in range(Depth_Bayesian_DNN):\n",
    "        W_hidden_loop = np.random.uniform(size=np.array([width,width]),low=-.5,high=.5)\n",
    "        if i_weights == 0:\n",
    "            W_hidden_list = [W_hidden_loop]\n",
    "        else:\n",
    "            W_hidden_list.append(W_hidden_loop)\n",
    "    # Define DNN Applier\n",
    "    def f_unknown(x):\n",
    "        x_internal = x.reshape(-1,)\n",
    "        x_internal = np.matmul(W_feature,x)\n",
    "        #Deep Layer(s)\n",
    "        for i in range(Depth_Bayesian_DNN):\n",
    "            W_internal = W_hidden_list[i]\n",
    "            x_internal = np.matmul(W_internal,x_internal)\n",
    "            x_internal = np.maximum(0,x_internal)    \n",
    "        # Readout Layer\n",
    "        x_internal = np.matmul(W_readout,x_internal)\n",
    "        return x_internal\n",
    "\n",
    "    # Define Simulator\n",
    "    def Simulator(x_in):\n",
    "        var = np.sqrt(np.sum(x_in**2))\n",
    "        # Pushforward\n",
    "        f_x = f_unknown(x_in)\n",
    "        # Apply Noise After\n",
    "        noise = np.random.laplace(0,var,N_Monte_Carlo_Samples)\n",
    "        f_x_noise = np.cos(f_x) + noise\n",
    "        return f_x_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if f_unknown_mode == \"DNN_with_Random_Weights\":\n",
    "    def f_unknown(x):\n",
    "        x_internal = x.reshape(-1,) \n",
    "        # Feature Map Layer\n",
    "        W_feature = np.random.uniform(size=np.array([width,problem_dim]),low=-.5,high=.5)\n",
    "        x_internal = np.matmul(W_feature,x)\n",
    "    #     Deep Layer(s)\n",
    "        for i in range(Depth_Bayesian_DNN):\n",
    "            W_internal = np.random.uniform(size=np.array([width,width]),low=-.5,high=.5)\n",
    "            x_internal = np.matmul(W_internal,x_internal)\n",
    "            x_internal = np.maximum(0,x_internal)    \n",
    "        # Readout Layer\n",
    "        W_readout = np.random.uniform(size=np.array([1,width]),low=-.5,high=.5)\n",
    "        x_internal = np.matmul(W_readout,x_internal)\n",
    "        return x_internal\n",
    "\n",
    "\n",
    "    def Simulator(x_in):\n",
    "        for i_MC in range(N_Monte_Carlo_Samples):\n",
    "            y_MC_loop = f_unknown(x_in)\n",
    "            if i_MC == 0:\n",
    "                y_MC = y_MC_loop\n",
    "            else:\n",
    "                y_MC = np.append(y_MC,y_MC_loop)\n",
    "        return y_MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if f_unknown_mode == \"DNN_with_Bayesian_Dropout\":\n",
    "    # Initialize Drouput Parameters\n",
    "    N_Dropout = int(np.maximum(1,round(width*Dropout_rate)))\n",
    "    \n",
    "    #-----------#\n",
    "    # Build DNN #\n",
    "    #-----------#\n",
    "    W_feature = np.random.uniform(size=np.array([width,problem_dim]),low=-.5,high=.5)\n",
    "    W_readout = np.random.uniform(size=np.array([1,width]),low=-.5,high=.5)\n",
    "    # Generate Matrices\n",
    "    for i_weights in range(Depth_Bayesian_DNN):\n",
    "        W_hidden_loop = np.random.uniform(size=np.array([width,width]),low=-.5,high=.5)\n",
    "        if i_weights == 0:\n",
    "            W_hidden_list = [W_hidden_loop]\n",
    "        else:\n",
    "            W_hidden_list.append(W_hidden_loop)\n",
    "    # Define DNN Applier\n",
    "    def f_unknown(x):\n",
    "        x_internal = x.reshape(-1,)\n",
    "        x_internal = np.matmul(W_feature,x)\n",
    "        #Deep Layer(s)\n",
    "        for i in range(Depth_Bayesian_DNN):\n",
    "            W_internal = W_hidden_list[i]\n",
    "            # Apply Random Dropout\n",
    "            random_mask_coordinates_i = np.random.choice(range(width),N_Dropout)\n",
    "            random_mask_coordinates_j = np.random.choice(range(width),N_Dropout)\n",
    "            W_internal[random_mask_coordinates_i,random_mask_coordinates_j] = 0\n",
    "            # Apply Dropped-out layer\n",
    "            x_internal = np.matmul(W_internal,x_internal)\n",
    "            x_internal = np.maximum(0,x_internal)    \n",
    "        # Readout Layer\n",
    "        x_internal = np.matmul(W_readout,x_internal)\n",
    "        return x_internal\n",
    "\n",
    "    def Simulator(x_in):\n",
    "        for i_MC in range(N_Monte_Carlo_Samples):\n",
    "            y_MC_loop = f_unknown(x_in)\n",
    "            if i_MC == 0:\n",
    "                y_MC = y_MC_loop\n",
    "            else:\n",
    "                y_MC = np.append(y_MC,y_MC_loop)\n",
    "        return y_MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fSDEs\n",
    "Lean the conditional law of $I_{X_1 \\in Ball(0,1)}$ where $X_t$ solves an SDE with fBM driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if f_unknown_mode == \"Rough_SDE\":\n",
    "    # Initialize Drouput Parameters\n",
    "    N_Dropout = int(np.maximum(1,round(width*Dropout_rate)))\n",
    "    \n",
    "    #-----------#\n",
    "    # Build DNN #\n",
    "    #-----------#\n",
    "    W_feature = np.random.uniform(size=np.array([width,problem_dim]),low=-.5,high=.5)\n",
    "    W_readout = np.random.uniform(size=np.array([1,width]),low=-.5,high=.5)\n",
    "    # Generate Matrices\n",
    "    for i_weights in range(Depth_Bayesian_DNN):\n",
    "        W_hidden_loop = np.random.uniform(size=np.array([width,width]),low=-.5,high=.5)\n",
    "        if i_weights == 0:\n",
    "            W_hidden_list = [W_hidden_loop]\n",
    "        else:\n",
    "            W_hidden_list.append(W_hidden_loop)\n",
    "    # Define DNN Applier\n",
    "    def f_unknown(x):\n",
    "        x_internal = x.reshape(-1,)\n",
    "        # Get fBM path\n",
    "        for d in range(problem_dim):\n",
    "            fBM_gen_loop = (((FBM(n=N_Euler_Steps, hurst=Hurst_Exponent, length=1, method='daviesharte')).fbm())[1:]).reshape(-1,1)\n",
    "            if d == 0:\n",
    "                fBM_gen = fBM_gen_loop\n",
    "            else:\n",
    "                fBM_gen = np.append(fBM_gen,fBM_gen_loop,axis=-1)\n",
    "        # Perform Integral\n",
    "        for t in range(N_Euler_Steps):\n",
    "            drift_update = alpha(t/N_Euler_Steps,x_internal)/N_Euler_Steps\n",
    "            vol_update = beta(t/N_Euler_Steps,x_internal)\n",
    "            x_internal = x_internal + drift_update + np.matmul(vol_update,fBM_gen[t,])\n",
    "        # Sum at output\n",
    "        output_indicator = np.max(x_internal)\n",
    "        return output_indicator\n",
    "\n",
    "    def Simulator(x_in):\n",
    "        for i_MC in range(N_Monte_Carlo_Samples):\n",
    "            y_MC_loop = f_unknown(x_in)\n",
    "            if i_MC == 0:\n",
    "                y_MC = y_MC_loop\n",
    "            else:\n",
    "                y_MC = np.append(y_MC,y_MC_loop)\n",
    "        return y_MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test_size = int(np.round(N_train_size*train_test_ratio,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training Data (Inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try initial sampling-type implementation!  It worked nicely..i.e.: centers were given!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Training Set\n",
    "X_train = np.random.uniform(size=np.array([N_train_size,problem_dim]),low=.5,high=1.5)\n",
    "\n",
    "# Get Testing Set\n",
    "test_set_indices = np.random.choice(range(X_train.shape[0]),N_test_size)\n",
    "X_test = X_train[test_set_indices,]\n",
    "X_test = X_test + np.random.uniform(low=-(delta/np.sqrt(problem_dim)), \n",
    "                                    high = -(delta/np.sqrt(problem_dim)),\n",
    "                                    size = X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize k_means\n",
    "N_Quantizers_to_parameterize = int(np.maximum(2,round(Proportion_per_cluster*X_train.shape[0])))\n",
    "kmeans = KMeans(n_clusters=N_Quantizers_to_parameterize, random_state=0).fit(X_train)\n",
    "# Get Classes\n",
    "Train_classes = np.array(pd.get_dummies(kmeans.labels_))\n",
    "# Get Center Measures\n",
    "Barycenters_Array_x = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Barycenters\n",
    "*Here we make the assumption that we can directly resample $f(X=x,U)$ if necessary...or that it is available as part of the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 4100.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(Barycenters_Array_x.shape[0])):\n",
    "    # Put Datum\n",
    "    Bar_x_loop = Barycenters_Array_x[i,]\n",
    "    # Product Monte-Carlo Sample for Input\n",
    "    Bar_y_loop = (Simulator(Bar_x_loop)).reshape(1,-1)\n",
    "\n",
    "    # Update Dataset\n",
    "    if i == 0:\n",
    "        Barycenters_Array = Bar_y_loop\n",
    "    else:\n",
    "        Barycenters_Array = np.append(Barycenters_Array,Bar_y_loop,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training Data (Outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2943.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(X_train.shape[0])):\n",
    "    # Put Datum\n",
    "    x_loop = X_train[i,]\n",
    "    # Product Monte-Carlo Sample for Input\n",
    "    y_loop = (Simulator(x_loop)).reshape(1,-1)\n",
    "\n",
    "    # Update Dataset\n",
    "    if i == 0:\n",
    "        Y_train = y_loop\n",
    "        Y_train_mean_emp = np.mean(y_loop)\n",
    "        Y_train_var_emp = np.mean((y_loop - np.mean(y_loop))**2)\n",
    "    else:\n",
    "        Y_train = np.append(Y_train,y_loop,axis=0)\n",
    "        Y_train_mean_emp = np.append(Y_train_mean_emp,np.mean(y_loop))\n",
    "        Y_train_var_emp = np.append(Y_train_var_emp,np.mean((y_loop - np.mean(y_loop))**2))\n",
    "# Join mean and Variance Training Data\n",
    "Y_train_var_emp = np.append(Y_train_mean_emp.reshape(-1,1),Y_train_var_emp.reshape(-1,1),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 5061.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Start Timer\n",
    "Test_Set_PredictionTime_MC = time.time()\n",
    "\n",
    "# Generate Data\n",
    "for i in tqdm(range(X_test.shape[0])):\n",
    "    # Put Datum\n",
    "    x_loop = X_test[i,]\n",
    "    # Product Monte-Carlo Sample for Input\n",
    "    y_loop = (Simulator(x_loop)).reshape(1,-1)\n",
    "\n",
    "    # Update Dataset\n",
    "    if i == 0:\n",
    "        Y_test = y_loop\n",
    "    else:\n",
    "        Y_test = np.append(Y_test,y_loop,axis=0)\n",
    "        \n",
    "# End Timer\n",
    "Test_Set_PredictionTime_MC = time.time() - Test_Set_PredictionTime_MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Packages and CV Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Training Classifer Portion of Type-A Model\n",
      "==========================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8968 - accuracy: 0.0100\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8873 - accuracy: 0.0100\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8790 - accuracy: 0.0100\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8716 - accuracy: 0.0100\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8643 - accuracy: 0.0100\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8573 - accuracy: 0.0200\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8505 - accuracy: 0.0700\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8434 - accuracy: 0.0700\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8366 - accuracy: 0.0700\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8299 - accuracy: 0.0600\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.8233 - accuracy: 0.0600\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8161 - accuracy: 0.0600\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.8095 - accuracy: 0.0600\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8021 - accuracy: 0.0600\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7952 - accuracy: 0.0600\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.7877 - accuracy: 0.0600\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.7804 - accuracy: 0.0600\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.7733 - accuracy: 0.0600\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.7656 - accuracy: 0.0600\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7585 - accuracy: 0.0600\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7498 - accuracy: 0.0600\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7417 - accuracy: 0.0600\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.7334 - accuracy: 0.0600\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7250 - accuracy: 0.0600\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.7162 - accuracy: 0.0600\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.7085 - accuracy: 0.0600\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.7007 - accuracy: 0.0600\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6928 - accuracy: 0.0600\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6843 - accuracy: 0.0600\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6755 - accuracy: 0.0600\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.6670 - accuracy: 0.0600\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.6579 - accuracy: 0.0600\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.6492 - accuracy: 0.0600\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6409 - accuracy: 0.0600\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.6327 - accuracy: 0.0600\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.6245 - accuracy: 0.0600\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.6177 - accuracy: 0.0600\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.6095 - accuracy: 0.0600\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.6022 - accuracy: 0.0600\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.5945 - accuracy: 0.0600\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.5874 - accuracy: 0.0600\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.5804 - accuracy: 0.0600\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.5732 - accuracy: 0.0600\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.5663 - accuracy: 0.0600\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.5599 - accuracy: 0.0600\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.5522 - accuracy: 0.0600\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5456 - accuracy: 0.0600\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.5384 - accuracy: 0.0600\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.5320 - accuracy: 0.0600\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.5250 - accuracy: 0.0600\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "===============================================\n",
      "Training Classifer Portion of Type Model: Done!\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "print(\"==========================================\")\n",
    "print(\"Training Classifer Portion of Type-A Model\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [problem_dim]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier, timer_output = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Train_classes,\n",
    "                                                                                                        X_test = X_test)\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"Training Classifer Portion of Type Model: Done!\")\n",
    "print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Empirical Weights\n",
    "empirical_weights = (np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples).reshape(-1,)\n",
    "\n",
    "for i in range(N_Quantizers_to_parameterize):\n",
    "    if i == 0:\n",
    "        points_of_mass = Barycenters_Array[i,]\n",
    "    else:\n",
    "        points_of_mass = np.append(points_of_mass,Barycenters_Array[i,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Noisless Mean\n",
    "direct_facts = np.apply_along_axis(f_unknown, 1, X_train)\n",
    "direct_facts_test = np.apply_along_axis(f_unknown, 1, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Error(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run Evaluation.ipynb\n",
    "exec(open('Evaluation.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute *Training* Error(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 178.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"#--------------------#\")\n",
    "print(\" Get Training Error(s)\")\n",
    "print(\"#--------------------#\")\n",
    "for i in tqdm(range((X_train.shape[0]))):\n",
    "    for j in range(N_Quantizers_to_parameterize):\n",
    "        b_loop = np.repeat(predicted_classes_train[i,j],N_Monte_Carlo_Samples)\n",
    "        if j == 0:\n",
    "            b = b_loop\n",
    "        else:\n",
    "            b = np.append(b,b_loop)\n",
    "        b = b.reshape(-1,1)\n",
    "        b = b\n",
    "    b = np.array(b,dtype=float).reshape(-1,)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    \n",
    "    # Compute Error(s)\n",
    "    ## W1\n",
    "    W1_loop = ot.emd2_1d(points_of_mass,\n",
    "                         np.array(Y_train[i,]).reshape(-1,),\n",
    "                         b,\n",
    "                         empirical_weights)\n",
    "    \n",
    "    ## M1\n",
    "    Mu_hat = np.sum(b*(points_of_mass))\n",
    "    Mu_MC = np.mean(np.array(Y_train[i,]))\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Mu = direct_facts[i,]\n",
    "    else:\n",
    "        Mu = Mu_MC\n",
    "        \n",
    "    ### Error(s)\n",
    "    Mean_loop = (Mu_hat-Mu)\n",
    "    Mean_loop_MC = (Mu_hat-Mu_MC)\n",
    "    \n",
    "    ## Variance\n",
    "    Var_hat = np.sum(((points_of_mass-Mu_hat)**2)*b)\n",
    "    Var_MC = np.mean(np.array(Y_train[i]-Mu_MC)**2)\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Var = 2*np.sum(X_train[i,]**2)\n",
    "    else:\n",
    "        Var = Var_MC     \n",
    "    ### Error(s)\n",
    "    Var_loop = np.abs(Var_hat-Var)\n",
    "    Var_loop_MC = np.abs(Var_MC-Var)\n",
    "        \n",
    "    # Skewness\n",
    "    Skewness_hat = np.sum((((points_of_mass-Mu_hat)/Var)**3)*b)\n",
    "    Skewness_MC = np.mean((np.array(Y_train[i]-Mu_MC)/Var_MC)**3)\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Skewness = 0\n",
    "    else:\n",
    "        Skewness = Skewness_MC\n",
    "    ### Error(s)\n",
    "    Skewness_loop = np.abs(Skewness_hat-Skewness)\n",
    "    Skewness_loop_MC = np.abs(Skewness_MC-Skewness)\n",
    "    \n",
    "    # Skewness\n",
    "    Ex_Kurtosis_hat = np.sum((((points_of_mass-Mu_hat)/Var)**4)*b) - 3\n",
    "    Ex_Kurtosis_MC = np.mean((np.array(Y_train[i]-Mu_MC)/Var_MC)**4) - 3\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Ex_Kurtosis = 3\n",
    "    else:\n",
    "        Ex_Kurtosis = Ex_Kurtosis_MC\n",
    "    ### Error(s)\n",
    "    Ex_Kurtosis_loop = np.abs(Ex_Kurtosis-Ex_Kurtosis_hat)\n",
    "    Ex_Kurtosis_loop_MC = np.abs(Ex_Kurtosis-Ex_Kurtosis_MC)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get Higher Moments Loss\n",
    "    Higher_momentserrors_loop,Higher_MC_momentserrors_loop = Higher_Moments_Loss(b,np.array(Y_train[i,]))\n",
    "    Higher_Moments_Errors_loop = np.abs(Higher_momentserrors_loop-Higher_MC_momentserrors_loop)\n",
    "    \n",
    "    \n",
    "    # Update\n",
    "    if i == 0:\n",
    "        W1_errors = W1_loop\n",
    "        # Moments\n",
    "        ## DNM\n",
    "        Mean_errors =  Mean_loop\n",
    "        Var_errors = Var_loop\n",
    "        Skewness_errors = Skewness_loop\n",
    "        Ex_Kurtosis_errors = Ex_Kurtosis_loop\n",
    "        ## Monte-Carlo\n",
    "        Mean_errors_MC =  Mean_loop_MC\n",
    "        Var_errors_MC = Var_loop_MC\n",
    "        Skewness_errors_MC = Skewness_loop_MC\n",
    "        Ex_Kurtosis_errors_MC = Ex_Kurtosis_loop_MC\n",
    "        # Higher Moments\n",
    "        Higher_Moments_Errors = Higher_Moments_Errors_loop\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        W1_errors = np.append(W1_errors,W1_loop)\n",
    "        # Moments\n",
    "        ## DNM\n",
    "        Mean_errors =  np.append(Mean_errors,Mean_loop)\n",
    "        Var_errors = np.append(Var_errors,Var_loop)\n",
    "        Skewness_errors = np.append(Skewness_errors,Skewness_loop)\n",
    "        Ex_Kurtosis_errors = np.append(Ex_Kurtosis_errors,Ex_Kurtosis_loop)\n",
    "        ## Monte-Carlo\n",
    "        Mean_errors_MC =  np.append(Mean_errors_MC,Mean_loop_MC)\n",
    "        Var_errors_MC = np.append(Var_errors_MC,Var_loop_MC)\n",
    "        Skewness_errors_MC = np.append(Skewness_errors_MC,Skewness_loop_MC)\n",
    "        Ex_Kurtosis_errors_MC = np.append(Ex_Kurtosis_errors_MC,Ex_Kurtosis_loop_MC)\n",
    "        # Higher Moments\n",
    "        Higher_Moments_Errors = np.append(Higher_Moments_Errors,Higher_Moments_Errors_loop)\n",
    "        \n",
    "print(\"#-------------------------#\")\n",
    "print(\" Get Training Error(s): END\")\n",
    "print(\"#-------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute *Testing* Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 226.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------#\n",
      " Get Test Error(s)\n",
      "#----------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------#\")\n",
    "print(\" Get Test Error(s)\")\n",
    "print(\"#----------------#\")\n",
    "for i in tqdm(range((X_test.shape[0]))):\n",
    "    for j in range(N_Quantizers_to_parameterize):\n",
    "        b_loop_test = np.repeat(predicted_classes_test[i,j],N_Monte_Carlo_Samples)\n",
    "        if j == 0:\n",
    "            b_test = b_loop_test\n",
    "        else:\n",
    "            b_test = np.append(b,b_loop)\n",
    "        b_test = b_test.reshape(-1,1)\n",
    "    b_test = np.array(b,dtype=float).reshape(-1,)\n",
    "    b_test = b/N_Monte_Carlo_Samples\n",
    "    \n",
    "    # Compute Error(s)\n",
    "    ## W1\n",
    "    W1_loop_test = ot.emd2_1d(points_of_mass,\n",
    "                         np.array(Y_test[i,]).reshape(-1,),\n",
    "                         b,\n",
    "                         empirical_weights)\n",
    "    \n",
    "    ## M1\n",
    "    Mu_hat_test = np.sum(b_test*(points_of_mass))\n",
    "    Mu_MC_test = np.mean(np.array(Y_test[i,]))\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Mu_test = direct_facts_test[i,]\n",
    "    else:\n",
    "        Mu_test = Mu_MC_test\n",
    "    Mu_test = direct_facts_test[i,]\n",
    "    ### Error(s)\n",
    "    Mean_loop_test = (Mu_hat_test-Mu_test)\n",
    "    Mean_loop_MC_test = (Mu_hat_test-Mu_MC_test)\n",
    "    \n",
    "    ## M2\n",
    "    Var_hat_test = np.sum(((points_of_mass-Mu_hat_test)**2)*b)\n",
    "    Var_MC_test = np.mean(np.array(Y_test[i]-Mu_MC)**2)\n",
    "    if f_unknown_mode == \"Rough_SDE\":\n",
    "        Var_test = 2*np.sum(X_test[i,]**2)\n",
    "    else:\n",
    "        Var_test = Var_MC\n",
    "    \n",
    "    ### Error(s)\n",
    "    Var_loop_test = np.abs(Var_hat_test-Var_test)\n",
    "    Var_loop_MC_test = np.abs(Var_MC_test-Var_test)\n",
    "    \n",
    "    # Skewness\n",
    "    Skewness_hat_test = np.sum((((points_of_mass-Mu_hat_test)/Var_test)**3)*b)\n",
    "    Skewness_MC_test = np.mean((np.array(Y_test[i]-Mu_MC_test)/Var_MC_test)**3)\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Skewness_test = 0\n",
    "    else:\n",
    "        Skewness_test = Skewness_MC_test\n",
    "    ### Error(s)\n",
    "    Skewness_loop_test = np.abs(Skewness_hat_test-Skewness_test)\n",
    "    Skewness_loop_MC_test = np.abs(Skewness_MC_test-Skewness_test)\n",
    "    \n",
    "    # Skewness\n",
    "    Ex_Kurtosis_hat_test = np.sum((((points_of_mass-Mu_hat_test)/Var_test)**4)*b) - 3\n",
    "    Ex_Kurtosis_MC_test = np.mean((np.array(Y_test[i]-Mu_MC_test)/Var_MC_test)**4) - 3\n",
    "    if f_unknown_mode == \"Heteroskedastic_NonLinear_Regression\":\n",
    "        Ex_Kurtosis_test = 3\n",
    "    else:\n",
    "        Ex_Kurtosis_test = Ex_Kurtosis_MC_test\n",
    "    ### Error(s)\n",
    "    Ex_Kurtosis_loop_test = np.abs(Ex_Kurtosis_test-Ex_Kurtosis_hat_test)\n",
    "    Ex_Kurtosis_loop_MC_test = np.abs(Ex_Kurtosis_test-Ex_Kurtosis_MC_test)\n",
    "    \n",
    "    \n",
    "    # Get Higher Moments Loss\n",
    "    Higher_momentserrors_test_loop,Higher_MC_momentserrors_test_loop = Higher_Moments_Loss(b,np.array(Y_test[i,]))\n",
    "    Higher_Moments_Errors_test_loop = np.abs(Higher_momentserrors_test_loop-Higher_MC_momentserrors_test_loop)\n",
    "    \n",
    "    # Update\n",
    "    if i == 0:\n",
    "        W1_errors_test = W1_loop_test\n",
    "        # Moments\n",
    "        ## DNM\n",
    "        Mean_errors_test =  Mean_loop_test\n",
    "        Var_errors_test = Var_loop_test\n",
    "        Skewness_errors_test = Skewness_loop_test\n",
    "        Ex_Kurtosis_errors_test = Ex_Kurtosis_loop_test\n",
    "        ## Monte-Carlo\n",
    "        Mean_errors_MC_test =  Mean_loop_MC_test\n",
    "        Var_errors_MC_test = Var_loop_MC_test\n",
    "        Skewness_errors_MC_test = Skewness_loop_MC_test\n",
    "        Ex_Kurtosis_errors_MC_test = Ex_Kurtosis_loop_MC_test\n",
    "        # Higher Moments\n",
    "        Higher_Moments_test_Errors = Higher_Moments_Errors_test_loop\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "        # Moments\n",
    "        ## DNM\n",
    "        Mean_errors_test =  np.append(Mean_errors_test,Mean_loop_test)\n",
    "        Var_errors_test = np.append(Var_errors_test,Var_loop_test)\n",
    "        Skewness_errors_test = np.append(Skewness_errors_test,Skewness_loop_test)\n",
    "        Ex_Kurtosis_errors_test = np.append(Ex_Kurtosis_errors_test,Ex_Kurtosis_loop_test)\n",
    "        ## Monte-Carlo\n",
    "        Mean_errors_MC_test =  np.append(Mean_errors_MC_test,Mean_loop_MC_test)\n",
    "        Var_errors_MC_test = np.append(Var_errors_MC_test,Var_loop_MC_test)\n",
    "        Skewness_errors_MC_test = np.append(Skewness_errors_MC_test,Skewness_loop_MC_test)\n",
    "        Ex_Kurtosis_errors_MC_test = np.append(Ex_Kurtosis_errors_MC_test,Ex_Kurtosis_loop_MC_test)\n",
    "        # Higher Moments\n",
    "        Higher_Moments_test_Errors = np.append(Higher_Moments_test_Errors,Higher_Moments_Errors_test_loop)\n",
    "        \n",
    "        \n",
    "print(\"#-------------------------#\")\n",
    "print(\" Get Training Error(s): END\")\n",
    "print(\"#-------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Benchmarks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Pointmass Benchmark(s)\n",
    "These benchmarks consist of subsets of $C(\\mathbb{R}^d,\\mathbb{R})$ which we lift to models in $C(\\mathbb{R}^d,\\cap_{1\\leq q<\\infty}\\mathscr{P}_{q}(\\mathbb{R}))$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to f(x) \\to \\delta_{f(x)}\\in \\cap_{1\\leq q<\\infty}\\mathcal{P}_{q}(\\mathbb{R}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "--------------\n",
      "Training: ENET\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 547.00it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 564.10it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0065s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      " 30%|███       | 30/100 [00:00<00:00, 297.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "-----------------\n",
      "Training: K-Ridge\n",
      "-----------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 412.72it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 501.31it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "--------------\n",
      "Training: GBRF\n",
      "--------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
      "100%|██████████| 100/100 [00:00<00:00, 576.15it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 511.82it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "-------------\n",
      "Training: DNN\n",
      "-------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8765 - mse: 0.8573 - mae: 0.8765 - mape: 91.8053\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8752 - mse: 0.8550 - mae: 0.8752 - mape: 91.6817\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8738 - mse: 0.8526 - mae: 0.8738 - mape: 91.6272\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8725 - mse: 0.8503 - mae: 0.8725 - mape: 91.5387\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8712 - mse: 0.8480 - mae: 0.8712 - mape: 91.4485\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8698 - mse: 0.8456 - mae: 0.8698 - mape: 91.3267\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8685 - mse: 0.8433 - mae: 0.8685 - mape: 91.2899\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8672 - mse: 0.8409 - mae: 0.8672 - mape: 91.1885\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8659 - mse: 0.8387 - mae: 0.8659 - mape: 91.0668\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8646 - mse: 0.8364 - mae: 0.8646 - mape: 90.9780\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8633 - mse: 0.8340 - mae: 0.8633 - mape: 90.9234\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8619 - mse: 0.8317 - mae: 0.8619 - mape: 90.8158\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8606 - mse: 0.8293 - mae: 0.8606 - mape: 90.7077\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8592 - mse: 0.8270 - mae: 0.8592 - mape: 90.6318\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8579 - mse: 0.8246 - mae: 0.8579 - mape: 90.5362\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8565 - mse: 0.8221 - mae: 0.8565 - mape: 90.4304\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8551 - mse: 0.8197 - mae: 0.8551 - mape: 90.3536\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8537 - mse: 0.8172 - mae: 0.8537 - mape: 90.2793\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8522 - mse: 0.8148 - mae: 0.8522 - mape: 90.1807\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8508 - mse: 0.8123 - mae: 0.8508 - mape: 90.1022\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8493 - mse: 0.8098 - mae: 0.8493 - mape: 89.9482\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8479 - mse: 0.8073 - mae: 0.8479 - mape: 89.8872\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8464 - mse: 0.8048 - mae: 0.8464 - mape: 89.7742\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8450 - mse: 0.8023 - mae: 0.8450 - mape: 89.6712\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8434 - mse: 0.7996 - mae: 0.8434 - mape: 89.5493\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8419 - mse: 0.7970 - mae: 0.8419 - mape: 89.4858\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8403 - mse: 0.7944 - mae: 0.8403 - mape: 89.3806\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8388 - mse: 0.7916 - mae: 0.8388 - mape: 89.2582\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8372 - mse: 0.7889 - mae: 0.8372 - mape: 89.1305\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8356 - mse: 0.7862 - mae: 0.8356 - mape: 89.0420\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8339 - mse: 0.7835 - mae: 0.8339 - mape: 88.9535\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8323 - mse: 0.7807 - mae: 0.8323 - mape: 88.8375\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8306 - mse: 0.7778 - mae: 0.8306 - mape: 88.6841\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8289 - mse: 0.7750 - mae: 0.8289 - mape: 88.5676\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8272 - mse: 0.7721 - mae: 0.8272 - mape: 88.4951\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8254 - mse: 0.7692 - mae: 0.8254 - mape: 88.3574\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8237 - mse: 0.7663 - mae: 0.8237 - mape: 88.2138\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8219 - mse: 0.7632 - mae: 0.8219 - mape: 88.0945\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8201 - mse: 0.7603 - mae: 0.8201 - mape: 88.0169\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8183 - mse: 0.7572 - mae: 0.8183 - mape: 87.9006\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8164 - mse: 0.7541 - mae: 0.8164 - mape: 87.7236\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8145 - mse: 0.7510 - mae: 0.8145 - mape: 87.6432\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8126 - mse: 0.7478 - mae: 0.8126 - mape: 87.4719\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8107 - mse: 0.7447 - mae: 0.8107 - mape: 87.4076\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8087 - mse: 0.7415 - mae: 0.8087 - mape: 87.2020\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8068 - mse: 0.7383 - mae: 0.8068 - mape: 87.1251\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8048 - mse: 0.7351 - mae: 0.8048 - mape: 86.9858\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8028 - mse: 0.7318 - mae: 0.8028 - mape: 86.8268\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8008 - mse: 0.7284 - mae: 0.8008 - mape: 86.6950\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7987 - mse: 0.7251 - mae: 0.7987 - mape: 86.5518\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 991us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 633.10it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [00:00<00:00, 570.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "-----------------------\n",
      "Computing Error Metrics\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exec(open('CV_Grid.py').read())\n",
    "# Notebook Mode:\n",
    "# %run Evaluation.ipynb\n",
    "# %run Benchmarks_Model_Builder_Pointmass_Based.ipynb\n",
    "# Terminal Mode (Default):\n",
    "exec(open('Evaluation.py').read())\n",
    "exec(open('Benchmarks_Model_Builder_Pointmass_Based.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Gaussian Benchmark(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bencharm 1: [Gaussian Process Regressor](https://scikit-learn.org/stable/modules/gaussian_process.html)\n",
    "- Benchmark 2: Deep Gaussian Networks:\n",
    "These models train models which assume Gaussianity.  We may view these as models in $\\mathcal{P}_2(\\mathbb{R})$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to (\\hat{\\mu}(x),\\hat{\\sigma}(x))\\triangleq f(x) \\in \\mathbb{R}\\times [0,\\infty) \\to \\frac1{\\hat{\\sigma}(x)\\sqrt{2\\pi}}\\exp\\left(\\frac{-(\\cdot-\\hat{\\mu}(x))^2}{\\hat{\\sigma(x)}^2}\\right) \\in \\mathcal{G}_1\\subset \\mathcal{P}_2(\\mathbb{R});\n",
    "$$\n",
    "where $\\mathcal{G}_1$ is the set of Gaussian measures on $\\mathbb{R}$ equipped with the relative Wasserstein-1 topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Feature Builder - Ready\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.1124s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training Deep Gaussian Network!\n",
      "===============================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.4640 - mse: 21.7707 - mae: 3.4640 - mape: 89.5667\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.4625 - mse: 21.7599 - mae: 3.4625 - mape: 89.4874\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4610 - mse: 21.7490 - mae: 3.4610 - mape: 89.4464\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.4596 - mse: 21.7384 - mae: 3.4596 - mape: 89.3865\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4581 - mse: 21.7279 - mae: 3.4581 - mape: 89.3257\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4566 - mse: 21.7172 - mae: 3.4566 - mape: 89.2478\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4551 - mse: 21.7066 - mae: 3.4551 - mape: 89.2166\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4537 - mse: 21.6959 - mae: 3.4537 - mape: 89.1501\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4522 - mse: 21.6856 - mae: 3.4522 - mape: 89.0718\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4507 - mse: 21.6749 - mae: 3.4507 - mape: 89.0123\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4493 - mse: 21.6643 - mae: 3.4493 - mape: 88.9720\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4478 - mse: 21.6536 - mae: 3.4478 - mape: 88.9027\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4463 - mse: 21.6428 - mae: 3.4463 - mape: 88.8334\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4448 - mse: 21.6318 - mae: 3.4448 - mape: 88.7821\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4433 - mse: 21.6213 - mae: 3.4433 - mape: 88.7204\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.4418 - mse: 21.6103 - mae: 3.4418 - mape: 88.6534\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4403 - mse: 21.5996 - mae: 3.4403 - mape: 88.6023\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4388 - mse: 21.5885 - mae: 3.4388 - mape: 88.5526\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4373 - mse: 21.5775 - mae: 3.4373 - mape: 88.4906\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4358 - mse: 21.5666 - mae: 3.4358 - mape: 88.4389\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4342 - mse: 21.5556 - mae: 3.4342 - mape: 88.3484\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4327 - mse: 21.5445 - mae: 3.4327 - mape: 88.3065\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.4015 - mse: 20.4036 - mae: 3.4015 - mape: 87.94 - 0s 2ms/step - loss: 3.4312 - mse: 21.5335 - mae: 3.4312 - mape: 88.2374\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4297 - mse: 21.5223 - mae: 3.4297 - mape: 88.1746\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4281 - mse: 21.5109 - mae: 3.4281 - mape: 88.1024\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4265 - mse: 21.4999 - mae: 3.4265 - mape: 88.0596\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.4250 - mse: 21.4882 - mae: 3.4250 - mape: 87.9967\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4234 - mse: 21.4770 - mae: 3.4234 - mape: 87.9254\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4218 - mse: 21.4653 - mae: 3.4218 - mape: 87.8523\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4202 - mse: 21.4538 - mae: 3.4202 - mape: 87.7983\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4186 - mse: 21.4421 - mae: 3.4186 - mape: 87.7442\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4170 - mse: 21.4304 - mae: 3.4170 - mape: 87.6775\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4154 - mse: 21.4188 - mae: 3.4154 - mape: 87.5931\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4137 - mse: 21.4067 - mae: 3.4137 - mape: 87.5268\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4121 - mse: 21.3946 - mae: 3.4121 - mape: 87.4811\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4104 - mse: 21.3828 - mae: 3.4104 - mape: 87.4051\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4087 - mse: 21.3706 - mae: 3.4087 - mape: 87.3271\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4071 - mse: 21.3584 - mae: 3.4071 - mape: 87.2602\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4054 - mse: 21.3460 - mae: 3.4054 - mape: 87.2124\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4037 - mse: 21.3335 - mae: 3.4037 - mape: 87.1473\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4019 - mse: 21.3211 - mae: 3.4019 - mape: 87.0549\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.4002 - mse: 21.3084 - mae: 3.4002 - mape: 87.0060\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.3984 - mse: 21.2955 - mae: 3.3984 - mape: 86.9172\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3967 - mse: 21.2826 - mae: 3.3967 - mape: 86.8752\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3949 - mse: 21.2698 - mae: 3.3949 - mape: 86.7710\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3931 - mse: 21.2569 - mae: 3.3931 - mape: 86.7233\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3913 - mse: 21.2436 - mae: 3.3913 - mape: 86.6487\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3895 - mse: 21.2303 - mae: 3.3895 - mape: 86.5657\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3876 - mse: 21.2171 - mae: 3.3876 - mape: 86.4945\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3857 - mse: 21.2031 - mae: 3.3857 - mape: 86.4188\n",
      "4/4 [==============================] - 0s 846us/step\n",
      "1/1 [==============================] - 0s 891us/step\n",
      "====================================\n",
      "Training Deep Gaussian Network!: END\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      " Get Training Errors for: Gaussian Models\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2026.31it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 1579.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#---------------------------------------#\n",
      " Get Testing Errors for: Gaussian Models\n",
      "#---------------------------------------#\n",
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run Benchmarks_Model_Builder_Mean_Var.ipynb\n",
    "# exec(open('Benchmarks_Model_Builder_Mean_Var.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Mean-Centric Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ENET     kRidge       GBRF       ffNN        GPR        DGN\n",
      "W1       7.0215E+00 7.0213E+00 7.0697E+00 7.7400E+00 7.0137E+00 3.7538E+00\n",
      "Mean     1.0204E+00 1.0135E+00 1.0958E+00 2.2312E-01 1.8091E-10 1.5339E-01\n",
      "Var      6.2838E+00 6.2838E+00 6.2838E+00 6.2838E+00 6.9022E+00 5.7887E+00\n",
      "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00\n",
      "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00 3.0000E+00 3.0000E+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>ffNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>7.0215E+00</td>\n",
       "      <td>7.0213E+00</td>\n",
       "      <td>7.0697E+00</td>\n",
       "      <td>7.7400E+00</td>\n",
       "      <td>7.0137E+00</td>\n",
       "      <td>3.7538E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>1.0204E+00</td>\n",
       "      <td>1.0135E+00</td>\n",
       "      <td>1.0958E+00</td>\n",
       "      <td>2.2312E-01</td>\n",
       "      <td>1.8091E-10</td>\n",
       "      <td>1.5339E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>6.2838E+00</td>\n",
       "      <td>6.2838E+00</td>\n",
       "      <td>6.2838E+00</td>\n",
       "      <td>6.2838E+00</td>\n",
       "      <td>6.9022E+00</td>\n",
       "      <td>5.7887E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex_Kur</th>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>3.0000E+00</td>\n",
       "      <td>3.0000E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ENET     kRidge       GBRF       ffNN        GPR        DGN\n",
       "W1       7.0215E+00 7.0213E+00 7.0697E+00 7.7400E+00 7.0137E+00 3.7538E+00\n",
       "Mean     1.0204E+00 1.0135E+00 1.0958E+00 2.2312E-01 1.8091E-10 1.5339E-01\n",
       "Var      6.2838E+00 6.2838E+00 6.2838E+00 6.2838E+00 6.9022E+00 5.7887E+00\n",
       "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00\n",
       "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00 3.0000E+00 3.0000E+00"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ENET     kRidge       GBRF       ffNN\n",
      "W1       7.1055E+00 7.1052E+00 7.0163E+00 7.7363E+00\n",
      "Mean     1.0201E+00 1.0133E+00 1.0201E+00 2.2610E-01\n",
      "Var      6.9022E+00 6.9022E+00 6.9022E+00 6.9022E+00\n",
      "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00\n",
      "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENET</th>\n",
       "      <th>kRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>ffNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>7.1055E+00</td>\n",
       "      <td>7.1052E+00</td>\n",
       "      <td>7.0163E+00</td>\n",
       "      <td>7.7363E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>1.0201E+00</td>\n",
       "      <td>1.0133E+00</td>\n",
       "      <td>1.0201E+00</td>\n",
       "      <td>2.2610E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>6.9022E+00</td>\n",
       "      <td>6.9022E+00</td>\n",
       "      <td>6.9022E+00</td>\n",
       "      <td>6.9022E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "      <td>0.0000E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex_Kur</th>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "      <td>6.0000E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ENET     kRidge       GBRF       ffNN\n",
       "W1       7.1055E+00 7.1052E+00 7.0163E+00 7.7363E+00\n",
       "Mean     1.0201E+00 1.0133E+00 1.0201E+00 2.2610E-01\n",
       "Var      6.9022E+00 6.9022E+00 6.9022E+00 6.9022E+00\n",
       "Skewness 0.0000E+00 0.0000E+00 0.0000E+00 0.0000E+00\n",
       "Ex_Kur   6.0000E+00 6.0000E+00 6.0000E+00 6.0000E+00"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Complexitie(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        N_Params     T_Time  T_Test/T_test-MC\n",
      "ENET           6 4.6286E+00        5.5304E-03\n",
      "GBRF       67602 6.6005E-01        9.3637E-02\n",
      "kRidge        12 3.6193E-01        4.2487E-02\n",
      "ffNN         101 4.8946E+00        4.2246E+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Params</th>\n",
       "      <th>T_Time</th>\n",
       "      <th>T_Test/T_test-MC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENET</th>\n",
       "      <td>6</td>\n",
       "      <td>4.6286E+00</td>\n",
       "      <td>5.5304E-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBRF</th>\n",
       "      <td>67602</td>\n",
       "      <td>6.6005E-01</td>\n",
       "      <td>9.3637E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kRidge</th>\n",
       "      <td>12</td>\n",
       "      <td>3.6193E-01</td>\n",
       "      <td>4.2487E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffNN</th>\n",
       "      <td>101</td>\n",
       "      <td>4.8946E+00</td>\n",
       "      <td>4.2246E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        N_Params     T_Time  T_Test/T_test-MC\n",
       "ENET           6 4.6286E+00        5.5304E-03\n",
       "GBRF       67602 6.6005E-01        9.3637E-02\n",
       "kRidge        12 3.6193E-01        4.2487E-02\n",
       "ffNN         101 4.8946E+00        4.2246E+00"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_Complexity_models)\n",
    "Summary_Complexity_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean+Variance Based Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Feature Builder - Ready\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.1285s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Training Deep Gaussian Network!\n",
      "===============================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3904 - mse: 21.2414 - mae: 3.3904 - mape: 86.7245\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3890 - mse: 21.2315 - mae: 3.3890 - mape: 86.6528\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3877 - mse: 21.2213 - mae: 3.3877 - mape: 86.6140\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.3863 - mse: 21.2114 - mae: 3.3863 - mape: 86.5587\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.3849 - mse: 21.2015 - mae: 3.3849 - mape: 86.5023\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3835 - mse: 21.1914 - mae: 3.3835 - mape: 86.4307\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3821 - mse: 21.1813 - mae: 3.3821 - mape: 86.4002\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.3807 - mse: 21.1711 - mae: 3.3807 - mape: 86.3381\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3794 - mse: 21.1611 - mae: 3.3794 - mape: 86.2649\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3779 - mse: 21.1509 - mae: 3.3779 - mape: 86.2083\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.3765 - mse: 21.1405 - mae: 3.3765 - mape: 86.1687\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3751 - mse: 21.1300 - mae: 3.3751 - mape: 86.1025\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3736 - mse: 21.1194 - mae: 3.3736 - mape: 86.0358\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3722 - mse: 21.1085 - mae: 3.3722 - mape: 85.9854\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3707 - mse: 21.0979 - mae: 3.3707 - mape: 85.9247\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3692 - mse: 21.0868 - mae: 3.3692 - mape: 85.8587\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3677 - mse: 21.0760 - mae: 3.3677 - mape: 85.8074\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3661 - mse: 21.0647 - mae: 3.3661 - mape: 85.7573\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3646 - mse: 21.0533 - mae: 3.3646 - mape: 85.6949\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3630 - mse: 21.0421 - mae: 3.3630 - mape: 85.6421\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.3615 - mse: 21.0306 - mae: 3.3615 - mape: 85.5508\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3599 - mse: 21.0190 - mae: 3.3599 - mape: 85.5068\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.3583 - mse: 21.0074 - mae: 3.3583 - mape: 85.4358\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3567 - mse: 20.9955 - mae: 3.3567 - mape: 85.3703\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3550 - mse: 20.9833 - mae: 3.3550 - mape: 85.2949\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3533 - mse: 20.9714 - mae: 3.3533 - mape: 85.2489\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3516 - mse: 20.9588 - mae: 3.3516 - mape: 85.1821\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3499 - mse: 20.9465 - mae: 3.3499 - mape: 85.1062\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3482 - mse: 20.9337 - mae: 3.3482 - mape: 85.0279\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3464 - mse: 20.9209 - mae: 3.3464 - mape: 84.9689\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.3447 - mse: 20.9079 - mae: 3.3447 - mape: 84.9095\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3429 - mse: 20.8947 - mae: 3.3429 - mape: 84.8365\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3410 - mse: 20.8816 - mae: 3.3410 - mape: 84.7441\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3392 - mse: 20.8679 - mae: 3.3392 - mape: 84.6703\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3.3373 - mse: 20.8541 - mae: 3.3373 - mape: 84.6187\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3354 - mse: 20.8404 - mae: 3.3354 - mape: 84.5338\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3335 - mse: 20.8263 - mae: 3.3335 - mape: 84.4460\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3316 - mse: 20.8121 - mae: 3.3316 - mape: 84.3698\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3296 - mse: 20.7976 - mae: 3.3296 - mape: 84.3146\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3276 - mse: 20.7827 - mae: 3.3276 - mape: 84.2398\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3255 - mse: 20.7681 - mae: 3.3255 - mape: 84.1340\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3235 - mse: 20.7529 - mae: 3.3235 - mape: 84.0767\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.3214 - mse: 20.7374 - mae: 3.3214 - mape: 83.9736\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3193 - mse: 20.7218 - mae: 3.3193 - mape: 83.9237\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3171 - mse: 20.7063 - mae: 3.3171 - mape: 83.8018\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3150 - mse: 20.6905 - mae: 3.3150 - mape: 83.7449\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 3.3128 - mse: 20.6742 - mae: 3.3128 - mape: 83.6565\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.3105 - mse: 20.6578 - mae: 3.3105 - mape: 83.5579\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3083 - mse: 20.6415 - mae: 3.3083 - mape: 83.4726\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3059 - mse: 20.6240 - mae: 3.3059 - mape: 83.3819\n",
      "4/4 [==============================] - 0s 812us/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "====================================\n",
      "Training Deep Gaussian Network!: END\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      " Get Training Errors for: Gaussian Models\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1932.48it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 1802.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#---------------------------------------#\n",
      " Get Testing Errors for: Gaussian Models\n",
      "#---------------------------------------#\n",
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run Benchmarks_Model_Builder_Mean_Var.ipynb\n",
    "# exec(open('Benchmarks_Model_Builder_Mean_Var.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.48277365, 0.2283676 , 5.70200474, 0.        , 3.        ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summary_pred_Qual_models_DGN_train[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          N_Centers  N_Q  N_Params  Training Time  \\\n",
      "Model_Complexity_metrics         50  100      1130     7.3712E+00   \n",
      "\n",
      "                          T_Test/T_Test-MC  Time Test  Time EM-MC  \n",
      "Model_Complexity_metrics        6.4897E+00 6.5188E-02  1.0045E-02  \n",
      "              W1         M1      M1_MC        Var     Var_MC       Skew  \\\n",
      "Train 6.1491E-01 1.0902E+00 2.3797E-01 1.4873E+00 1.3361E+00 2.2883E-02   \n",
      "Test  7.3832E-01 5.6005E-02 1.0175E+00 5.0728E+00 6.2828E+00 1.2417E-02   \n",
      "\n",
      "         Skew_MC     Ex_Kur  Ex_Kur_MC       High  N_Centers  N_Q  N_Params  \\\n",
      "Train 2.8985E-02 5.6647E+00 5.8400E+00 5.9955E+02         50  100      1130   \n",
      "Test  3.1887E-02 5.9878E+00 5.8452E+00 7.0056E+02         50  100      1130   \n",
      "\n",
      "       Training Time  T_Test/T_Test-MC  Problem_Dimension  \n",
      "Train     7.3712E+00        6.4897E+00                  3  \n",
      "Test      7.3712E+00        6.4897E+00                  3  \n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------#\n",
    "W1_95 = bootstrap(W1_errors, n=1000, func=np.mean)(.95)\n",
    "W1_99 = bootstrap(W1_errors, n=1000, func=np.mean)(.99)\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "Model_Complexity = pd.DataFrame({\"N_Centers\":N_Quantizers_to_parameterize,\n",
    "                                 \"N_Q\":N_Monte_Carlo_Samples,\n",
    "                                 \"N_Params\":N_params_deep_classifier,\n",
    "                                 \"Training Time\":Time_Lapse_Model_A,\n",
    "                                 \"T_Test/T_Test-MC\": (timer_output/Test_Set_PredictionTime_MC),\n",
    "                                 \"Time Test\": timer_output,\n",
    "                                 \"Time EM-MC\": Test_Set_PredictionTime_MC},index=[\"Model_Complexity_metrics\"])\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "Summary = pd.DataFrame({\"W1\":np.array([np.mean(np.abs(W1_errors)),np.mean(np.abs(W1_errors_test))]),\n",
    "                        \"M1\":np.array([np.mean(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors_test))]),\n",
    "                        \"M1_MC\":np.array([np.mean(np.abs(Mean_errors_MC)),np.mean(np.abs(Mean_errors_MC_test))]),\n",
    "                        \"Var\":np.array([np.mean(np.abs(Var_errors)),np.mean(np.abs(Var_errors_test))]),\n",
    "                        \"Var_MC\":np.array([np.mean(np.abs(Var_errors_MC)),np.mean(np.abs(Var_errors_MC_test))]),\n",
    "                        \"Skew\":np.array([np.mean(np.abs(Skewness_errors)),np.mean(np.abs(Skewness_errors_test))]),\n",
    "                        \"Skew_MC\":np.array([np.mean(np.abs(Skewness_errors_MC)),np.mean(np.abs(Skewness_errors_MC_test))]),\n",
    "                        \"Ex_Kur\":np.array([np.mean(np.abs(Ex_Kurtosis_errors)),np.mean(np.abs(Ex_Kurtosis_errors_test))]),\n",
    "                        \"Ex_Kur_MC\":np.array([np.mean(np.abs(Ex_Kurtosis_errors_MC)),np.mean(np.abs(Ex_Kurtosis_errors_MC_test))]),\n",
    "                        \"High\": np.array([np.mean(np.abs(Higher_Moments_Errors)),np.mean(np.abs(Higher_Moments_test_Errors))]),\n",
    "                        \"N_Centers\":np.array((N_Quantizers_to_parameterize,N_Quantizers_to_parameterize)),\n",
    "                        \"N_Q\":np.array((N_Monte_Carlo_Samples,N_Monte_Carlo_Samples)),\n",
    "                        \"N_Params\":np.array((N_params_deep_classifier,N_params_deep_classifier)),\n",
    "                        \"Training Time\":np.array((Time_Lapse_Model_A,Time_Lapse_Model_A)),\n",
    "                        \"T_Test/T_Test-MC\":np.array(((timer_output/Test_Set_PredictionTime_MC),(timer_output/Test_Set_PredictionTime_MC))),\n",
    "                        \"Problem_Dimension\":np.array((problem_dim,problem_dim))\n",
    "                       },index=[\"Train\",\"Test\"])\n",
    "\n",
    "\n",
    "# Write Performance Metrics to file #\n",
    "#-----------------------------------#\n",
    "pd.set_option('display.float_format', '{:.4E}'.format)\n",
    "Model_Complexity.to_latex((results_tables_path+\"Latent_Width_NSDE\"+str(width)+\"Problemdimension\"+str(problem_dim)+\"__ModelComplexities.tex\"))\n",
    "pd.set_option('display.float_format', '{:.4E}'.format)\n",
    "Summary.to_latex((results_tables_path+\"Latent_Width_NSDE\"+str(width)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "print(Model_Complexity)\n",
    "print(Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>M1</th>\n",
       "      <th>M1_MC</th>\n",
       "      <th>Var</th>\n",
       "      <th>Var_MC</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Skew_MC</th>\n",
       "      <th>Ex_Kur</th>\n",
       "      <th>Ex_Kur_MC</th>\n",
       "      <th>High</th>\n",
       "      <th>N_Centers</th>\n",
       "      <th>N_Q</th>\n",
       "      <th>N_Params</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>T_Test/T_Test-MC</th>\n",
       "      <th>Problem_Dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>6.1491E-01</td>\n",
       "      <td>1.0902E+00</td>\n",
       "      <td>2.3797E-01</td>\n",
       "      <td>1.4873E+00</td>\n",
       "      <td>1.3361E+00</td>\n",
       "      <td>2.2883E-02</td>\n",
       "      <td>2.8985E-02</td>\n",
       "      <td>5.6647E+00</td>\n",
       "      <td>5.8400E+00</td>\n",
       "      <td>5.9955E+02</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>1130</td>\n",
       "      <td>7.3712E+00</td>\n",
       "      <td>6.4897E+00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>7.3832E-01</td>\n",
       "      <td>5.6005E-02</td>\n",
       "      <td>1.0175E+00</td>\n",
       "      <td>5.0728E+00</td>\n",
       "      <td>6.2828E+00</td>\n",
       "      <td>1.2417E-02</td>\n",
       "      <td>3.1887E-02</td>\n",
       "      <td>5.9878E+00</td>\n",
       "      <td>5.8452E+00</td>\n",
       "      <td>7.0056E+02</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>1130</td>\n",
       "      <td>7.3712E+00</td>\n",
       "      <td>6.4897E+00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              W1         M1      M1_MC        Var     Var_MC       Skew  \\\n",
       "Train 6.1491E-01 1.0902E+00 2.3797E-01 1.4873E+00 1.3361E+00 2.2883E-02   \n",
       "Test  7.3832E-01 5.6005E-02 1.0175E+00 5.0728E+00 6.2828E+00 1.2417E-02   \n",
       "\n",
       "         Skew_MC     Ex_Kur  Ex_Kur_MC       High  N_Centers  N_Q  N_Params  \\\n",
       "Train 2.8985E-02 5.6647E+00 5.8400E+00 5.9955E+02         50  100      1130   \n",
       "Test  3.1887E-02 5.9878E+00 5.8452E+00 7.0056E+02         50  100      1130   \n",
       "\n",
       "       Training Time  T_Test/T_Test-MC  Problem_Dimension  \n",
       "Train     7.3712E+00        6.4897E+00                  3  \n",
       "Test      7.3712E+00        6.4897E+00                  3  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance wrt Mean Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
