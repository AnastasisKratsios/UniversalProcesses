{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model (Type A)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "## 1) Generate Data:\n",
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)* by simulating from:\n",
    "$$ \n",
    "X_T = x + \\int_0^T \\alpha(s,x)ds + \\int_0^T\\beta(s,x)dW_s.\n",
    "$$\n",
    "\n",
    "## 2) Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "## 3) Train Deep Classifier:\n",
    "$\\hat{f}\\in \\operatorname{argmin}_{f \\in \\mathcal{NN}_{d:N}^{\\star}} \n",
    "\\sum_{x \\in \\mathbb{X}}\n",
    "\\, \n",
    "\\mathbb{H}\n",
    "\\left(\n",
    "    \\operatorname{Softmax}_N\\circ f(x)_n| I\\left\\{W_1(\\hat{\\mu}_n,\\mu_x),\\inf_{m\\leq N} W_1(\\hat{\\mu}_m,\\mu_x)\\right\\}\n",
    "\\right);\n",
    "$\n",
    "where $\\mathbb{H}$ is the categorical cross-entropy.  \n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "*This hyperparameter describes the proportion of the data used as sample-barycenters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantization_Proportion = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 2\n",
    "N_Monte_Carlo_Samples = 100\n",
    "\n",
    "N_Monte_Carlo_Samples_Test = 10 # How many MC-samples to draw from test-set?\n",
    "T_end = 1\n",
    "Direct_Sampling = True #This hyperparameter determines if we use a Euler-Maryama scheme or if we use something else.  \n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 20\n",
    "Max_Grid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDE Simulation Hyper-Parameter(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return np.sin(math.pi*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 1+ (x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run Backend:\n",
    "*Runs the backend with these pre-specified hyperparameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 51087.75it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 6478.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 336.53it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]Universal_Processes_Trainer_BACKEND.ipynb:26: RuntimeWarning: invalid value encountered in multiply\n",
      "  \"1. $\\\\mathcal{M}^{(0)}\\\\triangleq \\\\left\\\\{\\\\hat{\\\\mu}_n\\\\right\\\\}_{n=1}^N$,\\n\",\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 5051.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Classifier - Ready\n",
      "Deep Feature Builder - Ready\n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "â€¢ Grid Instances:  20 and : 15  Testing instances.\n",
      "â€¢ 20  Centers will be produced; from a total datasize of:  20 !  (That's  1  percent).\n",
      "â€¢ Each Wasserstein-1 Ball should contain:  1 elements from the training set.\n",
      "Current Monte-Carlo Step:\n",
      "Using Monte-Carlo Sampling directly from measure at time-T of X_T.\n",
      "Done Simulation Step (Train Set)\n",
      "Done Simulation Step (Test Set)\n",
      "ðŸ˜š  Begin Building Distance Matrix  ðŸ˜š\n",
      "ðŸ˜€  Done Building Distance Matrix ðŸ˜€ !\n",
      "ðŸ˜š  Begin Identifying Sample Barycenters  ðŸ˜š\n",
      "ðŸ˜€  Done Identifying Sample Barycenters ðŸ˜€ !\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0037 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9945 - accuracy: 0.0500\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9857 - accuracy: 0.0500\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9771 - accuracy: 0.0500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9688 - accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9607 - accuracy: 0.1000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9527 - accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9448 - accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9369 - accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9290 - accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9209 - accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9128 - accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9045 - accuracy: 0.1000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8961 - accuracy: 0.1000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8875 - accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8785 - accuracy: 0.1000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8694 - accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8599 - accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8501 - accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8400 - accuracy: 0.1000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8297 - accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8192 - accuracy: 0.1000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8085 - accuracy: 0.1000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7974 - accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7860 - accuracy: 0.1000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7742 - accuracy: 0.1000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7622 - accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7499 - accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7373 - accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7245 - accuracy: 0.1000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7114 - accuracy: 0.1000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6980 - accuracy: 0.1000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6845 - accuracy: 0.1000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6707 - accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6568 - accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6427 - accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6286 - accuracy: 0.1000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6143 - accuracy: 0.1000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5999 - accuracy: 0.1000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5855 - accuracy: 0.1000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5711 - accuracy: 0.1000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5567 - accuracy: 0.1000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5424 - accuracy: 0.1000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5282 - accuracy: 0.1000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5140 - accuracy: 0.1000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5000 - accuracy: 0.1000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4861 - accuracy: 0.1000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4725 - accuracy: 0.1000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4591 - accuracy: 0.1000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4460 - accuracy: 0.1000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4331 - accuracy: 0.1000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4206 - accuracy: 0.1000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4083 - accuracy: 0.1000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3964 - accuracy: 0.1000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3848 - accuracy: 0.1000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3735 - accuracy: 0.1000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3625 - accuracy: 0.1000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3517 - accuracy: 0.1000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3411 - accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3308 - accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3206 - accuracy: 0.1000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3107 - accuracy: 0.1000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3009 - accuracy: 0.1000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2911 - accuracy: 0.1000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2815 - accuracy: 0.1000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2721 - accuracy: 0.1000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2629 - accuracy: 0.1000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2538 - accuracy: 0.1000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2446 - accuracy: 0.1000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2356 - accuracy: 0.1000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2267 - accuracy: 0.1000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2177 - accuracy: 0.1000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2086 - accuracy: 0.1500\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1996 - accuracy: 0.1500\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1907 - accuracy: 0.1500\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1818 - accuracy: 0.1500\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1729 - accuracy: 0.1500\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1641 - accuracy: 0.1500\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1553 - accuracy: 0.1500\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1463 - accuracy: 0.1500\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1374 - accuracy: 0.20 - 0s 1ms/step - loss: 2.1374 - accuracy: 0.2000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1285 - accuracy: 0.2000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1194 - accuracy: 0.2000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1103 - accuracy: 0.2000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1011 - accuracy: 0.2000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0918 - accuracy: 0.2000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0825 - accuracy: 0.2000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0730 - accuracy: 0.2500\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0635 - accuracy: 0.2500\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.0538 - accuracy: 0.3000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0441 - accuracy: 0.2500\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0344 - accuracy: 0.2500\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0245 - accuracy: 0.2500\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0146 - accuracy: 0.2500\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0047 - accuracy: 0.3000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9947 - accuracy: 0.3000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9846 - accuracy: 0.3000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9745 - accuracy: 0.3500\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9643 - accuracy: 0.3500\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9540 - accuracy: 0.3500\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 927us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 20748.47it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 21312.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: START\n",
      "#-----------------------------#\n",
      "#-----------------------------#\n",
      "Building Barycenters Set: END\n",
      "#-----------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 2172.68it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 2243.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "MAE   2.738511    0.863788             3.675043                1.352477   \n",
      "MSE  10.360077    1.157235            74.053032                2.064650   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "MAE              1.501028  \n",
      "MSE              2.453061  \n",
      "Building Test Set Performance Metrics\n",
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "            W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "MAE   2.738511    0.863788             3.675043                1.352477   \n",
      "MSE  10.360077    1.157235            74.053032                2.064650   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "MAE              1.501028  \n",
      "MSE              2.453061  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "           W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "MAE  0.852336    0.597638             1.001325                1.247780   \n",
      "MSE  1.085202    0.494858             2.105905                1.660948   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "MAE              1.299928  \n",
      "MSE              1.818999  \n",
      " \n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use is user prefers GUI\n",
    "%run Universal_Processes_Trainer_BACKEND.ipynb\n",
    "# Use for faster/shorter execution times (note: more amenable to terminal)\n",
    "# exec(open('Universal_Processes_Trainer_BACKEND.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
