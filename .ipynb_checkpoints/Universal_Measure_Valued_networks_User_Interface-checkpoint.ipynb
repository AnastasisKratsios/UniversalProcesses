{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Universal Regular Conditional Expectations:\n",
    "\n",
    "---\n",
    "This implements the universal deep neural model of $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$ [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---\n",
    "\n",
    "## What does this code do?\n",
    "1. Learn Heteroskedastic Non-Linear Regression Problem\n",
    "     - $Y\\sim f_{\\text{unkown}}(x) + \\epsilon$ where $f$ is an known function and $\\epsilon\\sim Laplace(0,\\|x\\|)$\n",
    "2. Learn Random Bayesian Network's Law:\n",
    "    - $Y = W_J Y^{J-1}, \\qquad Y^{j}\\triangleq \\sigma\\bullet A^{j}Y^{j-1} + b^{j}, \\qquad Y^0\\triangleq x$\n",
    "\n",
    "3. In the above example if $A_j = M_j\\odot \\tilde{A_j}$ where $\\tilde{A}_j$ is a deterministic matrix and $M_j$ is a \"mask\", that is, a random matrix with binary entries and $\\odot$ is the Hadamard product then we recover the dropout framework.\n",
    "4. Learn the probability distribution that the unique strong solution to the rough SDE with uniformly Lipschitz drivers driven by a factional Brownian motion with Hurst exponent $H \\in [\\frac1{2},1)$:\n",
    "$$\n",
    "X_t^x = x + \\int_0^t \\alpha(s,X_s^x)ds + \\int_0^t \\beta(s,X_s^x)dB_s^H\n",
    "$$\n",
    "belongs, at time $t=1$, to a ball about the initial point $x$ of random radius given by an independant exponential random-variable with shape parameter $\\lambda=2$\n",
    "5. Train a DNN to predict the returns of bitcoin with GD.  Since this has random initialization then each prediction of a given $x$ is stochastic...We learn the distribution of this conditional RV (conditioned on x in the input space).\n",
    "$$\n",
    "Y_x \\triangleq \\hat{f}_{\\theta_{T}}(x), \\qquad \\theta_{(t+1)}\\triangleq \\theta_{(t)} + \\lambda \\sum_{x \\in \\mathbb{X}} \\nabla_{\\theta}\\|\\hat{f}_{\\theta_t}(x) - f(x)\\|, \\qquad \\theta_0 \\sim N_d(0,1);\n",
    "$$\n",
    "$T\\in \\mathbb{N}$ is a fixed number of \"SGD\" iterations (typically identified by cross-validation on a single SGD trajectory for a single initialization) and where $\\theta \\in \\mathbb{R}^{(d_{J}+1)+\\sum_{j=0}^{J-1} (d_{j+1}d_j + 1)}$ and $d_j$ is the dimension of the \"bias\" vector $b_j$ defining each layer of the DNN with layer dimensions:\n",
    "$$\n",
    "\\hat{f}_{\\theta}(x)\\triangleq A^{(J)}x^{(J)} + b^{(J)},\\qquad x^{(j+1)}\\triangleq \\sigma\\bullet A^{j}x^{(j)} + b^{j},\\qquad x^{(0)}\\triangleq x\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode:\n",
    "Software/Hardware Testing or Real-Deal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random DNN\n",
    "# f_unknown_mode = \"Heteroskedastic_NonLinear_Regression\"\n",
    "\n",
    "# Random DNN internal noise\n",
    "#f_unknown_mode = \"DNN_with_Random_Weights\"\n",
    "Depth_Bayesian_DNN = 1\n",
    "width = 5\n",
    "\n",
    "# Random Dropout applied to trained DNN\n",
    "f_unknown_mode = \"DNN_with_Bayesian_Dropout\"\n",
    "Dropout_rate = 0.1\n",
    "\n",
    "# GD with Randomized Input\n",
    "# f_unknown_mode = \"GD_with_randomized_input\"\n",
    "GD_epochs = 50\n",
    "\n",
    "# SDE with fractional Driver\n",
    "# f_unknown_mode = \"Rough_SDE\"\n",
    "N_Euler_Steps = 10**2\n",
    "Hurst_Exponent = 0.75\n",
    "\n",
    "#f_unknown_mode = \"Rough_SDE_Vanilla\"\n",
    "## Define Process' dynamics in (2) cell(s) below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla fractional SDE:\n",
    "If f_unknown_mode == \"Rough_SDE_Vanilla\" is selected, then we can specify the process's dynamics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------#\n",
    "# Define Process' Dynamics #\n",
    "#--------------------------#\n",
    "drift_constant = 0.1\n",
    "volatility_constant = 0.01\n",
    "\n",
    "# Define DNN Applier\n",
    "def f_unknown_drift_vanilla(x):\n",
    "    x_internal = x\n",
    "    x_internal = drift_constant*x_internal\n",
    "    return x_internal\n",
    "def f_unknown_vol_vanilla(x):\n",
    "    x_internal = volatility_constant*np.diag(np.ones(problem_dim))\n",
    "    return x_internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: *Why the procedure is so computationally efficient*?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)\n",
    "- Ratio $\\frac{\\text{Testing Datasize}}{\\text{Training Datasize}}$.\n",
    "- Number of Training Points to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = .1\n",
    "N_train_size = 10**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Monte_Carlo_Samples = 10**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial radis of $\\delta$-bounded random partition of $\\mathcal{X}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "Proportion_per_cluster = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and Auxiliary Script(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "Deep Feature Builder - Ready\n"
     ]
    }
   ],
   "source": [
    "# %run Loader.ipynb\n",
    "exec(open('Loader.py').read())\n",
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "import time as time #<- Note sure why...but its always seems to need 'its own special loading...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate or Parse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<01:10, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Beginning Data-Parsing/Simulation Phase\n",
      "---------------------------------------\n",
      "Deciding on Which Simulator/Parser To Load\n",
      "Setting/Defining: Internal Parameters\n",
      "Deciding on Which Type of Data to Get/Simulate\n",
      "Simulating Output Data for given input data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:08<00:00, 14.69it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 15.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Done Data-Parsing/Simulation Phase\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %run Data_Simulator_and_Parser.ipynb\n",
    "exec(open('Data_Simulator_and_Parser.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Data\n",
    "This is especially important to avoid exploding gradient problems when training the ML-models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Running script for main model!\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 7473.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "==========================================\n",
      "Training Classifer Portion of Type-A Model\n",
      "==========================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   21.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   21.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2261 - accuracy: 0.0070\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.0112 - accuracy: 0.0210\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.3402 - accuracy: 0.0700\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2302 - accuracy: 0.2160\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9372 - accuracy: 0.4250\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8905 - accuracy: 0.5820\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2294 - accuracy: 0.7470\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8646 - accuracy: 0.8240\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.8940\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.9190\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.9380\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.9610\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.9590\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9790\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1697 - accuracy: 0.9760\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9850\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9820\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9790\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9870\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9900\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9910\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9960\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9980\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9970\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9970\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9980\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9990\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9940\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9950\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9950\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9980\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9990\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9970\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9940\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9970\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9960\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9870\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9930\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9920\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9860\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9580\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9440\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.9320\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.9530\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9700\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9820\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9960\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9990\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9990\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9980\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9920\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.8390\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.8040\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.9170\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9810\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9910\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9990\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "Epoch 99/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9990\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.7701e-04 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.4213e-04 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.0325e-04 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.7790e-04 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.4769e-04 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.1531e-04 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.8868e-04 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6312e-04 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.3666e-04 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.1219e-04 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.9013e-04 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.6730e-04 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.4548e-04 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.3040e-04 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.0389e-04 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8905e-04 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.7840e-04 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5112e-04 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.3582e-04 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1966e-04 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.0149e-04 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9113e-04 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7458e-04 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.5845e-04 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.4116e-04 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.3450e-04 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2019e-04 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.0603e-04 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.9629e-04 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.8941e-04 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.7239e-04 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.7131e-04 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.4764e-04 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.4504e-04 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.3747e-04 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.2659e-04 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.1380e-04 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.1000e-04 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9895e-04 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9089e-04 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.7531e-04 - accuracy: 1.0000\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 2.7221e-04 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6352e-04 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5674e-04 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4722e-04 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4161e-04 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3258e-04 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2737e-04 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2133e-04 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1472e-04 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1012e-04 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0546e-04 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9627e-04 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9170e-04 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8933e-04 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7973e-04 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7307e-04 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6928e-04 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6515e-04 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6371e-04 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5570e-04 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5520e-04 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4887e-04 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4216e-04 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3721e-04 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3506e-04 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3179e-04 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2689e-04 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2509e-04 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1736e-04 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1647e-04 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1333e-04 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1024e-04 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0543e-04 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0382e-04 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0201e-04 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.8938e-05 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.4311e-05 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.2000e-05 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.8206e-05 - accuracy: 1.0000\n",
      "63/63 [==============================] - 0s 717us/step\n",
      "7/7 [==============================] - 0s 975us/step\n",
      "===============================================\n",
      "Training Classifer Portion of Type Model: Done!\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:06<00:00,  7.91it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#----------------#\n",
      " Get Test Error(s)\n",
      "#----------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n",
      "                                         DNM  MC-Oracle\n",
      "W1-95L                              0.000000   0.000000\n",
      "W1                                  0.000000   0.000000\n",
      "W1-95R                              0.000000   0.000000\n",
      "M-95L                               0.000000   0.000000\n",
      "M                                   0.000000   0.000000\n",
      "M-95R                               0.000000   0.000000\n",
      "N_Par                          142900.000000   0.000000\n",
      "Train_Time                        196.867494  74.692599\n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000\n",
      "------------------------------------\n",
      "Done: Running script for main model!\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------\")\n",
    "print(\"Running script for main model!\")\n",
    "print(\"------------------------------\")\n",
    "# %run Universal_Measure_Valued_Networks_Backend.ipynb\n",
    "exec(open('Universal_Measure_Valued_Networks_Backend.py').read())\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Done: Running script for main model!\")\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run: All Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) *Pointmass Benchmark(s)*\n",
    "These benchmarks consist of subsets of $C(\\mathbb{R}^d,\\mathbb{R})$ which we lift to models in $C(\\mathbb{R}^d,\\cap_{1\\leq q<\\infty}\\mathscr{P}_{q}(\\mathbb{R}))$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to f(x) \\to \\delta_{f(x)}\\in \\cap_{1\\leq q<\\infty}\\mathcal{P}_{q}(\\mathbb{R}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "--------------\n",
      "Training: ENET\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 269/1000 [00:00<00:00, 2684.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Training: ENET - Done\n",
      "---------------------\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4222.09it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 3207.17it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0864s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                         DNM  MC-Oracle          ENET\n",
      "W1-95L                              0.000000   0.000000  1.709752e-14\n",
      "W1                                  0.000000   0.000000  1.709752e-14\n",
      "W1-95R                              0.000000   0.000000  1.709752e-14\n",
      "M-95L                               0.000000   0.000000  1.307575e-07\n",
      "M                                   0.000000   0.000000  1.307575e-07\n",
      "M-95R                               0.000000   0.000000  1.307575e-07\n",
      "N_Par                          142900.000000   0.000000  2.000000e+03\n",
      "Train_Time                        196.867494  74.692599  1.620045e+09\n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05\n",
      "-----------------\n",
      "Training: K-Ridge\n",
      "-----------------\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s finished\n",
      " 85%|████████▌ | 854/1000 [00:00<00:00, 4528.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4229.12it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 3681.89it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                         DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
      "W1                                  0.000000   0.000000  1.709752e-14   \n",
      "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
      "M-95L                               0.000000   0.000000  1.307575e-07   \n",
      "M                                   0.000000   0.000000  1.307575e-07   \n",
      "M-95R                               0.000000   0.000000  1.307575e-07   \n",
      "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
      "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
      "\n",
      "                                     KRidge  \n",
      "W1-95L                         1.169624e-09  \n",
      "W1                             1.535477e-09  \n",
      "W1-95R                         2.124551e-09  \n",
      "M-95L                          2.741548e-05  \n",
      "M                              3.126684e-05  \n",
      "M-95R                          3.713166e-05  \n",
      "N_Par                          0.000000e+00  \n",
      "Train_Time                     1.351780e+00  \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  \n",
      "--------------\n",
      "Training: GBRF\n",
      "--------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.3s finished\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5511.51it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3486.33it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                         DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
      "W1                                  0.000000   0.000000  1.709752e-14   \n",
      "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
      "M-95L                               0.000000   0.000000  1.307575e-07   \n",
      "M                                   0.000000   0.000000  1.307575e-07   \n",
      "M-95R                               0.000000   0.000000  1.307575e-07   \n",
      "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
      "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF  \n",
      "W1-95L                         1.169624e-09  1.709752e-14  \n",
      "W1                             1.535477e-09  1.709752e-14  \n",
      "W1-95R                         2.124551e-09  1.709752e-14  \n",
      "M-95L                          2.741548e-05  1.307575e-07  \n",
      "M                              3.126684e-05  1.307575e-07  \n",
      "M-95R                          3.713166e-05  1.307575e-07  \n",
      "N_Par                          0.000000e+00  1.000000e+04  \n",
      "Train_Time                     1.351780e+00  7.231278e-01  \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  \n",
      "-------------\n",
      "Training: DNN\n",
      "-------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   13.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   13.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0158 - mse: 3.8744e-04 - mae: 0.0158 - mape: 15777104.0000\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0058 - mse: 6.2280e-05 - mae: 0.0058 - mape: 5832541.0000\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 4.4150e-06 - mae: 0.0016 - mape: 1620176.8750\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 4.1036e-06 - mae: 0.0016 - mape: 1552260.7500\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 3.9175e-06 - mae: 0.0015 - mape: 1533865.7500\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 3.8221e-06 - mae: 0.0015 - mape: 1497656.7500\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 3.6480e-06 - mae: 0.0015 - mape: 1468448.5000\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 3.4316e-06 - mae: 0.0014 - mape: 1415886.3750\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 3.2439e-06 - mae: 0.0014 - mape: 1398163.0000\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0014 - mse: 3.2366e-06 - mae: 0.0014 - mape: 1383710.3750\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 2.9912e-06 - mae: 0.0013 - mape: 1334480.0000\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 2.9704e-06 - mae: 0.0013 - mape: 1313535.0000\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 2.7786e-06 - mae: 0.0013 - mape: 1277227.3750 \n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0013 - mse: 2.7451e-06 - mae: 0.0013 - mape: 1276540.3750\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 2.5632e-06 - mae: 0.0012 - mape: 1227731.8750 \n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 2.4344e-06 - mae: 0.0012 - mape: 1187373.5000\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 2.2930e-06 - mae: 0.0012 - mape: 1164010.1250 \n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0012 - mse: 2.2425e-06 - mae: 0.0012 - mape: 1153312.5000\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 2.0609e-06 - mae: 0.0011 - mape: 1091371.7500\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 2.0131e-06 - mae: 0.0011 - mape: 1098228.5000\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0011 - mse: 1.8808e-06 - mae: 0.0011 - mape: 1050572.5000\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0010 - mse: 1.7485e-06 - mae: 0.0010 - mape: 1016551.3750\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 9.9707e-04 - mse: 1.7115e-06 - mae: 9.9707e-04 - mape: 996458.0625\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 9.6774e-04 - mse: 1.6143e-06 - mae: 9.6774e-04 - mape: 967718.3750\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 9.5373e-04 - mse: 1.5646e-06 - mae: 9.5373e-04 - mape: 953295.4375\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 9.1899e-04 - mse: 1.4470e-06 - mae: 9.1899e-04 - mape: 918835.4375\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 9.0149e-04 - mse: 1.3909e-06 - mae: 9.0149e-04 - mape: 901436.9375\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.9488e-04 - mse: 1.3458e-06 - mae: 8.9488e-04 - mape: 894691.3750\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.6184e-04 - mse: 1.2691e-06 - mae: 8.6184e-04 - mape: 861360.6250\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.2418e-04 - mse: 1.1497e-06 - mae: 8.2418e-04 - mape: 823959.9375\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.0325e-04 - mse: 1.1005e-06 - mae: 8.0325e-04 - mape: 803165.8125\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.7902e-04 - mse: 1.0376e-06 - mae: 7.7902e-04 - mape: 778902.8750\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.5867e-04 - mse: 9.8682e-07 - mae: 7.5867e-04 - mape: 758607.5000\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.5242e-04 - mse: 9.6992e-07 - mae: 7.5242e-04 - mape: 752099.4375\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.3415e-04 - mse: 9.1412e-07 - mae: 7.3415e-04 - mape: 734101.8125\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.1235e-04 - mse: 8.8063e-07 - mae: 7.1235e-04 - mape: 712335.8750\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 6.7657e-04 - mse: 7.8974e-07 - mae: 6.7657e-04 - mape: 676427.3125\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 6.6487e-04 - mse: 7.4798e-07 - mae: 6.6487e-04 - mape: 664853.1875\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 6.5399e-04 - mse: 7.5397e-07 - mae: 6.5399e-04 - mape: 653188.5000\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 6.2806e-04 - mse: 6.9097e-07 - mae: 6.2806e-04 - mape: 627351.5625\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 6.2159e-04 - mse: 6.6708e-07 - mae: 6.2159e-04 - mape: 620794.5000\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 5.6831e-04 - mse: 5.6780e-07 - mae: 5.6831e-04 - mape: 567680.4375\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 5.5207e-04 - mse: 5.3545e-07 - mae: 5.5207e-04 - mape: 551437.8125\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 5.6311e-04 - mse: 5.5430e-07 - mae: 5.6311e-04 - mape: 562791.8750\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 5.4622e-04 - mse: 4.8196e-07 - mae: 5.4622e-04 - mape: 546126.8125\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 5.0837e-04 - mse: 4.4801e-07 - mae: 5.0837e-04 - mape: 508161.7500\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 5.0825e-04 - mse: 4.4531e-07 - mae: 5.0825e-04 - mape: 508020.1562\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 4.9630e-04 - mse: 4.4061e-07 - mae: 4.9630e-04 - mape: 496011.9062\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 4.7960e-04 - mse: 3.9005e-07 - mae: 4.7960e-04 - mape: 479415.3750\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 4.5132e-04 - mse: 3.5438e-07 - mae: 4.5132e-04 - mape: 451297.4062\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 4.3873e-04 - mse: 3.3224e-07 - mae: 4.3873e-04 - mape: 438713.6562\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 4.3007e-04 - mse: 3.2265e-07 - mae: 4.3007e-04 - mape: 430006.5625\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 4.2863e-04 - mse: 3.2352e-07 - mae: 4.2863e-04 - mape: 428441.5938\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 4.0066e-04 - mse: 2.7664e-07 - mae: 4.0066e-04 - mape: 400524.0000\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 3.9634e-04 - mse: 2.6954e-07 - mae: 3.9634e-04 - mape: 396248.5625\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 3.7935e-04 - mse: 2.5219e-07 - mae: 3.7935e-04 - mape: 379111.8750\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 3.5165e-04 - mse: 2.1766e-07 - mae: 3.5165e-04 - mape: 351650.7188\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 3.7444e-04 - mse: 2.3322e-07 - mae: 3.7444e-04 - mape: 374355.9688\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 3.3580e-04 - mse: 1.8909e-07 - mae: 3.3580e-04 - mape: 335552.7500\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 3.3720e-04 - mse: 1.9616e-07 - mae: 3.3720e-04 - mape: 336676.8125\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.9618e-04 - mse: 1.5845e-07 - mae: 2.9618e-04 - mape: 296172.1875\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 3.0949e-04 - mse: 1.6346e-07 - mae: 3.0949e-04 - mape: 309324.9375\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 3.0547e-04 - mse: 1.5696e-07 - mae: 3.0547e-04 - mape: 305077.0312\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.8132e-04 - mse: 1.3456e-07 - mae: 2.8132e-04 - mape: 281046.3125\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.6261e-04 - mse: 1.1934e-07 - mae: 2.6261e-04 - mape: 262388.2500\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.5853e-04 - mse: 1.1480e-07 - mae: 2.5853e-04 - mape: 258382.4219\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.4837e-04 - mse: 1.0602e-07 - mae: 2.4837e-04 - mape: 248309.8906\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.3918e-04 - mse: 9.7925e-08 - mae: 2.3918e-04 - mape: 238993.2188\n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.2721e-04 - mse: 8.8378e-08 - mae: 2.2721e-04 - mape: 227183.1562\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.1759e-04 - mse: 7.8863e-08 - mae: 2.1759e-04 - mape: 217253.6250\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.1252e-04 - mse: 7.6545e-08 - mae: 2.1252e-04 - mape: 212134.5469\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.2010e-04 - mse: 8.2607e-08 - mae: 2.2010e-04 - mape: 220047.6406\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.1711e-04 - mse: 8.2783e-08 - mae: 2.1711e-04 - mape: 217044.1406\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.0608e-04 - mse: 7.0668e-08 - mae: 2.0608e-04 - mape: 205914.9844\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.0213e-04 - mse: 6.7579e-08 - mae: 2.0213e-04 - mape: 201768.7344\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.7577e-04 - mse: 5.3846e-08 - mae: 1.7577e-04 - mape: 175520.6562\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.9150e-04 - mse: 6.0226e-08 - mae: 1.9150e-04 - mape: 191293.1406\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.7490e-04 - mse: 5.0592e-08 - mae: 1.7490e-04 - mape: 174897.2031\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.7983e-04 - mse: 5.3991e-08 - mae: 1.7983e-04 - mape: 179793.8281\n",
      "Epoch 80/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.6046e-04 - mse: 4.1819e-08 - mae: 1.6046e-04 - mape: 160130.6562\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.7486e-04 - mse: 4.9968e-08 - mae: 1.7486e-04 - mape: 174761.2656\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.7001e-04 - mse: 4.6017e-08 - mae: 1.7001e-04 - mape: 169822.6719\n",
      "Epoch 83/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.8288e-04 - mse: 5.4489e-08 - mae: 1.8288e-04 - mape: 182464.3906\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.6624e-04 - mse: 4.4074e-08 - mae: 1.6624e-04 - mape: 166089.1562\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3667e-04 - mse: 3.0780e-08 - mae: 1.3667e-04 - mape: 136460.9688\n",
      "Epoch 86/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.5980e-04 - mse: 4.0866e-08 - mae: 1.5980e-04 - mape: 159652.3125\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.5970e-04 - mse: 4.0548e-08 - mae: 1.5970e-04 - mape: 159524.4844\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.4330e-04 - mse: 3.3013e-08 - mae: 1.4330e-04 - mape: 143295.0781\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.4091e-04 - mse: 3.2089e-08 - mae: 1.4091e-04 - mape: 140872.6562\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3883e-04 - mse: 3.0297e-08 - mae: 1.3883e-04 - mape: 138724.2812\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.5157e-04 - mse: 3.6827e-08 - mae: 1.5157e-04 - mape: 151374.7656\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3669e-04 - mse: 3.0159e-08 - mae: 1.3669e-04 - mape: 136403.1250\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2956e-04 - mse: 2.8330e-08 - mae: 1.2956e-04 - mape: 129513.5781\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.5877e-04 - mse: 4.0599e-08 - mae: 1.5877e-04 - mape: 158420.3125\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.4852e-04 - mse: 3.6216e-08 - mae: 1.4852e-04 - mape: 148410.2656\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3485e-04 - mse: 2.9836e-08 - mae: 1.3485e-04 - mape: 134818.3906\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.4519e-04 - mse: 3.4891e-08 - mae: 1.4519e-04 - mape: 145055.9375\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2885e-04 - mse: 2.7758e-08 - mae: 1.2885e-04 - mape: 128678.5234\n",
      "Epoch 99/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.4193e-04 - mse: 3.2683e-08 - mae: 1.4193e-04 - mape: 141735.7812\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3773e-04 - mse: 3.1108e-08 - mae: 1.3773e-04 - mape: 137470.7969\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.5907e-04 - mse: 4.0908e-08 - mae: 1.5907e-04 - mape: 159006.3594\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.4933e-04 - mse: 3.5309e-08 - mae: 1.4933e-04 - mape: 149182.0469\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1511e-04 - mse: 2.1910e-08 - mae: 1.1511e-04 - mape: 114893.8281\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3277e-04 - mse: 2.9308e-08 - mae: 1.3277e-04 - mape: 132595.6719\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3157e-04 - mse: 2.8632e-08 - mae: 1.3157e-04 - mape: 131432.0312\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1783e-04 - mse: 2.2737e-08 - mae: 1.1783e-04 - mape: 117707.0703\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.6276e-04 - mse: 4.2023e-08 - mae: 1.6276e-04 - mape: 162426.1094\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3520e-04 - mse: 3.0564e-08 - mae: 1.3520e-04 - mape: 135163.5625\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1922e-04 - mse: 2.3577e-08 - mae: 1.1922e-04 - mape: 119219.3906\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2641e-04 - mse: 2.5384e-08 - mae: 1.2641e-04 - mape: 126274.5234\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.4636e-04 - mse: 3.5720e-08 - mae: 1.4636e-04 - mape: 146152.2500\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1058e-04 - mse: 2.0249e-08 - mae: 1.1058e-04 - mape: 110492.3438\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2180e-04 - mse: 2.4327e-08 - mae: 1.2180e-04 - mape: 121650.0859\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3363e-04 - mse: 2.8946e-08 - mae: 1.3363e-04 - mape: 133619.0625\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1831e-04 - mse: 2.2416e-08 - mae: 1.1831e-04 - mape: 118042.7969\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1255e-04 - mse: 2.0814e-08 - mae: 1.1255e-04 - mape: 112492.6719\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2120e-04 - mse: 2.3636e-08 - mae: 1.2120e-04 - mape: 121172.5781\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 1.5480e-04 - mse: 3.9483e-08 - mae: 1.5480e-04 - mape: 154611.0781\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3281e-04 - mse: 2.9308e-08 - mae: 1.3281e-04 - mape: 132775.9531\n",
      "Epoch 120/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3913e-04 - mse: 3.1735e-08 - mae: 1.3913e-04 - mape: 138980.5469\n",
      "Epoch 121/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1894e-04 - mse: 2.3691e-08 - mae: 1.1894e-04 - mape: 118722.4609\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2330e-04 - mse: 2.5567e-08 - mae: 1.2330e-04 - mape: 123068.0625\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3679e-04 - mse: 3.0047e-08 - mae: 1.3679e-04 - mape: 136769.6250\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1694e-04 - mse: 2.2455e-08 - mae: 1.1694e-04 - mape: 116709.2656\n",
      "Epoch 125/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2933e-04 - mse: 2.8167e-08 - mae: 1.2933e-04 - mape: 129284.2812\n",
      "Epoch 126/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3590e-04 - mse: 3.0426e-08 - mae: 1.3590e-04 - mape: 135586.5156\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2481e-04 - mse: 2.4922e-08 - mae: 1.2481e-04 - mape: 124592.4609\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3499e-04 - mse: 3.0031e-08 - mae: 1.3499e-04 - mape: 134897.6562\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3425e-04 - mse: 3.0837e-08 - mae: 1.3425e-04 - mape: 134107.6250\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2886e-04 - mse: 2.7094e-08 - mae: 1.2886e-04 - mape: 128716.7344\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1553e-04 - mse: 2.1621e-08 - mae: 1.1553e-04 - mape: 115445.7344\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2108e-04 - mse: 2.3674e-08 - mae: 1.2108e-04 - mape: 120948.9922\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3315e-04 - mse: 2.8185e-08 - mae: 1.3315e-04 - mape: 133032.2031\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2315e-04 - mse: 2.4616e-08 - mae: 1.2315e-04 - mape: 123111.8984\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1600e-04 - mse: 2.2105e-08 - mae: 1.1600e-04 - mape: 115911.3438\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3916e-04 - mse: 3.2262e-08 - mae: 1.3916e-04 - mape: 139148.7812\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1492e-04 - mse: 2.1127e-08 - mae: 1.1492e-04 - mape: 114868.0859\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1769e-04 - mse: 2.2691e-08 - mae: 1.1769e-04 - mape: 117607.9766\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1880e-04 - mse: 2.3763e-08 - mae: 1.1880e-04 - mape: 118663.8906\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2003e-04 - mse: 2.4337e-08 - mae: 1.2003e-04 - mape: 119908.8672\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2447e-04 - mse: 2.5468e-08 - mae: 1.2447e-04 - mape: 124280.3984\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3796e-04 - mse: 3.0581e-08 - mae: 1.3796e-04 - mape: 137912.9531\n",
      "Epoch 143/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2731e-04 - mse: 2.7620e-08 - mae: 1.2731e-04 - mape: 127172.2031\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2520e-04 - mse: 2.4330e-08 - mae: 1.2520e-04 - mape: 124868.8203\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3768e-04 - mse: 3.0562e-08 - mae: 1.3768e-04 - mape: 137270.9219\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2593e-04 - mse: 2.6339e-08 - mae: 1.2593e-04 - mape: 125679.5859\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2704e-04 - mse: 2.6552e-08 - mae: 1.2704e-04 - mape: 126841.5703\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2075e-04 - mse: 2.3925e-08 - mae: 1.2075e-04 - mape: 120685.1172\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2379e-04 - mse: 2.5179e-08 - mae: 1.2379e-04 - mape: 123742.2031\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1506e-04 - mse: 2.1162e-08 - mae: 1.1506e-04 - mape: 115059.0547\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3716e-04 - mse: 3.0913e-08 - mae: 1.3716e-04 - mape: 137106.2500\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0321e-04 - mse: 1.7148e-08 - mae: 1.0321e-04 - mape: 102968.4453\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0413e-04 - mse: 1.7836e-08 - mae: 1.0413e-04 - mape: 104055.1797\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3077e-04 - mse: 2.7796e-08 - mae: 1.3077e-04 - mape: 130711.2578\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3279e-04 - mse: 2.7378e-08 - mae: 1.3279e-04 - mape: 132778.0469\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2094e-04 - mse: 2.4276e-08 - mae: 1.2094e-04 - mape: 120820.4453\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2057e-04 - mse: 2.2633e-08 - mae: 1.2057e-04 - mape: 120474.8594\n",
      "Epoch 158/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0575e-04 - mse: 1.8274e-08 - mae: 1.0575e-04 - mape: 105518.7734\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2513e-04 - mse: 2.4458e-08 - mae: 1.2513e-04 - mape: 125036.3828\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1628e-04 - mse: 2.2027e-08 - mae: 1.1628e-04 - mape: 116033.5703\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3198e-04 - mse: 2.7796e-08 - mae: 1.3198e-04 - mape: 131839.9219\n",
      "Epoch 162/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2230e-04 - mse: 2.3858e-08 - mae: 1.2230e-04 - mape: 121916.1250\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2428e-04 - mse: 2.6476e-08 - mae: 1.2428e-04 - mape: 123920.9609\n",
      "Epoch 164/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2007e-04 - mse: 2.3050e-08 - mae: 1.2007e-04 - mape: 119887.2812\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2609e-04 - mse: 2.6057e-08 - mae: 1.2609e-04 - mape: 125897.6562\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2780e-04 - mse: 2.6241e-08 - mae: 1.2780e-04 - mape: 127686.0781\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2573e-04 - mse: 2.5873e-08 - mae: 1.2573e-04 - mape: 125491.4453\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3701e-04 - mse: 3.1326e-08 - mae: 1.3701e-04 - mape: 136856.7188\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1119e-04 - mse: 2.0732e-08 - mae: 1.1119e-04 - mape: 111119.8594\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2088e-04 - mse: 2.3818e-08 - mae: 1.2088e-04 - mape: 120813.7734\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3325e-04 - mse: 2.9479e-08 - mae: 1.3325e-04 - mape: 133048.9688\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0849e-04 - mse: 1.9272e-08 - mae: 1.0849e-04 - mape: 108409.0000\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0784e-04 - mse: 1.9540e-08 - mae: 1.0784e-04 - mape: 107770.0000\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.4376e-04 - mse: 3.5088e-08 - mae: 1.4376e-04 - mape: 143669.0312\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2070e-04 - mse: 2.3004e-08 - mae: 1.2070e-04 - mape: 120383.8906\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2391e-04 - mse: 2.4871e-08 - mae: 1.2391e-04 - mape: 123743.3750\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1796e-04 - mse: 2.2674e-08 - mae: 1.1796e-04 - mape: 117824.5625\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2682e-04 - mse: 2.6507e-08 - mae: 1.2682e-04 - mape: 126709.4141\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1595e-04 - mse: 2.1819e-08 - mae: 1.1595e-04 - mape: 115860.3984\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1346e-04 - mse: 2.1344e-08 - mae: 1.1346e-04 - mape: 113268.4219\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1741e-04 - mse: 2.2684e-08 - mae: 1.1741e-04 - mape: 117351.6328\n",
      "Epoch 182/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1832e-04 - mse: 2.3819e-08 - mae: 1.1832e-04 - mape: 118305.3125\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3119e-04 - mse: 2.8284e-08 - mae: 1.3119e-04 - mape: 131055.6016\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1208e-04 - mse: 2.1074e-08 - mae: 1.1208e-04 - mape: 111988.0391\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1529e-04 - mse: 2.2311e-08 - mae: 1.1529e-04 - mape: 115230.5469\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2420e-04 - mse: 2.5134e-08 - mae: 1.2420e-04 - mape: 124053.9688\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0956e-04 - mse: 1.9620e-08 - mae: 1.0956e-04 - mape: 109437.4297\n",
      "Epoch 188/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2223e-04 - mse: 2.4658e-08 - mae: 1.2223e-04 - mape: 122056.3594\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1862e-04 - mse: 2.3404e-08 - mae: 1.1862e-04 - mape: 118279.0938\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1067e-04 - mse: 2.0465e-08 - mae: 1.1067e-04 - mape: 110631.7734\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3570e-04 - mse: 3.0327e-08 - mae: 1.3570e-04 - mape: 135493.7500\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3359e-04 - mse: 2.8656e-08 - mae: 1.3359e-04 - mape: 133588.1719\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.3785e-04 - mse: 3.1016e-08 - mae: 1.3785e-04 - mape: 137755.5781\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1434e-04 - mse: 2.2399e-08 - mae: 1.1434e-04 - mape: 114250.3906\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1752e-04 - mse: 2.2428e-08 - mae: 1.1752e-04 - mape: 117424.0859\n",
      "Epoch 196/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2392e-04 - mse: 2.4592e-08 - mae: 1.2392e-04 - mape: 123776.5469\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2389e-04 - mse: 2.4606e-08 - mae: 1.2389e-04 - mape: 123512.1250\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2839e-04 - mse: 2.7092e-08 - mae: 1.2839e-04 - mape: 128293.6562\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2370e-04 - mse: 2.5472e-08 - mae: 1.2370e-04 - mape: 123692.6094\n",
      "Epoch 200/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2006e-04 - mse: 2.3557e-08 - mae: 1.2006e-04 - mape: 120024.4219\n",
      "63/63 [==============================] - 0s 559us/step\n",
      "7/7 [==============================] - 0s 842us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5165.66it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 100/100 [00:00<00:00, 3682.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                         DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
      "W1                                  0.000000   0.000000  1.709752e-14   \n",
      "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
      "M-95L                               0.000000   0.000000  1.307575e-07   \n",
      "M                                   0.000000   0.000000  1.307575e-07   \n",
      "M-95R                               0.000000   0.000000  1.307575e-07   \n",
      "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
      "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \n",
      "W1-95L                         1.169624e-09  1.709752e-14  2.737858e-08  \n",
      "W1                             1.535477e-09  1.709752e-14  3.526919e-08  \n",
      "W1-95R                         2.124551e-09  1.709752e-14  4.487373e-08  \n",
      "M-95L                          2.741548e-05  1.307575e-07  1.379667e-04  \n",
      "M                              3.126684e-05  1.307575e-07  1.567749e-04  \n",
      "M-95R                          3.713166e-05  1.307575e-07  1.808069e-04  \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04  \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01  \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exec(open('CV_Grid.py').read())\n",
    "# Notebook Mode:\n",
    "# %run Evaluation.ipynb\n",
    "# %run Benchmarks_Model_Builder_Pointmass_Based.ipynb\n",
    "# Terminal Mode (Default):\n",
    "exec(open('Evaluation.py').read())\n",
    "exec(open('Benchmarks_Model_Builder_Pointmass_Based.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Point-Mass Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM     MC-Oracle          ENET  \\\n",
      "W1-95L                         0.000000e+00  0.000000e+00  1.709752e-14   \n",
      "W1                             9.807499e-10  0.000000e+00  9.807326e-10   \n",
      "W1-95R                         2.942250e-09  0.000000e+00  2.942164e-09   \n",
      "M-95L                          0.000000e+00  0.000000e+00  1.307575e-07   \n",
      "M                              1.307575e-07  1.307575e-07  2.612535e-07   \n",
      "M-95R                          3.922725e-07  2.615150e-07  6.527414e-07   \n",
      "N_Par                          1.429000e+05  0.000000e+00  2.000000e+03   \n",
      "Train_Time                     1.968675e+02  7.469260e+01  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  6.746589e-03  1.000000e+00  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \n",
      "W1-95L                         1.418350e-09  1.709752e-14  2.985013e-08  \n",
      "W1                             2.467959e-09  9.807326e-10  3.257061e-08  \n",
      "W1-95R                         5.374323e-09  2.942164e-09  3.662443e-08  \n",
      "M-95L                          2.903003e-05  1.307575e-07  1.388953e-04  \n",
      "M                              3.041741e-05  2.612535e-07  1.444368e-04  \n",
      "M-95R                          3.175325e-05  6.527414e-07  1.519813e-04  \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04  \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01  \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>1.418350e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>2.985013e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>9.807499e-10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.807326e-10</td>\n",
       "      <td>2.467959e-09</td>\n",
       "      <td>9.807326e-10</td>\n",
       "      <td>3.257061e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>2.942250e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.942164e-09</td>\n",
       "      <td>5.374323e-09</td>\n",
       "      <td>2.942164e-09</td>\n",
       "      <td>3.662443e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>2.903003e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.388953e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>2.612535e-07</td>\n",
       "      <td>3.041741e-05</td>\n",
       "      <td>2.612535e-07</td>\n",
       "      <td>1.444368e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>3.922725e-07</td>\n",
       "      <td>2.615150e-07</td>\n",
       "      <td>6.527414e-07</td>\n",
       "      <td>3.175325e-05</td>\n",
       "      <td>6.527414e-07</td>\n",
       "      <td>1.519813e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>1.429000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>4.260100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.968675e+02</td>\n",
       "      <td>7.469260e+01</td>\n",
       "      <td>1.620045e+09</td>\n",
       "      <td>1.351780e+00</td>\n",
       "      <td>7.231278e-01</td>\n",
       "      <td>3.167162e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>6.746589e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.347323e-05</td>\n",
       "      <td>1.008267e-03</td>\n",
       "      <td>2.181460e-04</td>\n",
       "      <td>6.577985e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM     MC-Oracle          ENET  \\\n",
       "W1-95L                         0.000000e+00  0.000000e+00  1.709752e-14   \n",
       "W1                             9.807499e-10  0.000000e+00  9.807326e-10   \n",
       "W1-95R                         2.942250e-09  0.000000e+00  2.942164e-09   \n",
       "M-95L                          0.000000e+00  0.000000e+00  1.307575e-07   \n",
       "M                              1.307575e-07  1.307575e-07  2.612535e-07   \n",
       "M-95R                          3.922725e-07  2.615150e-07  6.527414e-07   \n",
       "N_Par                          1.429000e+05  0.000000e+00  2.000000e+03   \n",
       "Train_Time                     1.968675e+02  7.469260e+01  1.620045e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  6.746589e-03  1.000000e+00  2.347323e-05   \n",
       "\n",
       "                                     KRidge          GBRF           DNN  \n",
       "W1-95L                         1.418350e-09  1.709752e-14  2.985013e-08  \n",
       "W1                             2.467959e-09  9.807326e-10  3.257061e-08  \n",
       "W1-95R                         5.374323e-09  2.942164e-09  3.662443e-08  \n",
       "M-95L                          2.903003e-05  1.307575e-07  1.388953e-04  \n",
       "M                              3.041741e-05  2.612535e-07  1.444368e-04  \n",
       "M-95R                          3.175325e-05  6.527414e-07  1.519813e-04  \n",
       "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04  \n",
       "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01  \n",
       "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
      "W1                                  0.000000   0.000000  1.709752e-14   \n",
      "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
      "M-95L                               0.000000   0.000000  1.307575e-07   \n",
      "M                                   0.000000   0.000000  1.307575e-07   \n",
      "M-95R                               0.000000   0.000000  1.307575e-07   \n",
      "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
      "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \n",
      "W1-95L                         1.169624e-09  1.709752e-14  2.737858e-08  \n",
      "W1                             1.535477e-09  1.709752e-14  3.526919e-08  \n",
      "W1-95R                         2.124551e-09  1.709752e-14  4.487373e-08  \n",
      "M-95L                          2.741548e-05  1.307575e-07  1.379667e-04  \n",
      "M                              3.126684e-05  1.307575e-07  1.567749e-04  \n",
      "M-95R                          3.713166e-05  1.307575e-07  1.808069e-04  \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04  \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01  \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>1.169624e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>2.737858e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>1.535477e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>3.526919e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>2.124551e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>4.487373e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>2.741548e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.379667e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>3.126684e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.567749e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>3.713166e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.808069e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>142900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>4.260100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>196.867494</td>\n",
       "      <td>74.692599</td>\n",
       "      <td>1.620045e+09</td>\n",
       "      <td>1.351780e+00</td>\n",
       "      <td>7.231278e-01</td>\n",
       "      <td>3.167162e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>0.006747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.347323e-05</td>\n",
       "      <td>1.008267e-03</td>\n",
       "      <td>2.181460e-04</td>\n",
       "      <td>6.577985e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         DNM  MC-Oracle          ENET  \\\n",
       "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
       "W1                                  0.000000   0.000000  1.709752e-14   \n",
       "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
       "M-95L                               0.000000   0.000000  1.307575e-07   \n",
       "M                                   0.000000   0.000000  1.307575e-07   \n",
       "M-95R                               0.000000   0.000000  1.307575e-07   \n",
       "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
       "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
       "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
       "\n",
       "                                     KRidge          GBRF           DNN  \n",
       "W1-95L                         1.169624e-09  1.709752e-14  2.737858e-08  \n",
       "W1                             1.535477e-09  1.709752e-14  3.526919e-08  \n",
       "W1-95R                         2.124551e-09  1.709752e-14  4.487373e-08  \n",
       "M-95L                          2.741548e-05  1.307575e-07  1.379667e-04  \n",
       "M                              3.126684e-05  1.307575e-07  1.567749e-04  \n",
       "M-95R                          3.713166e-05  1.307575e-07  1.808069e-04  \n",
       "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04  \n",
       "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01  \n",
       "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) *Gaussian Benchmarks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bencharm 1: [Gaussian Process Regressor](https://scikit-learn.org/stable/modules/gaussian_process.html)\n",
    "- Benchmark 2: Deep Gaussian Networks:\n",
    "These models train models which assume Gaussianity.  We may view these as models in $\\mathcal{P}_2(\\mathbb{R})$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to (\\hat{\\mu}(x),\\hat{\\Sigma}(x)\\hat{\\Sigma}^{\\top})\\triangleq f(x) \\in \\mathbb{R}\\times [0,\\infty) \\to \n",
    "(2\\pi)^{-\\frac{d}{2}}\\det(\\hat{\\Sigma}(x))^{-\\frac{1}{2}} \\, e^{ -\\frac{1}{2}(\\cdot - \\hat{\\mu}(x))^{{{\\!\\mathsf{T}}}} \\hat{\\Sigma}(x)^{-1}(\\cdot - \\hat{\\mu}(x)) } \\mu \\in \\mathcal{G}_d\\subset \\mathcal{P}_2(\\mathbb{R});\n",
    "$$\n",
    "where $\\mathcal{G}_1$ is the set of Gaussian measures on $\\mathbb{R}$ equipped with the relative Wasserstein-1 topology.\n",
    "\n",
    "Examples of this type of architecture are especially prevalent in uncertainty quantification; see ([Deep Ensembles](https://arxiv.org/abs/1612.01474)] or [NOMU: Neural Optimization-based Model Uncertainty](https://arxiv.org/abs/2102.13640).  Moreover, their universality in $C(\\mathbb{R}^d,\\mathcal{G}_2)$ is known, and has been shown in [Corollary 4.7](https://arxiv.org/abs/2101.05390)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    1.5s remaining:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.8s finished\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5671.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering Parameters for Deep Gaussian Network to train on!\n",
      "Done Getting Parameters for Deep Gaussian Network!\n",
      "===============================\n",
      "Training Deep Gaussian Network!\n",
      "===============================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   14.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4999 - mse: 0.4642 - mae: 0.4999 - mape: 18614056.0000\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4997 - mse: 0.4726 - mae: 0.4997 - mape: 13895362.0000\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4996 - mse: 0.4787 - mae: 0.4996 - mape: 10585199.0000\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4996 - mse: 0.4839 - mae: 0.4996 - mape: 7798743.0000\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4870 - mae: 0.4995 - mape: 6195180.5000\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4902 - mae: 0.4995 - mape: 4494921.5000\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4913 - mae: 0.4995 - mape: 3962341.0000\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4921 - mae: 0.4995 - mape: 3552648.5000\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4916 - mae: 0.4995 - mape: 3800102.2500\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4922 - mae: 0.4995 - mape: 3506228.0000\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4923 - mae: 0.4995 - mape: 3430488.0000\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4916 - mae: 0.4995 - mape: 3787444.0000\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4915 - mae: 0.4995 - mape: 3843328.2500\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4929 - mae: 0.4995 - mape: 3131799.5000\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4918 - mae: 0.4995 - mape: 3719695.2500\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4916 - mae: 0.4995 - mape: 3821627.2500\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4930 - mae: 0.4995 - mape: 3105442.2500\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4917 - mae: 0.4995 - mape: 3762214.7500\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4925 - mae: 0.4995 - mape: 3330944.5000\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4923 - mae: 0.4995 - mape: 3454028.5000\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4921 - mae: 0.4995 - mape: 3538765.5000\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4928 - mae: 0.4995 - mape: 3187082.2500\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4932 - mae: 0.4995 - mape: 2997844.7500\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4924 - mae: 0.4995 - mape: 3411873.2500\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4924 - mae: 0.4995 - mape: 3373788.0000\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4934 - mae: 0.4995 - mape: 2883851.2500\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4920 - mae: 0.4995 - mape: 3602441.0000\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4924 - mae: 0.4995 - mape: 3406963.5000\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4932 - mae: 0.4995 - mape: 2973169.0000\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4923 - mae: 0.4995 - mape: 3457222.2500\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4927 - mae: 0.4995 - mape: 3225651.5000\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4933 - mae: 0.4995 - mape: 2932974.5000\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4927 - mae: 0.4995 - mape: 3228917.0000\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4931 - mae: 0.4995 - mape: 3050885.7500\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4930 - mae: 0.4995 - mape: 3108318.7500\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4934 - mae: 0.4995 - mape: 2864460.5000\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4929 - mae: 0.4995 - mape: 3113464.2500\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4929 - mae: 0.4995 - mape: 3114980.5000\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4929 - mae: 0.4995 - mape: 3110462.2500\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4929 - mae: 0.4995 - mape: 3141005.7500\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4931 - mae: 0.4995 - mape: 3034629.5000\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4932 - mae: 0.4995 - mape: 2972503.7500\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4936 - mae: 0.4995 - mape: 2795113.7500\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4924 - mae: 0.4995 - mape: 3381987.5000\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4934 - mae: 0.4995 - mape: 2893205.5000\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4938 - mae: 0.4995 - mape: 2696304.7500\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4934 - mae: 0.4995 - mape: 2876801.0000\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4932 - mae: 0.4995 - mape: 2977125.7500\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4938 - mae: 0.4995 - mape: 2670988.0000\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4932 - mae: 0.4995 - mape: 3003613.7500\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4924 - mae: 0.4995 - mape: 3398891.0000\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4930 - mae: 0.4995 - mape: 3070127.0000\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4937 - mae: 0.4995 - mape: 2738557.5000\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4940 - mae: 0.4995 - mape: 2550259.2500\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4931 - mae: 0.4995 - mape: 3013809.7500\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4936 - mae: 0.4995 - mape: 2762587.5000\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4939 - mae: 0.4995 - mape: 2616749.5000\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4940 - mae: 0.4995 - mape: 2595361.5000\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4935 - mae: 0.4995 - mape: 2849374.7500\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4930 - mae: 0.4995 - mape: 3092667.2500\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4935 - mae: 0.4995 - mape: 2833169.2500\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4941 - mae: 0.4995 - mape: 2540784.2500\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4939 - mae: 0.4995 - mape: 2643258.5000\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4942 - mae: 0.4995 - mape: 2480993.5000\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4941 - mae: 0.4995 - mape: 2536076.5000\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4937 - mae: 0.4995 - mape: 2741193.0000\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4937 - mae: 0.4995 - mape: 2727277.2500\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4937 - mae: 0.4995 - mape: 2703588.2500\n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4935 - mae: 0.4995 - mape: 2805266.5000\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4940 - mae: 0.4995 - mape: 2551213.5000\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4931 - mae: 0.4995 - mape: 3036625.2500\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4936 - mae: 0.4995 - mape: 2759879.7500\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4938 - mae: 0.4995 - mape: 2691857.7500\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4939 - mae: 0.4995 - mape: 2619511.0000\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4942 - mae: 0.4995 - mape: 2452383.0000\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4948 - mae: 0.4995 - mape: 2164074.5000\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4995 - mse: 0.4935 - mae: 0.4995 - mape: 2817735.2500\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4938 - mae: 0.4995 - mape: 2659632.7500\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4943 - mae: 0.4995 - mape: 2444717.2500\n",
      "Epoch 80/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4946 - mae: 0.4995 - mape: 2288768.5000\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4944 - mae: 0.4995 - mape: 2380489.0000\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4940 - mae: 0.4995 - mape: 2554546.7500\n",
      "Epoch 83/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4940 - mae: 0.4995 - mape: 2580003.5000\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4941 - mae: 0.4995 - mape: 2513485.2500\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4934 - mae: 0.4995 - mape: 2883413.2500\n",
      "Epoch 86/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4938 - mae: 0.4995 - mape: 2669651.0000\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4945 - mae: 0.4995 - mape: 2310460.2500\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4939 - mae: 0.4995 - mape: 2644571.5000\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4946 - mae: 0.4995 - mape: 2273946.2500\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4939 - mae: 0.4995 - mape: 2639257.5000\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4938 - mae: 0.4995 - mape: 2697407.5000\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4943 - mae: 0.4995 - mape: 2410396.2500\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4943 - mae: 0.4995 - mape: 2428662.2500\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4936 - mae: 0.4995 - mape: 2802602.2500\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4942 - mae: 0.4995 - mape: 2447575.7500\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4948 - mae: 0.4995 - mape: 2145707.7500\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4942 - mae: 0.4995 - mape: 2495624.7500\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4949 - mae: 0.4995 - mape: 2094290.8750\n",
      "Epoch 99/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4939 - mae: 0.4995 - mape: 2624382.0000\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4941 - mae: 0.4995 - mape: 2508167.7500\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4947 - mae: 0.4995 - mape: 2216085.7500\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4948 - mae: 0.4995 - mape: 2163798.0000\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4942 - mae: 0.4995 - mape: 2464659.2500\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4943 - mae: 0.4995 - mape: 2427458.7500\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1969805.2500\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4938 - mae: 0.4995 - mape: 2661720.5000\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4939 - mae: 0.4995 - mape: 2647954.7500\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4943 - mae: 0.4995 - mape: 2418380.2500\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4946 - mae: 0.4995 - mape: 2280510.2500\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4949 - mae: 0.4995 - mape: 2138537.7500\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4935 - mae: 0.4995 - mape: 2852722.7500\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4942 - mae: 0.4995 - mape: 2462087.5000\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4947 - mae: 0.4995 - mape: 2238860.2500\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1941556.5000\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4947 - mae: 0.4995 - mape: 2229241.7500\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4940 - mae: 0.4995 - mape: 2558807.5000\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4943 - mae: 0.4995 - mape: 2426760.5000\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4948 - mae: 0.4995 - mape: 2151993.7500\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4947 - mae: 0.4995 - mape: 2231369.0000\n",
      "Epoch 120/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4943 - mae: 0.4995 - mape: 2426312.2500\n",
      "Epoch 121/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4949 - mae: 0.4995 - mape: 2135692.2500\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4949 - mae: 0.4995 - mape: 2101342.0000\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1964765.2500\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2066391.3750\n",
      "Epoch 125/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4949 - mae: 0.4995 - mape: 2121484.5000\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2045750.3750\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4947 - mae: 0.4995 - mape: 2240417.7500\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4944 - mae: 0.4995 - mape: 2364962.7500\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4946 - mae: 0.4995 - mape: 2253879.7500\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4948 - mae: 0.4995 - mape: 2151479.0000\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4947 - mae: 0.4995 - mape: 2238074.5000\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4944 - mae: 0.4995 - mape: 2377608.5000\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4955 - mae: 0.4995 - mape: 1837549.5000\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4944 - mae: 0.4995 - mape: 2354621.5000\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4947 - mae: 0.4995 - mape: 2206479.5000\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4944 - mae: 0.4995 - mape: 2392489.0000\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4953 - mae: 0.4995 - mape: 1920772.1250\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4936 - mae: 0.4995 - mape: 2782778.5000\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4938 - mae: 0.4995 - mape: 2680040.5000\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4949 - mae: 0.4995 - mape: 2108177.0000\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2065808.0000\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1950105.3750\n",
      "Epoch 143/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4948 - mae: 0.4995 - mape: 2157577.5000\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2086444.1250\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4951 - mae: 0.4995 - mape: 2031152.6250\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4945 - mae: 0.4995 - mape: 2298958.2500\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4951 - mae: 0.4995 - mape: 2031745.7500\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4951 - mae: 0.4995 - mape: 2027686.5000\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2082945.8750\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4951 - mae: 0.4995 - mape: 2033471.6250\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4948 - mae: 0.4995 - mape: 2152275.7500\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2088044.6250\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4955 - mae: 0.4995 - mape: 1812591.2500\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4947 - mae: 0.4995 - mape: 2198965.7500\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1948502.3750\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4957 - mae: 0.4995 - mape: 1730588.2500\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4955 - mae: 0.4995 - mape: 1835858.0000\n",
      "Epoch 158/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4953 - mae: 0.4995 - mape: 1915788.8750\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2064961.1250\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1963878.5000\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1951490.2500\n",
      "Epoch 162/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1950194.0000\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4951 - mae: 0.4995 - mape: 2013507.8750\n",
      "Epoch 164/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4949 - mae: 0.4995 - mape: 2110167.7500\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4953 - mae: 0.4995 - mape: 1899458.8750\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4944 - mae: 0.4995 - mape: 2389854.7500\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4946 - mae: 0.4995 - mape: 2254701.5000\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2043534.1250\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4956 - mae: 0.4995 - mape: 1761631.8750\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2086586.5000\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4995 - mse: 0.4953 - mae: 0.4995 - mape: 1905754.3750\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4955 - mae: 0.4995 - mape: 1821430.5000\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2082722.0000\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4948 - mae: 0.4995 - mape: 2179538.5000\n",
      "Epoch 175/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4942 - mae: 0.4995 - mape: 2460142.5000\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4954 - mae: 0.4995 - mape: 1844667.7500\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4954 - mae: 0.4995 - mape: 1886999.3750\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1969657.5000\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4957 - mae: 0.4995 - mape: 1694668.2500\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4954 - mae: 0.4995 - mape: 1846483.3750\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4954 - mae: 0.4995 - mape: 1874422.3750\n",
      "Epoch 182/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4953 - mae: 0.4995 - mape: 1935800.1250\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1968267.2500\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4954 - mae: 0.4995 - mape: 1846895.5000\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4950 - mae: 0.4995 - mape: 2072270.1250\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1968100.8750\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4945 - mae: 0.4995 - mape: 2324242.2500\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4941 - mae: 0.4995 - mape: 2525318.2500\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1945354.0000\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4958 - mae: 0.4995 - mape: 1653536.6250\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4949 - mae: 0.4995 - mape: 2091643.5000\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4957 - mae: 0.4995 - mape: 1715769.7500\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1981144.1250\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4957 - mae: 0.4995 - mape: 1719421.1250\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4956 - mae: 0.4995 - mape: 1769174.5000\n",
      "Epoch 196/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4952 - mae: 0.4995 - mape: 1938245.3750\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4956 - mae: 0.4995 - mape: 1751633.8750\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4960 - mae: 0.4995 - mape: 1575722.1250\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4956 - mae: 0.4995 - mape: 1781758.2500\n",
      "Epoch 200/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - mse: 0.4957 - mae: 0.4995 - mape: 1703878.2500\n",
      "63/63 [==============================] - 0s 595us/step\n",
      "7/7 [==============================] - 0s 862us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Training Deep Gaussian Network!: END\n",
      "====================================\n",
      "#---------------------------------------#\n",
      " Get Training Errors for: Gaussian Models\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1638.54it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1663.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------------------------#\n",
      " Get Testing Errors for: Gaussian Models\n",
      "#--------------------------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "Training Results to date:\n",
      "                                         DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
      "W1                                  0.000000   0.000000  1.709752e-14   \n",
      "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
      "M-95L                               0.000000   0.000000  1.307575e-07   \n",
      "M                                   0.000000   0.000000  1.307575e-07   \n",
      "M-95R                               0.000000   0.000000  1.307575e-07   \n",
      "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
      "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \\\n",
      "W1-95L                         1.169624e-09  1.709752e-14  2.737858e-08   \n",
      "W1                             1.535477e-09  1.709752e-14  3.526919e-08   \n",
      "W1-95R                         2.124551e-09  1.709752e-14  4.487373e-08   \n",
      "M-95L                          2.741548e-05  1.307575e-07  1.379667e-04   \n",
      "M                              3.126684e-05  1.307575e-07  1.567749e-04   \n",
      "M-95R                          3.713166e-05  1.307575e-07  1.808069e-04   \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
      "\n",
      "                                    GPR           DGN  \n",
      "W1-95L                         0.000010      0.982011  \n",
      "W1                             0.000010      0.989217  \n",
      "W1-95R                         0.000010      0.998977  \n",
      "M-95L                          0.000000      0.003124  \n",
      "M                              0.000000      0.003425  \n",
      "M-95R                          0.000000      0.003639  \n",
      "N_Par                          0.000000  42601.000000  \n",
      "Train_Time                     3.119642     32.067623  \n",
      "Test_Time/MC-Oracle_Test_Time  0.001652      0.006597  \n",
      "Test Results to date:\n",
      "                                         DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
      "W1                                  0.000000   0.000000  1.709752e-14   \n",
      "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
      "M-95L                               0.000000   0.000000  1.307575e-07   \n",
      "M                                   0.000000   0.000000  1.307575e-07   \n",
      "M-95R                               0.000000   0.000000  1.307575e-07   \n",
      "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
      "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \\\n",
      "W1-95L                         1.169624e-09  1.709752e-14  2.737858e-08   \n",
      "W1                             1.535477e-09  1.709752e-14  3.526919e-08   \n",
      "W1-95R                         2.124551e-09  1.709752e-14  4.487373e-08   \n",
      "M-95L                          2.741548e-05  1.307575e-07  1.379667e-04   \n",
      "M                              3.126684e-05  1.307575e-07  1.567749e-04   \n",
      "M-95R                          3.713166e-05  1.307575e-07  1.808069e-04   \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
      "\n",
      "                                    GPR           DGN  \n",
      "W1-95L                         0.000010      0.982011  \n",
      "W1                             0.000010      0.989217  \n",
      "W1-95R                         0.000010      0.998977  \n",
      "M-95L                          0.000000      0.003124  \n",
      "M                              0.000000      0.003425  \n",
      "M-95R                          0.000000      0.003639  \n",
      "N_Par                          0.000000  42601.000000  \n",
      "Train_Time                     3.119642     32.067623  \n",
      "Test_Time/MC-Oracle_Test_Time  0.001652      0.006597  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# %run Benchmarks_Model_Builder_Mean_Var.ipynb\n",
    "exec(open('Benchmarks_Model_Builder_Mean_Var.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Quality (Updated): Test\n",
      "                                         DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
      "W1                                  0.000000   0.000000  1.709752e-14   \n",
      "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
      "M-95L                               0.000000   0.000000  1.307575e-07   \n",
      "M                                   0.000000   0.000000  1.307575e-07   \n",
      "M-95R                               0.000000   0.000000  1.307575e-07   \n",
      "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
      "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \\\n",
      "W1-95L                         1.169624e-09  1.709752e-14  2.737858e-08   \n",
      "W1                             1.535477e-09  1.709752e-14  3.526919e-08   \n",
      "W1-95R                         2.124551e-09  1.709752e-14  4.487373e-08   \n",
      "M-95L                          2.741548e-05  1.307575e-07  1.379667e-04   \n",
      "M                              3.126684e-05  1.307575e-07  1.567749e-04   \n",
      "M-95R                          3.713166e-05  1.307575e-07  1.808069e-04   \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
      "\n",
      "                                    GPR           DGN  \n",
      "W1-95L                         0.000010      0.982011  \n",
      "W1                             0.000010      0.989217  \n",
      "W1-95R                         0.000010      0.998977  \n",
      "M-95L                          0.000000      0.003124  \n",
      "M                              0.000000      0.003425  \n",
      "M-95R                          0.000000      0.003639  \n",
      "N_Par                          0.000000  42601.000000  \n",
      "Train_Time                     3.119642     32.067623  \n",
      "Test_Time/MC-Oracle_Test_Time  0.001652      0.006597  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>1.169624e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>2.737858e-08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.982011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>1.535477e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>3.526919e-08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.989217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>2.124551e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>4.487373e-08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.998977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>2.741548e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.379667e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>3.126684e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.567749e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>3.713166e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.808069e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>142900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>4.260100e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>196.867494</td>\n",
       "      <td>74.692599</td>\n",
       "      <td>1.620045e+09</td>\n",
       "      <td>1.351780e+00</td>\n",
       "      <td>7.231278e-01</td>\n",
       "      <td>3.167162e+01</td>\n",
       "      <td>3.119642</td>\n",
       "      <td>32.067623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>0.006747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.347323e-05</td>\n",
       "      <td>1.008267e-03</td>\n",
       "      <td>2.181460e-04</td>\n",
       "      <td>6.577985e-03</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.006597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         DNM  MC-Oracle          ENET  \\\n",
       "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
       "W1                                  0.000000   0.000000  1.709752e-14   \n",
       "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
       "M-95L                               0.000000   0.000000  1.307575e-07   \n",
       "M                                   0.000000   0.000000  1.307575e-07   \n",
       "M-95R                               0.000000   0.000000  1.307575e-07   \n",
       "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
       "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
       "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
       "\n",
       "                                     KRidge          GBRF           DNN  \\\n",
       "W1-95L                         1.169624e-09  1.709752e-14  2.737858e-08   \n",
       "W1                             1.535477e-09  1.709752e-14  3.526919e-08   \n",
       "W1-95R                         2.124551e-09  1.709752e-14  4.487373e-08   \n",
       "M-95L                          2.741548e-05  1.307575e-07  1.379667e-04   \n",
       "M                              3.126684e-05  1.307575e-07  1.567749e-04   \n",
       "M-95R                          3.713166e-05  1.307575e-07  1.808069e-04   \n",
       "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
       "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
       "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
       "\n",
       "                                    GPR           DGN  \n",
       "W1-95L                         0.000010      0.982011  \n",
       "W1                             0.000010      0.989217  \n",
       "W1-95R                         0.000010      0.998977  \n",
       "M-95L                          0.000000      0.003124  \n",
       "M                              0.000000      0.003425  \n",
       "M-95R                          0.000000      0.003639  \n",
       "N_Par                          0.000000  42601.000000  \n",
       "Train_Time                     3.119642     32.067623  \n",
       "Test_Time/MC-Oracle_Test_Time  0.001652      0.006597  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Prediction Quality (Updated): Test\")\n",
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Quality (Updated): Train\n",
      "                                        DNM     MC-Oracle          ENET  \\\n",
      "W1-95L                         0.000000e+00  0.000000e+00  1.709752e-14   \n",
      "W1                             9.807499e-10  0.000000e+00  9.807326e-10   \n",
      "W1-95R                         2.942250e-09  0.000000e+00  2.942164e-09   \n",
      "M-95L                          0.000000e+00  0.000000e+00  1.307575e-07   \n",
      "M                              1.307575e-07  1.307575e-07  2.612535e-07   \n",
      "M-95R                          3.922725e-07  2.615150e-07  6.527414e-07   \n",
      "N_Par                          1.429000e+05  0.000000e+00  2.000000e+03   \n",
      "Train_Time                     1.968675e+02  7.469260e+01  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  6.746589e-03  1.000000e+00  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \\\n",
      "W1-95L                         1.418350e-09  1.709752e-14  2.985013e-08   \n",
      "W1                             2.467959e-09  9.807326e-10  3.257061e-08   \n",
      "W1-95R                         5.374323e-09  2.942164e-09  3.662443e-08   \n",
      "M-95L                          2.903003e-05  1.307575e-07  1.388953e-04   \n",
      "M                              3.041741e-05  2.612535e-07  1.444368e-04   \n",
      "M-95R                          3.175325e-05  6.527414e-07  1.519813e-04   \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
      "\n",
      "                                        GPR           DGN  \n",
      "W1-95L                         9.974428e-06      0.993366  \n",
      "W1                             9.999199e-06      0.995671  \n",
      "W1-95R                         1.002150e-05      0.998542  \n",
      "M-95L                          0.000000e+00      0.003250  \n",
      "M                              1.307575e-07      0.003334  \n",
      "M-95R                          3.922725e-07      0.003401  \n",
      "N_Par                          0.000000e+00  42601.000000  \n",
      "Train_Time                     3.119642e+00     32.067623  \n",
      "Test_Time/MC-Oracle_Test_Time  1.652429e-03      0.006597  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>1.418350e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>2.985013e-08</td>\n",
       "      <td>9.974428e-06</td>\n",
       "      <td>0.993366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>9.807499e-10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.807326e-10</td>\n",
       "      <td>2.467959e-09</td>\n",
       "      <td>9.807326e-10</td>\n",
       "      <td>3.257061e-08</td>\n",
       "      <td>9.999199e-06</td>\n",
       "      <td>0.995671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>2.942250e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.942164e-09</td>\n",
       "      <td>5.374323e-09</td>\n",
       "      <td>2.942164e-09</td>\n",
       "      <td>3.662443e-08</td>\n",
       "      <td>1.002150e-05</td>\n",
       "      <td>0.998542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>2.903003e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.388953e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.003250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>2.612535e-07</td>\n",
       "      <td>3.041741e-05</td>\n",
       "      <td>2.612535e-07</td>\n",
       "      <td>1.444368e-04</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>0.003334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>3.922725e-07</td>\n",
       "      <td>2.615150e-07</td>\n",
       "      <td>6.527414e-07</td>\n",
       "      <td>3.175325e-05</td>\n",
       "      <td>6.527414e-07</td>\n",
       "      <td>1.519813e-04</td>\n",
       "      <td>3.922725e-07</td>\n",
       "      <td>0.003401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>1.429000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>4.260100e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>42601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.968675e+02</td>\n",
       "      <td>7.469260e+01</td>\n",
       "      <td>1.620045e+09</td>\n",
       "      <td>1.351780e+00</td>\n",
       "      <td>7.231278e-01</td>\n",
       "      <td>3.167162e+01</td>\n",
       "      <td>3.119642e+00</td>\n",
       "      <td>32.067623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>6.746589e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.347323e-05</td>\n",
       "      <td>1.008267e-03</td>\n",
       "      <td>2.181460e-04</td>\n",
       "      <td>6.577985e-03</td>\n",
       "      <td>1.652429e-03</td>\n",
       "      <td>0.006597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM     MC-Oracle          ENET  \\\n",
       "W1-95L                         0.000000e+00  0.000000e+00  1.709752e-14   \n",
       "W1                             9.807499e-10  0.000000e+00  9.807326e-10   \n",
       "W1-95R                         2.942250e-09  0.000000e+00  2.942164e-09   \n",
       "M-95L                          0.000000e+00  0.000000e+00  1.307575e-07   \n",
       "M                              1.307575e-07  1.307575e-07  2.612535e-07   \n",
       "M-95R                          3.922725e-07  2.615150e-07  6.527414e-07   \n",
       "N_Par                          1.429000e+05  0.000000e+00  2.000000e+03   \n",
       "Train_Time                     1.968675e+02  7.469260e+01  1.620045e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  6.746589e-03  1.000000e+00  2.347323e-05   \n",
       "\n",
       "                                     KRidge          GBRF           DNN  \\\n",
       "W1-95L                         1.418350e-09  1.709752e-14  2.985013e-08   \n",
       "W1                             2.467959e-09  9.807326e-10  3.257061e-08   \n",
       "W1-95R                         5.374323e-09  2.942164e-09  3.662443e-08   \n",
       "M-95L                          2.903003e-05  1.307575e-07  1.388953e-04   \n",
       "M                              3.041741e-05  2.612535e-07  1.444368e-04   \n",
       "M-95R                          3.175325e-05  6.527414e-07  1.519813e-04   \n",
       "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
       "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
       "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
       "\n",
       "                                        GPR           DGN  \n",
       "W1-95L                         9.974428e-06      0.993366  \n",
       "W1                             9.999199e-06      0.995671  \n",
       "W1-95R                         1.002150e-05      0.998542  \n",
       "M-95L                          0.000000e+00      0.003250  \n",
       "M                              1.307575e-07      0.003334  \n",
       "M-95R                          3.922725e-07      0.003401  \n",
       "N_Par                          0.000000e+00  42601.000000  \n",
       "Train_Time                     3.119642e+00     32.067623  \n",
       "Test_Time/MC-Oracle_Test_Time  1.652429e-03      0.006597  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Prediction Quality (Updated): Train\")\n",
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) The natural Universal Benchmark: [Bishop's Mixture Density Network](https://publications.aston.ac.uk/id/eprint/373/1/NCRG_94_004.pdf)\n",
    "\n",
    "This implementation is as follows:\n",
    "- For every $x$ in the trainingdata-set we fit a GMM $\\hat{\\nu}_x$, using the [Expectation-Maximization (EM) algorithm](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm), with the same number of centers as the deep neural model in $\\mathcal{NN}_{1_{\\mathbb{R}^d},\\mathcal{D}}^{\\sigma:\\star}$ which we are evaluating.  \n",
    "- A Mixture density network is then trained to predict the infered parameters; given any $x \\in \\mathbb{R}^d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Preparing Training Outputs for MDNs using EM-Algorithm\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [40:22<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Prepared Training Outputs for MDNs using EM-Algorithm!\n",
      "======================================================\n",
      "Deep Feature Builder - Ready\n",
      "(0)\n",
      "=====================================================\n",
      "Training Mixture Density Network (MDN): Means: Start!\n",
      "=====================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   20.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   20.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0452 - mse: 0.0033 - mae: 0.0452 - mape: 45171244.0000\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0030 - mae: 0.0422 - mape: 42178576.0000\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0027 - mae: 0.0394 - mape: 39324880.0000\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0366 - mse: 0.0025 - mae: 0.0366 - mape: 36536976.0000\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0338 - mse: 0.0022 - mae: 0.0338 - mape: 33770848.0000\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0310 - mse: 0.0019 - mae: 0.0310 - mape: 31009334.0000\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0283 - mse: 0.0017 - mae: 0.0283 - mape: 28249120.0000\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0255 - mse: 0.0015 - mae: 0.0255 - mape: 25520416.0000\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0013 - mae: 0.0229 - mape: 22860756.0000\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0011 - mae: 0.0203 - mape: 20313866.0000\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 9.0027e-04 - mae: 0.0179 - mape: 17923010.0000\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0157 - mse: 7.4623e-04 - mae: 0.0157 - mape: 15723039.0000\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0137 - mse: 6.1297e-04 - mae: 0.0137 - mape: 13735928.0000\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 4.9978e-04 - mae: 0.0120 - mape: 11964644.0000\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 4.0536e-04 - mae: 0.0104 - mape: 10420114.0000\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 3.2798e-04 - mae: 0.0091 - mape: 9104760.0000\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 2.6499e-04 - mae: 0.0080 - mape: 7998375.5000\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 2.1381e-04 - mae: 0.0071 - mape: 7062926.5000\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 1.7206e-04 - mae: 0.0063 - mape: 6264555.0000\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 1.3792e-04 - mae: 0.0056 - mape: 5579021.0000\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 1.0996e-04 - mae: 0.0050 - mape: 4983731.5000\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 8.7250e-05 - mae: 0.0045 - mape: 4464670.0000\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 6.8875e-05 - mae: 0.0040 - mape: 4010093.0000\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 5.4247e-05 - mae: 0.0036 - mape: 3618669.5000\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 4.2573e-05 - mae: 0.0033 - mape: 3281122.7500\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 3.3303e-05 - mae: 0.0030 - mape: 2988915.0000\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 2.6024e-05 - mae: 0.0027 - mape: 2737217.5000\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 2.0354e-05 - mae: 0.0025 - mape: 2524803.5000\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 1.5881e-05 - mae: 0.0023 - mape: 2343336.7500\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 1.2372e-05 - mae: 0.0022 - mape: 2181967.2500\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 9.7321e-06 - mae: 0.0020 - mape: 2041852.3750\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 7.8088e-06 - mae: 0.0019 - mape: 1921088.2500\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 6.4423e-06 - mae: 0.0018 - mape: 1817444.3750\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 5.5210e-06 - mae: 0.0017 - mape: 1728956.0000\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 4.9454e-06 - mae: 0.0017 - mape: 1656912.6250\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 4.5529e-06 - mae: 0.0016 - mape: 1597473.5000\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 4.2502e-06 - mae: 0.0015 - mape: 1546284.6250\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 3.9894e-06 - mae: 0.0015 - mape: 1501115.1250\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 3.7609e-06 - mae: 0.0015 - mape: 1460365.6250\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 3.5624e-06 - mae: 0.0014 - mape: 1423111.2500\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 3.3916e-06 - mae: 0.0014 - mape: 1389784.2500\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 3.2430e-06 - mae: 0.0014 - mape: 1360208.3750\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 3.1054e-06 - mae: 0.0013 - mape: 1332086.7500\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 2.9863e-06 - mae: 0.0013 - mape: 1306724.2500\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 2.8783e-06 - mae: 0.0013 - mape: 1284243.0000\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 2.7892e-06 - mae: 0.0013 - mape: 1264449.8750\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 2.6962e-06 - mae: 0.0012 - mape: 1243621.6250\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 2.6199e-06 - mae: 0.0012 - mape: 1225854.8750\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 2.5455e-06 - mae: 0.0012 - mape: 1208582.2500\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 2.4757e-06 - mae: 0.0012 - mape: 1192807.5000\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 2.4147e-06 - mae: 0.0012 - mape: 1177581.6250\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 2.3582e-06 - mae: 0.0012 - mape: 1163429.0000\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 2.3007e-06 - mae: 0.0012 - mape: 1150019.1250\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 2.2497e-06 - mae: 0.0011 - mape: 1137628.5000\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 2.2040e-06 - mae: 0.0011 - mape: 1125221.7500\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 2.1581e-06 - mae: 0.0011 - mape: 1113771.0000\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 2.1167e-06 - mae: 0.0011 - mape: 1102661.7500\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 2.0752e-06 - mae: 0.0011 - mape: 1092344.3750\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 2.0345e-06 - mae: 0.0011 - mape: 1081883.3750\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 1.9968e-06 - mae: 0.0011 - mape: 1071957.0000\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 1.9663e-06 - mae: 0.0011 - mape: 1062896.5000\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 1.9337e-06 - mae: 0.0011 - mape: 1054075.6250\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 1.8981e-06 - mae: 0.0010 - mape: 1044038.7500\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 1.8672e-06 - mae: 0.0010 - mape: 1035678.1875\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 1.8357e-06 - mae: 0.0010 - mape: 1027447.5000\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 1.8094e-06 - mae: 0.0010 - mape: 1019775.2500\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 1.7787e-06 - mae: 0.0010 - mape: 1011411.0625 \n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 1.7527e-06 - mae: 0.0010 - mape: 1003093.6875   \n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.9609e-04 - mse: 1.7201e-06 - mae: 9.9609e-04 - mape: 994789.3125\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.8898e-04 - mse: 1.6987e-06 - mae: 9.8898e-04 - mape: 987692.9375\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.8298e-04 - mse: 1.6758e-06 - mae: 9.8298e-04 - mape: 981691.4375\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.7506e-04 - mse: 1.6495e-06 - mae: 9.7506e-04 - mape: 973755.3750\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.6742e-04 - mse: 1.6256e-06 - mae: 9.6742e-04 - mape: 966155.0000\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.6187e-04 - mse: 1.6049e-06 - mae: 9.6187e-04 - mape: 960608.4375\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.5453e-04 - mse: 1.5795e-06 - mae: 9.5453e-04 - mape: 953279.3750\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.4716e-04 - mse: 1.5580e-06 - mae: 9.4716e-04 - mape: 945918.1250\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.4058e-04 - mse: 1.5351e-06 - mae: 9.4058e-04 - mape: 939377.6875\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.3424e-04 - mse: 1.5133e-06 - mae: 9.3424e-04 - mape: 933003.5000\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.2697e-04 - mse: 1.4915e-06 - mae: 9.2697e-04 - mape: 925720.1875\n",
      "Epoch 80/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.2094e-04 - mse: 1.4718e-06 - mae: 9.2094e-04 - mape: 919695.6875\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.1498e-04 - mse: 1.4534e-06 - mae: 9.1498e-04 - mape: 913754.0625\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.0799e-04 - mse: 1.4320e-06 - mae: 9.0799e-04 - mape: 906767.0000\n",
      "Epoch 83/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.0244e-04 - mse: 1.4142e-06 - mae: 9.0244e-04 - mape: 901247.5000\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.9548e-04 - mse: 1.3911e-06 - mae: 8.9548e-04 - mape: 894290.8750\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.9087e-04 - mse: 1.3783e-06 - mae: 8.9087e-04 - mape: 889697.5625\n",
      "Epoch 86/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.8459e-04 - mse: 1.3596e-06 - mae: 8.8459e-04 - mape: 883405.5000\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.7891e-04 - mse: 1.3401e-06 - mae: 8.7891e-04 - mape: 877741.7500\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.7329e-04 - mse: 1.3245e-06 - mae: 8.7329e-04 - mape: 872143.5000\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.6696e-04 - mse: 1.3057e-06 - mae: 8.6696e-04 - mape: 865811.0625\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.6317e-04 - mse: 1.2931e-06 - mae: 8.6317e-04 - mape: 862036.5625\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.5640e-04 - mse: 1.2736e-06 - mae: 8.5640e-04 - mape: 855257.5625\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.5105e-04 - mse: 1.2565e-06 - mae: 8.5105e-04 - mape: 849921.9375\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.4481e-04 - mse: 1.2392e-06 - mae: 8.4481e-04 - mape: 843675.3125\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.3958e-04 - mse: 1.2246e-06 - mae: 8.3958e-04 - mape: 838462.5000\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.3422e-04 - mse: 1.2083e-06 - mae: 8.3422e-04 - mape: 833121.6250\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.2872e-04 - mse: 1.1931e-06 - mae: 8.2872e-04 - mape: 827609.5000\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.2447e-04 - mse: 1.1802e-06 - mae: 8.2447e-04 - mape: 823372.8750\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.1832e-04 - mse: 1.1635e-06 - mae: 8.1832e-04 - mape: 817223.2500\n",
      "Epoch 99/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.1321e-04 - mse: 1.1490e-06 - mae: 8.1321e-04 - mape: 812111.6250\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.0832e-04 - mse: 1.1349e-06 - mae: 8.0832e-04 - mape: 807218.0000\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.0263e-04 - mse: 1.1190e-06 - mae: 8.0263e-04 - mape: 801557.8125\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.9788e-04 - mse: 1.1067e-06 - mae: 7.9788e-04 - mape: 796810.6250\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.9331e-04 - mse: 1.0926e-06 - mae: 7.9331e-04 - mape: 792235.5000\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.8788e-04 - mse: 1.0776e-06 - mae: 7.8788e-04 - mape: 786815.5625\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.8325e-04 - mse: 1.0661e-06 - mae: 7.8325e-04 - mape: 782186.6250\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.7844e-04 - mse: 1.0531e-06 - mae: 7.7844e-04 - mape: 777376.3750\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.7273e-04 - mse: 1.0380e-06 - mae: 7.7273e-04 - mape: 771681.8125\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6825e-04 - mse: 1.0259e-06 - mae: 7.6825e-04 - mape: 767210.0000\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6384e-04 - mse: 1.0138e-06 - mae: 7.6384e-04 - mape: 762803.3750\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.5885e-04 - mse: 1.0006e-06 - mae: 7.5885e-04 - mape: 757813.0625\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.5369e-04 - mse: 9.8856e-07 - mae: 7.5369e-04 - mape: 752691.9375\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.4940e-04 - mse: 9.7599e-07 - mae: 7.4940e-04 - mape: 748392.2500\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.4469e-04 - mse: 9.6394e-07 - mae: 7.4469e-04 - mape: 743661.8125\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.4027e-04 - mse: 9.5266e-07 - mae: 7.4027e-04 - mape: 739271.0000\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.3594e-04 - mse: 9.4157e-07 - mae: 7.3594e-04 - mape: 734975.6250\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.3208e-04 - mse: 9.3229e-07 - mae: 7.3208e-04 - mape: 731084.1875\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.2661e-04 - mse: 9.1870e-07 - mae: 7.2661e-04 - mape: 725605.8750\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.2242e-04 - mse: 9.0763e-07 - mae: 7.2242e-04 - mape: 721448.4375\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.1754e-04 - mse: 8.9608e-07 - mae: 7.1754e-04 - mape: 716550.6250\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 7.1324e-04 - mse: 8.8482e-07 - mae: 7.1324e-04 - mape: 712271.0000\n",
      "Epoch 121/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.0951e-04 - mse: 8.7591e-07 - mae: 7.0951e-04 - mape: 708566.9375\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.0551e-04 - mse: 8.6621e-07 - mae: 7.0551e-04 - mape: 704536.1250\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.0094e-04 - mse: 8.5531e-07 - mae: 7.0094e-04 - mape: 699969.6250\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.9732e-04 - mse: 8.4557e-07 - mae: 6.9732e-04 - mape: 696370.5000\n",
      "Epoch 125/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.9236e-04 - mse: 8.3357e-07 - mae: 6.9236e-04 - mape: 691426.9375\n",
      "Epoch 126/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.8788e-04 - mse: 8.2357e-07 - mae: 6.8788e-04 - mape: 686944.8750\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.8352e-04 - mse: 8.1332e-07 - mae: 6.8352e-04 - mape: 682581.0625\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.8076e-04 - mse: 8.0588e-07 - mae: 6.8076e-04 - mape: 679835.8750\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.7673e-04 - mse: 7.9801e-07 - mae: 6.7673e-04 - mape: 675778.8750\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.7201e-04 - mse: 7.8503e-07 - mae: 6.7201e-04 - mape: 671100.8750\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.6822e-04 - mse: 7.7737e-07 - mae: 6.6822e-04 - mape: 667306.3750\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.6475e-04 - mse: 7.6929e-07 - mae: 6.6475e-04 - mape: 663805.3750\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.5990e-04 - mse: 7.5788e-07 - mae: 6.5990e-04 - mape: 659008.6250\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.5692e-04 - mse: 7.5118e-07 - mae: 6.5692e-04 - mape: 656025.5625\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.5235e-04 - mse: 7.4145e-07 - mae: 6.5235e-04 - mape: 651455.3750\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.4839e-04 - mse: 7.3200e-07 - mae: 6.4839e-04 - mape: 647495.6875\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.4529e-04 - mse: 7.2439e-07 - mae: 6.4529e-04 - mape: 644414.0625\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.4105e-04 - mse: 7.1544e-07 - mae: 6.4105e-04 - mape: 640138.5000\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.3747e-04 - mse: 7.0734e-07 - mae: 6.3747e-04 - mape: 636606.1875\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.3356e-04 - mse: 6.9908e-07 - mae: 6.3356e-04 - mape: 632702.8750\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2989e-04 - mse: 6.9092e-07 - mae: 6.2989e-04 - mape: 629026.5625\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2677e-04 - mse: 6.8383e-07 - mae: 6.2677e-04 - mape: 625898.8750\n",
      "Epoch 143/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2248e-04 - mse: 6.7513e-07 - mae: 6.2248e-04 - mape: 621599.4375\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.1879e-04 - mse: 6.6730e-07 - mae: 6.1879e-04 - mape: 617937.1250\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.1573e-04 - mse: 6.6028e-07 - mae: 6.1573e-04 - mape: 614852.8125\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.1216e-04 - mse: 6.5313e-07 - mae: 6.1216e-04 - mape: 611325.8750\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.0892e-04 - mse: 6.4527e-07 - mae: 6.0892e-04 - mape: 608077.7500\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.0525e-04 - mse: 6.3882e-07 - mae: 6.0525e-04 - mape: 604413.8125\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.0154e-04 - mse: 6.2975e-07 - mae: 6.0154e-04 - mape: 600699.6875\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.9834e-04 - mse: 6.2403e-07 - mae: 5.9834e-04 - mape: 597507.5625\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.9405e-04 - mse: 6.1533e-07 - mae: 5.9405e-04 - mape: 593218.3750\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.9119e-04 - mse: 6.0910e-07 - mae: 5.9119e-04 - mape: 590388.1250\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8822e-04 - mse: 6.0322e-07 - mae: 5.8822e-04 - mape: 587403.0000\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8490e-04 - mse: 5.9568e-07 - mae: 5.8490e-04 - mape: 584091.7500\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8120e-04 - mse: 5.8865e-07 - mae: 5.8120e-04 - mape: 580399.9375\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.7753e-04 - mse: 5.8098e-07 - mae: 5.7753e-04 - mape: 576705.6250\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.7452e-04 - mse: 5.7496e-07 - mae: 5.7452e-04 - mape: 573730.6875\n",
      "Epoch 158/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.7143e-04 - mse: 5.6910e-07 - mae: 5.7143e-04 - mape: 570642.2500\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.6838e-04 - mse: 5.6305e-07 - mae: 5.6838e-04 - mape: 567582.0000\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.6452e-04 - mse: 5.5650e-07 - mae: 5.6452e-04 - mape: 563736.3125\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.6173e-04 - mse: 5.5021e-07 - mae: 5.6173e-04 - mape: 560946.2500\n",
      "Epoch 162/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5853e-04 - mse: 5.4390e-07 - mae: 5.5853e-04 - mape: 557747.3125\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5563e-04 - mse: 5.3889e-07 - mae: 5.5563e-04 - mape: 554841.3750\n",
      "Epoch 164/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5233e-04 - mse: 5.3180e-07 - mae: 5.5233e-04 - mape: 551553.5000\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.4989e-04 - mse: 5.2710e-07 - mae: 5.4989e-04 - mape: 549149.4375\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.4598e-04 - mse: 5.1929e-07 - mae: 5.4598e-04 - mape: 545216.5000\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.4316e-04 - mse: 5.1462e-07 - mae: 5.4316e-04 - mape: 542407.3125\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.4028e-04 - mse: 5.0899e-07 - mae: 5.4028e-04 - mape: 539541.6250\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.3651e-04 - mse: 5.0222e-07 - mae: 5.3651e-04 - mape: 535762.0625\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.3417e-04 - mse: 4.9767e-07 - mae: 5.3417e-04 - mape: 533417.3750\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.3097e-04 - mse: 4.9185e-07 - mae: 5.3097e-04 - mape: 530219.1875\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.2775e-04 - mse: 4.8570e-07 - mae: 5.2775e-04 - mape: 527011.0625\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.2506e-04 - mse: 4.8118e-07 - mae: 5.2506e-04 - mape: 524332.8750\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.2271e-04 - mse: 4.7670e-07 - mae: 5.2271e-04 - mape: 521994.1250\n",
      "Epoch 175/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.2003e-04 - mse: 4.7174e-07 - mae: 5.2003e-04 - mape: 519307.2500\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1686e-04 - mse: 4.6628e-07 - mae: 5.1686e-04 - mape: 516120.2188\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1381e-04 - mse: 4.6049e-07 - mae: 5.1381e-04 - mape: 513090.1250\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1081e-04 - mse: 4.5496e-07 - mae: 5.1081e-04 - mape: 510100.1562\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.0788e-04 - mse: 4.5015e-07 - mae: 5.0788e-04 - mape: 507160.2500\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.0549e-04 - mse: 4.4603e-07 - mae: 5.0549e-04 - mape: 504786.7188\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.0294e-04 - mse: 4.4167e-07 - mae: 5.0294e-04 - mape: 502279.7500\n",
      "Epoch 182/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.0008e-04 - mse: 4.3626e-07 - mae: 5.0008e-04 - mape: 499356.8438\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9697e-04 - mse: 4.3130e-07 - mae: 4.9697e-04 - mape: 496269.5938\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9475e-04 - mse: 4.2744e-07 - mae: 4.9475e-04 - mape: 494051.0938\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9197e-04 - mse: 4.2255e-07 - mae: 4.9197e-04 - mape: 491286.3438\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8938e-04 - mse: 4.1806e-07 - mae: 4.8938e-04 - mape: 488694.4688\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8693e-04 - mse: 4.1384e-07 - mae: 4.8693e-04 - mape: 486248.3125\n",
      "Epoch 188/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8433e-04 - mse: 4.0946e-07 - mae: 4.8433e-04 - mape: 483651.5625\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8202e-04 - mse: 4.0552e-07 - mae: 4.8202e-04 - mape: 481347.6562\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7919e-04 - mse: 4.0053e-07 - mae: 4.7919e-04 - mape: 478496.1875\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7684e-04 - mse: 3.9743e-07 - mae: 4.7684e-04 - mape: 476168.2812\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7416e-04 - mse: 3.9282e-07 - mae: 4.7416e-04 - mape: 473486.5000\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7209e-04 - mse: 3.8870e-07 - mae: 4.7209e-04 - mape: 471399.5938\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.6943e-04 - mse: 3.8465e-07 - mae: 4.6943e-04 - mape: 468781.5000\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.6651e-04 - mse: 3.7998e-07 - mae: 4.6651e-04 - mape: 465864.1875\n",
      "Epoch 196/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.6460e-04 - mse: 3.7679e-07 - mae: 4.6460e-04 - mape: 463938.6562\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.6139e-04 - mse: 3.7183e-07 - mae: 4.6139e-04 - mape: 460744.2500\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.5857e-04 - mse: 3.6754e-07 - mae: 4.5857e-04 - mape: 457924.2812\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.5642e-04 - mse: 3.6393e-07 - mae: 4.5642e-04 - mape: 455761.0625\n",
      "Epoch 200/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.5472e-04 - mse: 3.6106e-07 - mae: 4.5472e-04 - mape: 454074.8125\n",
      "63/63 [==============================] - 0s 749us/step\n",
      "7/7 [==============================] - 0s 919us/step\n",
      "===================================================\n",
      "Training Mixture Density Network (MDN): Means: END!\n",
      "===================================================\n",
      "(1)\n",
      "===================================================\n",
      "Training Mixture Density Network (MDN): SD: Start!\n",
      "===================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   20.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   20.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0000 - mse: 1.0028 - mae: 1.0000 - mape: 99998992.0000\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9967 - mse: 0.9963 - mae: 0.9967 - mape: 99671456.0000\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9932 - mse: 0.9893 - mae: 0.9932 - mape: 99322048.0000\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9894 - mse: 0.9817 - mae: 0.9894 - mape: 98937504.0000\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9851 - mse: 0.9732 - mae: 0.9851 - mape: 98507672.0000\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9803 - mse: 0.9637 - mae: 0.9803 - mape: 98024048.0000\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9748 - mse: 0.9530 - mae: 0.9748 - mape: 97478040.0000\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9686 - mse: 0.9411 - mae: 0.9686 - mape: 96861640.0000\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9617 - mse: 0.9277 - mae: 0.9617 - mape: 96168536.0000\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9539 - mse: 0.9129 - mae: 0.9539 - mape: 95392264.0000\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9453 - mse: 0.8965 - mae: 0.9453 - mape: 94528552.0000\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9358 - mse: 0.8786 - mae: 0.9358 - mape: 93573272.0000\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9252 - mse: 0.8591 - mae: 0.9252 - mape: 92522560.0000\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9138 - mse: 0.8380 - mae: 0.9138 - mape: 91375216.0000\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9013 - mse: 0.8154 - mae: 0.9013 - mape: 90130280.0000\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8879 - mse: 0.7915 - mae: 0.8879 - mape: 88790336.0000\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8736 - mse: 0.7663 - mae: 0.8736 - mape: 87354136.0000\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8583 - mse: 0.7399 - mae: 0.8583 - mape: 85827944.0000\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8422 - mse: 0.7125 - mae: 0.8422 - mape: 84213864.0000\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8252 - mse: 0.6842 - mae: 0.8252 - mape: 82518424.0000\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8075 - mse: 0.6554 - mae: 0.8075 - mape: 80750296.0000\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7892 - mse: 0.6261 - mae: 0.7892 - mape: 78914512.0000\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7702 - mse: 0.5966 - mae: 0.7702 - mape: 77016112.0000\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7507 - mse: 0.5670 - mae: 0.7507 - mape: 75067536.0000\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7308 - mse: 0.5375 - mae: 0.7308 - mape: 73074720.0000\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7105 - mse: 0.5082 - mae: 0.7105 - mape: 71046968.0000\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6899 - mse: 0.4794 - mae: 0.6899 - mape: 68989832.0000\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6691 - mse: 0.4512 - mae: 0.6691 - mape: 66912960.0000\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6482 - mse: 0.4237 - mae: 0.6482 - mape: 64823328.0000\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6273 - mse: 0.3969 - mae: 0.6273 - mape: 62730732.0000\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6064 - mse: 0.3711 - mae: 0.6064 - mape: 60637544.0000\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5856 - mse: 0.3462 - mae: 0.5856 - mape: 58554608.0000\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5649 - mse: 0.3224 - mae: 0.5649 - mape: 56487272.0000\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5444 - mse: 0.2996 - mae: 0.5444 - mape: 54441780.0000\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5242 - mse: 0.2779 - mae: 0.5242 - mape: 52422660.0000\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5043 - mse: 0.2574 - mae: 0.5043 - mape: 50433816.0000\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4848 - mse: 0.2379 - mae: 0.4848 - mape: 48477048.0000\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4656 - mse: 0.2196 - mae: 0.4656 - mape: 46561804.0000\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4469 - mse: 0.2024 - mae: 0.4469 - mape: 44689328.0000\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4286 - mse: 0.1863 - mae: 0.4286 - mape: 42860560.0000\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4108 - mse: 0.1713 - mae: 0.4108 - mape: 41079788.0000\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3935 - mse: 0.1572 - mae: 0.3935 - mape: 39348868.0000\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3767 - mse: 0.1442 - mae: 0.3767 - mape: 37666752.0000\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3604 - mse: 0.1321 - mae: 0.3604 - mape: 36037632.0000\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3446 - mse: 0.1208 - mae: 0.3446 - mape: 34460572.0000\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3294 - mse: 0.1105 - mae: 0.3294 - mape: 32937902.0000\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3147 - mse: 0.1009 - mae: 0.3147 - mape: 31469582.0000\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3005 - mse: 0.0921 - mae: 0.3005 - mape: 30052174.0000\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2869 - mse: 0.0840 - mae: 0.2869 - mape: 28688626.0000\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2738 - mse: 0.0765 - mae: 0.2738 - mape: 27378880.0000\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2612 - mse: 0.0697 - mae: 0.2612 - mape: 26119380.0000\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2491 - mse: 0.0634 - mae: 0.2491 - mape: 24910254.0000\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2375 - mse: 0.0577 - mae: 0.2375 - mape: 23751228.0000\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2264 - mse: 0.0524 - mae: 0.2264 - mape: 22640898.0000\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2158 - mse: 0.0477 - mae: 0.2158 - mape: 21578958.0000\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2056 - mse: 0.0433 - mae: 0.2056 - mape: 20561810.0000\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1959 - mse: 0.0393 - mae: 0.1959 - mape: 19589174.0000\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1866 - mse: 0.0357 - mae: 0.1866 - mape: 18662036.0000\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1777 - mse: 0.0324 - mae: 0.1777 - mape: 17774486.0000\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1693 - mse: 0.0294 - mae: 0.1693 - mape: 16929012.0000\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1612 - mse: 0.0267 - mae: 0.1612 - mape: 16121245.0000\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1535 - mse: 0.0242 - mae: 0.1535 - mape: 15352144.0000\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1462 - mse: 0.0220 - mae: 0.1462 - mape: 14617332.0000\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1392 - mse: 0.0199 - mae: 0.1392 - mape: 13917460.0000\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1325 - mse: 0.0181 - mae: 0.1325 - mape: 13252238.0000\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1262 - mse: 0.0164 - mae: 0.1262 - mape: 12617263.0000\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1201 - mse: 0.0149 - mae: 0.1201 - mape: 12014324.0000\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1144 - mse: 0.0135 - mae: 0.1144 - mape: 11438579.0000\n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1089 - mse: 0.0122 - mae: 0.1089 - mape: 10891381.0000\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1037 - mse: 0.0111 - mae: 0.1037 - mape: 10370608.0000\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0988 - mse: 0.0101 - mae: 0.0988 - mape: 9875584.0000\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0940 - mse: 0.0091 - mae: 0.0940 - mape: 9403799.0000\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0896 - mse: 0.0083 - mae: 0.0896 - mape: 8956171.0000\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0853 - mse: 0.0075 - mae: 0.0853 - mape: 8529626.0000\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0812 - mse: 0.0068 - mae: 0.0812 - mape: 8123825.5000\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0774 - mse: 0.0062 - mae: 0.0774 - mape: 7738498.5000\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0737 - mse: 0.0056 - mae: 0.0737 - mape: 7371571.5000\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0702 - mse: 0.0051 - mae: 0.0702 - mape: 7022360.5000\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0669 - mse: 0.0046 - mae: 0.0669 - mape: 6690721.0000\n",
      "Epoch 80/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0638 - mse: 0.0042 - mae: 0.0638 - mape: 6375406.5000\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0608 - mse: 0.0038 - mae: 0.0608 - mape: 6075503.0000\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0035 - mae: 0.0579 - mape: 5790133.0000\n",
      "Epoch 83/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0552 - mse: 0.0032 - mae: 0.0552 - mape: 5519085.0000\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0029 - mae: 0.0526 - mape: 5260872.0000\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0502 - mse: 0.0026 - mae: 0.0502 - mape: 5015584.5000\n",
      "Epoch 86/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0478 - mse: 0.0024 - mae: 0.0478 - mape: 4782206.0000\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0456 - mse: 0.0022 - mae: 0.0456 - mape: 4560256.5000\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0020 - mae: 0.0435 - mape: 4349001.0000\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0018 - mae: 0.0415 - mape: 4148054.5000\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0016 - mae: 0.0396 - mape: 3956811.0000\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0015 - mae: 0.0377 - mape: 3774931.0000\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0014 - mae: 0.0360 - mape: 3601876.2500\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0344 - mse: 0.0012 - mae: 0.0344 - mape: 3437042.0000\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0328 - mse: 0.0011 - mae: 0.0328 - mape: 3280221.7500\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0010 - mae: 0.0313 - mape: 3130941.2500\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0299 - mse: 9.3254e-04 - mae: 0.0299 - mape: 2988592.2500\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0285 - mse: 8.5047e-04 - mae: 0.0285 - mape: 2853356.5000\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0272 - mse: 7.7577e-04 - mae: 0.0272 - mape: 2724476.7500\n",
      "Epoch 99/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 7.0763e-04 - mae: 0.0260 - mape: 2601668.5000\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0248 - mse: 6.4583e-04 - mae: 0.0248 - mape: 2484866.2500\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0237 - mse: 5.8943e-04 - mae: 0.0237 - mape: 2373373.7500\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0227 - mse: 5.3817e-04 - mae: 0.0227 - mape: 2267270.2500\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0217 - mse: 4.9134e-04 - mae: 0.0217 - mape: 2166083.2500\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 4.4879e-04 - mae: 0.0207 - mape: 2069665.7500\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 4.1000e-04 - mae: 0.0198 - mape: 1977834.3750\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 3.7463e-04 - mae: 0.0189 - mape: 1890282.5000\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 3.4248e-04 - mae: 0.0181 - mape: 1806869.3750\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0173 - mse: 3.1310e-04 - mae: 0.0173 - mape: 1727286.5000\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 2.8633e-04 - mae: 0.0165 - mape: 1651393.2500\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 2.6188e-04 - mae: 0.0158 - mape: 1578999.3750\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 2.3960e-04 - mae: 0.0151 - mape: 1510028.1250\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 2.1923e-04 - mae: 0.0144 - mape: 1444085.8750\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 2.0069e-04 - mae: 0.0138 - mape: 1381295.2500\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0132 - mse: 1.8370e-04 - mae: 0.0132 - mape: 1321446.1250\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 1.6824e-04 - mae: 0.0126 - mape: 1264198.2500\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 1.5409e-04 - mae: 0.0121 - mape: 1209600.2500\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 1.4114e-04 - mae: 0.0116 - mape: 1157472.7500\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 1.2934e-04 - mae: 0.0111 - mape: 1107799.0000\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 1.1853e-04 - mae: 0.0106 - mape: 1060267.2500\n",
      "Epoch 120/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 1.0863e-04 - mae: 0.0101 - mape: 1014862.9375\n",
      "Epoch 121/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 9.9608e-05 - mae: 0.0097 - mape: 971560.5625\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 9.1352e-05 - mae: 0.0093 - mape: 930233.9375\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 8.3782e-05 - mae: 0.0089 - mape: 890683.2500\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 7.6881e-05 - mae: 0.0085 - mape: 852943.9375\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 7.0534e-05 - mae: 0.0082 - mape: 816898.1875\n",
      "Epoch 126/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0078 - mse: 6.4735e-05 - mae: 0.0078 - mape: 782408.7500\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 5.9419e-05 - mae: 0.0075 - mape: 749461.1250\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 5.4556e-05 - mae: 0.0072 - mape: 718003.0000\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 5.0099e-05 - mae: 0.0069 - mape: 687883.8125\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 4.6015e-05 - mae: 0.0066 - mape: 659080.9375\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 4.2278e-05 - mae: 0.0063 - mape: 631633.6250\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 3.8838e-05 - mae: 0.0061 - mape: 605292.8125\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 3.5697e-05 - mae: 0.0058 - mape: 580149.8125\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 3.2805e-05 - mae: 0.0056 - mape: 556066.4375\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 3.0163e-05 - mae: 0.0053 - mape: 533076.3750\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 2.7729e-05 - mae: 0.0051 - mape: 511040.6875\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 2.5499e-05 - mae: 0.0049 - mape: 489966.4688\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 2.3460e-05 - mae: 0.0047 - mape: 469820.3438\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 2.1579e-05 - mae: 0.0045 - mape: 450524.7500\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 1.9857e-05 - mae: 0.0043 - mape: 432073.0625\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 1.8272e-05 - mae: 0.0041 - mape: 414397.9375\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 1.6816e-05 - mae: 0.0040 - mape: 397455.9375\n",
      "Epoch 143/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 1.5482e-05 - mae: 0.0038 - mape: 381276.6250\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 1.4253e-05 - mae: 0.0037 - mape: 365752.4688\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 1.3125e-05 - mae: 0.0035 - mape: 350911.0312\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 1.2086e-05 - mae: 0.0034 - mape: 336677.7188\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 1.1135e-05 - mae: 0.0032 - mape: 323081.3750\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0031 - mse: 1.0254e-05 - mae: 0.0031 - mape: 309999.1250\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 9.4511e-06 - mae: 0.0030 - mape: 297534.1562\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 8.7072e-06 - mae: 0.0029 - mape: 285537.5312\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 8.0274e-06 - mae: 0.0027 - mape: 274076.8438\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 7.3987e-06 - mae: 0.0026 - mape: 263090.3438\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 6.8210e-06 - mae: 0.0025 - mape: 252565.7812\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 6.2889e-06 - mae: 0.0024 - mape: 242461.3438\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 5.8005e-06 - mae: 0.0023 - mape: 232798.8281\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0022 - mse: 5.3480e-06 - mae: 0.0022 - mape: 223517.4375\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 4.9348e-06 - mae: 0.0021 - mape: 214646.6719\n",
      "Epoch 158/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 4.5520e-06 - mae: 0.0021 - mape: 206113.3125\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 4.1999e-06 - mae: 0.0020 - mape: 197948.8281\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 3.8770e-06 - mae: 0.0019 - mape: 190121.7188\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 3.5779e-06 - mae: 0.0018 - mape: 182616.0938\n",
      "Epoch 162/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 3.3024e-06 - mae: 0.0018 - mape: 175409.5781\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 3.0483e-06 - mae: 0.0017 - mape: 168502.4844\n",
      "Epoch 164/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 2.8152e-06 - mae: 0.0016 - mape: 161887.8906\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 2.5991e-06 - mae: 0.0016 - mape: 155522.7500\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 2.4005e-06 - mae: 0.0015 - mape: 149429.4062\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 2.2172e-06 - mae: 0.0014 - mape: 143579.0156\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 2.0483e-06 - mae: 0.0014 - mape: 137967.7031\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 1.8921e-06 - mae: 0.0013 - mape: 132583.9062\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 1.7482e-06 - mae: 0.0013 - mape: 127419.9922\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 1.6158e-06 - mae: 0.0012 - mape: 122463.5781\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 1.4931e-06 - mae: 0.0012 - mape: 117706.7891\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 1.3805e-06 - mae: 0.0011 - mape: 113142.9062\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 1.2760e-06 - mae: 0.0011 - mape: 108758.4609\n",
      "Epoch 175/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 1.1795e-06 - mae: 0.0010 - mape: 104551.3594\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 1.0907e-06 - mae: 0.0010 - mape: 100508.9219\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.6635e-04 - mse: 1.0086e-06 - mae: 9.6635e-04 - mape: 96633.6875\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.2912e-04 - mse: 9.3276e-07 - mae: 9.2912e-04 - mape: 92910.9297\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.9338e-04 - mse: 8.6276e-07 - mae: 8.9338e-04 - mape: 89336.8047\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.5906e-04 - mse: 7.9794e-07 - mae: 8.5906e-04 - mape: 85905.2891\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.2611e-04 - mse: 7.3824e-07 - mae: 8.2611e-04 - mape: 82609.8047\n",
      "Epoch 182/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.9445e-04 - mse: 6.8301e-07 - mae: 7.9445e-04 - mape: 79443.7344\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6405e-04 - mse: 6.3193e-07 - mae: 7.6405e-04 - mape: 76404.0703\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.3486e-04 - mse: 5.8493e-07 - mae: 7.3486e-04 - mape: 73484.6719\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 7.0682e-04 - mse: 5.4140e-07 - mae: 7.0682e-04 - mape: 70680.8203\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.7985e-04 - mse: 5.0097e-07 - mae: 6.7985e-04 - mape: 67984.1562\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.5402e-04 - mse: 4.6396e-07 - mae: 6.5402e-04 - mape: 65400.8867\n",
      "Epoch 188/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2914e-04 - mse: 4.2946e-07 - mae: 6.2914e-04 - mape: 62913.2852\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.0526e-04 - mse: 3.9762e-07 - mae: 6.0526e-04 - mape: 60524.8867\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8232e-04 - mse: 3.6821e-07 - mae: 5.8232e-04 - mape: 58230.7812\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.6030e-04 - mse: 3.4109e-07 - mae: 5.6030e-04 - mape: 56028.8320\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.3909e-04 - mse: 3.1581e-07 - mae: 5.3909e-04 - mape: 53908.7422\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1872e-04 - mse: 2.9247e-07 - mae: 5.1872e-04 - mape: 51871.5273\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9913e-04 - mse: 2.7092e-07 - mae: 4.9913e-04 - mape: 49912.7617\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8033e-04 - mse: 2.5106e-07 - mae: 4.8033e-04 - mape: 48032.2344\n",
      "Epoch 196/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.6223e-04 - mse: 2.3258e-07 - mae: 4.6223e-04 - mape: 46222.0391\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.4485e-04 - mse: 2.1552e-07 - mae: 4.4485e-04 - mape: 44484.8711\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2815e-04 - mse: 1.9970e-07 - mae: 4.2815e-04 - mape: 42814.0938\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.1208e-04 - mse: 1.8510e-07 - mae: 4.1208e-04 - mape: 41207.9219\n",
      "Epoch 200/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.9664e-04 - mse: 1.7157e-07 - mae: 3.9664e-04 - mape: 39663.2031\n",
      "63/63 [==============================] - 0s 746us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "=================================================\n",
      "Training Mixture Density Network (MDN): SD: END!\n",
      "=================================================\n",
      "(2)\n",
      "====================================================================\n",
      "Training Mixture Density Network (MDN): Mixture Coefficients: Start!\n",
      "====================================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   18.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   18.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5999 - accuracy: 0.9630\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9990\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9990\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9990\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9990\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9990\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9990\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9990\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9990\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9990\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9990\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9990\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9990\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9990\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9990\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9990\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9990\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.3116e-04 - accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.3986e-04 - accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 8.7477e-04 - accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9990\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.0102e-04 - accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9990\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.1746e-04 - accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.2370e-04 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9477e-04 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6692e-04 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5467e-04 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6219e-04 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4555e-04 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2141e-04 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2034e-04 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0942e-04 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0626e-04 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9552e-04 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0144e-04 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9457e-04 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8828e-04 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8778e-04 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8040e-04 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8115e-04 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7560e-04 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7521e-04 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6996e-04 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7194e-04 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6668e-04 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6695e-04 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6422e-04 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6552e-04 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6284e-04 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5960e-04 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6046e-04 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5880e-04 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6364e-04 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6028e-04 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6666e-04 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5653e-04 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5614e-04 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5587e-04 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5724e-04 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5539e-04 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5777e-04 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5341e-04 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5444e-04 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5175e-04 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5628e-04 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5185e-04 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5245e-04 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5057e-04 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5278e-04 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4953e-04 - accuracy: 1.0000\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5093e-04 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4883e-04 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4930e-04 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4870e-04 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4995e-04 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4753e-04 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5095e-04 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4767e-04 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7236e-04 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4568e-04 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4616e-04 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4723e-04 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4481e-04 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4602e-04 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4276e-04 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4293e-04 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4211e-04 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4278e-04 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4404e-04 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4449e-04 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4696e-04 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4642e-04 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5492e-04 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4425e-04 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4907e-04 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4583e-04 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5343e-04 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4308e-04 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4609e-04 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4400e-04 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5005e-04 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4332e-04 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4489e-04 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4136e-04 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4051e-04 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4152e-04 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4388e-04 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4449e-04 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5673e-04 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4580e-04 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5716e-04 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4365e-04 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5131e-04 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4441e-04 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5242e-04 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4385e-04 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4942e-04 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4424e-04 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5317e-04 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4388e-04 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5144e-04 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4450e-04 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5205e-04 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4418e-04 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5248e-04 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4471e-04 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5385e-04 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4366e-04 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5257e-04 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4514e-04 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5622e-04 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4343e-04 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5208e-04 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4413e-04 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5267e-04 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4472e-04 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5501e-04 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4295e-04 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5008e-04 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4565e-04 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5846e-04 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4354e-04 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5282e-04 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4509e-04 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5645e-04 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4299e-04 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5064e-04 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6815e-04 - accuracy: 1.0000\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 2.7948e-04 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0458e-04 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6660e-04 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9990\n",
      "Epoch 162/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9970\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9147e-04 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4859e-04 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4614e-04 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4440e-04 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4376e-04 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4339e-04 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4297e-04 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4265e-04 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4243e-04 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4234e-04 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4207e-04 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4196e-04 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4170e-04 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4174e-04 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4137e-04 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4133e-04 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4123e-04 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4109e-04 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4094e-04 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4081e-04 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4074e-04 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4060e-04 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4058e-04 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4046e-04 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4042e-04 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4025e-04 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4020e-04 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4005e-04 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4001e-04 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3994e-04 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3991e-04 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3979e-04 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3976e-04 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3974e-04 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3961e-04 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3959e-04 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3955e-04 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3943e-04 - accuracy: 1.0000\n",
      "63/63 [==============================] - 0s 795us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "Training Mixture Density Network (MDN): Mixture Coefficients: END!\n",
      "==================================================================\n",
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:04<00:00,  2.74it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------#\n",
      " Get Test Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:36<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      " Get Test Error(s): END\n",
      "#---------------------#\n",
      "#---------------------------#\n",
      " Get Training Error(s): Begin\n",
      "#---------------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------------#\n",
      " Get Testing Error(s): Begin\n",
      "#--------------------------#\n",
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n",
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "Updated DataFrame\n",
      "-------------------------------------------------\n",
      "Train\n",
      "                                        DNM     MC-Oracle          ENET  \\\n",
      "W1-95L                         0.000000e+00  0.000000e+00  1.709752e-14   \n",
      "W1                             9.807499e-10  0.000000e+00  9.807326e-10   \n",
      "W1-95R                         2.942250e-09  0.000000e+00  2.942164e-09   \n",
      "M-95L                          0.000000e+00  0.000000e+00  1.307575e-07   \n",
      "M                              1.307575e-07  1.307575e-07  2.612535e-07   \n",
      "M-95R                          3.922725e-07  2.615150e-07  6.527414e-07   \n",
      "N_Par                          1.429000e+05  0.000000e+00  2.000000e+03   \n",
      "Train_Time                     1.968675e+02  7.469260e+01  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  6.746589e-03  1.000000e+00  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \\\n",
      "W1-95L                         1.418350e-09  1.709752e-14  2.985013e-08   \n",
      "W1                             2.467959e-09  9.807326e-10  3.257061e-08   \n",
      "W1-95R                         5.374323e-09  2.942164e-09  3.662443e-08   \n",
      "M-95L                          2.903003e-05  1.307575e-07  1.388953e-04   \n",
      "M                              3.041741e-05  2.612535e-07  1.444368e-04   \n",
      "M-95R                          3.175325e-05  6.527414e-07  1.519813e-04   \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
      "\n",
      "                                        GPR           DGN           MDN  \n",
      "W1-95L                         9.974428e-06      0.993366  3.604657e-07  \n",
      "W1                             9.999199e-06      0.995671  3.880173e-07  \n",
      "W1-95R                         1.002150e-05      0.998542  4.121277e-07  \n",
      "M-95L                          0.000000e+00      0.003250  4.086847e-04  \n",
      "M                              1.307575e-07      0.003334  4.313512e-04  \n",
      "M-95R                          3.922725e-07      0.003401  4.543688e-04  \n",
      "N_Par                          0.000000e+00  42601.000000  4.287000e+05  \n",
      "Train_Time                     3.119642e+00     32.067623  1.339602e-01  \n",
      "Test_Time/MC-Oracle_Test_Time  1.652429e-03      0.006597  4.481116e+02  \n",
      "-------------------------------------------------\n",
      "Test\n",
      "                                         DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
      "W1                                  0.000000   0.000000  1.709752e-14   \n",
      "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
      "M-95L                               0.000000   0.000000  1.307575e-07   \n",
      "M                                   0.000000   0.000000  1.307575e-07   \n",
      "M-95R                               0.000000   0.000000  1.307575e-07   \n",
      "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
      "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \\\n",
      "W1-95L                         1.169624e-09  1.709752e-14  2.737858e-08   \n",
      "W1                             1.535477e-09  1.709752e-14  3.526919e-08   \n",
      "W1-95R                         2.124551e-09  1.709752e-14  4.487373e-08   \n",
      "M-95L                          2.741548e-05  1.307575e-07  1.379667e-04   \n",
      "M                              3.126684e-05  1.307575e-07  1.567749e-04   \n",
      "M-95R                          3.713166e-05  1.307575e-07  1.808069e-04   \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
      "\n",
      "                                    GPR           DGN           MDN  \n",
      "W1-95L                         0.000010      0.982011  3.521168e-07  \n",
      "W1                             0.000010      0.989217  4.602369e-07  \n",
      "W1-95R                         0.000010      0.998977  5.900902e-07  \n",
      "M-95L                          0.000000      0.003124  3.801897e-04  \n",
      "M                              0.000000      0.003425  4.665028e-04  \n",
      "M-95R                          0.000000      0.003639  5.484304e-04  \n",
      "N_Par                          0.000000  42601.000000  4.287000e+05  \n",
      "Train_Time                     3.119642     32.067623  1.339602e-01  \n",
      "Test_Time/MC-Oracle_Test_Time  0.001652      0.006597  4.481116e+02  \n",
      "-------------------------------------------------\n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "Have a jolly old day!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if output_dim == 1:\n",
    "    # %run Mixture_Density_Network.ipynb\n",
    "    exec(open('Mixture_Density_Network.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Final Outputs\n",
    "Now we piece together all the numerical experiments and report a nice summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training-Set Result(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "      <th>MDN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>1.418350e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>2.985013e-08</td>\n",
       "      <td>9.974428e-06</td>\n",
       "      <td>0.993366</td>\n",
       "      <td>3.604657e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>9.807499e-10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.807326e-10</td>\n",
       "      <td>2.467959e-09</td>\n",
       "      <td>9.807326e-10</td>\n",
       "      <td>3.257061e-08</td>\n",
       "      <td>9.999199e-06</td>\n",
       "      <td>0.995671</td>\n",
       "      <td>3.880173e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>2.942250e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.942164e-09</td>\n",
       "      <td>5.374323e-09</td>\n",
       "      <td>2.942164e-09</td>\n",
       "      <td>3.662443e-08</td>\n",
       "      <td>1.002150e-05</td>\n",
       "      <td>0.998542</td>\n",
       "      <td>4.121277e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>2.903003e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.388953e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>4.086847e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>2.612535e-07</td>\n",
       "      <td>3.041741e-05</td>\n",
       "      <td>2.612535e-07</td>\n",
       "      <td>1.444368e-04</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.313512e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>3.922725e-07</td>\n",
       "      <td>2.615150e-07</td>\n",
       "      <td>6.527414e-07</td>\n",
       "      <td>3.175325e-05</td>\n",
       "      <td>6.527414e-07</td>\n",
       "      <td>1.519813e-04</td>\n",
       "      <td>3.922725e-07</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>4.543688e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>1.429000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>4.260100e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>42601.000000</td>\n",
       "      <td>4.287000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.968675e+02</td>\n",
       "      <td>7.469260e+01</td>\n",
       "      <td>1.620045e+09</td>\n",
       "      <td>1.351780e+00</td>\n",
       "      <td>7.231278e-01</td>\n",
       "      <td>3.167162e+01</td>\n",
       "      <td>3.119642e+00</td>\n",
       "      <td>32.067623</td>\n",
       "      <td>1.339602e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>6.746589e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.347323e-05</td>\n",
       "      <td>1.008267e-03</td>\n",
       "      <td>2.181460e-04</td>\n",
       "      <td>6.577985e-03</td>\n",
       "      <td>1.652429e-03</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>4.481116e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM     MC-Oracle          ENET  \\\n",
       "W1-95L                         0.000000e+00  0.000000e+00  1.709752e-14   \n",
       "W1                             9.807499e-10  0.000000e+00  9.807326e-10   \n",
       "W1-95R                         2.942250e-09  0.000000e+00  2.942164e-09   \n",
       "M-95L                          0.000000e+00  0.000000e+00  1.307575e-07   \n",
       "M                              1.307575e-07  1.307575e-07  2.612535e-07   \n",
       "M-95R                          3.922725e-07  2.615150e-07  6.527414e-07   \n",
       "N_Par                          1.429000e+05  0.000000e+00  2.000000e+03   \n",
       "Train_Time                     1.968675e+02  7.469260e+01  1.620045e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  6.746589e-03  1.000000e+00  2.347323e-05   \n",
       "\n",
       "                                     KRidge          GBRF           DNN  \\\n",
       "W1-95L                         1.418350e-09  1.709752e-14  2.985013e-08   \n",
       "W1                             2.467959e-09  9.807326e-10  3.257061e-08   \n",
       "W1-95R                         5.374323e-09  2.942164e-09  3.662443e-08   \n",
       "M-95L                          2.903003e-05  1.307575e-07  1.388953e-04   \n",
       "M                              3.041741e-05  2.612535e-07  1.444368e-04   \n",
       "M-95R                          3.175325e-05  6.527414e-07  1.519813e-04   \n",
       "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
       "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
       "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
       "\n",
       "                                        GPR           DGN           MDN  \n",
       "W1-95L                         9.974428e-06      0.993366  3.604657e-07  \n",
       "W1                             9.999199e-06      0.995671  3.880173e-07  \n",
       "W1-95R                         1.002150e-05      0.998542  4.121277e-07  \n",
       "M-95L                          0.000000e+00      0.003250  4.086847e-04  \n",
       "M                              1.307575e-07      0.003334  4.313512e-04  \n",
       "M-95R                          3.922725e-07      0.003401  4.543688e-04  \n",
       "N_Par                          0.000000e+00  42601.000000  4.287000e+05  \n",
       "Train_Time                     3.119642e+00     32.067623  1.339602e-01  \n",
       "Test_Time/MC-Oracle_Test_Time  1.652429e-03      0.006597  4.481116e+02  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Final Training-Set Result(s)\")\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test-Set Result(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "      <th>MDN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>1.169624e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>2.737858e-08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>3.521168e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>1.535477e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>3.526919e-08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.989217</td>\n",
       "      <td>4.602369e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>2.124551e-09</td>\n",
       "      <td>1.709752e-14</td>\n",
       "      <td>4.487373e-08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.998977</td>\n",
       "      <td>5.900902e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>2.741548e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.379667e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>3.801897e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>3.126684e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.567749e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>4.665028e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>3.713166e-05</td>\n",
       "      <td>1.307575e-07</td>\n",
       "      <td>1.808069e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>5.484304e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>142900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>4.260100e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42601.000000</td>\n",
       "      <td>4.287000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>196.867494</td>\n",
       "      <td>74.692599</td>\n",
       "      <td>1.620045e+09</td>\n",
       "      <td>1.351780e+00</td>\n",
       "      <td>7.231278e-01</td>\n",
       "      <td>3.167162e+01</td>\n",
       "      <td>3.119642</td>\n",
       "      <td>32.067623</td>\n",
       "      <td>1.339602e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>0.006747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.347323e-05</td>\n",
       "      <td>1.008267e-03</td>\n",
       "      <td>2.181460e-04</td>\n",
       "      <td>6.577985e-03</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>4.481116e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         DNM  MC-Oracle          ENET  \\\n",
       "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
       "W1                                  0.000000   0.000000  1.709752e-14   \n",
       "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
       "M-95L                               0.000000   0.000000  1.307575e-07   \n",
       "M                                   0.000000   0.000000  1.307575e-07   \n",
       "M-95R                               0.000000   0.000000  1.307575e-07   \n",
       "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
       "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
       "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
       "\n",
       "                                     KRidge          GBRF           DNN  \\\n",
       "W1-95L                         1.169624e-09  1.709752e-14  2.737858e-08   \n",
       "W1                             1.535477e-09  1.709752e-14  3.526919e-08   \n",
       "W1-95R                         2.124551e-09  1.709752e-14  4.487373e-08   \n",
       "M-95L                          2.741548e-05  1.307575e-07  1.379667e-04   \n",
       "M                              3.126684e-05  1.307575e-07  1.567749e-04   \n",
       "M-95R                          3.713166e-05  1.307575e-07  1.808069e-04   \n",
       "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
       "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
       "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
       "\n",
       "                                    GPR           DGN           MDN  \n",
       "W1-95L                         0.000010      0.982011  3.521168e-07  \n",
       "W1                             0.000010      0.989217  4.602369e-07  \n",
       "W1-95R                         0.000010      0.998977  5.900902e-07  \n",
       "M-95L                          0.000000      0.003124  3.801897e-04  \n",
       "M                              0.000000      0.003425  4.665028e-04  \n",
       "M-95R                          0.000000      0.003639  5.484304e-04  \n",
       "N_Par                          0.000000  42601.000000  4.287000e+05  \n",
       "Train_Time                     3.119642     32.067623  1.339602e-01  \n",
       "Test_Time/MC-Oracle_Test_Time  0.001652      0.006597  4.481116e+02  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Final Test-Set Result(s)\")\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Terminal Runner(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Training Predictive Quality:\n",
      "============================\n",
      "                                        DNM     MC-Oracle          ENET  \\\n",
      "W1-95L                         0.000000e+00  0.000000e+00  1.709752e-14   \n",
      "W1                             9.807499e-10  0.000000e+00  9.807326e-10   \n",
      "W1-95R                         2.942250e-09  0.000000e+00  2.942164e-09   \n",
      "M-95L                          0.000000e+00  0.000000e+00  1.307575e-07   \n",
      "M                              1.307575e-07  1.307575e-07  2.612535e-07   \n",
      "M-95R                          3.922725e-07  2.615150e-07  6.527414e-07   \n",
      "N_Par                          1.429000e+05  0.000000e+00  2.000000e+03   \n",
      "Train_Time                     1.968675e+02  7.469260e+01  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  6.746589e-03  1.000000e+00  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \\\n",
      "W1-95L                         1.418350e-09  1.709752e-14  2.985013e-08   \n",
      "W1                             2.467959e-09  9.807326e-10  3.257061e-08   \n",
      "W1-95R                         5.374323e-09  2.942164e-09  3.662443e-08   \n",
      "M-95L                          2.903003e-05  1.307575e-07  1.388953e-04   \n",
      "M                              3.041741e-05  2.612535e-07  1.444368e-04   \n",
      "M-95R                          3.175325e-05  6.527414e-07  1.519813e-04   \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
      "\n",
      "                                        GPR           DGN           MDN  \n",
      "W1-95L                         9.974428e-06      0.993366  3.604657e-07  \n",
      "W1                             9.999199e-06      0.995671  3.880173e-07  \n",
      "W1-95R                         1.002150e-05      0.998542  4.121277e-07  \n",
      "M-95L                          0.000000e+00      0.003250  4.086847e-04  \n",
      "M                              1.307575e-07      0.003334  4.313512e-04  \n",
      "M-95R                          3.922725e-07      0.003401  4.543688e-04  \n",
      "N_Par                          0.000000e+00  42601.000000  4.287000e+05  \n",
      "Train_Time                     3.119642e+00     32.067623  1.339602e-01  \n",
      "Test_Time/MC-Oracle_Test_Time  1.652429e-03      0.006597  4.481116e+02  \n",
      " \n",
      " \n",
      " \n",
      "===========================\n",
      "Testing Predictive Quality:\n",
      "===========================\n",
      "                                         DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                              0.000000   0.000000  1.709752e-14   \n",
      "W1                                  0.000000   0.000000  1.709752e-14   \n",
      "W1-95R                              0.000000   0.000000  1.709752e-14   \n",
      "M-95L                               0.000000   0.000000  1.307575e-07   \n",
      "M                                   0.000000   0.000000  1.307575e-07   \n",
      "M-95R                               0.000000   0.000000  1.307575e-07   \n",
      "N_Par                          142900.000000   0.000000  2.000000e+03   \n",
      "Train_Time                        196.867494  74.692599  1.620045e+09   \n",
      "Test_Time/MC-Oracle_Test_Time       0.006747   1.000000  2.347323e-05   \n",
      "\n",
      "                                     KRidge          GBRF           DNN  \\\n",
      "W1-95L                         1.169624e-09  1.709752e-14  2.737858e-08   \n",
      "W1                             1.535477e-09  1.709752e-14  3.526919e-08   \n",
      "W1-95R                         2.124551e-09  1.709752e-14  4.487373e-08   \n",
      "M-95L                          2.741548e-05  1.307575e-07  1.379667e-04   \n",
      "M                              3.126684e-05  1.307575e-07  1.567749e-04   \n",
      "M-95R                          3.713166e-05  1.307575e-07  1.808069e-04   \n",
      "N_Par                          0.000000e+00  1.000000e+04  4.260100e+04   \n",
      "Train_Time                     1.351780e+00  7.231278e-01  3.167162e+01   \n",
      "Test_Time/MC-Oracle_Test_Time  1.008267e-03  2.181460e-04  6.577985e-03   \n",
      "\n",
      "                                    GPR           DGN           MDN  \n",
      "W1-95L                         0.000010      0.982011  3.521168e-07  \n",
      "W1                             0.000010      0.989217  4.602369e-07  \n",
      "W1-95R                         0.000010      0.998977  5.900902e-07  \n",
      "M-95L                          0.000000      0.003124  3.801897e-04  \n",
      "M                              0.000000      0.003425  4.665028e-04  \n",
      "M-95R                          0.000000      0.003639  5.484304e-04  \n",
      "N_Par                          0.000000  42601.000000  4.287000e+05  \n",
      "Train_Time                     3.119642     32.067623  1.339602e-01  \n",
      "Test_Time/MC-Oracle_Test_Time  0.001652      0.006597  4.481116e+02  \n",
      "================================\n",
      " \n",
      " \n",
      " \n",
      "Kernel_Used_in_GPR: WhiteKernel(noise_level=1)\n",
      "🙃🙃 Have a wonderful day! 🙃🙃\n"
     ]
    }
   ],
   "source": [
    "# For Terminal Running\n",
    "print(\"============================\")\n",
    "print(\"Training Predictive Quality:\")\n",
    "print(\"============================\")\n",
    "print(Summary_pred_Qual_models)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"===========================\")\n",
    "print(\"Testing Predictive Quality:\")\n",
    "print(\"===========================\")\n",
    "print(Summary_pred_Qual_models_test)\n",
    "print(\"================================\")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Kernel_Used_in_GPR: \"+str(GPR_trash.kernel))\n",
    "print(\"🙃🙃 Have a wonderful day! 🙃🙃\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
