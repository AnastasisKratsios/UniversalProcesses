{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"Random_DNN_internal_noise\":\n",
    "    def Simulator(x_in):\n",
    "        # Initialize Gaussian\n",
    "        cov = np.diag(np.ones(problem_dim))*0.01\n",
    "        noise = np.random.multivariate_normal(np.zeros(problem_dim), cov, N_Monte_Carlo_Samples)\n",
    "        x_inputs = x_in + noise\n",
    "        f_x_noise = np.apply_along_axis(f_unknown, 1, x_in)\n",
    "        return f_x_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\omega^{-1}(\\epsilon)$-Bounded Random Partitioner\n",
    "Generates a bounded random partition, in the sense of: [Geometry, Flows, and Graph-Partitioning Algorithms](https://cacm.acm.org/magazines/2008/10/515-geometry-flows-and-graph-partitioning-algorithms/fulltext?mobile=false), [A. Naor et al.](https://link.springer.com/article/10.1007/s00222-004-0400-5), as implemented in [Learning Sub-Patterns in Piece-Wise Continuous Functions](https://arxiv.org/abs/2010.15571)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize #\n",
    "#------------#\n",
    "X_training_remaining = np.copy(X_train)\n",
    "possible_indices_for_center = np.repeat(True,X_training_remaining.shape[0])\n",
    "indexing_set = np.array(range(X_training_remaining.shape[0]))\n",
    "\n",
    "# Tweak Radius of Balls\n",
    "# Note: To avoid \"too small\" of a delta\n",
    "dist_matrix = (distance_matrix(X_training_remaining[np.random.choice(indexing_set,max(1,round(X_training_remaining.shape[0]*.5)))],X_training_remaining[np.random.choice(indexing_set,max(1,round(X_training_remaining.shape[0]*.5)))]))\n",
    "dist_matrix = (dist_matrix[np.logical_not(dist_matrix == 0)]).reshape(-1,)\n",
    "delta = np.maximum(delta,np.quantile(dist_matrix,Proportion_per_cluster))\n",
    "\n",
    "\n",
    "\n",
    "# Build #\n",
    "#-------#\n",
    "while np.max(possible_indices_for_center)==True:  \n",
    "    # Randomize Radius\n",
    "    delta_loop = np.random.uniform(low=0,high=delta,size=1)[0]\n",
    "\n",
    "    # Get Random Center\n",
    "    random_center_loop_index = np.random.choice(indexing_set[possible_indices_for_center])\n",
    "    random_center_loop = (X_training_remaining[random_center_loop_index]).reshape([1,-1])\n",
    "\n",
    "    # Get Distances To Current Center\n",
    "    dist_mat_loop = np.sqrt(np.sum((random_center_loop-X_training_remaining)**2,axis=1))\n",
    "    ## Indentify which must lie in cluster but not counting previously removed elements\n",
    "    indices_cluster_loop = (dist_mat_loop<delta_loop)*possible_indices_for_center\n",
    "\n",
    "    # Update(s)\n",
    "    ## Outputs\n",
    "    if np.min(possible_indices_for_center)==True:\n",
    "        ## Initialize Classes\n",
    "        Train_classes = (indices_cluster_loop*1).reshape(-1,1)\n",
    "        ## PointMasses Center\n",
    "        Masses = int(random_center_loop_index)\n",
    "        # INITIALIZE: Barycenters Array\n",
    "        Barycenters_Array = (Y_train[int(random_center_loop_index)]).reshape(-1,)\n",
    "    else:\n",
    "        ## Update Classes\n",
    "        Train_classes = np.append(Train_classes,(indices_cluster_loop*1).reshape(-1,1),axis=-1)\n",
    "        ## PointMasses Center\n",
    "        Masses = np.append(Masses,random_center_loop_index)\n",
    "        # UPDATE: Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,(Y_train[int(random_center_loop_index)]).reshape(-1,),axis=-1)\n",
    "    ## Remove Clusterd Centers from Current Dataset\n",
    "    possible_indices_for_center = np.logical_not(indices_cluster_loop)*possible_indices_for_center\n",
    "\n",
    "# Format Training Classes\n",
    "Train_classes = pd.DataFrame(Train_classes)\n",
    "\n",
    "# Get Number of Classes\n",
    "N_Quantizers_to_parameterize = Train_classes.shape[1]\n",
    "\n",
    "# Update User #\n",
    "print(\"---------------\")\n",
    "print(\"==============---------------------------------------------------=============\")\n",
    "print(\"Number of Classes/measures Which Were Produced:\", N_Quantizers_to_parameterize)\n",
    "print(\"==============---------------------------------------------------=============\")\n",
    "print(\"===========================\")\n",
    "print(\"Training Classes Produced:\")\n",
    "print(\"===========================\")\n",
    "print(Train_classes)\n",
    "print(\"---------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
