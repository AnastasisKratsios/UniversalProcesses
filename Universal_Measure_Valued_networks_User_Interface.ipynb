{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Universal Regular Conditional Expectations:\n",
    "\n",
    "---\n",
    "This implements the universal deep neural model of $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$ [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---\n",
    "\n",
    "## What does this code do?\n",
    "1. Learn Heteroskedastic Non-Linear Regression Problem\n",
    "     - $Y\\sim f_{\\text{unkown}}(x) + \\epsilon$ where $f$ is an known function and $\\epsilon\\sim Laplace(0,\\|x\\|)$\n",
    "2. Learn Random Bayesian Network's Law:\n",
    "    - $Y = W_J Y^{J-1}, \\qquad Y^{j}\\triangleq \\sigma\\bullet A^{j}Y^{j-1} + b^{j}, \\qquad Y^0\\triangleq x$\n",
    "\n",
    "3. In the above example if $A_j = M_j\\odot \\tilde{A_j}$ where $\\tilde{A}_j$ is a deterministic matrix and $M_j$ is a \"mask\", that is, a random matrix with binary entries and $\\odot$ is the Hadamard product then we recover the dropout framework.\n",
    "4. Learn the probability distribution that the unique strong solution to the rough SDE with uniformly Lipschitz drivers driven by a factional Brownian motion with Hurst exponent $H \\in [\\frac1{2},1)$:\n",
    "$$\n",
    "X_t^x = x + \\int_0^t \\alpha(s,X_s^x)ds + \\int_0^t \\beta(s,X_s^x)dB_s^H\n",
    "$$\n",
    "belongs, at time $t=1$, to a ball about the initial point $x$ of random radius given by an independant exponential random-variable with shape parameter $\\lambda=2$\n",
    "5. Train a DNN to predict the returns of bitcoin with GD.  Since this has random initialization then each prediction of a given $x$ is stochastic...We learn the distribution of this conditional RV (conditioned on x in the input space).\n",
    "$$\n",
    "Y_x \\triangleq \\hat{f}_{\\theta_{T}}(x), \\qquad \\theta_{(t+1)}\\triangleq \\theta_{(t)} + \\lambda \\sum_{x \\in \\mathbb{X}} \\nabla_{\\theta}\\|\\hat{f}_{\\theta_t}(x) - f(x)\\|, \\qquad \\theta_0 \\sim N_d(0,1);\n",
    "$$\n",
    "$T\\in \\mathbb{N}$ is a fixed number of \"SGD\" iterations (typically identified by cross-validation on a single SGD trajectory for a single initialization) and where $\\theta \\in \\mathbb{R}^{(d_{J}+1)+\\sum_{j=0}^{J-1} (d_{j+1}d_j + 1)}$ and $d_j$ is the dimension of the \"bias\" vector $b_j$ defining each layer of the DNN with layer dimensions:\n",
    "$$\n",
    "\\hat{f}_{\\theta}(x)\\triangleq A^{(J)}x^{(J)} + b^{(J)},\\qquad x^{(j+1)}\\triangleq \\sigma\\bullet A^{j}x^{(j)} + b^{j},\\qquad x^{(0)}\\triangleq x\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode:\n",
    "Software/Hardware Testing or Real-Deal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random DNN\n",
    "# f_unknown_mode = \"Heteroskedastic_NonLinear_Regression\"\n",
    "\n",
    "# Random DNN internal noise\n",
    "f_unknown_mode = \"DNN_with_Random_Weights\"\n",
    "Depth_Bayesian_DNN = 1\n",
    "width = 5\n",
    "\n",
    "# Random Dropout applied to trained DNN\n",
    "# f_unknown_mode = \"DNN_with_Bayesian_Dropout\"\n",
    "Dropout_rate = 0.1\n",
    "\n",
    "# GD with Randomized Input\n",
    "# f_unknown_mode = \"GD_with_randomized_input\"\n",
    "GD_epochs = 50\n",
    "\n",
    "# SDE with fractional Driver\n",
    "#f_unknown_mode = \"Rough_SDE\"\n",
    "N_Euler_Steps = 10**2\n",
    "Hurst_Exponent = 0.75\n",
    "\n",
    "# f_unknown_mode = \"Rough_SDE_Vanilla\"\n",
    "## Define Process' dynamics in (2) cell(s) below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla fractional SDE:\n",
    "If f_unknown_mode == \"Rough_SDE_Vanilla\" is selected, then we can specify the process's dynamics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------#\n",
    "# Define Process' Dynamics #\n",
    "#--------------------------#\n",
    "drift_constant = 0.1\n",
    "volatility_constant = 0.01\n",
    "\n",
    "# Define DNN Applier\n",
    "def f_unknown_drift_vanilla(x):\n",
    "    x_internal = x\n",
    "    x_internal = drift_constant*x_internal\n",
    "    return x_internal\n",
    "def f_unknown_vol_vanilla(x):\n",
    "    x_internal = volatility_constant*np.diag(np.ones(problem_dim))\n",
    "    return x_internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: *Why the procedure is so computationally efficient*?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)\n",
    "- Ratio $\\frac{\\text{Testing Datasize}}{\\text{Training Datasize}}$.\n",
    "- Number of Training Points to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = .2\n",
    "N_train_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Monte_Carlo_Samples = 10**5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial radis of $\\delta$-bounded random partition of $\\mathcal{X}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.1\n",
    "Proportion_per_cluster = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and Auxiliary Script(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "Deep Feature Builder - Ready\n"
     ]
    }
   ],
   "source": [
    "# %run Loader.ipynb\n",
    "exec(open('Loader.py').read())\n",
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "import time as time #<- Note sure why...but its always seems to need 'its own special loading...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate or Parse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Beginning Data-Parsing/Simulation Phase\n",
      "---------------------------------------\n",
      "Deciding on Which Simulator/Parser To Load\n",
      "Setting/Defining: Internal Parameters\n",
      "Deciding on Which Type of Data to Get/Simulate\n",
      "Simulating Output Data for given input data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:45<00:00,  4.52s/it]\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Done Data-Parsing/Simulation Phase\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %run Data_Simulator_and_Parser.ipynb\n",
    "exec(open('Data_Simulator_and_Parser.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Data\n",
    "This is especially important to avoid exploding gradient problems when training the ML-models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 16170.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Running script for main model!\n",
      "------------------------------\n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "==========================================\n",
      "Training Classifer Portion of Type-A Model\n",
      "==========================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0729 - accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0633 - accuracy: 0.1000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0544 - accuracy: 0.1000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0456 - accuracy: 0.1000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 832us/step - loss: 2.0373 - accuracy: 0.1000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0295 - accuracy: 0.1000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0219 - accuracy: 0.1000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0139 - accuracy: 0.1000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0063 - accuracy: 0.1000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9988 - accuracy: 0.1000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9913 - accuracy: 0.1000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 918us/step - loss: 1.9840 - accuracy: 0.1000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 950us/step - loss: 1.9765 - accuracy: 0.1000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9689 - accuracy: 0.1000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9612 - accuracy: 0.1000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9533 - accuracy: 0.1000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9455 - accuracy: 0.1000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9375 - accuracy: 0.1000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9296 - accuracy: 0.1000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9216 - accuracy: 0.1000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9136 - accuracy: 0.1000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9056 - accuracy: 0.1000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8976 - accuracy: 0.1000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8895 - accuracy: 0.1000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 859us/step - loss: 1.8815 - accuracy: 0.1000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8734 - accuracy: 0.1000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8653 - accuracy: 0.2000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8571 - accuracy: 0.2000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 974us/step - loss: 1.8488 - accuracy: 0.3000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8406 - accuracy: 0.3000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8323 - accuracy: 0.3000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8242 - accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8161 - accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8081 - accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8002 - accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7922 - accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7843 - accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7762 - accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7682 - accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7601 - accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7520 - accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7438 - accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7357 - accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7275 - accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7193 - accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7109 - accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7025 - accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6939 - accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6852 - accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6763 - accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6672 - accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6580 - accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6488 - accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6393 - accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6297 - accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6199 - accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6099 - accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5997 - accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5894 - accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5788 - accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5681 - accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5572 - accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5463 - accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5351 - accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5238 - accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5125 - accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5010 - accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4894 - accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4776 - accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4657 - accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4539 - accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4420 - accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4300 - accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4180 - accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4061 - accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3942 - accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3823 - accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3705 - accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3588 - accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3472 - accuracy: 0.50 - 0s 1ms/step - loss: 1.3472 - accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3358 - accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3244 - accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3131 - accuracy: 0.5000\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3018 - accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2907 - accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2796 - accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2686 - accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 984us/step - loss: 1.2578 - accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2469 - accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2362 - accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2255 - accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 870us/step - loss: 1.2148 - accuracy: 0.6000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2043 - accuracy: 0.6000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1939 - accuracy: 0.6000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1834 - accuracy: 0.6000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1731 - accuracy: 0.6000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1627 - accuracy: 0.6000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1525 - accuracy: 0.6000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1421 - accuracy: 0.6000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1320 - accuracy: 0.6000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 926us/step - loss: 1.1220 - accuracy: 0.6000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1122 - accuracy: 0.6000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1023 - accuracy: 0.6000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0925 - accuracy: 0.6000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0827 - accuracy: 0.6000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0730 - accuracy: 0.6000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0634 - accuracy: 0.6000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0540 - accuracy: 0.6000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0446 - accuracy: 0.6000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0352 - accuracy: 0.6000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0259 - accuracy: 0.6000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0168 - accuracy: 0.6000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0077 - accuracy: 0.6000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9987 - accuracy: 0.6000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9898 - accuracy: 0.6000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9809 - accuracy: 0.6000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9720 - accuracy: 0.6000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9632 - accuracy: 0.7000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9546 - accuracy: 0.7000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9458 - accuracy: 0.7000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9372 - accuracy: 0.7000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9287 - accuracy: 0.7000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9203 - accuracy: 0.7000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9120 - accuracy: 0.7000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9038 - accuracy: 0.7000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8956 - accuracy: 0.7000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8876 - accuracy: 0.7000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8795 - accuracy: 0.7000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8717 - accuracy: 0.7000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8639 - accuracy: 0.7000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8560 - accuracy: 0.7000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8484 - accuracy: 0.7000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8410 - accuracy: 0.7000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8335 - accuracy: 0.7000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8261 - accuracy: 0.7000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8188 - accuracy: 0.7000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8117 - accuracy: 0.7000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8047 - accuracy: 0.7000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7975 - accuracy: 0.7000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7906 - accuracy: 0.7000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7838 - accuracy: 0.7000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7770 - accuracy: 0.7000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7703 - accuracy: 0.7000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7636 - accuracy: 0.7000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7571 - accuracy: 0.7000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7507 - accuracy: 0.7000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7443 - accuracy: 0.7000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.7000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7317 - accuracy: 0.7000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.7000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.7000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7134 - accuracy: 0.7000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.7000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.7000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.7000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.7000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.7000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.8000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.8000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.8000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.9000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.8000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.8000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6411 - accuracy: 0.8000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6359 - accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.9000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.9000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.9000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.9000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.9000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.9000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.9000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.9000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.9000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.9000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.9000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.9000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.9000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.9000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.9000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.9000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.9000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.9000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.9000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.9000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.9000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.9000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.9000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.9000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.9000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.9000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.9000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.9000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.9000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.9000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.9000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.9000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.9000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f73c0242560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "===============================================\n",
      "Training Classifer Portion of Type Model: Done!\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.23it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#----------------#\n",
      " Get Test Error(s)\n",
      "#----------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n",
      "                                        DNM  MC-Oracle\n",
      "W1-95L                         3.326321e-07   0.000000\n",
      "W1                             6.896845e-07   0.000000\n",
      "W1-95R                         1.046737e-06   0.000000\n",
      "M-95L                          1.290718e-05   0.000013\n",
      "M                              4.281266e-05   0.000043\n",
      "M-95R                          7.271814e-05   0.000073\n",
      "N_Par                          4.220800e+04   0.000000\n",
      "Train_Time                     1.104827e+01  53.664175\n",
      "Test_Time/MC-Oracle_Test_Time  5.298994e-03   1.000000\n",
      "------------------------------------\n",
      "Done: Running script for main model!\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------\")\n",
    "print(\"Running script for main model!\")\n",
    "print(\"------------------------------\")\n",
    "# %run Universal_Measure_Valued_Networks_Backend.ipynb\n",
    "exec(open('Universal_Measure_Valued_Networks_Backend.py').read())\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Done: Running script for main model!\")\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run: All Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) *Pointmass Benchmark(s)*\n",
    "These benchmarks consist of subsets of $C(\\mathbb{R}^d,\\mathbb{R})$ which we lift to models in $C(\\mathbb{R}^d,\\cap_{1\\leq q<\\infty}\\mathscr{P}_{q}(\\mathbb{R}))$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to f(x) \\to \\delta_{f(x)}\\in \\cap_{1\\leq q<\\infty}\\mathcal{P}_{q}(\\mathbb{R}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "--------------\n",
      "Training: ENET\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 72.51it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 63.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Training: ENET - Done\n",
      "---------------------\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0636s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle         ENET KRidge  \\\n",
      "W1-95L                             0.000002   0.000000            -      -   \n",
      "W1                                 0.000005   0.000000            -      -   \n",
      "W1-95R                             0.000009   0.000000            -      -   \n",
      "M-95L                              0.000092   0.000080  9.15661e-05    NaN   \n",
      "M                                  0.000145   0.000145  0.000168421    NaN   \n",
      "M-95R                              0.000199   0.000185  0.000236557    NaN   \n",
      "N_Par                          42208.000000   0.000000           20    NaN   \n",
      "Train_Time                        11.048274  53.664175  1.62012e+09    NaN   \n",
      "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06    NaN   \n",
      "\n",
      "                              GBRF  DNN  \n",
      "W1-95L                           -    -  \n",
      "W1                               -    -  \n",
      "W1-95R                           -    -  \n",
      "M-95L                          NaN  NaN  \n",
      "M                              NaN  NaN  \n",
      "M-95R                          NaN  NaN  \n",
      "N_Par                          NaN  NaN  \n",
      "Train_Time                     NaN  NaN  \n",
      "Test_Time/MC-Oracle_Test_Time  NaN  NaN  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "-----------------\n",
      "Training: K-Ridge\n",
      "-----------------\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s finished\n",
      "100%|██████████| 10/10 [00:00<00:00, 64.41it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 65.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                             0.000002   0.000000            -   \n",
      "W1                                 0.000005   0.000000            -   \n",
      "W1-95R                             0.000009   0.000000            -   \n",
      "M-95L                              0.000092   0.000080  9.15661e-05   \n",
      "M                                  0.000145   0.000145  0.000168421   \n",
      "M-95R                              0.000199   0.000185  0.000236557   \n",
      "N_Par                          42208.000000   0.000000           20   \n",
      "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
      "\n",
      "                                    KRidge GBRF  DNN  \n",
      "W1-95L                                   -    -    -  \n",
      "W1                                       -    -    -  \n",
      "W1-95R                                   -    -    -  \n",
      "M-95L                          0.000107537  NaN  NaN  \n",
      "M                              0.000169909  NaN  NaN  \n",
      "M-95R                          0.000233372  NaN  NaN  \n",
      "N_Par                                    0  NaN  NaN  \n",
      "Train_Time                        0.561581  NaN  NaN  \n",
      "Test_Time/MC-Oracle_Test_Time  2.19537e-05  NaN  NaN  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "--------------\n",
      "Training: GBRF\n",
      "--------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.3s finished\n",
      "100%|██████████| 10/10 [00:00<00:00, 71.71it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 67.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n",
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                             0.000002   0.000000            -   \n",
      "W1                                 0.000005   0.000000            -   \n",
      "W1-95R                             0.000009   0.000000            -   \n",
      "M-95L                              0.000092   0.000080  9.15661e-05   \n",
      "M                                  0.000145   0.000145  0.000168421   \n",
      "M-95R                              0.000199   0.000185  0.000236557   \n",
      "N_Par                          42208.000000   0.000000           20   \n",
      "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
      "\n",
      "                                    KRidge         GBRF  DNN  \n",
      "W1-95L                                   -            -    -  \n",
      "W1                                       -            -    -  \n",
      "W1-95R                                   -            -    -  \n",
      "M-95L                          0.000107537  7.06454e-05  NaN  \n",
      "M                              0.000169909  0.000174036  NaN  \n",
      "M-95R                          0.000233372  0.000253984  NaN  \n",
      "N_Par                                    0         1000  NaN  \n",
      "Train_Time                        0.561581     0.779469  NaN  \n",
      "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  NaN  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "-------------\n",
      "Training: DNN\n",
      "-------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0820 - mse: 0.0068 - mae: 0.0820 - mape: 67258.7344\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0817 - mse: 0.0067 - mae: 0.0817 - mape: 67044.5000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0814 - mse: 0.0067 - mae: 0.0814 - mape: 66829.9766\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0812 - mse: 0.0066 - mae: 0.0812 - mape: 66615.3125\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0809 - mse: 0.0066 - mae: 0.0809 - mape: 66400.5703\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0807 - mse: 0.0065 - mae: 0.0807 - mape: 66185.7656\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0804 - mse: 0.0065 - mae: 0.0804 - mape: 65970.9062\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0801 - mse: 0.0065 - mae: 0.0801 - mape: 65756.0156\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0799 - mse: 0.0064 - mae: 0.0799 - mape: 65541.0781\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0796 - mse: 0.0064 - mae: 0.0796 - mape: 65326.1172\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0794 - mse: 0.0063 - mae: 0.0794 - mape: 65111.1328\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0791 - mse: 0.0063 - mae: 0.0791 - mape: 64896.1133\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0788 - mse: 0.0063 - mae: 0.0788 - mape: 64681.0625\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0786 - mse: 0.0062 - mae: 0.0786 - mape: 64465.9922\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0783 - mse: 0.0062 - mae: 0.0783 - mape: 64250.8984\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0780 - mse: 0.0061 - mae: 0.0780 - mape: 64035.7695\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0778 - mse: 0.0061 - mae: 0.0778 - mape: 63820.6250\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0775 - mse: 0.0061 - mae: 0.0775 - mape: 63605.4453\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0773 - mse: 0.0060 - mae: 0.0773 - mape: 63390.2500\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0770 - mse: 0.0060 - mae: 0.0770 - mape: 63175.0195\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0767 - mse: 0.0059 - mae: 0.0767 - mape: 62959.7617\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0765 - mse: 0.0059 - mae: 0.0765 - mape: 62744.4883\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0762 - mse: 0.0059 - mae: 0.0762 - mape: 62529.1758\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0759 - mse: 0.0058 - mae: 0.0759 - mape: 62313.8320\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0757 - mse: 0.0058 - mae: 0.0757 - mape: 62098.4609\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0754 - mse: 0.0057 - mae: 0.0754 - mape: 61883.0625\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0752 - mse: 0.0057 - mae: 0.0752 - mape: 61667.6250\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0749 - mse: 0.0057 - mae: 0.0749 - mape: 61452.1484\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0746 - mse: 0.0056 - mae: 0.0746 - mape: 61236.6484\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0744 - mse: 0.0056 - mae: 0.0744 - mape: 61021.1133\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0741 - mse: 0.0055 - mae: 0.0741 - mape: 60805.5391\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0738 - mse: 0.0055 - mae: 0.0738 - mape: 60589.9258\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0736 - mse: 0.0055 - mae: 0.0736 - mape: 60374.2695\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0733 - mse: 0.0054 - mae: 0.0733 - mape: 60158.5820\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0731 - mse: 0.0054 - mae: 0.0731 - mape: 59942.8516\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0728 - mse: 0.0053 - mae: 0.0728 - mape: 59727.0820\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0725 - mse: 0.0053 - mae: 0.0725 - mape: 59511.2695\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0723 - mse: 0.0053 - mae: 0.0723 - mape: 59295.4141\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0720 - mse: 0.0052 - mae: 0.0720 - mape: 59079.5117\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0717 - mse: 0.0052 - mae: 0.0717 - mape: 58863.5547\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0715 - mse: 0.0052 - mae: 0.0715 - mape: 58647.5703\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0712 - mse: 0.0051 - mae: 0.0712 - mape: 58431.5234\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0710 - mse: 0.0051 - mae: 0.0710 - mape: 58215.4297\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0707 - mse: 0.0050 - mae: 0.0707 - mape: 57999.3008\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0704 - mse: 0.0050 - mae: 0.0704 - mape: 57783.1055\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0702 - mse: 0.0050 - mae: 0.0702 - mape: 57566.8672\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0699 - mse: 0.0049 - mae: 0.0699 - mape: 57350.5742\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0696 - mse: 0.0049 - mae: 0.0696 - mape: 57134.2305\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0694 - mse: 0.0049 - mae: 0.0694 - mape: 56917.8320\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0691 - mse: 0.0048 - mae: 0.0691 - mape: 56701.3750\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0689 - mse: 0.0048 - mae: 0.0689 - mape: 56484.8633\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0686 - mse: 0.0048 - mae: 0.0686 - mape: 56268.3008\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0683 - mse: 0.0047 - mae: 0.0683 - mape: 56051.6797\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0047 - mae: 0.0681 - mape: 55834.9922\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0678 - mse: 0.0046 - mae: 0.0678 - mape: 55618.2500\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0046 - mae: 0.0675 - mape: 55401.4453\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0673 - mse: 0.0046 - mae: 0.0673 - mape: 55184.5820\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0670 - mse: 0.0045 - mae: 0.0670 - mape: 54967.6562\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0045 - mae: 0.0667 - mape: 54750.6641\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0665 - mse: 0.0045 - mae: 0.0665 - mape: 54533.6133\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0662 - mse: 0.0044 - mae: 0.0662 - mape: 54316.4883\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0659 - mse: 0.0044 - mae: 0.0659 - mape: 54099.3047\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0657 - mse: 0.0044 - mae: 0.0657 - mape: 53882.0547\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0654 - mse: 0.0043 - mae: 0.0654 - mape: 53664.7422\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0652 - mse: 0.0043 - mae: 0.0652 - mape: 53447.3555\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0649 - mse: 0.0043 - mae: 0.0649 - mape: 53229.8984\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0646 - mse: 0.0042 - mae: 0.0646 - mape: 53012.3750\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0644 - mse: 0.0042 - mae: 0.0644 - mape: 52794.7734\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0641 - mse: 0.0042 - mae: 0.0641 - mape: 52577.1133\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0638 - mse: 0.0041 - mae: 0.0638 - mape: 52359.3750\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0636 - mse: 0.0041 - mae: 0.0636 - mape: 52141.5703\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0633 - mse: 0.0041 - mae: 0.0633 - mape: 51923.6836\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0630 - mse: 0.0040 - mae: 0.0630 - mape: 51705.7266\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0628 - mse: 0.0040 - mae: 0.0628 - mape: 51487.6953\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0625 - mse: 0.0040 - mae: 0.0625 - mape: 51269.5859\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0622 - mse: 0.0039 - mae: 0.0622 - mape: 51051.3984\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0039 - mae: 0.0620 - mape: 50833.1445\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0617 - mse: 0.0039 - mae: 0.0617 - mape: 50614.8047\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0614 - mse: 0.0038 - mae: 0.0614 - mape: 50396.3867\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0612 - mse: 0.0038 - mae: 0.0612 - mape: 50177.8945\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0038 - mae: 0.0609 - mape: 49959.3203\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0606 - mse: 0.0037 - mae: 0.0606 - mape: 49740.6641\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0037 - mae: 0.0604 - mape: 49521.9258\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0601 - mse: 0.0037 - mae: 0.0601 - mape: 49303.1094\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0036 - mae: 0.0598 - mape: 49084.2109\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0036 - mae: 0.0596 - mape: 48865.2266\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0593 - mse: 0.0036 - mae: 0.0593 - mape: 48646.1641\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0035 - mae: 0.0590 - mape: 48427.0117\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0035 - mae: 0.0588 - mape: 48207.7773\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0585 - mse: 0.0035 - mae: 0.0585 - mape: 47988.4531\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0582 - mse: 0.0035 - mae: 0.0582 - mape: 47769.0547\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0034 - mae: 0.0580 - mape: 47549.5586\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0034 - mae: 0.0577 - mape: 47329.9766\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0034 - mae: 0.0574 - mape: 47110.3203\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0572 - mse: 0.0033 - mae: 0.0572 - mape: 46890.5547\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0569 - mse: 0.0033 - mae: 0.0569 - mape: 46670.7188\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0566 - mse: 0.0033 - mae: 0.0566 - mape: 46450.7891\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0564 - mse: 0.0032 - mae: 0.0564 - mape: 46230.7617\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0032 - mae: 0.0561 - mape: 46010.6484\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0558 - mse: 0.0032 - mae: 0.0558 - mape: 45790.4453\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0556 - mse: 0.0031 - mae: 0.0556 - mape: 45570.1523\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0031 - mae: 0.0553 - mape: 45349.7656\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0550 - mse: 0.0031 - mae: 0.0550 - mape: 45129.2891\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0031 - mae: 0.0548 - mape: 44908.7109\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0545 - mse: 0.0030 - mae: 0.0545 - mape: 44688.0508\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0542 - mse: 0.0030 - mae: 0.0542 - mape: 44467.2891\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0540 - mse: 0.0030 - mae: 0.0540 - mape: 44246.4297\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0537 - mse: 0.0029 - mae: 0.0537 - mape: 44025.4883\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0534 - mse: 0.0029 - mae: 0.0534 - mape: 43804.4375\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0531 - mse: 0.0029 - mae: 0.0531 - mape: 43583.2930\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0029 - mae: 0.0529 - mape: 43362.0547\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0526 - mse: 0.0028 - mae: 0.0526 - mape: 43140.7188\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0028 - mae: 0.0523 - mape: 42919.2891\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0521 - mse: 0.0028 - mae: 0.0521 - mape: 42697.7422\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0027 - mae: 0.0518 - mape: 42476.1172\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0515 - mse: 0.0027 - mae: 0.0515 - mape: 42254.3867\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0513 - mse: 0.0027 - mae: 0.0513 - mape: 42032.5547\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0027 - mae: 0.0510 - mape: 41810.6250\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0507 - mse: 0.0026 - mae: 0.0507 - mape: 41588.5938\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0504 - mse: 0.0026 - mae: 0.0504 - mape: 41366.4609\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0502 - mse: 0.0026 - mae: 0.0502 - mape: 41144.2188\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0499 - mse: 0.0026 - mae: 0.0499 - mape: 40921.8828\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0496 - mse: 0.0025 - mae: 0.0496 - mape: 40699.4375\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0494 - mse: 0.0025 - mae: 0.0494 - mape: 40476.8945\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0491 - mse: 0.0025 - mae: 0.0491 - mape: 40254.2422\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0488 - mse: 0.0025 - mae: 0.0488 - mape: 40031.4922\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0486 - mse: 0.0024 - mae: 0.0486 - mape: 39808.6328\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0483 - mse: 0.0024 - mae: 0.0483 - mape: 39585.6680\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0480 - mse: 0.0024 - mae: 0.0480 - mape: 39362.5938\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0477 - mse: 0.0023 - mae: 0.0477 - mape: 39139.4258\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0023 - mae: 0.0475 - mape: 38916.1445\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0472 - mse: 0.0023 - mae: 0.0472 - mape: 38692.7500\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0023 - mae: 0.0469 - mape: 38469.2539\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0466 - mse: 0.0022 - mae: 0.0466 - mape: 38245.6445\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0464 - mse: 0.0022 - mae: 0.0464 - mape: 38021.9258\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0022 - mae: 0.0461 - mape: 37798.1016\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0458 - mse: 0.0022 - mae: 0.0458 - mape: 37574.1680\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0456 - mse: 0.0021 - mae: 0.0456 - mape: 37350.1172\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0453 - mse: 0.0021 - mae: 0.0453 - mape: 37125.9688\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0450 - mse: 0.0021 - mae: 0.0450 - mape: 36901.6992\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0447 - mse: 0.0021 - mae: 0.0447 - mape: 36677.3203\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0445 - mse: 0.0020 - mae: 0.0445 - mape: 36452.82 - 0s 1ms/step - loss: 0.0445 - mse: 0.0020 - mae: 0.0445 - mape: 36452.8242\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0442 - mse: 0.0020 - mae: 0.0442 - mape: 36228.2188\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0439 - mse: 0.0020 - mae: 0.0439 - mape: 36003.5000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0020 - mae: 0.0436 - mape: 35778.6641\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0434 - mse: 0.0020 - mae: 0.0434 - mape: 35553.7227\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0431 - mse: 0.0019 - mae: 0.0431 - mape: 35328.6602\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0019 - mae: 0.0428 - mape: 35103.4844\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0019 - mae: 0.0426 - mape: 34878.1953\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0423 - mse: 0.0019 - mae: 0.0423 - mape: 34652.7812\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0018 - mae: 0.0420 - mape: 34427.2617\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0018 - mae: 0.0417 - mape: 34201.6172\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0415 - mse: 0.0018 - mae: 0.0415 - mape: 33975.8555\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0018 - mae: 0.0412 - mape: 33749.9805\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0017 - mae: 0.0409 - mape: 33523.9844\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0406 - mse: 0.0017 - mae: 0.0406 - mape: 33297.8672\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0404 - mse: 0.0017 - mae: 0.0404 - mape: 33071.6328\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0401 - mse: 0.0017 - mae: 0.0401 - mape: 32845.2773\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0017 - mae: 0.0398 - mape: 32618.8027\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0016 - mae: 0.0395 - mape: 32392.2070\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0392 - mse: 0.0016 - mae: 0.0392 - mape: 32165.4941\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0390 - mse: 0.0016 - mae: 0.0390 - mape: 31938.6523\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0016 - mae: 0.0387 - mape: 31711.6875\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0016 - mae: 0.0384 - mape: 31484.6035\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0381 - mse: 0.0015 - mae: 0.0381 - mape: 31257.3965\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0015 - mae: 0.0379 - mape: 31030.0664\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0376 - mse: 0.0015 - mae: 0.0376 - mape: 30802.6055\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0373 - mse: 0.0015 - mae: 0.0373 - mape: 30575.0273\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0370 - mse: 0.0014 - mae: 0.0370 - mape: 30347.3223\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0368 - mse: 0.0014 - mae: 0.0368 - mape: 30119.4902\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0365 - mse: 0.0014 - mae: 0.0365 - mape: 29891.5312\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0014 - mae: 0.0362 - mape: 29663.4473\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0359 - mse: 0.0014 - mae: 0.0359 - mape: 29435.2383\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0014 - mae: 0.0356 - mape: 29206.9004\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0354 - mse: 0.0013 - mae: 0.0354 - mape: 28978.4316\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0351 - mse: 0.0013 - mae: 0.0351 - mape: 28749.8398\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0013 - mae: 0.0348 - mape: 28521.1152\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0345 - mse: 0.0013 - mae: 0.0345 - mape: 28292.2598\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0343 - mse: 0.0013 - mae: 0.0343 - mape: 28063.2812\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0012 - mae: 0.0340 - mape: 27834.1660\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0337 - mse: 0.0012 - mae: 0.0337 - mape: 27604.9180\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0012 - mae: 0.0334 - mape: 27375.5430\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0331 - mse: 0.0012 - mae: 0.0331 - mape: 27146.0410\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0329 - mse: 0.0012 - mae: 0.0329 - mape: 26916.4004\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0326 - mse: 0.0011 - mae: 0.0326 - mape: 26686.6309\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0011 - mae: 0.0323 - mape: 26456.7305\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0011 - mae: 0.0320 - mape: 26226.6914\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0011 - mae: 0.0317 - mape: 25996.5195\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0011 - mae: 0.0315 - mape: 25766.2188\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0312 - mse: 0.0011 - mae: 0.0312 - mape: 25535.7773\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0309 - mse: 0.0010 - mae: 0.0309 - mape: 25305.2051\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0306 - mse: 0.0010 - mae: 0.0306 - mape: 25074.4961\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0303 - mse: 0.0010 - mae: 0.0303 - mape: 24843.6465\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0301 - mse: 9.8771e-04 - mae: 0.0301 - mape: 24612.6660\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 9.7113e-04 - mae: 0.0298 - mape: 24381.5430\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0295 - mse: 9.5469e-04 - mae: 0.0295 - mape: 24150.2910\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0292 - mse: 9.3840e-04 - mae: 0.0292 - mape: 23918.8984\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0289 - mse: 9.2226e-04 - mae: 0.0289 - mape: 23687.3672\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0286 - mse: 9.0627e-04 - mae: 0.0286 - mape: 23455.6953\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0284 - mse: 8.9043e-04 - mae: 0.0284 - mape: 23223.8848\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f73c00413b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 57.01it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "#------------#\n",
      " Get Error(s) \n",
      "#------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:00<00:00, 54.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----------------#\n",
      " Get Error(s): END \n",
      "#-----------------#\n",
      "Updated DataFrame\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                             0.000002   0.000000            -   \n",
      "W1                                 0.000005   0.000000            -   \n",
      "W1-95R                             0.000009   0.000000            -   \n",
      "M-95L                              0.000092   0.000080  9.15661e-05   \n",
      "M                                  0.000145   0.000145  0.000168421   \n",
      "M-95R                              0.000199   0.000185  0.000236557   \n",
      "N_Par                          42208.000000   0.000000           20   \n",
      "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
      "\n",
      "                                    KRidge         GBRF         DNN  \n",
      "W1-95L                                   -            -           -  \n",
      "W1                                       -            -           -  \n",
      "W1-95R                                   -            -           -  \n",
      "M-95L                          0.000107537  7.06454e-05   0.0228225  \n",
      "M                              0.000169909  0.000174036   0.0280817  \n",
      "M-95R                          0.000233372  0.000253984   0.0324094  \n",
      "N_Par                                    0         1000       40801  \n",
      "Train_Time                        0.561581     0.779469      7.5179  \n",
      "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  0.00706781  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exec(open('CV_Grid.py').read())\n",
    "# Notebook Mode:\n",
    "# %run Evaluation.ipynb\n",
    "# %run Benchmarks_Model_Builder_Pointmass_Based.ipynb\n",
    "# Terminal Mode (Default):\n",
    "exec(open('Evaluation.py').read())\n",
    "exec(open('Benchmarks_Model_Builder_Pointmass_Based.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Point-Mass Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                             0.000002   0.000000            -   \n",
      "W1                                 0.000005   0.000000            -   \n",
      "W1-95R                             0.000009   0.000000            -   \n",
      "M-95L                              0.000092   0.000080  9.15661e-05   \n",
      "M                                  0.000145   0.000145  0.000168421   \n",
      "M-95R                              0.000199   0.000185  0.000236557   \n",
      "N_Par                          42208.000000   0.000000           20   \n",
      "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
      "\n",
      "                                    KRidge         GBRF         DNN  \n",
      "W1-95L                                   -            -           -  \n",
      "W1                                       -            -           -  \n",
      "W1-95R                                   -            -           -  \n",
      "M-95L                          0.000107537  7.06454e-05   0.0228225  \n",
      "M                              0.000169909  0.000174036   0.0280817  \n",
      "M-95R                          0.000233372  0.000253984   0.0324094  \n",
      "N_Par                                    0         1000       40801  \n",
      "Train_Time                        0.561581     0.779469      7.5179  \n",
      "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  0.00706781  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>9.15661e-05</td>\n",
       "      <td>0.000107537</td>\n",
       "      <td>7.06454e-05</td>\n",
       "      <td>0.0228225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000168421</td>\n",
       "      <td>0.000169909</td>\n",
       "      <td>0.000174036</td>\n",
       "      <td>0.0280817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000236557</td>\n",
       "      <td>0.000233372</td>\n",
       "      <td>0.000253984</td>\n",
       "      <td>0.0324094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>42208.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>40801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>11.048274</td>\n",
       "      <td>53.664175</td>\n",
       "      <td>1.62012e+09</td>\n",
       "      <td>0.561581</td>\n",
       "      <td>0.779469</td>\n",
       "      <td>7.5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>0.005299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.68157e-06</td>\n",
       "      <td>2.19537e-05</td>\n",
       "      <td>6.77703e-05</td>\n",
       "      <td>0.00706781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle         ENET  \\\n",
       "W1-95L                             0.000002   0.000000            -   \n",
       "W1                                 0.000005   0.000000            -   \n",
       "W1-95R                             0.000009   0.000000            -   \n",
       "M-95L                              0.000092   0.000080  9.15661e-05   \n",
       "M                                  0.000145   0.000145  0.000168421   \n",
       "M-95R                              0.000199   0.000185  0.000236557   \n",
       "N_Par                          42208.000000   0.000000           20   \n",
       "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
       "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
       "\n",
       "                                    KRidge         GBRF         DNN  \n",
       "W1-95L                                   -            -           -  \n",
       "W1                                       -            -           -  \n",
       "W1-95R                                   -            -           -  \n",
       "M-95L                          0.000107537  7.06454e-05   0.0228225  \n",
       "M                              0.000169909  0.000174036   0.0280817  \n",
       "M-95R                          0.000233372  0.000253984   0.0324094  \n",
       "N_Par                                    0         1000       40801  \n",
       "Train_Time                        0.561581     0.779469      7.5179  \n",
       "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  0.00706781  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Model Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                         3.326321e-07   0.000000  3.269980e-03   \n",
      "W1                             6.896845e-07   0.000000  3.307251e-03   \n",
      "W1-95R                         1.046737e-06   0.000000  3.344523e-03   \n",
      "M-95L                          1.290718e-05   0.000013  1.759886e-05   \n",
      "M                              4.281266e-05   0.000043  4.789610e-05   \n",
      "M-95R                          7.271814e-05   0.000073  7.819334e-05   \n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
      "Train_Time                     1.104827e+01  53.664175  1.620115e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  5.298994e-03   1.000000  6.681574e-06   \n",
      "\n",
      "                                 KRidge         GBRF           DNN  \n",
      "W1-95L                         0.003270     0.003270      0.003582  \n",
      "W1                             0.003307     0.003307      0.003621  \n",
      "W1-95R                         0.003345     0.003345      0.003660  \n",
      "M-95L                          0.000009     0.000070      0.017658  \n",
      "M                              0.000039     0.000100      0.017717  \n",
      "M-95R                          0.000068     0.000130      0.017775  \n",
      "N_Par                          0.000000  1000.000000  40801.000000  \n",
      "Train_Time                     0.561581     0.779469      7.517898  \n",
      "Test_Time/MC-Oracle_Test_Time  0.000022     0.000068      0.007068  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>3.326321e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.269980e-03</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.003582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>6.896845e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.307251e-03</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.003621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>1.046737e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.344523e-03</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.003660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>1.290718e-05</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.759886e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.017658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>4.281266e-05</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>4.789610e-05</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.017717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>7.271814e-05</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>7.819334e-05</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.017775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>4.220800e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>40801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.104827e+01</td>\n",
       "      <td>53.664175</td>\n",
       "      <td>1.620115e+09</td>\n",
       "      <td>0.561581</td>\n",
       "      <td>0.779469</td>\n",
       "      <td>7.517898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>5.298994e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.681574e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.007068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle          ENET  \\\n",
       "W1-95L                         3.326321e-07   0.000000  3.269980e-03   \n",
       "W1                             6.896845e-07   0.000000  3.307251e-03   \n",
       "W1-95R                         1.046737e-06   0.000000  3.344523e-03   \n",
       "M-95L                          1.290718e-05   0.000013  1.759886e-05   \n",
       "M                              4.281266e-05   0.000043  4.789610e-05   \n",
       "M-95R                          7.271814e-05   0.000073  7.819334e-05   \n",
       "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
       "Train_Time                     1.104827e+01  53.664175  1.620115e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  5.298994e-03   1.000000  6.681574e-06   \n",
       "\n",
       "                                 KRidge         GBRF           DNN  \n",
       "W1-95L                         0.003270     0.003270      0.003582  \n",
       "W1                             0.003307     0.003307      0.003621  \n",
       "W1-95R                         0.003345     0.003345      0.003660  \n",
       "M-95L                          0.000009     0.000070      0.017658  \n",
       "M                              0.000039     0.000100      0.017717  \n",
       "M-95R                          0.000068     0.000130      0.017775  \n",
       "N_Par                          0.000000  1000.000000  40801.000000  \n",
       "Train_Time                     0.561581     0.779469      7.517898  \n",
       "Test_Time/MC-Oracle_Test_Time  0.000022     0.000068      0.007068  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) *Gaussian Benchmarks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bencharm 1: [Gaussian Process Regressor](https://scikit-learn.org/stable/modules/gaussian_process.html)\n",
    "- Benchmark 2: Deep Gaussian Networks:\n",
    "These models train models which assume Gaussianity.  We may view these as models in $\\mathcal{P}_2(\\mathbb{R})$ via:\n",
    "$$\n",
    "\\mathbb{R}^d \\ni x \\to (\\hat{\\mu}(x),\\hat{\\Sigma}(x)\\hat{\\Sigma}^{\\top})\\triangleq f(x) \\in \\mathbb{R}\\times [0,\\infty) \\to \n",
    "(2\\pi)^{-\\frac{d}{2}}\\det(\\hat{\\Sigma}(x))^{-\\frac{1}{2}} \\, e^{ -\\frac{1}{2}(\\cdot - \\hat{\\mu}(x))^{{{\\!\\mathsf{T}}}} \\hat{\\Sigma}(x)^{-1}(\\cdot - \\hat{\\mu}(x)) } \\mu \\in \\mathcal{G}_d\\subset \\mathcal{P}_2(\\mathbb{R});\n",
    "$$\n",
    "where $\\mathcal{G}_1$ is the set of Gaussian measures on $\\mathbb{R}$ equipped with the relative Wasserstein-1 topology.\n",
    "\n",
    "Examples of this type of architecture are especially prevalent in uncertainty quantification; see ([Deep Ensembles](https://arxiv.org/abs/1612.01474)] or [NOMU: Neural Optimization-based Model Uncertainty](https://arxiv.org/abs/2102.13640).  Moreover, their universality in $C(\\mathbb{R}^d,\\mathcal{G}_2)$ is known, and has been shown in [Corollary 4.7](https://arxiv.org/abs/2101.05390)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.7s finished\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering Parameters for Deep Gaussian Network to train on!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Getting Parameters for Deep Gaussian Network!\n",
      "===============================\n",
      "Training Deep Gaussian Network!\n",
      "===============================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4590 - mse: 0.3738 - mae: 0.4590 - mape: 23193.6895\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4590 - mse: 0.3740 - mae: 0.4590 - mape: 23102.3633\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4590 - mse: 0.3741 - mae: 0.4590 - mape: 23008.4902\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4590 - mse: 0.3743 - mae: 0.4590 - mape: 22913.3652\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4590 - mse: 0.3745 - mae: 0.4590 - mape: 22817.4688\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4590 - mse: 0.3747 - mae: 0.4590 - mape: 22721.0293\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4590 - mse: 0.3749 - mae: 0.4590 - mape: 22624.1992\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4590 - mse: 0.3750 - mae: 0.4590 - mape: 22527.0664\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4590 - mse: 0.3752 - mae: 0.4590 - mape: 22429.6992\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4590 - mse: 0.3754 - mae: 0.4590 - mape: 22332.1562\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4590 - mse: 0.3756 - mae: 0.4590 - mape: 22234.4766\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4590 - mse: 0.3758 - mae: 0.4590 - mape: 22136.6934\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4590 - mse: 0.3760 - mae: 0.4590 - mape: 22038.8340\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4590 - mse: 0.3761 - mae: 0.4590 - mape: 21940.9219\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4590 - mse: 0.3763 - mae: 0.4590 - mape: 21842.9805\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4590 - mse: 0.3765 - mae: 0.4590 - mape: 21745.0234\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4589 - mse: 0.3767 - mae: 0.4589 - mape: 21647.0723\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3769 - mae: 0.4589 - mape: 21549.1426\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4589 - mse: 0.3771 - mae: 0.4589 - mape: 21451.2480\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3773 - mae: 0.4589 - mape: 21353.3965\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3774 - mae: 0.4589 - mape: 21255.6035\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4589 - mse: 0.3776 - mae: 0.4589 - mape: 21157.8789\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4589 - mse: 0.3778 - mae: 0.4589 - mape: 21060.2344\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3780 - mae: 0.4589 - mape: 20962.6758\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3782 - mae: 0.4589 - mape: 20865.2148\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3784 - mae: 0.4589 - mape: 20767.8633\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3786 - mae: 0.4589 - mape: 20670.6211\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3787 - mae: 0.4589 - mape: 20573.4980\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3789 - mae: 0.4589 - mape: 20476.5039\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4589 - mse: 0.3791 - mae: 0.4589 - mape: 20379.6426\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3793 - mae: 0.4589 - mape: 20282.9199\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4589 - mse: 0.3795 - mae: 0.4589 - mape: 20186.3477\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4589 - mse: 0.3797 - mae: 0.4589 - mape: 20089.9180\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4589 - mse: 0.3799 - mae: 0.4589 - mape: 19993.6445\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3800 - mae: 0.4588 - mape: 19897.5352\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4588 - mse: 0.3802 - mae: 0.4588 - mape: 19801.5898\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4588 - mse: 0.3804 - mae: 0.4588 - mape: 19705.8145\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4588 - mse: 0.3806 - mae: 0.4588 - mape: 19610.2090\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3808 - mae: 0.4588 - mape: 19514.7793\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3810 - mae: 0.4588 - mape: 19419.5352\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3811 - mae: 0.4588 - mape: 19324.4688\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3813 - mae: 0.4588 - mape: 19229.5977\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4588 - mse: 0.3815 - mae: 0.4588 - mape: 19134.9121\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3817 - mae: 0.4588 - mape: 19040.4199\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3819 - mae: 0.4588 - mape: 18946.1250\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4588 - mse: 0.3821 - mae: 0.4588 - mape: 18852.0273\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3822 - mae: 0.4588 - mape: 18758.1289\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3824 - mae: 0.4588 - mape: 18664.4336\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4588 - mse: 0.3826 - mae: 0.4588 - mape: 18570.9492\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3828 - mae: 0.4588 - mape: 18477.6719\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.3830 - mae: 0.4588 - mape: 18384.6016\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3831 - mae: 0.4588 - mape: 18291.7441\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.3833 - mae: 0.4588 - mape: 18199.0977\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3835 - mae: 0.4587 - mape: 18106.6680\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3837 - mae: 0.4587 - mape: 18014.4570\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3839 - mae: 0.4587 - mape: 17922.4629\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3840 - mae: 0.4587 - mape: 17830.6875\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3842 - mae: 0.4587 - mape: 17739.1367\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4587 - mse: 0.3844 - mae: 0.4587 - mape: 17647.8066\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4587 - mse: 0.3846 - mae: 0.4587 - mape: 17556.6992\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3848 - mae: 0.4587 - mape: 17465.8203\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3849 - mae: 0.4587 - mape: 17375.1621\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3851 - mae: 0.4587 - mape: 17284.7383\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3853 - mae: 0.4587 - mape: 17194.5391\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3855 - mae: 0.4587 - mape: 17104.5742\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4587 - mse: 0.3857 - mae: 0.4587 - mape: 17014.8359\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3858 - mae: 0.4587 - mape: 16925.3320\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3860 - mae: 0.4587 - mape: 16836.0586\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4587 - mse: 0.3862 - mae: 0.4587 - mape: 16747.0195\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4587 - mse: 0.3864 - mae: 0.4587 - mape: 16658.2168\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3865 - mae: 0.4587 - mape: 16569.6484\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3867 - mae: 0.4587 - mape: 16481.3164\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4587 - mse: 0.3869 - mae: 0.4587 - mape: 16393.2227\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4587 - mse: 0.3871 - mae: 0.4587 - mape: 16305.3691\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - mse: 0.3872 - mae: 0.4587 - mape: 16217.7529\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4587 - mse: 0.3874 - mae: 0.4587 - mape: 16130.3770\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3876 - mae: 0.4586 - mape: 16043.2373\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3877 - mae: 0.4586 - mape: 15956.3467\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3879 - mae: 0.4586 - mape: 15869.6924\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3881 - mae: 0.4586 - mape: 15783.2812\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3883 - mae: 0.4586 - mape: 15697.1191\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3884 - mae: 0.4586 - mape: 15611.1973\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4586 - mse: 0.3886 - mae: 0.4586 - mape: 15525.5205\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3888 - mae: 0.4586 - mape: 15440.0889\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3889 - mae: 0.4586 - mape: 15354.9033\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4586 - mse: 0.3891 - mae: 0.4586 - mape: 15269.9668\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4586 - mse: 0.3893 - mae: 0.4586 - mape: 15185.2764\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3895 - mae: 0.4586 - mape: 15100.8359\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4586 - mse: 0.3896 - mae: 0.4586 - mape: 15016.6426\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4586 - mse: 0.3898 - mae: 0.4586 - mape: 14932.6982\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3900 - mae: 0.4586 - mape: 14849.0049\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3901 - mae: 0.4586 - mape: 14765.5625\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3903 - mae: 0.4586 - mape: 14682.3701\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4586 - mse: 0.3905 - mae: 0.4586 - mape: 14599.4326\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4586 - mse: 0.3906 - mae: 0.4586 - mape: 14516.7441\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3908 - mae: 0.4586 - mape: 14434.3105\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3910 - mae: 0.4586 - mape: 14352.1299\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3911 - mae: 0.4586 - mape: 14270.2031\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4586 - mse: 0.3913 - mae: 0.4586 - mape: 14188.5293\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3915 - mae: 0.4586 - mape: 14107.1152\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3916 - mae: 0.4586 - mape: 14025.9512\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.3918 - mae: 0.4586 - mape: 13945.0469\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.3919 - mae: 0.4586 - mape: 13864.3984\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3921 - mae: 0.4585 - mape: 13784.0098\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3923 - mae: 0.4585 - mape: 13703.8770\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3924 - mae: 0.4585 - mape: 13624.0029\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3926 - mae: 0.4585 - mape: 13544.3877\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3928 - mae: 0.4585 - mape: 13465.0312\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3929 - mae: 0.4585 - mape: 13385.9346\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3931 - mae: 0.4585 - mape: 13307.0996\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3932 - mae: 0.4585 - mape: 13228.5254\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3934 - mae: 0.4585 - mape: 13150.2109\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3936 - mae: 0.4585 - mape: 13072.1582\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3937 - mae: 0.4585 - mape: 12994.3691\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3939 - mae: 0.4585 - mape: 12916.8457\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3940 - mae: 0.4585 - mape: 12839.5840\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3942 - mae: 0.4585 - mape: 12762.5840\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4585 - mse: 0.3943 - mae: 0.4585 - mape: 12685.8496\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3945 - mae: 0.4585 - mape: 12609.3799\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3947 - mae: 0.4585 - mape: 12533.1768\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3948 - mae: 0.4585 - mape: 12457.2363\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3950 - mae: 0.4585 - mape: 12381.5615\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3951 - mae: 0.4585 - mape: 12306.1553\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3953 - mae: 0.4585 - mape: 12231.0156\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4585 - mse: 0.3954 - mae: 0.4585 - mape: 12156.1445\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3956 - mae: 0.4585 - mape: 12081.5430\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3957 - mae: 0.4585 - mape: 12007.2061\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3959 - mae: 0.4585 - mape: 11933.1377\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3960 - mae: 0.4585 - mape: 11859.3408\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3962 - mae: 0.4585 - mape: 11785.8145\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3963 - mae: 0.4585 - mape: 11712.5566\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3965 - mae: 0.4585 - mape: 11639.5703\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3966 - mae: 0.4585 - mape: 11566.8506\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3968 - mae: 0.4585 - mape: 11494.4043\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3969 - mae: 0.4585 - mape: 11422.2295\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3971 - mae: 0.4585 - mape: 11350.3262\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3972 - mae: 0.4585 - mape: 11278.6973\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4585 - mse: 0.3974 - mae: 0.4585 - mape: 11207.3418\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3975 - mae: 0.4585 - mape: 11136.2559\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - mse: 0.3977 - mae: 0.4585 - mape: 11065.4453\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.3978 - mae: 0.4585 - mape: 10994.9062\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.3980 - mae: 0.4584 - mape: 10924.6436\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.3981 - mae: 0.4584 - mape: 10854.6523\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.3983 - mae: 0.4584 - mape: 10784.9385\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.3984 - mae: 0.4584 - mape: 10715.5000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.3986 - mae: 0.4584 - mape: 10646.3359\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4584 - mse: 0.3987 - mae: 0.4584 - mape: 10577.4482\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.3988 - mae: 0.4584 - mape: 10508.8359\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4584 - mse: 0.3990 - mae: 0.4584 - mape: 10440.4980\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.3991 - mae: 0.4584 - mape: 10372.4375\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.3993 - mae: 0.4584 - mape: 10304.6543\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.3994 - mae: 0.4584 - mape: 10237.1504\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.3995 - mae: 0.4584 - mape: 10169.9238\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.3997 - mae: 0.4584 - mape: 10102.9717\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.3998 - mae: 0.4584 - mape: 10036.3027\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4000 - mae: 0.4584 - mape: 9969.9092\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4001 - mae: 0.4584 - mape: 9903.7910\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4002 - mae: 0.4584 - mape: 9837.9531\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4004 - mae: 0.4584 - mape: 9772.3955\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4005 - mae: 0.4584 - mape: 9707.1172\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4006 - mae: 0.4584 - mape: 9642.1172\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4008 - mae: 0.4584 - mape: 9577.3984\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4009 - mae: 0.4584 - mape: 9512.9590\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4011 - mae: 0.4584 - mape: 9448.7998\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4012 - mae: 0.4584 - mape: 9384.9219\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4013 - mae: 0.4584 - mape: 9321.3223\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4015 - mae: 0.4584 - mape: 9258.0029\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4584 - mse: 0.4016 - mae: 0.4584 - mape: 9194.9648\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4017 - mae: 0.4584 - mape: 9132.2070\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4019 - mae: 0.4584 - mape: 9069.7324\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4020 - mae: 0.4584 - mape: 9007.5371\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4021 - mae: 0.4584 - mape: 8945.6270\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4022 - mae: 0.4584 - mape: 8883.9971\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4024 - mae: 0.4584 - mape: 8822.6494\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4025 - mae: 0.4584 - mape: 8761.5830\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4026 - mae: 0.4584 - mape: 8700.7959\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4028 - mae: 0.4584 - mape: 8640.2910\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4029 - mae: 0.4584 - mape: 8580.0684\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4030 - mae: 0.4584 - mape: 8520.1299\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4031 - mae: 0.4584 - mape: 8460.4736\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4033 - mae: 0.4584 - mape: 8401.0986\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4034 - mae: 0.4584 - mape: 8342.0078\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4035 - mae: 0.4584 - mape: 8283.2002\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4036 - mae: 0.4584 - mape: 8224.6709\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4038 - mae: 0.4584 - mape: 8166.4258\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4039 - mae: 0.4584 - mape: 8108.4639\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4040 - mae: 0.4584 - mape: 8050.7861\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4041 - mae: 0.4584 - mape: 7993.3882\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4043 - mae: 0.4584 - mape: 7936.2749\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4584 - mse: 0.4044 - mae: 0.4584 - mape: 7879.4443\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4584 - mse: 0.4045 - mae: 0.4584 - mape: 7822.8984\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4046 - mae: 0.4584 - mape: 7766.6299\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4047 - mae: 0.4584 - mape: 7710.6455\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4049 - mae: 0.4584 - mape: 7654.9453\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4050 - mae: 0.4584 - mape: 7599.5264\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4051 - mae: 0.4584 - mape: 7544.3916\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4052 - mae: 0.4584 - mape: 7489.5376\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4053 - mae: 0.4584 - mape: 7434.9639\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4584 - mse: 0.4054 - mae: 0.4584 - mape: 7380.6743\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4584 - mse: 0.4056 - mae: 0.4584 - mape: 7326.6670\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f73c0041830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Training Deep Gaussian Network!: END\n",
      "====================================\n",
      "#---------------------------------------#\n",
      " Get Training Errors for: Gaussian Models\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 14.35it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------------------------#\n",
      " Get Testing Errors for: Gaussian Models\n",
      "#--------------------------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                             0.000002   0.000000            -   \n",
      "W1                                 0.000005   0.000000            -   \n",
      "W1-95R                             0.000009   0.000000            -   \n",
      "M-95L                              0.000092   0.000080  9.15661e-05   \n",
      "M                                  0.000145   0.000145  0.000168421   \n",
      "M-95R                              0.000199   0.000185  0.000236557   \n",
      "N_Par                          42208.000000   0.000000           20   \n",
      "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
      "\n",
      "                                    KRidge         GBRF         DNN       GPR  \\\n",
      "W1-95L                                   -            -           -  0.004363   \n",
      "W1                                       -            -           -  0.007077   \n",
      "W1-95R                                   -            -           -  0.009855   \n",
      "M-95L                          0.000107537  7.06454e-05   0.0228225  0.000118   \n",
      "M                              0.000169909  0.000174036   0.0280817  0.000198   \n",
      "M-95R                          0.000233372  0.000253984   0.0324094  0.000273   \n",
      "N_Par                                    0         1000       40801  0.000000   \n",
      "Train_Time                        0.561581     0.779469      7.5179  0.730688   \n",
      "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  0.00706781  0.000036   \n",
      "\n",
      "                                        DGN  \n",
      "W1-95L                             0.868309  \n",
      "W1                                 0.873949  \n",
      "W1-95R                             0.879589  \n",
      "M-95L                              0.018154  \n",
      "M                                  0.018198  \n",
      "M-95R                              0.018242  \n",
      "N_Par                          40801.000000  \n",
      "Train_Time                         5.024743  \n",
      "Test_Time/MC-Oracle_Test_Time      0.007340  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %run Benchmarks_Model_Builder_Mean_Var.ipynb\n",
    "exec(open('Benchmarks_Model_Builder_Mean_Var.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Quality (Updated): Test\n",
      "                                        DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                         3.326321e-07   0.000000  3.269980e-03   \n",
      "W1                             6.896845e-07   0.000000  3.307251e-03   \n",
      "W1-95R                         1.046737e-06   0.000000  3.344523e-03   \n",
      "M-95L                          1.290718e-05   0.000013  1.759886e-05   \n",
      "M                              4.281266e-05   0.000043  4.789610e-05   \n",
      "M-95R                          7.271814e-05   0.000073  7.819334e-05   \n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
      "Train_Time                     1.104827e+01  53.664175  1.620115e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  5.298994e-03   1.000000  6.681574e-06   \n",
      "\n",
      "                                 KRidge         GBRF           DNN       GPR  \\\n",
      "W1-95L                         0.003270     0.003270      0.003582  0.002923   \n",
      "W1                             0.003307     0.003307      0.003621  0.002958   \n",
      "W1-95R                         0.003345     0.003345      0.003660  0.002993   \n",
      "M-95L                          0.000009     0.000070      0.017658  0.000007   \n",
      "M                              0.000039     0.000100      0.017717  0.000030   \n",
      "M-95R                          0.000068     0.000130      0.017775  0.000052   \n",
      "N_Par                          0.000000  1000.000000  40801.000000  0.000000   \n",
      "Train_Time                     0.561581     0.779469      7.517898  0.730688   \n",
      "Test_Time/MC-Oracle_Test_Time  0.000022     0.000068      0.007068  0.000036   \n",
      "\n",
      "                                        DGN  \n",
      "W1-95L                             0.868309  \n",
      "W1                                 0.873949  \n",
      "W1-95R                             0.879589  \n",
      "M-95L                              0.018154  \n",
      "M                                  0.018198  \n",
      "M-95R                              0.018242  \n",
      "N_Par                          40801.000000  \n",
      "Train_Time                         5.024743  \n",
      "Test_Time/MC-Oracle_Test_Time      0.007340  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>3.326321e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.269980e-03</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.868309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>6.896845e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.307251e-03</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.873949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>1.046737e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.344523e-03</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.879589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>1.290718e-05</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.759886e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.017658</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.018154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>4.281266e-05</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>4.789610e-05</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.018198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>7.271814e-05</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>7.819334e-05</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.018242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>4.220800e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>40801.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>1.104827e+01</td>\n",
       "      <td>53.664175</td>\n",
       "      <td>1.620115e+09</td>\n",
       "      <td>0.561581</td>\n",
       "      <td>0.779469</td>\n",
       "      <td>7.517898</td>\n",
       "      <td>0.730688</td>\n",
       "      <td>5.024743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>5.298994e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.681574e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.007340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle          ENET  \\\n",
       "W1-95L                         3.326321e-07   0.000000  3.269980e-03   \n",
       "W1                             6.896845e-07   0.000000  3.307251e-03   \n",
       "W1-95R                         1.046737e-06   0.000000  3.344523e-03   \n",
       "M-95L                          1.290718e-05   0.000013  1.759886e-05   \n",
       "M                              4.281266e-05   0.000043  4.789610e-05   \n",
       "M-95R                          7.271814e-05   0.000073  7.819334e-05   \n",
       "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
       "Train_Time                     1.104827e+01  53.664175  1.620115e+09   \n",
       "Test_Time/MC-Oracle_Test_Time  5.298994e-03   1.000000  6.681574e-06   \n",
       "\n",
       "                                 KRidge         GBRF           DNN       GPR  \\\n",
       "W1-95L                         0.003270     0.003270      0.003582  0.002923   \n",
       "W1                             0.003307     0.003307      0.003621  0.002958   \n",
       "W1-95R                         0.003345     0.003345      0.003660  0.002993   \n",
       "M-95L                          0.000009     0.000070      0.017658  0.000007   \n",
       "M                              0.000039     0.000100      0.017717  0.000030   \n",
       "M-95R                          0.000068     0.000130      0.017775  0.000052   \n",
       "N_Par                          0.000000  1000.000000  40801.000000  0.000000   \n",
       "Train_Time                     0.561581     0.779469      7.517898  0.730688   \n",
       "Test_Time/MC-Oracle_Test_Time  0.000022     0.000068      0.007068  0.000036   \n",
       "\n",
       "                                        DGN  \n",
       "W1-95L                             0.868309  \n",
       "W1                                 0.873949  \n",
       "W1-95R                             0.879589  \n",
       "M-95L                              0.018154  \n",
       "M                                  0.018198  \n",
       "M-95R                              0.018242  \n",
       "N_Par                          40801.000000  \n",
       "Train_Time                         5.024743  \n",
       "Test_Time/MC-Oracle_Test_Time      0.007340  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Prediction Quality (Updated): Test\")\n",
    "print(Summary_pred_Qual_models_test)\n",
    "Summary_pred_Qual_models_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Quality (Updated): Train\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                             0.000002   0.000000            -   \n",
      "W1                                 0.000005   0.000000            -   \n",
      "W1-95R                             0.000009   0.000000            -   \n",
      "M-95L                              0.000092   0.000080  9.15661e-05   \n",
      "M                                  0.000145   0.000145  0.000168421   \n",
      "M-95R                              0.000199   0.000185  0.000236557   \n",
      "N_Par                          42208.000000   0.000000           20   \n",
      "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
      "\n",
      "                                    KRidge         GBRF         DNN       GPR  \\\n",
      "W1-95L                                   -            -           -  0.004363   \n",
      "W1                                       -            -           -  0.007077   \n",
      "W1-95R                                   -            -           -  0.009855   \n",
      "M-95L                          0.000107537  7.06454e-05   0.0228225  0.000118   \n",
      "M                              0.000169909  0.000174036   0.0280817  0.000198   \n",
      "M-95R                          0.000233372  0.000253984   0.0324094  0.000273   \n",
      "N_Par                                    0         1000       40801  0.000000   \n",
      "Train_Time                        0.561581     0.779469      7.5179  0.730688   \n",
      "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  0.00706781  0.000036   \n",
      "\n",
      "                                        DGN  \n",
      "W1-95L                             0.868309  \n",
      "W1                                 0.873949  \n",
      "W1-95R                             0.879589  \n",
      "M-95L                              0.018154  \n",
      "M                                  0.018198  \n",
      "M-95R                              0.018242  \n",
      "N_Par                          40801.000000  \n",
      "Train_Time                         5.024743  \n",
      "Test_Time/MC-Oracle_Test_Time      0.007340  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.868309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>0.873949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>0.879589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>9.15661e-05</td>\n",
       "      <td>0.000107537</td>\n",
       "      <td>7.06454e-05</td>\n",
       "      <td>0.0228225</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.018154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000168421</td>\n",
       "      <td>0.000169909</td>\n",
       "      <td>0.000174036</td>\n",
       "      <td>0.0280817</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.018198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000236557</td>\n",
       "      <td>0.000233372</td>\n",
       "      <td>0.000253984</td>\n",
       "      <td>0.0324094</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.018242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>42208.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>40801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>11.048274</td>\n",
       "      <td>53.664175</td>\n",
       "      <td>1.62012e+09</td>\n",
       "      <td>0.561581</td>\n",
       "      <td>0.779469</td>\n",
       "      <td>7.5179</td>\n",
       "      <td>0.730688</td>\n",
       "      <td>5.024743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>0.005299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.68157e-06</td>\n",
       "      <td>2.19537e-05</td>\n",
       "      <td>6.77703e-05</td>\n",
       "      <td>0.00706781</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.007340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle         ENET  \\\n",
       "W1-95L                             0.000002   0.000000            -   \n",
       "W1                                 0.000005   0.000000            -   \n",
       "W1-95R                             0.000009   0.000000            -   \n",
       "M-95L                              0.000092   0.000080  9.15661e-05   \n",
       "M                                  0.000145   0.000145  0.000168421   \n",
       "M-95R                              0.000199   0.000185  0.000236557   \n",
       "N_Par                          42208.000000   0.000000           20   \n",
       "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
       "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
       "\n",
       "                                    KRidge         GBRF         DNN       GPR  \\\n",
       "W1-95L                                   -            -           -  0.004363   \n",
       "W1                                       -            -           -  0.007077   \n",
       "W1-95R                                   -            -           -  0.009855   \n",
       "M-95L                          0.000107537  7.06454e-05   0.0228225  0.000118   \n",
       "M                              0.000169909  0.000174036   0.0280817  0.000198   \n",
       "M-95R                          0.000233372  0.000253984   0.0324094  0.000273   \n",
       "N_Par                                    0         1000       40801  0.000000   \n",
       "Train_Time                        0.561581     0.779469      7.5179  0.730688   \n",
       "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  0.00706781  0.000036   \n",
       "\n",
       "                                        DGN  \n",
       "W1-95L                             0.868309  \n",
       "W1                                 0.873949  \n",
       "W1-95R                             0.879589  \n",
       "M-95L                              0.018154  \n",
       "M                                  0.018198  \n",
       "M-95R                              0.018242  \n",
       "N_Par                          40801.000000  \n",
       "Train_Time                         5.024743  \n",
       "Test_Time/MC-Oracle_Test_Time      0.007340  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Prediction Quality (Updated): Train\")\n",
    "print(Summary_pred_Qual_models)\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) The natural Universal Benchmark: [Bishop's Mixture Density Network](https://publications.aston.ac.uk/id/eprint/373/1/NCRG_94_004.pdf)\n",
    "\n",
    "This implementation is as follows:\n",
    "- For every $x$ in the trainingdata-set we fit a GMM $\\hat{\\nu}_x$, using the [Expectation-Maximization (EM) algorithm](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm), with the same number of centers as the deep neural model in $\\mathcal{NN}_{1_{\\mathbb{R}^d},\\mathcal{D}}^{\\sigma:\\star}$ which we are evaluating.  \n",
    "- A Mixture density network is then trained to predict the infered parameters; given any $x \\in \\mathbb{R}^d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Preparing Training Outputs for MDNs using EM-Algorithm\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.17s/it]\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Prepared Training Outputs for MDNs using EM-Algorithm!\n",
      "======================================================\n",
      "Deep Feature Builder - Ready\n",
      "(0)\n",
      "=====================================================\n",
      "Training Mixture Density Network (MDN): Means: Start!\n",
      "=====================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1162 - mse: 0.0212 - mae: 0.1162 - mape: 230.3401\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1161 - mse: 0.0212 - mae: 0.1161 - mape: 229.8515\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1161 - mse: 0.0212 - mae: 0.1161 - mape: 229.3606\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1160 - mse: 0.0212 - mae: 0.1160 - mape: 228.8686\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1159 - mse: 0.0212 - mae: 0.1159 - mape: 228.3759\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1159 - mse: 0.0211 - mae: 0.1159 - mape: 227.8829\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1158 - mse: 0.0211 - mae: 0.1158 - mape: 227.3895\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1157 - mse: 0.0211 - mae: 0.1157 - mape: 226.8958\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1157 - mse: 0.0211 - mae: 0.1157 - mape: 226.4019\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1156 - mse: 0.0211 - mae: 0.1156 - mape: 225.9078\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1155 - mse: 0.0211 - mae: 0.1155 - mape: 225.4135\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1155 - mse: 0.0210 - mae: 0.1155 - mape: 224.9190\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1154 - mse: 0.0210 - mae: 0.1154 - mape: 224.4242\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1153 - mse: 0.0210 - mae: 0.1153 - mape: 223.9349\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1153 - mse: 0.0210 - mae: 0.1153 - mape: 223.4471\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1152 - mse: 0.0210 - mae: 0.1152 - mape: 222.9601\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1151 - mse: 0.0209 - mae: 0.1151 - mape: 222.4738\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1151 - mse: 0.0209 - mae: 0.1151 - mape: 221.9882\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1150 - mse: 0.0209 - mae: 0.1150 - mape: 221.5031\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1149 - mse: 0.0209 - mae: 0.1149 - mape: 221.0186\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1149 - mse: 0.0209 - mae: 0.1149 - mape: 220.5343\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1148 - mse: 0.0209 - mae: 0.1148 - mape: 220.0504\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1147 - mse: 0.0208 - mae: 0.1147 - mape: 219.5668\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1147 - mse: 0.0208 - mae: 0.1147 - mape: 219.0833\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1146 - mse: 0.0208 - mae: 0.1146 - mape: 218.6000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1146 - mse: 0.0208 - mae: 0.1146 - mape: 218.1168\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1145 - mse: 0.0208 - mae: 0.1145 - mape: 217.6337\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1144 - mse: 0.0207 - mae: 0.1144 - mape: 217.1505\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1144 - mse: 0.0207 - mae: 0.1144 - mape: 216.6674\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1143 - mse: 0.0207 - mae: 0.1143 - mape: 216.1843\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1142 - mse: 0.0207 - mae: 0.1142 - mape: 215.7011\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1142 - mse: 0.0207 - mae: 0.1142 - mape: 215.2179\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1141 - mse: 0.0207 - mae: 0.1141 - mape: 214.7345\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1141 - mse: 0.0206 - mae: 0.1141 - mape: 214.2511\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1140 - mse: 0.0206 - mae: 0.1140 - mape: 213.7676\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1139 - mse: 0.0206 - mae: 0.1139 - mape: 213.2840\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1139 - mse: 0.0206 - mae: 0.1139 - mape: 212.8002\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1138 - mse: 0.0206 - mae: 0.1138 - mape: 212.3210\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1137 - mse: 0.0206 - mae: 0.1137 - mape: 211.8433\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1137 - mse: 0.0205 - mae: 0.1137 - mape: 211.3650\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1136 - mse: 0.0205 - mae: 0.1136 - mape: 210.8861\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1136 - mse: 0.0205 - mae: 0.1136 - mape: 210.4067\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1135 - mse: 0.0205 - mae: 0.1135 - mape: 209.9268\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1134 - mse: 0.0205 - mae: 0.1134 - mape: 209.4467\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1134 - mse: 0.0204 - mae: 0.1134 - mape: 208.9661\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1133 - mse: 0.0204 - mae: 0.1133 - mape: 208.4853\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1133 - mse: 0.0204 - mae: 0.1133 - mape: 208.0042\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1132 - mse: 0.0204 - mae: 0.1132 - mape: 207.5229\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1132 - mse: 0.0204 - mae: 0.1132 - mape: 207.0413\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1131 - mse: 0.0204 - mae: 0.1131 - mape: 206.5595\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1130 - mse: 0.0203 - mae: 0.1130 - mape: 206.0774\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1130 - mse: 0.0203 - mae: 0.1130 - mape: 205.5952\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1129 - mse: 0.0203 - mae: 0.1129 - mape: 205.1128\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1129 - mse: 0.0203 - mae: 0.1129 - mape: 204.6301\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1128 - mse: 0.0203 - mae: 0.1128 - mape: 204.1473\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1127 - mse: 0.0203 - mae: 0.1127 - mape: 203.6643\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1127 - mse: 0.0203 - mae: 0.1127 - mape: 203.1811\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1126 - mse: 0.0202 - mae: 0.1126 - mape: 202.6977\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1126 - mse: 0.0202 - mae: 0.1126 - mape: 202.2141\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1125 - mse: 0.0202 - mae: 0.1125 - mape: 201.7304\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1124 - mse: 0.0202 - mae: 0.1124 - mape: 201.2464\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1124 - mse: 0.0202 - mae: 0.1124 - mape: 200.7623\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1123 - mse: 0.0202 - mae: 0.1123 - mape: 200.2780\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1123 - mse: 0.0201 - mae: 0.1123 - mape: 199.7935\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1122 - mse: 0.0201 - mae: 0.1122 - mape: 199.3088\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1122 - mse: 0.0201 - mae: 0.1122 - mape: 198.8240\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1121 - mse: 0.0201 - mae: 0.1121 - mape: 198.3389\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1120 - mse: 0.0201 - mae: 0.1120 - mape: 197.8537\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1120 - mse: 0.0201 - mae: 0.1120 - mape: 197.3683\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1119 - mse: 0.0200 - mae: 0.1119 - mape: 196.8828\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1119 - mse: 0.0200 - mae: 0.1119 - mape: 196.3970\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1118 - mse: 0.0200 - mae: 0.1118 - mape: 195.9111\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1117 - mse: 0.0200 - mae: 0.1117 - mape: 195.4250\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1117 - mse: 0.0200 - mae: 0.1117 - mape: 194.9387\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1116 - mse: 0.0200 - mae: 0.1116 - mape: 194.4522\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1116 - mse: 0.0199 - mae: 0.1116 - mape: 193.9655\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1115 - mse: 0.0199 - mae: 0.1115 - mape: 193.4787\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1115 - mse: 0.0199 - mae: 0.1115 - mape: 192.9917\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1114 - mse: 0.0199 - mae: 0.1114 - mape: 192.5044\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1113 - mse: 0.0199 - mae: 0.1113 - mape: 192.0171\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1113 - mse: 0.0199 - mae: 0.1113 - mape: 191.5295\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1112 - mse: 0.0199 - mae: 0.1112 - mape: 191.0418\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1112 - mse: 0.0198 - mae: 0.1112 - mape: 190.5538\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1111 - mse: 0.0198 - mae: 0.1111 - mape: 190.0657\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1110 - mse: 0.0198 - mae: 0.1110 - mape: 189.5774\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1110 - mse: 0.0198 - mae: 0.1110 - mape: 189.0890\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1109 - mse: 0.0198 - mae: 0.1109 - mape: 188.6003\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1109 - mse: 0.0198 - mae: 0.1109 - mape: 188.1115\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1108 - mse: 0.0197 - mae: 0.1108 - mape: 187.6225\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1107 - mse: 0.0197 - mae: 0.1107 - mape: 187.1333\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1107 - mse: 0.0197 - mae: 0.1107 - mape: 186.6438\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1106 - mse: 0.0197 - mae: 0.1106 - mape: 186.1543\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1106 - mse: 0.0197 - mae: 0.1106 - mape: 185.6646\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1105 - mse: 0.0197 - mae: 0.1105 - mape: 185.1746\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1104 - mse: 0.0196 - mae: 0.1104 - mape: 184.6845\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1104 - mse: 0.0196 - mae: 0.1104 - mape: 184.1942\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1103 - mse: 0.0196 - mae: 0.1103 - mape: 183.7037\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1103 - mse: 0.0196 - mae: 0.1103 - mape: 183.2131\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1102 - mse: 0.0196 - mae: 0.1102 - mape: 182.7230\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1102 - mse: 0.0196 - mae: 0.1102 - mape: 182.2358\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1101 - mse: 0.0196 - mae: 0.1101 - mape: 181.7483\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1100 - mse: 0.0195 - mae: 0.1100 - mape: 181.2606\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1100 - mse: 0.0195 - mae: 0.1100 - mape: 180.7727\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1099 - mse: 0.0195 - mae: 0.1099 - mape: 180.2866\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1099 - mse: 0.0195 - mae: 0.1099 - mape: 179.8075\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1098 - mse: 0.0195 - mae: 0.1098 - mape: 179.3293\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1098 - mse: 0.0195 - mae: 0.1098 - mape: 178.8914\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1097 - mse: 0.0195 - mae: 0.1097 - mape: 178.5579\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1097 - mse: 0.0194 - mae: 0.1097 - mape: 178.2341\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1096 - mse: 0.0194 - mae: 0.1096 - mape: 177.9190\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1095 - mse: 0.0194 - mae: 0.1095 - mape: 177.6116\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1095 - mse: 0.0194 - mae: 0.1095 - mape: 177.3111\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1094 - mse: 0.0194 - mae: 0.1094 - mape: 177.0166\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1094 - mse: 0.0194 - mae: 0.1094 - mape: 176.7275\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1093 - mse: 0.0194 - mae: 0.1093 - mape: 176.4433\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1093 - mse: 0.0193 - mae: 0.1093 - mape: 176.1634\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1092 - mse: 0.0193 - mae: 0.1092 - mape: 175.8873\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1092 - mse: 0.0193 - mae: 0.1092 - mape: 175.7018\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1091 - mse: 0.0193 - mae: 0.1091 - mape: 175.5148\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1091 - mse: 0.0193 - mae: 0.1091 - mape: 175.3223\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1090 - mse: 0.0193 - mae: 0.1090 - mape: 175.1249\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1090 - mse: 0.0193 - mae: 0.1090 - mape: 174.9231\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1089 - mse: 0.0192 - mae: 0.1089 - mape: 174.7176\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1089 - mse: 0.0192 - mae: 0.1089 - mape: 174.5087\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1088 - mse: 0.0192 - mae: 0.1088 - mape: 174.2969\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1088 - mse: 0.0192 - mae: 0.1088 - mape: 174.0824\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1087 - mse: 0.0192 - mae: 0.1087 - mape: 173.8658\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1086 - mse: 0.0192 - mae: 0.1086 - mape: 173.6471\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1086 - mse: 0.0192 - mae: 0.1086 - mape: 173.5348\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1085 - mse: 0.0191 - mae: 0.1085 - mape: 173.4143\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1085 - mse: 0.0191 - mae: 0.1085 - mape: 173.2862\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1084 - mse: 0.0191 - mae: 0.1084 - mape: 173.1512\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1084 - mse: 0.0191 - mae: 0.1084 - mape: 173.0189\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1083 - mse: 0.0191 - mae: 0.1083 - mape: 172.8610\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1083 - mse: 0.0191 - mae: 0.1083 - mape: 172.6845\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1082 - mse: 0.0191 - mae: 0.1082 - mape: 172.5124\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1082 - mse: 0.0190 - mae: 0.1082 - mape: 172.3376\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1081 - mse: 0.0190 - mae: 0.1081 - mape: 172.1606\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1081 - mse: 0.0190 - mae: 0.1081 - mape: 171.9815\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1080 - mse: 0.0190 - mae: 0.1080 - mape: 171.8004\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1080 - mse: 0.0190 - mae: 0.1080 - mape: 171.6178\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1079 - mse: 0.0190 - mae: 0.1079 - mape: 171.4399\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1079 - mse: 0.0190 - mae: 0.1079 - mape: 171.2716\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1078 - mse: 0.0190 - mae: 0.1078 - mape: 171.0988\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1078 - mse: 0.0189 - mae: 0.1078 - mape: 170.9222\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1077 - mse: 0.0189 - mae: 0.1077 - mape: 170.7611\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1077 - mse: 0.0189 - mae: 0.1077 - mape: 170.5974\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1076 - mse: 0.0189 - mae: 0.1076 - mape: 170.4349\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1076 - mse: 0.0189 - mae: 0.1076 - mape: 170.2804\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1075 - mse: 0.0189 - mae: 0.1075 - mape: 170.1235\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1075 - mse: 0.0189 - mae: 0.1075 - mape: 169.9642\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1074 - mse: 0.0188 - mae: 0.1074 - mape: 169.8085\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1074 - mse: 0.0188 - mae: 0.1074 - mape: 169.6549\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1074 - mse: 0.0188 - mae: 0.1074 - mape: 169.4985\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1073 - mse: 0.0188 - mae: 0.1073 - mape: 169.3397\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1073 - mse: 0.0188 - mae: 0.1073 - mape: 169.1787\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1072 - mse: 0.0188 - mae: 0.1072 - mape: 169.0157\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1072 - mse: 0.0188 - mae: 0.1072 - mape: 168.8510\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1071 - mse: 0.0188 - mae: 0.1071 - mape: 168.6847\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1071 - mse: 0.0187 - mae: 0.1071 - mape: 168.5199\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1071 - mse: 0.0187 - mae: 0.1071 - mape: 168.3601\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1070 - mse: 0.0187 - mae: 0.1070 - mape: 168.2032\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1070 - mse: 0.0187 - mae: 0.1070 - mape: 168.0470\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1069 - mse: 0.0187 - mae: 0.1069 - mape: 167.8884\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1069 - mse: 0.0187 - mae: 0.1069 - mape: 167.7276\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1068 - mse: 0.0187 - mae: 0.1068 - mape: 167.5648\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1068 - mse: 0.0187 - mae: 0.1068 - mape: 167.4002\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1068 - mse: 0.0186 - mae: 0.1068 - mape: 167.2340\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1067 - mse: 0.0186 - mae: 0.1067 - mape: 167.0664\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1067 - mse: 0.0186 - mae: 0.1067 - mape: 166.9050\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066 - mse: 0.0186 - mae: 0.1066 - mape: 166.7413\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1066 - mse: 0.0186 - mae: 0.1066 - mape: 166.5819\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1066 - mse: 0.0186 - mae: 0.1066 - mape: 166.4250\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1065 - mse: 0.0186 - mae: 0.1065 - mape: 166.2657\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1065 - mse: 0.0186 - mae: 0.1065 - mape: 166.1081\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1064 - mse: 0.0185 - mae: 0.1064 - mape: 165.9308\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1064 - mse: 0.0185 - mae: 0.1064 - mape: 165.7587\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1063 - mse: 0.0185 - mae: 0.1063 - mape: 165.5949\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1063 - mse: 0.0185 - mae: 0.1063 - mape: 165.4326\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1063 - mse: 0.0185 - mae: 0.1063 - mape: 165.2750\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1062 - mse: 0.0185 - mae: 0.1062 - mape: 165.1001\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1062 - mse: 0.0185 - mae: 0.1062 - mape: 164.9349\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1061 - mse: 0.0185 - mae: 0.1061 - mape: 164.7702\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1061 - mse: 0.0184 - mae: 0.1061 - mape: 164.6263\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1060 - mse: 0.0184 - mae: 0.1060 - mape: 164.4490\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1060 - mse: 0.0184 - mae: 0.1060 - mape: 164.2784\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1060 - mse: 0.0184 - mae: 0.1060 - mape: 164.1145\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1059 - mse: 0.0184 - mae: 0.1059 - mape: 163.9478\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1059 - mse: 0.0184 - mae: 0.1059 - mape: 163.7805\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1058 - mse: 0.0184 - mae: 0.1058 - mape: 163.6283\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1058 - mse: 0.0184 - mae: 0.1058 - mape: 163.4715\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1057 - mse: 0.0183 - mae: 0.1057 - mape: 163.3125\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1057 - mse: 0.0183 - mae: 0.1057 - mape: 163.1310\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1057 - mse: 0.0183 - mae: 0.1057 - mape: 162.9494\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1056 - mse: 0.0183 - mae: 0.1056 - mape: 162.7740\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1056 - mse: 0.0183 - mae: 0.1056 - mape: 162.6054\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1055 - mse: 0.0183 - mae: 0.1055 - mape: 162.4423\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1055 - mse: 0.0183 - mae: 0.1055 - mape: 162.2827\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1055 - mse: 0.0183 - mae: 0.1055 - mape: 162.1193\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1054 - mse: 0.0182 - mae: 0.1054 - mape: 161.9524\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f73c021e5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "===================================================\n",
      "Training Mixture Density Network (MDN): Means: END!\n",
      "===================================================\n",
      "(1)\n",
      "===================================================\n",
      "Training Mixture Density Network (MDN): SD: Start!\n",
      "===================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9998 - mse: 1.0022 - mae: 0.9998 - mape: 212352.9062\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9997 - mse: 1.0020 - mae: 0.9997 - mape: 212329.5938\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9996 - mse: 1.0017 - mae: 0.9996 - mape: 212306.2500\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9994 - mse: 1.0015 - mae: 0.9994 - mape: 212282.8438\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9993 - mse: 1.0013 - mae: 0.9993 - mape: 212259.4531\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9992 - mse: 1.0010 - mae: 0.9992 - mape: 212236.0469\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9991 - mse: 1.0008 - mae: 0.9991 - mape: 212212.5938\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9990 - mse: 1.0005 - mae: 0.9990 - mape: 212189.2031\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9989 - mse: 1.0003 - mae: 0.9989 - mape: 212165.7812\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9987 - mse: 1.0001 - mae: 0.9987 - mape: 212142.3281\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9986 - mse: 0.9998 - mae: 0.9986 - mape: 212118.9062\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9985 - mse: 0.9996 - mae: 0.9985 - mape: 212095.4531\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9984 - mse: 0.9994 - mae: 0.9984 - mape: 212072.0469\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9983 - mse: 0.9991 - mae: 0.9983 - mape: 212048.5938\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9982 - mse: 0.9989 - mae: 0.9982 - mape: 212025.1719\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9980 - mse: 0.9987 - mae: 0.9980 - mape: 212001.7500\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9979 - mse: 0.9984 - mae: 0.9979 - mape: 211978.2969\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9978 - mse: 0.9982 - mae: 0.9978 - mape: 211954.9062\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9977 - mse: 0.9980 - mae: 0.9977 - mape: 211931.4531\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9976 - mse: 0.9977 - mae: 0.9976 - mape: 211908.0469\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9975 - mse: 0.9975 - mae: 0.9975 - mape: 211884.5938\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9973 - mse: 0.9973 - mae: 0.9973 - mape: 211861.1719\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 971us/step - loss: 0.9972 - mse: 0.9970 - mae: 0.9972 - mape: 211837.7812\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9971 - mse: 0.9968 - mae: 0.9971 - mape: 211814.3281\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9970 - mse: 0.9966 - mae: 0.9970 - mape: 211790.9531\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 942us/step - loss: 0.9969 - mse: 0.9963 - mae: 0.9969 - mape: 211767.5000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9968 - mse: 0.9961 - mae: 0.9968 - mape: 211744.0938\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9966 - mse: 0.9959 - mae: 0.9966 - mape: 211720.6719\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9965 - mse: 0.9956 - mae: 0.9965 - mape: 211697.2812\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9964 - mse: 0.9954 - mae: 0.9964 - mape: 211673.8438\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9963 - mse: 0.9952 - mae: 0.9963 - mape: 211650.4531\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9962 - mse: 0.9949 - mae: 0.9962 - mape: 211627.0469\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9961 - mse: 0.9947 - mae: 0.9961 - mape: 211603.6562\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 973us/step - loss: 0.9960 - mse: 0.9945 - mae: 0.9960 - mape: 211580.2500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9958 - mse: 0.9942 - mae: 0.9958 - mape: 211556.8438\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9957 - mse: 0.9940 - mae: 0.9957 - mape: 211533.4531\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9956 - mse: 0.9938 - mae: 0.9956 - mape: 211510.0469\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9955 - mse: 0.9935 - mae: 0.9955 - mape: 211486.6562\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9954 - mse: 0.9933 - mae: 0.9954 - mape: 211463.2812\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9953 - mse: 0.9931 - mae: 0.9953 - mape: 211439.8750\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9951 - mse: 0.9928 - mae: 0.9951 - mape: 211416.4688\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9950 - mse: 0.9926 - mae: 0.9950 - mape: 211393.0938\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9949 - mse: 0.9924 - mae: 0.9949 - mape: 211369.7031\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9948 - mse: 0.9921 - mae: 0.9948 - mape: 211346.2969\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9947 - mse: 0.9919 - mae: 0.9947 - mape: 211322.9219\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9946 - mse: 0.9917 - mae: 0.9946 - mape: 211299.5469\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9944 - mse: 0.9914 - mae: 0.9944 - mape: 211276.1562\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9943 - mse: 0.9912 - mae: 0.9943 - mape: 211252.7500\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9942 - mse: 0.9910 - mae: 0.9942 - mape: 211229.3750\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9941 - mse: 0.9907 - mae: 0.9941 - mape: 211206.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9940 - mse: 0.9905 - mae: 0.9940 - mape: 211182.593 - 0s 1ms/step - loss: 0.9940 - mse: 0.9905 - mae: 0.9940 - mape: 211182.5938\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9939 - mse: 0.9903 - mae: 0.9939 - mape: 211159.2031\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 958us/step - loss: 0.9937 - mse: 0.9900 - mae: 0.9937 - mape: 211135.8281\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9936 - mse: 0.9898 - mae: 0.9936 - mape: 211112.4219\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9935 - mse: 0.9896 - mae: 0.9935 - mape: 211089.0469\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9934 - mse: 0.9894 - mae: 0.9934 - mape: 211065.6562\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9933 - mse: 0.9891 - mae: 0.9933 - mape: 211042.2500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9932 - mse: 0.9889 - mae: 0.9932 - mape: 211018.8438\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9930 - mse: 0.9887 - mae: 0.9930 - mape: 210995.5000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9929 - mse: 0.9884 - mae: 0.9929 - mape: 210972.0781\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9928 - mse: 0.9882 - mae: 0.9928 - mape: 210948.6719\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9927 - mse: 0.9880 - mae: 0.9927 - mape: 210925.2812\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9926 - mse: 0.9877 - mae: 0.9926 - mape: 210901.8750\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9925 - mse: 0.9875 - mae: 0.9925 - mape: 210878.5000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9923 - mse: 0.9873 - mae: 0.9923 - mape: 210855.0781\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9922 - mse: 0.9870 - mae: 0.9922 - mape: 210831.6719\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9921 - mse: 0.9868 - mae: 0.9921 - mape: 210808.2500\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 927us/step - loss: 0.9920 - mse: 0.9866 - mae: 0.9920 - mape: 210784.8438\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9919 - mse: 0.9863 - mae: 0.9919 - mape: 210761.4219\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9918 - mse: 0.9861 - mae: 0.9918 - mape: 210738.0312\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9916 - mse: 0.9859 - mae: 0.9916 - mape: 210714.5938\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9915 - mse: 0.9856 - mae: 0.9915 - mape: 210691.1719\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9914 - mse: 0.9854 - mae: 0.9914 - mape: 210667.7500\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9913 - mse: 0.9852 - mae: 0.9913 - mape: 210644.2969\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9912 - mse: 0.9849 - mae: 0.9912 - mape: 210620.9062\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9910 - mse: 0.9847 - mae: 0.9910 - mape: 210597.4531\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9909 - mse: 0.9845 - mae: 0.9909 - mape: 210574.0312\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9908 - mse: 0.9842 - mae: 0.9908 - mape: 210550.5469\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9907 - mse: 0.9840 - mae: 0.9907 - mape: 210527.1250\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9906 - mse: 0.9838 - mae: 0.9906 - mape: 210503.6719\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9905 - mse: 0.9835 - mae: 0.9905 - mape: 210480.2031\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9903 - mse: 0.9833 - mae: 0.9903 - mape: 210456.7500\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9902 - mse: 0.9831 - mae: 0.9902 - mape: 210433.2969\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9901 - mse: 0.9828 - mae: 0.9901 - mape: 210409.8281\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9900 - mse: 0.9826 - mae: 0.9900 - mape: 210386.3438\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9899 - mse: 0.9824 - mae: 0.9899 - mape: 210362.9062\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9898 - mse: 0.9821 - mae: 0.9898 - mape: 210339.4062\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9896 - mse: 0.9819 - mae: 0.9896 - mape: 210315.9062\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9895 - mse: 0.9817 - mae: 0.9895 - mape: 210292.4062\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9894 - mse: 0.9814 - mae: 0.9894 - mape: 210268.9062\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9893 - mse: 0.9812 - mae: 0.9893 - mape: 210245.4062\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9892 - mse: 0.9810 - mae: 0.9892 - mape: 210221.9062\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9891 - mse: 0.9807 - mae: 0.9891 - mape: 210198.4062\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9889 - mse: 0.9805 - mae: 0.9889 - mape: 210174.8750\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9888 - mse: 0.9803 - mae: 0.9888 - mape: 210151.3438\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9887 - mse: 0.9800 - mae: 0.9887 - mape: 210127.8281\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9886 - mse: 0.9798 - mae: 0.9886 - mape: 210104.2812\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9885 - mse: 0.9796 - mae: 0.9885 - mape: 210080.7500\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9884 - mse: 0.9793 - mae: 0.9884 - mape: 210057.2031\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9882 - mse: 0.9791 - mae: 0.9882 - mape: 210033.6562\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9881 - mse: 0.9789 - mae: 0.9881 - mape: 210010.0781\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9880 - mse: 0.9786 - mae: 0.9880 - mape: 209986.5000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9879 - mse: 0.9784 - mae: 0.9879 - mape: 209962.9531\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9878 - mse: 0.9782 - mae: 0.9878 - mape: 209939.3750\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9876 - mse: 0.9779 - mae: 0.9876 - mape: 209915.7812\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9875 - mse: 0.9777 - mae: 0.9875 - mape: 209892.2031\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9874 - mse: 0.9775 - mae: 0.9874 - mape: 209868.5938\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9873 - mse: 0.9772 - mae: 0.9873 - mape: 209845.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9872 - mse: 0.9770 - mae: 0.9872 - mape: 209821.3750\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9871 - mse: 0.9768 - mae: 0.9871 - mape: 209797.7500\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9869 - mse: 0.9765 - mae: 0.9869 - mape: 209774.1250\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9868 - mse: 0.9763 - mae: 0.9868 - mape: 209750.5000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9867 - mse: 0.9761 - mae: 0.9867 - mape: 209726.8438\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9866 - mse: 0.9758 - mae: 0.9866 - mape: 209703.2031\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9865 - mse: 0.9756 - mae: 0.9865 - mape: 209679.5469\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9863 - mse: 0.9753 - mae: 0.9863 - mape: 209655.8906\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9862 - mse: 0.9751 - mae: 0.9862 - mape: 209632.2188\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9861 - mse: 0.9749 - mae: 0.9861 - mape: 209608.5312\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9860 - mse: 0.9746 - mae: 0.9860 - mape: 209584.8438\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9859 - mse: 0.9744 - mae: 0.9859 - mape: 209561.1562\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9858 - mse: 0.9742 - mae: 0.9858 - mape: 209537.4375\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9856 - mse: 0.9739 - mae: 0.9856 - mape: 209513.7500\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9855 - mse: 0.9737 - mae: 0.9855 - mape: 209490.0312\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9854 - mse: 0.9735 - mae: 0.9854 - mape: 209466.2969\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9853 - mse: 0.9732 - mae: 0.9853 - mape: 209442.5469\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9852 - mse: 0.9730 - mae: 0.9852 - mape: 209418.8281\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9850 - mse: 0.9728 - mae: 0.9850 - mape: 209395.0469\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9849 - mse: 0.9725 - mae: 0.9849 - mape: 209371.2812\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9848 - mse: 0.9723 - mae: 0.9848 - mape: 209347.5312\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9847 - mse: 0.9721 - mae: 0.9847 - mape: 209323.7344\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9846 - mse: 0.9718 - mae: 0.9846 - mape: 209299.9531\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9844 - mse: 0.9716 - mae: 0.9844 - mape: 209276.1562\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9843 - mse: 0.9714 - mae: 0.9843 - mape: 209252.3438\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9842 - mse: 0.9711 - mae: 0.9842 - mape: 209228.5312\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9841 - mse: 0.9709 - mae: 0.9841 - mape: 209204.7188\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9840 - mse: 0.9706 - mae: 0.9840 - mape: 209180.8750\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9839 - mse: 0.9704 - mae: 0.9839 - mape: 209157.0312\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9837 - mse: 0.9702 - mae: 0.9837 - mape: 209133.1719\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9836 - mse: 0.9699 - mae: 0.9836 - mape: 209109.3125\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9835 - mse: 0.9697 - mae: 0.9835 - mape: 209085.4531\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9834 - mse: 0.9695 - mae: 0.9834 - mape: 209061.5781\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9833 - mse: 0.9692 - mae: 0.9833 - mape: 209037.6719\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9831 - mse: 0.9690 - mae: 0.9831 - mape: 209013.7656\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9830 - mse: 0.9688 - mae: 0.9830 - mape: 208989.8438\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9829 - mse: 0.9685 - mae: 0.9829 - mape: 208965.9219\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9828 - mse: 0.9683 - mae: 0.9828 - mape: 208941.9688\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9827 - mse: 0.9681 - mae: 0.9827 - mape: 208918.0312\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9825 - mse: 0.9678 - mae: 0.9825 - mape: 208894.0781\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9824 - mse: 0.9676 - mae: 0.9824 - mape: 208870.1250\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9823 - mse: 0.9673 - mae: 0.9823 - mape: 208846.1562\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9822 - mse: 0.9671 - mae: 0.9822 - mape: 208822.1562\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9821 - mse: 0.9669 - mae: 0.9821 - mape: 208798.1562\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9819 - mse: 0.9666 - mae: 0.9819 - mape: 208774.1562\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9818 - mse: 0.9664 - mae: 0.9818 - mape: 208750.1250\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9817 - mse: 0.9662 - mae: 0.9817 - mape: 208726.1094\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9816 - mse: 0.9659 - mae: 0.9816 - mape: 208702.0625\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9815 - mse: 0.9657 - mae: 0.9815 - mape: 208678.0156\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9813 - mse: 0.9654 - mae: 0.9813 - mape: 208653.9375\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9812 - mse: 0.9652 - mae: 0.9812 - mape: 208629.8594\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9811 - mse: 0.9650 - mae: 0.9811 - mape: 208605.7656\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9810 - mse: 0.9647 - mae: 0.9810 - mape: 208581.6719\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9809 - mse: 0.9645 - mae: 0.9809 - mape: 208557.5469\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9807 - mse: 0.9643 - mae: 0.9807 - mape: 208533.4219\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9806 - mse: 0.9640 - mae: 0.9806 - mape: 208509.2812\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9805 - mse: 0.9638 - mae: 0.9805 - mape: 208485.1562\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9804 - mse: 0.9635 - mae: 0.9804 - mape: 208460.9688\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9802 - mse: 0.9633 - mae: 0.9802 - mape: 208436.8125\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9801 - mse: 0.9631 - mae: 0.9801 - mape: 208412.6250\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9800 - mse: 0.9628 - mae: 0.9800 - mape: 208388.4062\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9799 - mse: 0.9626 - mae: 0.9799 - mape: 208364.2031\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9798 - mse: 0.9623 - mae: 0.9798 - mape: 208339.9688\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9796 - mse: 0.9621 - mae: 0.9796 - mape: 208315.7500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9795 - mse: 0.9619 - mae: 0.9795 - mape: 208291.5000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9794 - mse: 0.9616 - mae: 0.9794 - mape: 208267.2188\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9793 - mse: 0.9614 - mae: 0.9793 - mape: 208242.9531\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9792 - mse: 0.9612 - mae: 0.9792 - mape: 208218.6719\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9790 - mse: 0.9609 - mae: 0.9790 - mape: 208194.3438\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9789 - mse: 0.9607 - mae: 0.9789 - mape: 208170.0469\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9788 - mse: 0.9604 - mae: 0.9788 - mape: 208145.7031\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9787 - mse: 0.9602 - mae: 0.9787 - mape: 208121.3594\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9785 - mse: 0.9600 - mae: 0.9785 - mape: 208097.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9784 - mse: 0.9597 - mae: 0.9784 - mape: 208072.6250\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9783 - mse: 0.9595 - mae: 0.9783 - mape: 208048.2188\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9782 - mse: 0.9592 - mae: 0.9782 - mape: 208023.8438\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9781 - mse: 0.9590 - mae: 0.9781 - mape: 207999.4375\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9779 - mse: 0.9588 - mae: 0.9779 - mape: 207975.0156\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9778 - mse: 0.9585 - mae: 0.9778 - mape: 207950.5625\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9777 - mse: 0.9583 - mae: 0.9777 - mape: 207926.0938\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9776 - mse: 0.9580 - mae: 0.9776 - mape: 207901.6250\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9774 - mse: 0.9578 - mae: 0.9774 - mape: 207877.1250\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9773 - mse: 0.9576 - mae: 0.9773 - mape: 207852.6562\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9772 - mse: 0.9573 - mae: 0.9772 - mape: 207828.0938\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9771 - mse: 0.9571 - mae: 0.9771 - mape: 207803.5938\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9769 - mse: 0.9568 - mae: 0.9769 - mape: 207779.0469\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9768 - mse: 0.9566 - mae: 0.9768 - mape: 207754.4688\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9767 - mse: 0.9563 - mae: 0.9767 - mape: 207729.9062\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9766 - mse: 0.9561 - mae: 0.9766 - mape: 207705.2969\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9765 - mse: 0.9559 - mae: 0.9765 - mape: 207680.7031\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9763 - mse: 0.9556 - mae: 0.9763 - mape: 207656.0781\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9762 - mse: 0.9554 - mae: 0.9762 - mape: 207631.4375\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f73c0c560e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 843us/step\n",
      "=================================================\n",
      "Training Mixture Density Network (MDN): SD: END!\n",
      "=================================================\n",
      "(2)\n",
      "====================================================================\n",
      "Training Mixture Density Network (MDN): Mixture Coefficients: Start!\n",
      "====================================================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 916us/step - loss: 2.0863 - accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 921us/step - loss: 2.0802 - accuracy: 0.2000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 943us/step - loss: 2.0750 - accuracy: 0.4000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0705 - accuracy: 0.4000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0666 - accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0631 - accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0600 - accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 954us/step - loss: 2.0572 - accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 914us/step - loss: 2.0546 - accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0524 - accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0503 - accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0483 - accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0466 - accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0449 - accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0434 - accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0420 - accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0407 - accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0395 - accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 855us/step - loss: 2.0385 - accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0374 - accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0365 - accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0355 - accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0346 - accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0336 - accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 906us/step - loss: 2.0326 - accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0316 - accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 899us/step - loss: 2.0304 - accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0293 - accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 828us/step - loss: 2.0281 - accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0269 - accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0256 - accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0244 - accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0231 - accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0217 - accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0204 - accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0191 - accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0179 - accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0166 - accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0154 - accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0142 - accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0131 - accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0120 - accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0109 - accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0098 - accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0088 - accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0078 - accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0068 - accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 912us/step - loss: 2.0059 - accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0051 - accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0044 - accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0037 - accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0030 - accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0025 - accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0020 - accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 946us/step - loss: 2.0016 - accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 901us/step - loss: 2.0012 - accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0008 - accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0005 - accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0002 - accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0000 - accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9998 - accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9996 - accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9994 - accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9992 - accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9989 - accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9988 - accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9986 - accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9984 - accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9981 - accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9979 - accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9977 - accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9976 - accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9974 - accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9971 - accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9969 - accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9967 - accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9965 - accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9963 - accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9962 - accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9960 - accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9958 - accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9956 - accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9955 - accuracy: 0.5000\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9953 - accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9951 - accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9949 - accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9947 - accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9945 - accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9943 - accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9941 - accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9939 - accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9937 - accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9935 - accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9932 - accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9930 - accuracy: 0.5000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9928 - accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9925 - accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9923 - accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9921 - accuracy: 0.5000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9918 - accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9916 - accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9913 - accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9911 - accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9908 - accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9906 - accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9903 - accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9900 - accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9898 - accuracy: 0.5000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9895 - accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9892 - accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9890 - accuracy: 0.5000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9887 - accuracy: 0.5000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9884 - accuracy: 0.5000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9881 - accuracy: 0.5000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9878 - accuracy: 0.5000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9876 - accuracy: 0.5000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9873 - accuracy: 0.5000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9870 - accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9867 - accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9864 - accuracy: 0.5000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9861 - accuracy: 0.5000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9858 - accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9855 - accuracy: 0.5000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9852 - accuracy: 0.5000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9849 - accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9846 - accuracy: 0.5000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9843 - accuracy: 0.5000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9840 - accuracy: 0.5000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9837 - accuracy: 0.5000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9834 - accuracy: 0.5000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9831 - accuracy: 0.5000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9828 - accuracy: 0.5000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9825 - accuracy: 0.5000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9821 - accuracy: 0.5000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9818 - accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9816 - accuracy: 0.5000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9812 - accuracy: 0.5000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9810 - accuracy: 0.5000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9806 - accuracy: 0.5000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9803 - accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9801 - accuracy: 0.5000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9798 - accuracy: 0.5000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9795 - accuracy: 0.5000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9792 - accuracy: 0.5000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9789 - accuracy: 0.5000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9787 - accuracy: 0.5000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9784 - accuracy: 0.5000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9781 - accuracy: 0.5000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9779 - accuracy: 0.5000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9776 - accuracy: 0.5000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9773 - accuracy: 0.5000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9771 - accuracy: 0.5000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9768 - accuracy: 0.5000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9766 - accuracy: 0.5000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9763 - accuracy: 0.5000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9761 - accuracy: 0.5000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9759 - accuracy: 0.5000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9756 - accuracy: 0.5000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9754 - accuracy: 0.5000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9752 - accuracy: 0.5000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9749 - accuracy: 0.5000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9747 - accuracy: 0.5000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9745 - accuracy: 0.5000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9743 - accuracy: 0.5000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9741 - accuracy: 0.5000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9739 - accuracy: 0.5000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9736 - accuracy: 0.6000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9734 - accuracy: 0.6000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9732 - accuracy: 0.6000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9730 - accuracy: 0.6000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9728 - accuracy: 0.6000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9726 - accuracy: 0.6000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9724 - accuracy: 0.6000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9722 - accuracy: 0.6000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9720 - accuracy: 0.6000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9718 - accuracy: 0.6000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9716 - accuracy: 0.6000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9714 - accuracy: 0.6000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9712 - accuracy: 0.6000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9710 - accuracy: 0.6000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9708 - accuracy: 0.6000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9706 - accuracy: 0.6000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9704 - accuracy: 0.6000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9701 - accuracy: 0.6000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9699 - accuracy: 0.6000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9697 - accuracy: 0.6000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9695 - accuracy: 0.6000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9693 - accuracy: 0.6000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9691 - accuracy: 0.6000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9688 - accuracy: 0.6000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9686 - accuracy: 0.6000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9684 - accuracy: 0.6000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9681 - accuracy: 0.6000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9679 - accuracy: 0.6000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9677 - accuracy: 0.6000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 874us/step - loss: 1.9675 - accuracy: 0.6000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9672 - accuracy: 0.6000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9670 - accuracy: 0.6000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9667 - accuracy: 0.6000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9665 - accuracy: 0.6000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f73c152c290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 791us/step\n",
      "1/1 [==============================] - 0s 823us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "Training Mixture Density Network (MDN): Mixture Coefficients: END!\n",
      "==================================================================\n",
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.64it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------#\n",
      " Get Test Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------#\n",
      " Get Test Error(s): END\n",
      "#---------------------#\n",
      "#---------------------------#\n",
      " Get Training Error(s): Begin\n",
      "#---------------------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n",
      "#--------------------------#\n",
      " Get Testing Error(s): Begin\n",
      "#--------------------------#\n",
      "#------------------------#\n",
      " Get Testing Error(s): END\n",
      "#------------------------#\n",
      "-------------------------------------------------\n",
      "Updating Performance Metrics Dataframe and Saved!\n",
      "-------------------------------------------------\n",
      "Updated DataFrame\n",
      "-------------------------------------------------\n",
      "Train\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                             0.000002   0.000000            -   \n",
      "W1                                 0.000005   0.000000            -   \n",
      "W1-95R                             0.000009   0.000000            -   \n",
      "M-95L                              0.000092   0.000080  9.15661e-05   \n",
      "M                                  0.000145   0.000145  0.000168421   \n",
      "M-95R                              0.000199   0.000185  0.000236557   \n",
      "N_Par                          42208.000000   0.000000           20   \n",
      "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
      "\n",
      "                                    KRidge         GBRF         DNN       GPR  \\\n",
      "W1-95L                                   -            -           -  0.004363   \n",
      "W1                                       -            -           -  0.007077   \n",
      "W1-95R                                   -            -           -  0.009855   \n",
      "M-95L                          0.000107537  7.06454e-05   0.0228225  0.000118   \n",
      "M                              0.000169909  0.000174036   0.0280817  0.000198   \n",
      "M-95R                          0.000233372  0.000253984   0.0324094  0.000273   \n",
      "N_Par                                    0         1000       40801  0.000000   \n",
      "Train_Time                        0.561581     0.779469      7.5179  0.730688   \n",
      "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  0.00706781  0.000036   \n",
      "\n",
      "                                        DGN  \n",
      "W1-95L                             0.868309  \n",
      "W1                                 0.873949  \n",
      "W1-95R                             0.879589  \n",
      "M-95L                              0.018154  \n",
      "M                                  0.018198  \n",
      "M-95R                              0.018242  \n",
      "N_Par                          40801.000000  \n",
      "Train_Time                         5.024743  \n",
      "Test_Time/MC-Oracle_Test_Time      0.007340  \n",
      "-------------------------------------------------\n",
      "Test\n",
      "                                        DNM  MC-Oracle          ENET  \\\n",
      "W1-95L                         3.326321e-07   0.000000  3.269980e-03   \n",
      "W1                             6.896845e-07   0.000000  3.307251e-03   \n",
      "W1-95R                         1.046737e-06   0.000000  3.344523e-03   \n",
      "M-95L                          1.290718e-05   0.000013  1.759886e-05   \n",
      "M                              4.281266e-05   0.000043  4.789610e-05   \n",
      "M-95R                          7.271814e-05   0.000073  7.819334e-05   \n",
      "N_Par                          4.220800e+04   0.000000  2.000000e+01   \n",
      "Train_Time                     1.104827e+01  53.664175  1.620115e+09   \n",
      "Test_Time/MC-Oracle_Test_Time  5.298994e-03   1.000000  6.681574e-06   \n",
      "\n",
      "                                 KRidge         GBRF           DNN       GPR  \\\n",
      "W1-95L                         0.003270     0.003270      0.003582  0.002923   \n",
      "W1                             0.003307     0.003307      0.003621  0.002958   \n",
      "W1-95R                         0.003345     0.003345      0.003660  0.002993   \n",
      "M-95L                          0.000009     0.000070      0.017658  0.000007   \n",
      "M                              0.000039     0.000100      0.017717  0.000030   \n",
      "M-95R                          0.000068     0.000130      0.017775  0.000052   \n",
      "N_Par                          0.000000  1000.000000  40801.000000  0.000000   \n",
      "Train_Time                     0.561581     0.779469      7.517898  0.730688   \n",
      "Test_Time/MC-Oracle_Test_Time  0.000022     0.000068      0.007068  0.000036   \n",
      "\n",
      "                                        DGN            MDN  \n",
      "W1-95L                             0.868309       0.825095  \n",
      "W1                                 0.873949       0.826658  \n",
      "W1-95R                             0.879589       0.828222  \n",
      "M-95L                              0.018154       0.002619  \n",
      "M                                  0.018198       0.003108  \n",
      "M-95R                              0.018242       0.003597  \n",
      "N_Par                          40801.000000  126624.000000  \n",
      "Train_Time                         5.024743       0.146728  \n",
      "Test_Time/MC-Oracle_Test_Time      0.007340       3.969606  \n",
      "-------------------------------------------------\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                             0.000002   0.000000            -   \n",
      "W1                                 0.000005   0.000000            -   \n",
      "W1-95R                             0.000009   0.000000            -   \n",
      "M-95L                              0.000092   0.000080  9.15661e-05   \n",
      "M                                  0.000145   0.000145  0.000168421   \n",
      "M-95R                              0.000199   0.000185  0.000236557   \n",
      "N_Par                          42208.000000   0.000000           20   \n",
      "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
      "\n",
      "                                    KRidge         GBRF         DNN       GPR  \\\n",
      "W1-95L                                   -            -           -  0.004363   \n",
      "W1                                       -            -           -  0.007077   \n",
      "W1-95R                                   -            -           -  0.009855   \n",
      "M-95L                          0.000107537  7.06454e-05   0.0228225  0.000118   \n",
      "M                              0.000169909  0.000174036   0.0280817  0.000198   \n",
      "M-95R                          0.000233372  0.000253984   0.0324094  0.000273   \n",
      "N_Par                                    0         1000       40801  0.000000   \n",
      "Train_Time                        0.561581     0.779469      7.5179  0.730688   \n",
      "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  0.00706781  0.000036   \n",
      "\n",
      "                                        DGN            MDN  \n",
      "W1-95L                             0.868309       0.825095  \n",
      "W1                                 0.873949       0.826658  \n",
      "W1-95R                             0.879589       0.828222  \n",
      "M-95L                              0.018154       0.004934  \n",
      "M                                  0.018198       0.007488  \n",
      "M-95R                              0.018242       0.009666  \n",
      "N_Par                          40801.000000  126624.000000  \n",
      "Train_Time                         5.024743       0.146728  \n",
      "Test_Time/MC-Oracle_Test_Time      0.007340       3.969606  \n",
      "------------------------------------------------\n",
      "Updated Performance Metrics Dataframe and Saved!\n",
      "------------------------------------------------\n",
      "Have a jolly old day!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if output_dim == 1:\n",
    "    # %run Mixture_Density_Network.ipynb\n",
    "    exec(open('Mixture_Density_Network.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Final Outputs\n",
    "Now we piece together all the numerical experiments and report a nice summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prasing Quality Metric Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalizing Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write Performance Metrics\n",
    "Summary_pred_Qual_models.to_latex((results_tables_path+\"/Final_Results/\"+\"Performance_metrics_Problem_Type_\"+str(f_unknown_mode)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS.tex\"),\n",
    "                                 caption=(\"Quality Metrics; d:\"+str(problem_dim)+\", D:\"+str(output_dim)+\", Depth:\"+str(Depth_Bayesian_DNN)+\", Width:\"+str(width)+\", Dropout rate:\"+str(Dropout_rate)+\".\"),\n",
    "                                 float_format=\"{:0.3g}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Terminal Runner(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Predictive Quality:\n",
      "===================\n",
      "                                        DNM  MC-Oracle         ENET  \\\n",
      "W1-95L                             0.000002   0.000000            -   \n",
      "W1                                 0.000005   0.000000            -   \n",
      "W1-95R                             0.000009   0.000000            -   \n",
      "M-95L                              0.000092   0.000080  9.15661e-05   \n",
      "M                                  0.000145   0.000145  0.000168421   \n",
      "M-95R                              0.000199   0.000185  0.000236557   \n",
      "N_Par                          42208.000000   0.000000           20   \n",
      "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
      "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
      "\n",
      "                                    KRidge         GBRF         DNN       GPR  \\\n",
      "W1-95L                                   -            -           -  0.004363   \n",
      "W1                                       -            -           -  0.007077   \n",
      "W1-95R                                   -            -           -  0.009855   \n",
      "M-95L                          0.000107537  7.06454e-05   0.0228225  0.000118   \n",
      "M                              0.000169909  0.000174036   0.0280817  0.000198   \n",
      "M-95R                          0.000233372  0.000253984   0.0324094  0.000273   \n",
      "N_Par                                    0         1000       40801  0.000000   \n",
      "Train_Time                        0.561581     0.779469      7.5179  0.730688   \n",
      "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  0.00706781  0.000036   \n",
      "\n",
      "                                        DGN            MDN  \n",
      "W1-95L                             0.868309       0.825095  \n",
      "W1                                 0.873949       0.826658  \n",
      "W1-95R                             0.879589       0.828222  \n",
      "M-95L                              0.018154       0.004934  \n",
      "M                                  0.018198       0.007488  \n",
      "M-95R                              0.018242       0.009666  \n",
      "N_Par                          40801.000000  126624.000000  \n",
      "Train_Time                         5.024743       0.146728  \n",
      "Test_Time/MC-Oracle_Test_Time      0.007340       3.969606  \n",
      "===================\n",
      " \n",
      " \n",
      " \n",
      "Kernel_Used_in_GPR: WhiteKernel(noise_level=1)\n",
      "🙃🙃 Have a wonderful day! 🙃🙃\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNM</th>\n",
       "      <th>MC-Oracle</th>\n",
       "      <th>ENET</th>\n",
       "      <th>KRidge</th>\n",
       "      <th>GBRF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>GPR</th>\n",
       "      <th>DGN</th>\n",
       "      <th>MDN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W1-95L</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.868309</td>\n",
       "      <td>0.825095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>0.873949</td>\n",
       "      <td>0.826658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W1-95R</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>0.879589</td>\n",
       "      <td>0.828222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95L</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>9.15661e-05</td>\n",
       "      <td>0.000107537</td>\n",
       "      <td>7.06454e-05</td>\n",
       "      <td>0.0228225</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>0.004934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000168421</td>\n",
       "      <td>0.000169909</td>\n",
       "      <td>0.000174036</td>\n",
       "      <td>0.0280817</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>0.007488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-95R</th>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000236557</td>\n",
       "      <td>0.000233372</td>\n",
       "      <td>0.000253984</td>\n",
       "      <td>0.0324094</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>0.009666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Par</th>\n",
       "      <td>42208.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>40801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40801.000000</td>\n",
       "      <td>126624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_Time</th>\n",
       "      <td>11.048274</td>\n",
       "      <td>53.664175</td>\n",
       "      <td>1.62012e+09</td>\n",
       "      <td>0.561581</td>\n",
       "      <td>0.779469</td>\n",
       "      <td>7.5179</td>\n",
       "      <td>0.730688</td>\n",
       "      <td>5.024743</td>\n",
       "      <td>0.146728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Time/MC-Oracle_Test_Time</th>\n",
       "      <td>0.005299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.68157e-06</td>\n",
       "      <td>2.19537e-05</td>\n",
       "      <td>6.77703e-05</td>\n",
       "      <td>0.00706781</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.007340</td>\n",
       "      <td>3.969606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        DNM  MC-Oracle         ENET  \\\n",
       "W1-95L                             0.000002   0.000000            -   \n",
       "W1                                 0.000005   0.000000            -   \n",
       "W1-95R                             0.000009   0.000000            -   \n",
       "M-95L                              0.000092   0.000080  9.15661e-05   \n",
       "M                                  0.000145   0.000145  0.000168421   \n",
       "M-95R                              0.000199   0.000185  0.000236557   \n",
       "N_Par                          42208.000000   0.000000           20   \n",
       "Train_Time                        11.048274  53.664175  1.62012e+09   \n",
       "Test_Time/MC-Oracle_Test_Time      0.005299   1.000000  6.68157e-06   \n",
       "\n",
       "                                    KRidge         GBRF         DNN       GPR  \\\n",
       "W1-95L                                   -            -           -  0.004363   \n",
       "W1                                       -            -           -  0.007077   \n",
       "W1-95R                                   -            -           -  0.009855   \n",
       "M-95L                          0.000107537  7.06454e-05   0.0228225  0.000118   \n",
       "M                              0.000169909  0.000174036   0.0280817  0.000198   \n",
       "M-95R                          0.000233372  0.000253984   0.0324094  0.000273   \n",
       "N_Par                                    0         1000       40801  0.000000   \n",
       "Train_Time                        0.561581     0.779469      7.5179  0.730688   \n",
       "Test_Time/MC-Oracle_Test_Time  2.19537e-05  6.77703e-05  0.00706781  0.000036   \n",
       "\n",
       "                                        DGN            MDN  \n",
       "W1-95L                             0.868309       0.825095  \n",
       "W1                                 0.873949       0.826658  \n",
       "W1-95R                             0.879589       0.828222  \n",
       "M-95L                              0.018154       0.004934  \n",
       "M                                  0.018198       0.007488  \n",
       "M-95R                              0.018242       0.009666  \n",
       "N_Par                          40801.000000  126624.000000  \n",
       "Train_Time                         5.024743       0.146728  \n",
       "Test_Time/MC-Oracle_Test_Time      0.007340       3.969606  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Terminal Running\n",
    "print(\"===================\")\n",
    "print(\"Predictive Quality:\")\n",
    "print(\"===================\")\n",
    "print(Summary_pred_Qual_models)\n",
    "print(\"===================\")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Kernel_Used_in_GPR: \"+str(GPR_trash.kernel))\n",
    "print(\"🙃🙃 Have a wonderful day! 🙃🙃\")\n",
    "Summary_pred_Qual_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
