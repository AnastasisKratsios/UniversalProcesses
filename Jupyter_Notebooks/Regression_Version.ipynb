{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Conditional Laws for Random-Fields - via:\n",
    "\n",
    "## Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$.\n",
    "\n",
    "---\n",
    "\n",
    "By: [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode:\n",
    "Software/Hardware Testing or Real-Deal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random DNN\n",
    "method = \"Random_DNN\"\n",
    "\n",
    "# Random DNN internal noise\n",
    "# method = \"Random_DNN_internal_noise\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "- Random $\\delta$-bounded partition on input space,\n",
    "- Train deep classifier on infered classes.\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Auxiliaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time\n",
    "\n",
    "\n",
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\"\n",
    "\n",
    "\n",
    "### Set Seed\n",
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dim = 20\n",
    "width = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)\n",
    "- Ratio $\\frac{\\text{Testing Datasize}}{\\text{Training Datasize}}$.\n",
    "- Number of Training Points to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = .2\n",
    "N_train_size = 10**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Monte_Carlo_Samples = 10**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial radis of $\\delta$-bounded random partition of $\\mathcal{X}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.01\n",
    "Proportion_per_cluster = .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate from: $Y=f(X,U)$ \n",
    "- Random DNN (internal noise): \n",
    "    - $f(X,U) = f_{\\text{unknown}}(X+U)$\n",
    "- Random DNN: \n",
    "    - $f(X,U) = f_{\\text{unknown}}(X)+U$\n",
    "    \n",
    "*Non-linear dependance on exhaugenous noise.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard\n",
    "W_2a = np.random.uniform(size=np.array([1,width]),low=-.5,high=.5)\n",
    "W_1a = np.random.uniform(size=np.array([width,problem_dim]),low=-.5,high=.5)\n",
    "def f_unknown(x):\n",
    "    x_internal = x.reshape(-1,)\n",
    "    x_internal = np.matmul(W_1a,x_internal)\n",
    "    x_internal = np.matmul(W_2a,np.cos(x_internal))\n",
    "    return x_internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == \"Random_DNN\":\n",
    "    def Simulator(x_in):\n",
    "        var = np.sqrt(np.sum(x_in**2))\n",
    "        # Pushforward\n",
    "        f_x = f_unknown(x_in)\n",
    "        # Apply Noise After\n",
    "        noise = np.random.laplace(0,var,N_Monte_Carlo_Samples)\n",
    "        f_x_noise = f_x + noise\n",
    "        return f_x_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test_size = int(np.round(N_train_size*train_test_ratio,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training Data (Inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try initial sampling-type implementation!  It worked nicely..i.e.: centers were given!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Training Set\n",
    "X_train = np.random.uniform(size=np.array([N_train_size,problem_dim]),low=.5,high=1.5)\n",
    "\n",
    "# Get Testing Set\n",
    "test_set_indices = np.random.choice(range(X_train.shape[0]),N_test_size)\n",
    "X_test = X_train[test_set_indices,]\n",
    "X_test = X_test + np.random.uniform(low=-(delta/np.sqrt(problem_dim)), \n",
    "                                    high = -(delta/np.sqrt(problem_dim)),\n",
    "                                    size = X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize k_means\n",
    "N_Quantizers_to_parameterize = int(round(Proportion_per_cluster*X_train.shape[0]))\n",
    "kmeans = KMeans(n_clusters=N_Quantizers_to_parameterize, random_state=0).fit(X_train)\n",
    "# Get Classes\n",
    "Train_classes = np.array(pd.get_dummies(kmeans.labels_))\n",
    "# Get Center Measures\n",
    "Barycenters_Array_x = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Barycenters\n",
    "*Here we make the assumption that we can directly resample $f(X=x,U)$ if necessary...or that it is available as part of the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 3602.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(Barycenters_Array_x.shape[0])):\n",
    "    # Put Datum\n",
    "    Bar_x_loop = Barycenters_Array_x[i,]\n",
    "    # Product Monte-Carlo Sample for Input\n",
    "    Bar_y_loop = (Simulator(Bar_x_loop)).reshape(1,-1)\n",
    "\n",
    "    # Update Dataset\n",
    "    if i == 0:\n",
    "        Barycenters_Array = Bar_y_loop\n",
    "    else:\n",
    "        Barycenters_Array = np.append(Barycenters_Array,Bar_y_loop,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training Data (Outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 6212.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(X_train.shape[0])):\n",
    "    # Put Datum\n",
    "    x_loop = X_train[i,]\n",
    "    # Product Monte-Carlo Sample for Input\n",
    "    y_loop = (Simulator(x_loop)).reshape(1,-1)\n",
    "\n",
    "    # Update Dataset\n",
    "    if i == 0:\n",
    "        Y_train = y_loop\n",
    "    else:\n",
    "        Y_train = np.append(Y_train,y_loop,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 6887.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Start Timer\n",
    "Test_Set_PredictionTime_MC = time.time()\n",
    "\n",
    "# Generate Data\n",
    "for i in tqdm(range(X_test.shape[0])):\n",
    "    # Put Datum\n",
    "    x_loop = X_test[i,]\n",
    "    # Product Monte-Carlo Sample for Input\n",
    "    y_loop = (Simulator(x_loop)).reshape(1,-1)\n",
    "\n",
    "    # Update Dataset\n",
    "    if i == 0:\n",
    "        Y_test = y_loop\n",
    "    else:\n",
    "        Y_test = np.append(Y_test,y_loop,axis=0)\n",
    "        \n",
    "# End Timer\n",
    "Test_Set_PredictionTime_MC = time.time() - Test_Set_PredictionTime_MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Packages and CV Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Training Classifer Portion of Type-A Model\n",
      "==========================================\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=4)]: Done  16 out of  20 | elapsed:   34.8s remaining:    8.7s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:   43.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.6161 - accuracy: 0.2300\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5686 - accuracy: 0.3400\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5379 - accuracy: 0.3000\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5185 - accuracy: 0.3000\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.5005 - accuracy: 0.3000\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.4853 - accuracy: 0.3000\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4715 - accuracy: 0.3000\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4562 - accuracy: 0.3000\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4398 - accuracy: 0.3000\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.4182 - accuracy: 0.3100\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3973 - accuracy: 0.3400\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3806 - accuracy: 0.3800\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3564 - accuracy: 0.4600\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3253 - accuracy: 0.4900\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3012 - accuracy: 0.5700\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.2659 - accuracy: 0.5800\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2292 - accuracy: 0.5300\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1918 - accuracy: 0.5700\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1506 - accuracy: 0.6000\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1096 - accuracy: 0.7000\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0633 - accuracy: 0.7700\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0151 - accuracy: 0.7500\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0431 - accuracy: 0.71 - 0s 3ms/step - loss: 0.9682 - accuracy: 0.7800\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9203 - accuracy: 0.8100\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8654 - accuracy: 0.8900\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8220 - accuracy: 0.8800\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7751 - accuracy: 0.8700\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7232 - accuracy: 0.8800\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.9100\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.9200\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.9100\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.9400\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.9500\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.9400\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.9600\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.9600\n",
      "Epoch 37/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.9500\n",
      "Epoch 38/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.9500\n",
      "Epoch 39/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.9500\n",
      "Epoch 40/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.9700\n",
      "Epoch 41/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.9700\n",
      "Epoch 42/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9700\n",
      "Epoch 43/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9700\n",
      "Epoch 44/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2060 - accuracy: 0.9800\n",
      "Epoch 45/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9900\n",
      "Epoch 46/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1819 - accuracy: 0.9900\n",
      "Epoch 47/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9800\n",
      "Epoch 48/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1727 - accuracy: 0.9900\n",
      "Epoch 49/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9800\n",
      "Epoch 50/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9900\n",
      "Epoch 51/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1378 - accuracy: 1.0000\n",
      "Epoch 52/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1280 - accuracy: 1.0000\n",
      "Epoch 53/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 1.0000\n",
      "Epoch 54/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 1.0000\n",
      "Epoch 55/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 1.0000\n",
      "Epoch 56/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 1.0000\n",
      "Epoch 57/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 1.0000\n",
      "Epoch 58/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 1.0000\n",
      "Epoch 59/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 1.0000\n",
      "Epoch 60/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 1.0000\n",
      "Epoch 61/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 1.0000\n",
      "Epoch 62/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 1.0000\n",
      "Epoch 63/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 1.0000\n",
      "Epoch 64/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 1.0000\n",
      "Epoch 65/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 1.0000\n",
      "Epoch 66/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 1.0000\n",
      "Epoch 67/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 1.0000\n",
      "Epoch 68/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 1.0000\n",
      "Epoch 69/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 1.0000\n",
      "Epoch 70/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 1.0000\n",
      "Epoch 71/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 1.0000\n",
      "Epoch 72/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 1.0000\n",
      "Epoch 73/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 1.0000\n",
      "Epoch 74/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 1.0000\n",
      "Epoch 75/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 1.0000\n",
      "Epoch 76/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 77/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 78/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 1.0000\n",
      "Epoch 79/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 1.0000\n",
      "Epoch 80/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 1.0000\n",
      "Epoch 81/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 82/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 83/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 84/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 85/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 1.0000\n",
      "Epoch 86/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 87/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 88/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 89/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 90/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 91/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 92/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 93/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 94/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 95/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 96/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 97/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 98/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 99/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 100/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 101/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 102/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 103/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 104/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 105/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 106/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 107/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 108/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 109/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 110/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 111/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 112/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 113/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 114/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 115/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 116/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 117/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 118/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 119/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 120/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 121/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 122/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 123/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 124/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 125/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 126/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 127/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 128/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 129/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 130/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 131/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 132/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 133/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 134/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 135/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 136/250\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.00 - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 137/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 138/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 139/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 140/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 141/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 142/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 143/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 144/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 145/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 146/250\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 147/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 148/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 149/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 150/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 151/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 152/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 153/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 154/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 155/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 156/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 157/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 158/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 159/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 160/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 161/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 162/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 163/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 164/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 165/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 166/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 167/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 168/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 169/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 170/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 171/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 172/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 173/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 174/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 175/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 176/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 177/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 178/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 179/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 180/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 181/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 182/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 183/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 184/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 185/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 186/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 187/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 188/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 189/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 190/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 191/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 192/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 193/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 194/250\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 195/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 196/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 197/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 198/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 199/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 200/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 201/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 202/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 203/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 204/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 205/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 206/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 207/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 208/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 209/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 210/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 211/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 212/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 213/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 214/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 215/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 216/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 217/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 218/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 219/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 220/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 221/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 222/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 223/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 224/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 225/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 226/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 227/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 228/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 229/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 230/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 231/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 232/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 233/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 234/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 235/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 236/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 237/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 238/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 239/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 240/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 241/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 242/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 243/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 244/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 245/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 246/250\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 247/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 248/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 249/250\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 250/250\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "===============================================\n",
      "Training Classifer Portion of Type Model: Done!\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "print(\"==========================================\")\n",
    "print(\"Training Classifer Portion of Type-A Model\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [problem_dim]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier, timer_output = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Train_classes,\n",
    "                                                                                                        X_test = X_test)\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"Training Classifer Portion of Type Model: Done!\")\n",
    "print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Empirical Weights\n",
    "empirical_weights = (np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples).reshape(-1,)\n",
    "\n",
    "for i in range(N_Quantizers_to_parameterize):\n",
    "    if i == 0:\n",
    "        points_of_mass = Barycenters_Array[i,]\n",
    "    else:\n",
    "        points_of_mass = np.append(points_of_mass,Barycenters_Array[i,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Noisless Mean\n",
    "direct_facts = np.apply_along_axis(f_unknown, 1, X_train)\n",
    "direct_facts_test = np.apply_along_axis(f_unknown, 1, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Training Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------#\n",
      " Get Training Error(s)\n",
      "#--------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 630.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"#--------------------#\")\n",
    "print(\" Get Training Error(s)\")\n",
    "print(\"#--------------------#\")\n",
    "for i in tqdm(range((X_train.shape[0]))):\n",
    "    for j in range(N_Quantizers_to_parameterize):\n",
    "        b_loop = np.repeat(predicted_classes_train[i,j],N_Monte_Carlo_Samples)\n",
    "        if j == 0:\n",
    "            b = b_loop\n",
    "        else:\n",
    "            b = np.append(b,b_loop)\n",
    "        b = b.reshape(-1,1)\n",
    "        b = b\n",
    "    b = np.array(b,dtype=float).reshape(-1,)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    \n",
    "    # Compute Error(s)\n",
    "    ## W1\n",
    "    W1_loop = ot.emd2_1d(points_of_mass,\n",
    "                         np.array(Y_train[i,]).reshape(-1,),\n",
    "                         b,\n",
    "                         empirical_weights)\n",
    "    \n",
    "    ## M1\n",
    "    Mu_hat = np.sum(b*(points_of_mass))\n",
    "    Mu_MC = np.mean(np.array(Y_train[i,]))\n",
    "    Mu = direct_facts[i,]\n",
    "    ### Error(s)\n",
    "    Mean_loop = (Mu_hat-Mu)\n",
    "    Mean_loop_MC = (Mu_hat-Mu_MC)\n",
    "    \n",
    "    ## M2\n",
    "    Var_hat = np.sum(((points_of_mass-Mu_hat)**2)*b)\n",
    "    Var_MC = np.mean(np.array(Y_train[i]-Mu_MC)**2)\n",
    "    Var = np.mean((direct_facts[i,]-Mu)**2)\n",
    "    \n",
    "    ### Error(s)\n",
    "    Var_loop = np.abs(Var_hat-Var)\n",
    "    Var_loop_MC = np.abs(Var_MC-Var)\n",
    "    \n",
    "    # Update\n",
    "    if i == 0:\n",
    "        W1_errors = W1_loop\n",
    "        Mean_errors =  Mean_loop\n",
    "        Var_errors = Var_loop\n",
    "        Mean_errors_MC =  Mean_loop_MC\n",
    "        Var_errors_MC = Var_loop_MC\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        W1_errors = np.append(W1_errors,W1_loop)\n",
    "        Mean_errors =  np.append(Mean_errors,Mean_loop)\n",
    "        Var_errors = np.append(Var_errors,Var_loop)\n",
    "        Mean_errors_MC =  np.append(Mean_errors_MC,Mean_loop_MC)\n",
    "        Var_errors_MC = np.append(Var_errors_MC,Var_loop_MC)\n",
    "        \n",
    "print(\"#-------------------------#\")\n",
    "print(\" Get Training Error(s): END\")\n",
    "print(\"#-------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Test Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 592.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------#\n",
      " Get Test Error(s)\n",
      "#----------------#\n",
      "#-------------------------#\n",
      " Get Training Error(s): END\n",
      "#-------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------#\")\n",
    "print(\" Get Test Error(s)\")\n",
    "print(\"#----------------#\")\n",
    "for i in tqdm(range((X_test.shape[0]))):\n",
    "    for j in range(N_Quantizers_to_parameterize):\n",
    "        b_loop_test = np.repeat(predicted_classes_test[i,j],N_Monte_Carlo_Samples)\n",
    "        if j == 0:\n",
    "            b_test = b_loop_test\n",
    "        else:\n",
    "            b_test = np.append(b,b_loop)\n",
    "        b_test = b_test.reshape(-1,1)\n",
    "    b_test = np.array(b,dtype=float).reshape(-1,)\n",
    "    b_test = b/N_Monte_Carlo_Samples\n",
    "    \n",
    "    # Compute Error(s)\n",
    "    ## W1\n",
    "    W1_loop_test = ot.emd2_1d(points_of_mass,\n",
    "                         np.array(Y_test[i,]).reshape(-1,),\n",
    "                         b,\n",
    "                         empirical_weights)\n",
    "    \n",
    "    ## M1\n",
    "    Mu_hat_test = np.sum(b_test*(points_of_mass))\n",
    "    Mu_MC_test = np.mean(np.array(Y_test[i,]))\n",
    "    Mu_test = direct_facts_test[i,]\n",
    "    ### Error(s)\n",
    "    Mean_loop_test = (Mu_hat_test-Mu_test)\n",
    "    Mean_loop_MC_test = (Mu_hat_test-Mu_MC_test)\n",
    "    \n",
    "    ## M2\n",
    "    Var_hat_test = np.sum(((points_of_mass-Mu_hat_test)**2)*b)\n",
    "    Var_MC_test = np.mean(np.array(Y_test[i]-Mu_MC)**2)\n",
    "    Var_test = np.mean((direct_facts_test[i,]-Mu)**2)\n",
    "    \n",
    "    ### Error(s)\n",
    "    Var_loop_test = np.abs(Var_hat_test-Var_test)\n",
    "    Var_loop_MC_test = np.abs(Var_MC_test-Var_test)\n",
    "    \n",
    "    # Update\n",
    "    if i == 0:\n",
    "        W1_errors_test = W1_loop_test\n",
    "        Mean_errors_test =  Mean_loop_test\n",
    "        Var_errors_test = Var_loop_test\n",
    "        Mean_errors_MC_test =  Mean_loop_MC_test\n",
    "        Var_errors_MC_test = Var_loop_MC_test\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "        Mean_errors_test =  np.append(Mean_errors_test,Mean_loop_test)\n",
    "        Var_errors_test = np.append(Var_errors_test,Var_loop_test)\n",
    "        Mean_errors_MC_test =  np.append(Mean_errors_MC_test,Mean_loop_MC_test)\n",
    "        Var_errors_MC_test = np.append(Var_errors_MC_test,Var_loop_MC_test)\n",
    "        \n",
    "print(\"#-------------------------#\")\n",
    "print(\" Get Training Error(s): END\")\n",
    "print(\"#-------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          N_Centers   N_Q  N_Params  Training Time  \\\n",
      "Model_Complexity_metrics          5  1000      6405     5.0971E+01   \n",
      "\n",
      "                          T_Test/T_Test-MC  Time Test  Time EM-MC  \n",
      "Model_Complexity_metrics        9.6519E+00 5.8446E-02  6.0554E-03  \n",
      "              W1         M1      M1_MC        Var     Var_MC  N_Centers   N_Q  \\\n",
      "Train 2.0629E+00 9.7211E-01 9.8554E-01 4.0317E+01 4.3272E+01          5  1000   \n",
      "Test  5.1292E+00 7.6066E+00 7.6825E+00 7.6263E+01 4.2872E+01          5  1000   \n",
      "\n",
      "       N_Params  Training Time  T_Test/T_Test-MC  Problem_Dimension  \n",
      "Train      6405     5.0971E+01        9.6519E+00                 20  \n",
      "Test       6405     5.0971E+01        9.6519E+00                 20  \n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------#\n",
    "W1_95 = bootstrap(W1_errors, n=1000, func=np.mean)(.95)\n",
    "W1_99 = bootstrap(W1_errors, n=1000, func=np.mean)(.99)\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "Model_Complexity = pd.DataFrame({\"N_Centers\":N_Quantizers_to_parameterize,\n",
    "                                 \"N_Q\":N_Monte_Carlo_Samples,\n",
    "                                 \"N_Params\":N_params_deep_classifier,\n",
    "                                 \"Training Time\":Time_Lapse_Model_A,\n",
    "                                 \"T_Test/T_Test-MC\": (timer_output/Test_Set_PredictionTime_MC),\n",
    "                                 \"Time Test\": timer_output,\n",
    "                                 \"Time EM-MC\": Test_Set_PredictionTime_MC},index=[\"Model_Complexity_metrics\"])\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "Summary = pd.DataFrame({\"W1\":np.array([np.mean(np.abs(W1_errors)),np.mean(np.abs(W1_errors_test))]),\n",
    "                        \"M1\":np.array([np.mean(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors_test))]),\n",
    "                        \"M1_MC\":np.array([np.mean(np.abs(Mean_errors_MC)),np.mean(np.abs(Mean_errors_MC_test))]),\n",
    "                        \"Var\":np.array([np.mean(np.abs(Var_errors)),np.mean(np.abs(Var_errors_test))]),\n",
    "                        \"Var_MC\":np.array([np.mean(np.abs(Var_errors_MC)),np.mean(np.abs(Var_errors_MC_test))]),                                             \n",
    "                        \"N_Centers\":np.array((N_Quantizers_to_parameterize,N_Quantizers_to_parameterize)),\n",
    "                        \"N_Q\":np.array((N_Monte_Carlo_Samples,N_Monte_Carlo_Samples)),\n",
    "                        \"N_Params\":np.array((N_params_deep_classifier,N_params_deep_classifier)),\n",
    "                        \"Training Time\":np.array((Time_Lapse_Model_A,Time_Lapse_Model_A)),\n",
    "                        \"T_Test/T_Test-MC\":np.array(((timer_output/Test_Set_PredictionTime_MC),(timer_output/Test_Set_PredictionTime_MC))),\n",
    "                        \"Problem_Dimension\":np.array((problem_dim,problem_dim))\n",
    "                       },index=[\"Train\",\"Test\"])\n",
    "\n",
    "\n",
    "# Write Performance Metrics to file #\n",
    "#-----------------------------------#\n",
    "pd.set_option('display.float_format', '{:.4E}'.format)\n",
    "Model_Complexity.to_latex((results_tables_path+\"Latent_Width_NSDE\"+str(width)+\"Problemdimension\"+str(problem_dim)+\"__ModelComplexities.tex\"))\n",
    "pd.set_option('display.float_format', '{:.4E}'.format)\n",
    "Summary.to_latex((results_tables_path+\"Latent_Width_NSDE\"+str(width)+\"Problemdimension\"+str(problem_dim)+\"__SUMMARY_METRICS.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "print(Model_Complexity)\n",
    "print(Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Prediction Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>M1</th>\n",
       "      <th>M1_MC</th>\n",
       "      <th>Var</th>\n",
       "      <th>Var_MC</th>\n",
       "      <th>N_Centers</th>\n",
       "      <th>N_Q</th>\n",
       "      <th>N_Params</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>T_Test/T_Test-MC</th>\n",
       "      <th>Problem_Dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>2.0629E+00</td>\n",
       "      <td>9.7211E-01</td>\n",
       "      <td>9.8554E-01</td>\n",
       "      <td>4.0317E+01</td>\n",
       "      <td>4.3272E+01</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>6405</td>\n",
       "      <td>5.0971E+01</td>\n",
       "      <td>9.6519E+00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>5.1292E+00</td>\n",
       "      <td>7.6066E+00</td>\n",
       "      <td>7.6825E+00</td>\n",
       "      <td>7.6263E+01</td>\n",
       "      <td>4.2872E+01</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>6405</td>\n",
       "      <td>5.0971E+01</td>\n",
       "      <td>9.6519E+00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              W1         M1      M1_MC        Var     Var_MC  N_Centers   N_Q  \\\n",
       "Train 2.0629E+00 9.7211E-01 9.8554E-01 4.0317E+01 4.3272E+01          5  1000   \n",
       "Test  5.1292E+00 7.6066E+00 7.6825E+00 7.6263E+01 4.2872E+01          5  1000   \n",
       "\n",
       "       N_Params  Training Time  T_Test/T_Test-MC  Problem_Dimension  \n",
       "Train      6405     5.0971E+01        9.6519E+00                 20  \n",
       "Test       6405     5.0971E+01        9.6519E+00                 20  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
