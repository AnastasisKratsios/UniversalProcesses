{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Weak Stochastic Processes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 5\n",
    "N_Monte_Carlo_Samples = 10000\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 1000\n",
    "Max_Grid = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Quantizer_support = 5\n",
    "N_Quantizers_to_parameterize = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Algorithm\n",
    "---\n",
    "Given a set of training inputs $\\mathbb{X}$ and a stochastic process $(X_t)_{t\\geq 0}$ which we can sample from:\n",
    "1. **For:** x in $\\mathbb{X}$:\n",
    "    - *Simulate:* $\\{x\\mapsto X_T(\\omega_n)\\}_{n=1}^N$\n",
    "    - *Set*: $\\hat{\\nu}_{x,T}\\triangleq \\frac1{N}\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$\n",
    "2. **Learn:** Wasserstein Barycenters $\\hat{\\mu}_1,\\dots,\\hat{\\mu}_N\n",
    "    \\in \\underset{{\\hat{\\mu}_n\\in\\mathscr{P}_{N}(\\mathbb{R}^d)}}{\\operatorname{argmin}}\n",
    "    \\, \\sum_{n=1}^N W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$\n",
    "3. **Train Classifier:** $\\hat{f}:x\\mapsto \\operatorname{n\\leq N}\\, W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = .3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Path\n",
    "$d X_t = \\alpha(t,x)dt + \\beta(t,x)dW_t ;\\qquad X_0 =x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return np.sin(math.pi*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return (t+1)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Grid\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Instances:  1000\n"
     ]
    }
   ],
   "source": [
    "# Get Input Data\n",
    "x_Grid = np.arange(start=-Max_Grid,\n",
    "                   stop=Max_Grid,\n",
    "                   step=(2*Max_Grid/N_Grid_Finess))\n",
    "\n",
    "# Get Number of Instances in Grid\n",
    "N_Grid_Instances = len(x_Grid)\n",
    "\n",
    "# Updater User\n",
    "print(\"Grid Instances: \", N_Grid_Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates the empirical measure $\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$ of $X_T$ conditional on $X_0=x_0\\in \\mathbb{R}$ *($x_0$ and $T>0$ are user-provided)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euler_Maruyama_Generator(x_0,\n",
    "                             N_Euler_Maruyama_Steps = N_Euler_Maruyama_Steps,\n",
    "                             N_Monte_Carlo_Samples = N_Monte_Carlo_Samples,\n",
    "                             T = 1): \n",
    "    \n",
    "    #----------------------------#    \n",
    "    # DEFINE INTERNAL PARAMETERS #\n",
    "    #----------------------------#\n",
    "    # Initialize Empirical Measure\n",
    "    X_T_Empirical = np.zeros(N_Monte_Carlo_Samples)\n",
    "\n",
    "\n",
    "    # Internal Initialization(s)\n",
    "    ## Initialize current state\n",
    "    n_sample = 0\n",
    "    ## Initialize Incriments\n",
    "    dt = T/N_Euler_Maruyama_Steps\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "\n",
    "    #-----------------------------#    \n",
    "    # Generate Monte-Carlo Sample #\n",
    "    #-----------------------------#\n",
    "    while n_sample < N_Monte_Carlo_Samples:\n",
    "        # Reset Step Counter\n",
    "        t = 1\n",
    "        # Initialize Current State \n",
    "        X_current = x_0\n",
    "        # Perform Euler-Maruyama Simulation\n",
    "        while t<N_Euler_Maruyama_Steps:\n",
    "            # Update Internal Parameters\n",
    "            ## Get Current Time\n",
    "            t_current = t*(T/N_Euler_Maruyama_Steps)\n",
    "\n",
    "            # Update Generated Path\n",
    "            X_current = X_current + alpha(t_current,X_current)*dt + beta(t_current,X_current)*np.random.normal(0,sqrt_dt)\n",
    "\n",
    "            # Update Counter (EM)\n",
    "            t = t+1\n",
    "\n",
    "        # Update Empirical Measure\n",
    "        X_T_Empirical[n_sample] = X_current\n",
    "\n",
    "        # Update Counter (MC)\n",
    "        n_sample = n_sample + 1\n",
    "\n",
    "    return X_T_Empirical#.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List of Barycenters\n",
    "Wasserstein_Barycenters = []\n",
    "# Initialize Terminal-Time Empirical Measures\n",
    "measures_locations_list = []\n",
    "measures_weights_list = []\n",
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "# Initialize Quantizer\n",
    "Init_Quantizer_generic = np.ones(N_Quantizer_support)/N_Quantizer_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $\\{\\hat{\\nu}^{N}_{T,x}\\}_{x \\in \\mathbb{X}}$ Build Wasserstein Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step: 0.0\n",
      "Current Monte-Carlo Step: 0.001\n",
      "Current Monte-Carlo Step: 0.002\n",
      "Current Monte-Carlo Step: 0.003\n",
      "Current Monte-Carlo Step: 0.004\n",
      "Current Monte-Carlo Step: 0.005\n",
      "Current Monte-Carlo Step: 0.006\n",
      "Current Monte-Carlo Step: 0.007\n",
      "Current Monte-Carlo Step: 0.008\n",
      "Current Monte-Carlo Step: 0.009\n",
      "Current Monte-Carlo Step: 0.01\n",
      "Current Monte-Carlo Step: 0.011\n",
      "Current Monte-Carlo Step: 0.012\n",
      "Current Monte-Carlo Step: 0.013\n",
      "Current Monte-Carlo Step: 0.014\n",
      "Current Monte-Carlo Step: 0.015\n",
      "Current Monte-Carlo Step: 0.016\n",
      "Current Monte-Carlo Step: 0.017\n",
      "Current Monte-Carlo Step: 0.018\n",
      "Current Monte-Carlo Step: 0.019\n",
      "Current Monte-Carlo Step: 0.02\n",
      "Current Monte-Carlo Step: 0.021\n",
      "Current Monte-Carlo Step: 0.022\n",
      "Current Monte-Carlo Step: 0.023\n",
      "Current Monte-Carlo Step: 0.024\n",
      "Current Monte-Carlo Step: 0.025\n",
      "Current Monte-Carlo Step: 0.026\n",
      "Current Monte-Carlo Step: 0.027\n",
      "Current Monte-Carlo Step: 0.028\n",
      "Current Monte-Carlo Step: 0.029\n",
      "Current Monte-Carlo Step: 0.03\n",
      "Current Monte-Carlo Step: 0.031\n",
      "Current Monte-Carlo Step: 0.032\n",
      "Current Monte-Carlo Step: 0.033\n",
      "Current Monte-Carlo Step: 0.034\n",
      "Current Monte-Carlo Step: 0.035\n",
      "Current Monte-Carlo Step: 0.036\n",
      "Current Monte-Carlo Step: 0.037\n",
      "Current Monte-Carlo Step: 0.038\n",
      "Current Monte-Carlo Step: 0.039\n",
      "Current Monte-Carlo Step: 0.04\n",
      "Current Monte-Carlo Step: 0.041\n",
      "Current Monte-Carlo Step: 0.042\n",
      "Current Monte-Carlo Step: 0.043\n",
      "Current Monte-Carlo Step: 0.044\n",
      "Current Monte-Carlo Step: 0.045\n",
      "Current Monte-Carlo Step: 0.046\n",
      "Current Monte-Carlo Step: 0.047\n",
      "Current Monte-Carlo Step: 0.048\n",
      "Current Monte-Carlo Step: 0.049\n",
      "Current Monte-Carlo Step: 0.05\n",
      "Current Monte-Carlo Step: 0.051\n",
      "Current Monte-Carlo Step: 0.052\n",
      "Current Monte-Carlo Step: 0.053\n",
      "Current Monte-Carlo Step: 0.054\n",
      "Current Monte-Carlo Step: 0.055\n",
      "Current Monte-Carlo Step: 0.056\n",
      "Current Monte-Carlo Step: 0.057\n",
      "Current Monte-Carlo Step: 0.058\n",
      "Current Monte-Carlo Step: 0.059\n",
      "Current Monte-Carlo Step: 0.06\n",
      "Current Monte-Carlo Step: 0.061\n",
      "Current Monte-Carlo Step: 0.062\n",
      "Current Monte-Carlo Step: 0.063\n",
      "Current Monte-Carlo Step: 0.064\n",
      "Current Monte-Carlo Step: 0.065\n",
      "Current Monte-Carlo Step: 0.066\n",
      "Current Monte-Carlo Step: 0.067\n",
      "Current Monte-Carlo Step: 0.068\n",
      "Current Monte-Carlo Step: 0.069\n",
      "Current Monte-Carlo Step: 0.07\n",
      "Current Monte-Carlo Step: 0.071\n",
      "Current Monte-Carlo Step: 0.072\n",
      "Current Monte-Carlo Step: 0.073\n",
      "Current Monte-Carlo Step: 0.074\n",
      "Current Monte-Carlo Step: 0.075\n",
      "Current Monte-Carlo Step: 0.076\n",
      "Current Monte-Carlo Step: 0.077\n",
      "Current Monte-Carlo Step: 0.078\n",
      "Current Monte-Carlo Step: 0.079\n",
      "Current Monte-Carlo Step: 0.08\n",
      "Current Monte-Carlo Step: 0.081\n",
      "Current Monte-Carlo Step: 0.082\n",
      "Current Monte-Carlo Step: 0.083\n",
      "Current Monte-Carlo Step: 0.084\n",
      "Current Monte-Carlo Step: 0.085\n",
      "Current Monte-Carlo Step: 0.086\n",
      "Current Monte-Carlo Step: 0.087\n",
      "Current Monte-Carlo Step: 0.088\n",
      "Current Monte-Carlo Step: 0.089\n",
      "Current Monte-Carlo Step: 0.09\n",
      "Current Monte-Carlo Step: 0.091\n",
      "Current Monte-Carlo Step: 0.092\n",
      "Current Monte-Carlo Step: 0.093\n",
      "Current Monte-Carlo Step: 0.094\n",
      "Current Monte-Carlo Step: 0.095\n",
      "Current Monte-Carlo Step: 0.096\n",
      "Current Monte-Carlo Step: 0.097\n",
      "Current Monte-Carlo Step: 0.098\n",
      "Current Monte-Carlo Step: 0.099\n",
      "Current Monte-Carlo Step: 0.1\n",
      "Current Monte-Carlo Step: 0.101\n",
      "Current Monte-Carlo Step: 0.102\n",
      "Current Monte-Carlo Step: 0.103\n",
      "Current Monte-Carlo Step: 0.104\n",
      "Current Monte-Carlo Step: 0.105\n",
      "Current Monte-Carlo Step: 0.106\n",
      "Current Monte-Carlo Step: 0.107\n",
      "Current Monte-Carlo Step: 0.108\n",
      "Current Monte-Carlo Step: 0.109\n",
      "Current Monte-Carlo Step: 0.11\n",
      "Current Monte-Carlo Step: 0.111\n",
      "Current Monte-Carlo Step: 0.112\n",
      "Current Monte-Carlo Step: 0.113\n",
      "Current Monte-Carlo Step: 0.114\n",
      "Current Monte-Carlo Step: 0.115\n",
      "Current Monte-Carlo Step: 0.116\n",
      "Current Monte-Carlo Step: 0.117\n",
      "Current Monte-Carlo Step: 0.118\n",
      "Current Monte-Carlo Step: 0.119\n",
      "Current Monte-Carlo Step: 0.12\n",
      "Current Monte-Carlo Step: 0.121\n",
      "Current Monte-Carlo Step: 0.122\n",
      "Current Monte-Carlo Step: 0.123\n",
      "Current Monte-Carlo Step: 0.124\n",
      "Current Monte-Carlo Step: 0.125\n",
      "Current Monte-Carlo Step: 0.126\n",
      "Current Monte-Carlo Step: 0.127\n",
      "Current Monte-Carlo Step: 0.128\n",
      "Current Monte-Carlo Step: 0.129\n",
      "Current Monte-Carlo Step: 0.13\n",
      "Current Monte-Carlo Step: 0.131\n",
      "Current Monte-Carlo Step: 0.132\n",
      "Current Monte-Carlo Step: 0.133\n",
      "Current Monte-Carlo Step: 0.134\n",
      "Current Monte-Carlo Step: 0.135\n",
      "Current Monte-Carlo Step: 0.136\n",
      "Current Monte-Carlo Step: 0.137\n",
      "Current Monte-Carlo Step: 0.138\n",
      "Current Monte-Carlo Step: 0.139\n",
      "Current Monte-Carlo Step: 0.14\n",
      "Current Monte-Carlo Step: 0.141\n",
      "Current Monte-Carlo Step: 0.142\n",
      "Current Monte-Carlo Step: 0.143\n",
      "Current Monte-Carlo Step: 0.144\n",
      "Current Monte-Carlo Step: 0.145\n",
      "Current Monte-Carlo Step: 0.146\n",
      "Current Monte-Carlo Step: 0.147\n",
      "Current Monte-Carlo Step: 0.148\n",
      "Current Monte-Carlo Step: 0.149\n",
      "Current Monte-Carlo Step: 0.15\n",
      "Current Monte-Carlo Step: 0.151\n",
      "Current Monte-Carlo Step: 0.152\n",
      "Current Monte-Carlo Step: 0.153\n",
      "Current Monte-Carlo Step: 0.154\n",
      "Current Monte-Carlo Step: 0.155\n",
      "Current Monte-Carlo Step: 0.156\n",
      "Current Monte-Carlo Step: 0.157\n",
      "Current Monte-Carlo Step: 0.158\n",
      "Current Monte-Carlo Step: 0.159\n",
      "Current Monte-Carlo Step: 0.16\n",
      "Current Monte-Carlo Step: 0.161\n",
      "Current Monte-Carlo Step: 0.162\n",
      "Current Monte-Carlo Step: 0.163\n",
      "Current Monte-Carlo Step: 0.164\n",
      "Current Monte-Carlo Step: 0.165\n",
      "Current Monte-Carlo Step: 0.166\n",
      "Current Monte-Carlo Step: 0.167\n",
      "Current Monte-Carlo Step: 0.168\n",
      "Current Monte-Carlo Step: 0.169\n",
      "Current Monte-Carlo Step: 0.17\n",
      "Current Monte-Carlo Step: 0.171\n",
      "Current Monte-Carlo Step: 0.172\n",
      "Current Monte-Carlo Step: 0.173\n",
      "Current Monte-Carlo Step: 0.174\n",
      "Current Monte-Carlo Step: 0.175\n",
      "Current Monte-Carlo Step: 0.176\n",
      "Current Monte-Carlo Step: 0.177\n",
      "Current Monte-Carlo Step: 0.178\n",
      "Current Monte-Carlo Step: 0.179\n",
      "Current Monte-Carlo Step: 0.18\n",
      "Current Monte-Carlo Step: 0.181\n",
      "Current Monte-Carlo Step: 0.182\n",
      "Current Monte-Carlo Step: 0.183\n",
      "Current Monte-Carlo Step: 0.184\n",
      "Current Monte-Carlo Step: 0.185\n",
      "Current Monte-Carlo Step: 0.186\n",
      "Current Monte-Carlo Step: 0.187\n",
      "Current Monte-Carlo Step: 0.188\n",
      "Current Monte-Carlo Step: 0.189\n",
      "Current Monte-Carlo Step: 0.19\n",
      "Current Monte-Carlo Step: 0.191\n",
      "Current Monte-Carlo Step: 0.192\n",
      "Current Monte-Carlo Step: 0.193\n",
      "Current Monte-Carlo Step: 0.194\n",
      "Current Monte-Carlo Step: 0.195\n",
      "Current Monte-Carlo Step: 0.196\n",
      "Current Monte-Carlo Step: 0.197\n",
      "Current Monte-Carlo Step: 0.198\n",
      "Current Monte-Carlo Step: 0.199\n",
      "Current Monte-Carlo Step: 0.2\n",
      "Current Monte-Carlo Step: 0.201\n",
      "Current Monte-Carlo Step: 0.202\n",
      "Current Monte-Carlo Step: 0.203\n",
      "Current Monte-Carlo Step: 0.204\n",
      "Current Monte-Carlo Step: 0.205\n",
      "Current Monte-Carlo Step: 0.206\n",
      "Current Monte-Carlo Step: 0.207\n",
      "Current Monte-Carlo Step: 0.208\n",
      "Current Monte-Carlo Step: 0.209\n",
      "Current Monte-Carlo Step: 0.21\n",
      "Current Monte-Carlo Step: 0.211\n",
      "Current Monte-Carlo Step: 0.212\n",
      "Current Monte-Carlo Step: 0.213\n",
      "Current Monte-Carlo Step: 0.214\n",
      "Current Monte-Carlo Step: 0.215\n",
      "Current Monte-Carlo Step: 0.216\n",
      "Current Monte-Carlo Step: 0.217\n",
      "Current Monte-Carlo Step: 0.218\n",
      "Current Monte-Carlo Step: 0.219\n",
      "Current Monte-Carlo Step: 0.22\n",
      "Current Monte-Carlo Step: 0.221\n",
      "Current Monte-Carlo Step: 0.222\n",
      "Current Monte-Carlo Step: 0.223\n",
      "Current Monte-Carlo Step: 0.224\n",
      "Current Monte-Carlo Step: 0.225\n",
      "Current Monte-Carlo Step: 0.226\n",
      "Current Monte-Carlo Step: 0.227\n",
      "Current Monte-Carlo Step: 0.228\n",
      "Current Monte-Carlo Step: 0.229\n",
      "Current Monte-Carlo Step: 0.23\n",
      "Current Monte-Carlo Step: 0.231\n",
      "Current Monte-Carlo Step: 0.232\n",
      "Current Monte-Carlo Step: 0.233\n",
      "Current Monte-Carlo Step: 0.234\n",
      "Current Monte-Carlo Step: 0.235\n",
      "Current Monte-Carlo Step: 0.236\n",
      "Current Monte-Carlo Step: 0.237\n",
      "Current Monte-Carlo Step: 0.238\n",
      "Current Monte-Carlo Step: 0.239\n",
      "Current Monte-Carlo Step: 0.24\n",
      "Current Monte-Carlo Step: 0.241\n",
      "Current Monte-Carlo Step: 0.242\n",
      "Current Monte-Carlo Step: 0.243\n",
      "Current Monte-Carlo Step: 0.244\n",
      "Current Monte-Carlo Step: 0.245\n",
      "Current Monte-Carlo Step: 0.246\n",
      "Current Monte-Carlo Step: 0.247\n",
      "Current Monte-Carlo Step: 0.248\n",
      "Current Monte-Carlo Step: 0.249\n",
      "Current Monte-Carlo Step: 0.25\n",
      "Current Monte-Carlo Step: 0.251\n",
      "Current Monte-Carlo Step: 0.252\n",
      "Current Monte-Carlo Step: 0.253\n",
      "Current Monte-Carlo Step: 0.254\n",
      "Current Monte-Carlo Step: 0.255\n",
      "Current Monte-Carlo Step: 0.256\n",
      "Current Monte-Carlo Step: 0.257\n",
      "Current Monte-Carlo Step: 0.258\n",
      "Current Monte-Carlo Step: 0.259\n",
      "Current Monte-Carlo Step: 0.26\n",
      "Current Monte-Carlo Step: 0.261\n",
      "Current Monte-Carlo Step: 0.262\n",
      "Current Monte-Carlo Step: 0.263\n",
      "Current Monte-Carlo Step: 0.264\n",
      "Current Monte-Carlo Step: 0.265\n",
      "Current Monte-Carlo Step: 0.266\n",
      "Current Monte-Carlo Step: 0.267\n",
      "Current Monte-Carlo Step: 0.268\n",
      "Current Monte-Carlo Step: 0.269\n",
      "Current Monte-Carlo Step: 0.27\n",
      "Current Monte-Carlo Step: 0.271\n",
      "Current Monte-Carlo Step: 0.272\n",
      "Current Monte-Carlo Step: 0.273\n",
      "Current Monte-Carlo Step: 0.274\n",
      "Current Monte-Carlo Step: 0.275\n",
      "Current Monte-Carlo Step: 0.276\n",
      "Current Monte-Carlo Step: 0.277\n",
      "Current Monte-Carlo Step: 0.278\n",
      "Current Monte-Carlo Step: 0.279\n",
      "Current Monte-Carlo Step: 0.28\n",
      "Current Monte-Carlo Step: 0.281\n",
      "Current Monte-Carlo Step: 0.282\n",
      "Current Monte-Carlo Step: 0.283\n",
      "Current Monte-Carlo Step: 0.284\n",
      "Current Monte-Carlo Step: 0.285\n",
      "Current Monte-Carlo Step: 0.286\n",
      "Current Monte-Carlo Step: 0.287\n",
      "Current Monte-Carlo Step: 0.288\n",
      "Current Monte-Carlo Step: 0.289\n",
      "Current Monte-Carlo Step: 0.29\n",
      "Current Monte-Carlo Step: 0.291\n",
      "Current Monte-Carlo Step: 0.292\n",
      "Current Monte-Carlo Step: 0.293\n",
      "Current Monte-Carlo Step: 0.294\n",
      "Current Monte-Carlo Step: 0.295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step: 0.296\n",
      "Current Monte-Carlo Step: 0.297\n",
      "Current Monte-Carlo Step: 0.298\n",
      "Current Monte-Carlo Step: 0.299\n",
      "Current Monte-Carlo Step: 0.3\n",
      "Current Monte-Carlo Step: 0.301\n",
      "Current Monte-Carlo Step: 0.302\n",
      "Current Monte-Carlo Step: 0.303\n",
      "Current Monte-Carlo Step: 0.304\n",
      "Current Monte-Carlo Step: 0.305\n",
      "Current Monte-Carlo Step: 0.306\n",
      "Current Monte-Carlo Step: 0.307\n",
      "Current Monte-Carlo Step: 0.308\n",
      "Current Monte-Carlo Step: 0.309\n",
      "Current Monte-Carlo Step: 0.31\n",
      "Current Monte-Carlo Step: 0.311\n",
      "Current Monte-Carlo Step: 0.312\n",
      "Current Monte-Carlo Step: 0.313\n",
      "Current Monte-Carlo Step: 0.314\n",
      "Current Monte-Carlo Step: 0.315\n",
      "Current Monte-Carlo Step: 0.316\n",
      "Current Monte-Carlo Step: 0.317\n",
      "Current Monte-Carlo Step: 0.318\n",
      "Current Monte-Carlo Step: 0.319\n",
      "Current Monte-Carlo Step: 0.32\n",
      "Current Monte-Carlo Step: 0.321\n",
      "Current Monte-Carlo Step: 0.322\n",
      "Current Monte-Carlo Step: 0.323\n",
      "Current Monte-Carlo Step: 0.324\n",
      "Current Monte-Carlo Step: 0.325\n",
      "Current Monte-Carlo Step: 0.326\n",
      "Current Monte-Carlo Step: 0.327\n",
      "Current Monte-Carlo Step: 0.328\n",
      "Current Monte-Carlo Step: 0.329\n",
      "Current Monte-Carlo Step: 0.33\n",
      "Current Monte-Carlo Step: 0.331\n",
      "Current Monte-Carlo Step: 0.332\n",
      "Current Monte-Carlo Step: 0.333\n",
      "Current Monte-Carlo Step: 0.334\n",
      "Current Monte-Carlo Step: 0.335\n",
      "Current Monte-Carlo Step: 0.336\n",
      "Current Monte-Carlo Step: 0.337\n",
      "Current Monte-Carlo Step: 0.338\n",
      "Current Monte-Carlo Step: 0.339\n",
      "Current Monte-Carlo Step: 0.34\n",
      "Current Monte-Carlo Step: 0.341\n",
      "Current Monte-Carlo Step: 0.342\n",
      "Current Monte-Carlo Step: 0.343\n",
      "Current Monte-Carlo Step: 0.344\n",
      "Current Monte-Carlo Step: 0.345\n",
      "Current Monte-Carlo Step: 0.346\n",
      "Current Monte-Carlo Step: 0.347\n",
      "Current Monte-Carlo Step: 0.348\n",
      "Current Monte-Carlo Step: 0.349\n",
      "Current Monte-Carlo Step: 0.35\n",
      "Current Monte-Carlo Step: 0.351\n",
      "Current Monte-Carlo Step: 0.352\n",
      "Current Monte-Carlo Step: 0.353\n",
      "Current Monte-Carlo Step: 0.354\n",
      "Current Monte-Carlo Step: 0.355\n",
      "Current Monte-Carlo Step: 0.356\n",
      "Current Monte-Carlo Step: 0.357\n",
      "Current Monte-Carlo Step: 0.358\n",
      "Current Monte-Carlo Step: 0.359\n",
      "Current Monte-Carlo Step: 0.36\n",
      "Current Monte-Carlo Step: 0.361\n",
      "Current Monte-Carlo Step: 0.362\n",
      "Current Monte-Carlo Step: 0.363\n",
      "Current Monte-Carlo Step: 0.364\n",
      "Current Monte-Carlo Step: 0.365\n",
      "Current Monte-Carlo Step: 0.366\n",
      "Current Monte-Carlo Step: 0.367\n",
      "Current Monte-Carlo Step: 0.368\n",
      "Current Monte-Carlo Step: 0.369\n",
      "Current Monte-Carlo Step: 0.37\n",
      "Current Monte-Carlo Step: 0.371\n",
      "Current Monte-Carlo Step: 0.372\n",
      "Current Monte-Carlo Step: 0.373\n",
      "Current Monte-Carlo Step: 0.374\n",
      "Current Monte-Carlo Step: 0.375\n",
      "Current Monte-Carlo Step: 0.376\n",
      "Current Monte-Carlo Step: 0.377\n",
      "Current Monte-Carlo Step: 0.378\n",
      "Current Monte-Carlo Step: 0.379\n",
      "Current Monte-Carlo Step: 0.38\n",
      "Current Monte-Carlo Step: 0.381\n",
      "Current Monte-Carlo Step: 0.382\n",
      "Current Monte-Carlo Step: 0.383\n",
      "Current Monte-Carlo Step: 0.384\n",
      "Current Monte-Carlo Step: 0.385\n",
      "Current Monte-Carlo Step: 0.386\n",
      "Current Monte-Carlo Step: 0.387\n",
      "Current Monte-Carlo Step: 0.388\n",
      "Current Monte-Carlo Step: 0.389\n",
      "Current Monte-Carlo Step: 0.39\n",
      "Current Monte-Carlo Step: 0.391\n",
      "Current Monte-Carlo Step: 0.392\n",
      "Current Monte-Carlo Step: 0.393\n",
      "Current Monte-Carlo Step: 0.394\n",
      "Current Monte-Carlo Step: 0.395\n",
      "Current Monte-Carlo Step: 0.396\n",
      "Current Monte-Carlo Step: 0.397\n",
      "Current Monte-Carlo Step: 0.398\n",
      "Current Monte-Carlo Step: 0.399\n",
      "Current Monte-Carlo Step: 0.4\n",
      "Current Monte-Carlo Step: 0.401\n",
      "Current Monte-Carlo Step: 0.402\n",
      "Current Monte-Carlo Step: 0.403\n",
      "Current Monte-Carlo Step: 0.404\n",
      "Current Monte-Carlo Step: 0.405\n",
      "Current Monte-Carlo Step: 0.406\n",
      "Current Monte-Carlo Step: 0.407\n",
      "Current Monte-Carlo Step: 0.408\n",
      "Current Monte-Carlo Step: 0.409\n",
      "Current Monte-Carlo Step: 0.41\n",
      "Current Monte-Carlo Step: 0.411\n",
      "Current Monte-Carlo Step: 0.412\n",
      "Current Monte-Carlo Step: 0.413\n",
      "Current Monte-Carlo Step: 0.414\n",
      "Current Monte-Carlo Step: 0.415\n",
      "Current Monte-Carlo Step: 0.416\n",
      "Current Monte-Carlo Step: 0.417\n",
      "Current Monte-Carlo Step: 0.418\n",
      "Current Monte-Carlo Step: 0.419\n",
      "Current Monte-Carlo Step: 0.42\n",
      "Current Monte-Carlo Step: 0.421\n",
      "Current Monte-Carlo Step: 0.422\n",
      "Current Monte-Carlo Step: 0.423\n",
      "Current Monte-Carlo Step: 0.424\n",
      "Current Monte-Carlo Step: 0.425\n",
      "Current Monte-Carlo Step: 0.426\n",
      "Current Monte-Carlo Step: 0.427\n",
      "Current Monte-Carlo Step: 0.428\n",
      "Current Monte-Carlo Step: 0.429\n",
      "Current Monte-Carlo Step: 0.43\n",
      "Current Monte-Carlo Step: 0.431\n",
      "Current Monte-Carlo Step: 0.432\n",
      "Current Monte-Carlo Step: 0.433\n",
      "Current Monte-Carlo Step: 0.434\n",
      "Current Monte-Carlo Step: 0.435\n",
      "Current Monte-Carlo Step: 0.436\n",
      "Current Monte-Carlo Step: 0.437\n",
      "Current Monte-Carlo Step: 0.438\n",
      "Current Monte-Carlo Step: 0.439\n",
      "Current Monte-Carlo Step: 0.44\n",
      "Current Monte-Carlo Step: 0.441\n",
      "Current Monte-Carlo Step: 0.442\n",
      "Current Monte-Carlo Step: 0.443\n",
      "Current Monte-Carlo Step: 0.444\n",
      "Current Monte-Carlo Step: 0.445\n",
      "Current Monte-Carlo Step: 0.446\n",
      "Current Monte-Carlo Step: 0.447\n",
      "Current Monte-Carlo Step: 0.448\n",
      "Current Monte-Carlo Step: 0.449\n",
      "Current Monte-Carlo Step: 0.45\n",
      "Current Monte-Carlo Step: 0.451\n",
      "Current Monte-Carlo Step: 0.452\n",
      "Current Monte-Carlo Step: 0.453\n",
      "Current Monte-Carlo Step: 0.454\n",
      "Current Monte-Carlo Step: 0.455\n",
      "Current Monte-Carlo Step: 0.456\n",
      "Current Monte-Carlo Step: 0.457\n",
      "Current Monte-Carlo Step: 0.458\n",
      "Current Monte-Carlo Step: 0.459\n",
      "Current Monte-Carlo Step: 0.46\n",
      "Current Monte-Carlo Step: 0.461\n",
      "Current Monte-Carlo Step: 0.462\n",
      "Current Monte-Carlo Step: 0.463\n",
      "Current Monte-Carlo Step: 0.464\n",
      "Current Monte-Carlo Step: 0.465\n",
      "Current Monte-Carlo Step: 0.466\n",
      "Current Monte-Carlo Step: 0.467\n",
      "Current Monte-Carlo Step: 0.468\n",
      "Current Monte-Carlo Step: 0.469\n",
      "Current Monte-Carlo Step: 0.47\n",
      "Current Monte-Carlo Step: 0.471\n",
      "Current Monte-Carlo Step: 0.472\n",
      "Current Monte-Carlo Step: 0.473\n",
      "Current Monte-Carlo Step: 0.474\n",
      "Current Monte-Carlo Step: 0.475\n",
      "Current Monte-Carlo Step: 0.476\n",
      "Current Monte-Carlo Step: 0.477\n",
      "Current Monte-Carlo Step: 0.478\n",
      "Current Monte-Carlo Step: 0.479\n",
      "Current Monte-Carlo Step: 0.48\n",
      "Current Monte-Carlo Step: 0.481\n",
      "Current Monte-Carlo Step: 0.482\n",
      "Current Monte-Carlo Step: 0.483\n",
      "Current Monte-Carlo Step: 0.484\n",
      "Current Monte-Carlo Step: 0.485\n",
      "Current Monte-Carlo Step: 0.486\n",
      "Current Monte-Carlo Step: 0.487\n",
      "Current Monte-Carlo Step: 0.488\n",
      "Current Monte-Carlo Step: 0.489\n",
      "Current Monte-Carlo Step: 0.49\n",
      "Current Monte-Carlo Step: 0.491\n",
      "Current Monte-Carlo Step: 0.492\n",
      "Current Monte-Carlo Step: 0.493\n",
      "Current Monte-Carlo Step: 0.494\n",
      "Current Monte-Carlo Step: 0.495\n",
      "Current Monte-Carlo Step: 0.496\n",
      "Current Monte-Carlo Step: 0.497\n",
      "Current Monte-Carlo Step: 0.498\n",
      "Current Monte-Carlo Step: 0.499\n",
      "Current Monte-Carlo Step: 0.5\n",
      "Current Monte-Carlo Step: 0.501\n",
      "Current Monte-Carlo Step: 0.502\n",
      "Current Monte-Carlo Step: 0.503\n",
      "Current Monte-Carlo Step: 0.504\n",
      "Current Monte-Carlo Step: 0.505\n",
      "Current Monte-Carlo Step: 0.506\n",
      "Current Monte-Carlo Step: 0.507\n",
      "Current Monte-Carlo Step: 0.508\n",
      "Current Monte-Carlo Step: 0.509\n",
      "Current Monte-Carlo Step: 0.51\n",
      "Current Monte-Carlo Step: 0.511\n",
      "Current Monte-Carlo Step: 0.512\n",
      "Current Monte-Carlo Step: 0.513\n",
      "Current Monte-Carlo Step: 0.514\n",
      "Current Monte-Carlo Step: 0.515\n",
      "Current Monte-Carlo Step: 0.516\n",
      "Current Monte-Carlo Step: 0.517\n",
      "Current Monte-Carlo Step: 0.518\n",
      "Current Monte-Carlo Step: 0.519\n",
      "Current Monte-Carlo Step: 0.52\n",
      "Current Monte-Carlo Step: 0.521\n",
      "Current Monte-Carlo Step: 0.522\n",
      "Current Monte-Carlo Step: 0.523\n",
      "Current Monte-Carlo Step: 0.524\n",
      "Current Monte-Carlo Step: 0.525\n",
      "Current Monte-Carlo Step: 0.526\n",
      "Current Monte-Carlo Step: 0.527\n",
      "Current Monte-Carlo Step: 0.528\n",
      "Current Monte-Carlo Step: 0.529\n",
      "Current Monte-Carlo Step: 0.53\n",
      "Current Monte-Carlo Step: 0.531\n",
      "Current Monte-Carlo Step: 0.532\n",
      "Current Monte-Carlo Step: 0.533\n",
      "Current Monte-Carlo Step: 0.534\n",
      "Current Monte-Carlo Step: 0.535\n",
      "Current Monte-Carlo Step: 0.536\n",
      "Current Monte-Carlo Step: 0.537\n",
      "Current Monte-Carlo Step: 0.538\n",
      "Current Monte-Carlo Step: 0.539\n",
      "Current Monte-Carlo Step: 0.54\n",
      "Current Monte-Carlo Step: 0.541\n",
      "Current Monte-Carlo Step: 0.542\n",
      "Current Monte-Carlo Step: 0.543\n",
      "Current Monte-Carlo Step: 0.544\n",
      "Current Monte-Carlo Step: 0.545\n",
      "Current Monte-Carlo Step: 0.546\n",
      "Current Monte-Carlo Step: 0.547\n",
      "Current Monte-Carlo Step: 0.548\n",
      "Current Monte-Carlo Step: 0.549\n",
      "Current Monte-Carlo Step: 0.55\n",
      "Current Monte-Carlo Step: 0.551\n",
      "Current Monte-Carlo Step: 0.552\n",
      "Current Monte-Carlo Step: 0.553\n",
      "Current Monte-Carlo Step: 0.554\n",
      "Current Monte-Carlo Step: 0.555\n",
      "Current Monte-Carlo Step: 0.556\n",
      "Current Monte-Carlo Step: 0.557\n",
      "Current Monte-Carlo Step: 0.558\n",
      "Current Monte-Carlo Step: 0.559\n",
      "Current Monte-Carlo Step: 0.56\n",
      "Current Monte-Carlo Step: 0.561\n",
      "Current Monte-Carlo Step: 0.562\n",
      "Current Monte-Carlo Step: 0.563\n",
      "Current Monte-Carlo Step: 0.564\n",
      "Current Monte-Carlo Step: 0.565\n",
      "Current Monte-Carlo Step: 0.566\n",
      "Current Monte-Carlo Step: 0.567\n",
      "Current Monte-Carlo Step: 0.568\n",
      "Current Monte-Carlo Step: 0.569\n",
      "Current Monte-Carlo Step: 0.57\n",
      "Current Monte-Carlo Step: 0.571\n",
      "Current Monte-Carlo Step: 0.572\n",
      "Current Monte-Carlo Step: 0.573\n",
      "Current Monte-Carlo Step: 0.574\n",
      "Current Monte-Carlo Step: 0.575\n",
      "Current Monte-Carlo Step: 0.576\n",
      "Current Monte-Carlo Step: 0.577\n",
      "Current Monte-Carlo Step: 0.578\n",
      "Current Monte-Carlo Step: 0.579\n",
      "Current Monte-Carlo Step: 0.58\n",
      "Current Monte-Carlo Step: 0.581\n",
      "Current Monte-Carlo Step: 0.582\n",
      "Current Monte-Carlo Step: 0.583\n",
      "Current Monte-Carlo Step: 0.584\n",
      "Current Monte-Carlo Step: 0.585\n",
      "Current Monte-Carlo Step: 0.586\n",
      "Current Monte-Carlo Step: 0.587\n",
      "Current Monte-Carlo Step: 0.588\n",
      "Current Monte-Carlo Step: 0.589\n",
      "Current Monte-Carlo Step: 0.59\n",
      "Current Monte-Carlo Step: 0.591\n",
      "Current Monte-Carlo Step: 0.592\n",
      "Current Monte-Carlo Step: 0.593\n",
      "Current Monte-Carlo Step: 0.594\n",
      "Current Monte-Carlo Step: 0.595\n",
      "Current Monte-Carlo Step: 0.596\n",
      "Current Monte-Carlo Step: 0.597\n",
      "Current Monte-Carlo Step: 0.598\n",
      "Current Monte-Carlo Step: 0.599\n",
      "Current Monte-Carlo Step: 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step: 0.601\n",
      "Current Monte-Carlo Step: 0.602\n",
      "Current Monte-Carlo Step: 0.603\n",
      "Current Monte-Carlo Step: 0.604\n",
      "Current Monte-Carlo Step: 0.605\n",
      "Current Monte-Carlo Step: 0.606\n",
      "Current Monte-Carlo Step: 0.607\n",
      "Current Monte-Carlo Step: 0.608\n",
      "Current Monte-Carlo Step: 0.609\n",
      "Current Monte-Carlo Step: 0.61\n",
      "Current Monte-Carlo Step: 0.611\n",
      "Current Monte-Carlo Step: 0.612\n",
      "Current Monte-Carlo Step: 0.613\n",
      "Current Monte-Carlo Step: 0.614\n",
      "Current Monte-Carlo Step: 0.615\n",
      "Current Monte-Carlo Step: 0.616\n",
      "Current Monte-Carlo Step: 0.617\n",
      "Current Monte-Carlo Step: 0.618\n",
      "Current Monte-Carlo Step: 0.619\n",
      "Current Monte-Carlo Step: 0.62\n",
      "Current Monte-Carlo Step: 0.621\n",
      "Current Monte-Carlo Step: 0.622\n",
      "Current Monte-Carlo Step: 0.623\n",
      "Current Monte-Carlo Step: 0.624\n",
      "Current Monte-Carlo Step: 0.625\n",
      "Current Monte-Carlo Step: 0.626\n",
      "Current Monte-Carlo Step: 0.627\n",
      "Current Monte-Carlo Step: 0.628\n",
      "Current Monte-Carlo Step: 0.629\n",
      "Current Monte-Carlo Step: 0.63\n",
      "Current Monte-Carlo Step: 0.631\n",
      "Current Monte-Carlo Step: 0.632\n",
      "Current Monte-Carlo Step: 0.633\n",
      "Current Monte-Carlo Step: 0.634\n",
      "Current Monte-Carlo Step: 0.635\n",
      "Current Monte-Carlo Step: 0.636\n",
      "Current Monte-Carlo Step: 0.637\n",
      "Current Monte-Carlo Step: 0.638\n",
      "Current Monte-Carlo Step: 0.639\n",
      "Current Monte-Carlo Step: 0.64\n",
      "Current Monte-Carlo Step: 0.641\n",
      "Current Monte-Carlo Step: 0.642\n",
      "Current Monte-Carlo Step: 0.643\n",
      "Current Monte-Carlo Step: 0.644\n",
      "Current Monte-Carlo Step: 0.645\n",
      "Current Monte-Carlo Step: 0.646\n",
      "Current Monte-Carlo Step: 0.647\n",
      "Current Monte-Carlo Step: 0.648\n",
      "Current Monte-Carlo Step: 0.649\n",
      "Current Monte-Carlo Step: 0.65\n",
      "Current Monte-Carlo Step: 0.651\n",
      "Current Monte-Carlo Step: 0.652\n",
      "Current Monte-Carlo Step: 0.653\n",
      "Current Monte-Carlo Step: 0.654\n",
      "Current Monte-Carlo Step: 0.655\n",
      "Current Monte-Carlo Step: 0.656\n",
      "Current Monte-Carlo Step: 0.657\n",
      "Current Monte-Carlo Step: 0.658\n",
      "Current Monte-Carlo Step: 0.659\n",
      "Current Monte-Carlo Step: 0.66\n",
      "Current Monte-Carlo Step: 0.661\n",
      "Current Monte-Carlo Step: 0.662\n",
      "Current Monte-Carlo Step: 0.663\n",
      "Current Monte-Carlo Step: 0.664\n",
      "Current Monte-Carlo Step: 0.665\n",
      "Current Monte-Carlo Step: 0.666\n",
      "Current Monte-Carlo Step: 0.667\n",
      "Current Monte-Carlo Step: 0.668\n",
      "Current Monte-Carlo Step: 0.669\n",
      "Current Monte-Carlo Step: 0.67\n",
      "Current Monte-Carlo Step: 0.671\n",
      "Current Monte-Carlo Step: 0.672\n",
      "Current Monte-Carlo Step: 0.673\n",
      "Current Monte-Carlo Step: 0.674\n",
      "Current Monte-Carlo Step: 0.675\n",
      "Current Monte-Carlo Step: 0.676\n",
      "Current Monte-Carlo Step: 0.677\n",
      "Current Monte-Carlo Step: 0.678\n",
      "Current Monte-Carlo Step: 0.679\n",
      "Current Monte-Carlo Step: 0.68\n",
      "Current Monte-Carlo Step: 0.681\n",
      "Current Monte-Carlo Step: 0.682\n",
      "Current Monte-Carlo Step: 0.683\n",
      "Current Monte-Carlo Step: 0.684\n",
      "Current Monte-Carlo Step: 0.685\n",
      "Current Monte-Carlo Step: 0.686\n",
      "Current Monte-Carlo Step: 0.687\n",
      "Current Monte-Carlo Step: 0.688\n",
      "Current Monte-Carlo Step: 0.689\n",
      "Current Monte-Carlo Step: 0.69\n",
      "Current Monte-Carlo Step: 0.691\n",
      "Current Monte-Carlo Step: 0.692\n",
      "Current Monte-Carlo Step: 0.693\n",
      "Current Monte-Carlo Step: 0.694\n",
      "Current Monte-Carlo Step: 0.695\n",
      "Current Monte-Carlo Step: 0.696\n",
      "Current Monte-Carlo Step: 0.697\n",
      "Current Monte-Carlo Step: 0.698\n",
      "Current Monte-Carlo Step: 0.699\n",
      "Current Monte-Carlo Step: 0.7\n",
      "Current Monte-Carlo Step: 0.701\n",
      "Current Monte-Carlo Step: 0.702\n",
      "Current Monte-Carlo Step: 0.703\n",
      "Current Monte-Carlo Step: 0.704\n",
      "Current Monte-Carlo Step: 0.705\n",
      "Current Monte-Carlo Step: 0.706\n",
      "Current Monte-Carlo Step: 0.707\n",
      "Current Monte-Carlo Step: 0.708\n",
      "Current Monte-Carlo Step: 0.709\n",
      "Current Monte-Carlo Step: 0.71\n",
      "Current Monte-Carlo Step: 0.711\n",
      "Current Monte-Carlo Step: 0.712\n",
      "Current Monte-Carlo Step: 0.713\n",
      "Current Monte-Carlo Step: 0.714\n",
      "Current Monte-Carlo Step: 0.715\n",
      "Current Monte-Carlo Step: 0.716\n",
      "Current Monte-Carlo Step: 0.717\n",
      "Current Monte-Carlo Step: 0.718\n",
      "Current Monte-Carlo Step: 0.719\n",
      "Current Monte-Carlo Step: 0.72\n",
      "Current Monte-Carlo Step: 0.721\n",
      "Current Monte-Carlo Step: 0.722\n",
      "Current Monte-Carlo Step: 0.723\n",
      "Current Monte-Carlo Step: 0.724\n",
      "Current Monte-Carlo Step: 0.725\n",
      "Current Monte-Carlo Step: 0.726\n",
      "Current Monte-Carlo Step: 0.727\n",
      "Current Monte-Carlo Step: 0.728\n",
      "Current Monte-Carlo Step: 0.729\n",
      "Current Monte-Carlo Step: 0.73\n",
      "Current Monte-Carlo Step: 0.731\n",
      "Current Monte-Carlo Step: 0.732\n",
      "Current Monte-Carlo Step: 0.733\n",
      "Current Monte-Carlo Step: 0.734\n",
      "Current Monte-Carlo Step: 0.735\n",
      "Current Monte-Carlo Step: 0.736\n",
      "Current Monte-Carlo Step: 0.737\n",
      "Current Monte-Carlo Step: 0.738\n",
      "Current Monte-Carlo Step: 0.739\n",
      "Current Monte-Carlo Step: 0.74\n",
      "Current Monte-Carlo Step: 0.741\n",
      "Current Monte-Carlo Step: 0.742\n",
      "Current Monte-Carlo Step: 0.743\n",
      "Current Monte-Carlo Step: 0.744\n",
      "Current Monte-Carlo Step: 0.745\n",
      "Current Monte-Carlo Step: 0.746\n",
      "Current Monte-Carlo Step: 0.747\n",
      "Current Monte-Carlo Step: 0.748\n",
      "Current Monte-Carlo Step: 0.749\n",
      "Current Monte-Carlo Step: 0.75\n",
      "Current Monte-Carlo Step: 0.751\n",
      "Current Monte-Carlo Step: 0.752\n",
      "Current Monte-Carlo Step: 0.753\n",
      "Current Monte-Carlo Step: 0.754\n",
      "Current Monte-Carlo Step: 0.755\n",
      "Current Monte-Carlo Step: 0.756\n",
      "Current Monte-Carlo Step: 0.757\n",
      "Current Monte-Carlo Step: 0.758\n",
      "Current Monte-Carlo Step: 0.759\n",
      "Current Monte-Carlo Step: 0.76\n",
      "Current Monte-Carlo Step: 0.761\n",
      "Current Monte-Carlo Step: 0.762\n",
      "Current Monte-Carlo Step: 0.763\n",
      "Current Monte-Carlo Step: 0.764\n",
      "Current Monte-Carlo Step: 0.765\n",
      "Current Monte-Carlo Step: 0.766\n",
      "Current Monte-Carlo Step: 0.767\n",
      "Current Monte-Carlo Step: 0.768\n",
      "Current Monte-Carlo Step: 0.769\n",
      "Current Monte-Carlo Step: 0.77\n",
      "Current Monte-Carlo Step: 0.771\n",
      "Current Monte-Carlo Step: 0.772\n",
      "Current Monte-Carlo Step: 0.773\n",
      "Current Monte-Carlo Step: 0.774\n",
      "Current Monte-Carlo Step: 0.775\n",
      "Current Monte-Carlo Step: 0.776\n",
      "Current Monte-Carlo Step: 0.777\n",
      "Current Monte-Carlo Step: 0.778\n",
      "Current Monte-Carlo Step: 0.779\n",
      "Current Monte-Carlo Step: 0.78\n",
      "Current Monte-Carlo Step: 0.781\n",
      "Current Monte-Carlo Step: 0.782\n",
      "Current Monte-Carlo Step: 0.783\n",
      "Current Monte-Carlo Step: 0.784\n",
      "Current Monte-Carlo Step: 0.785\n",
      "Current Monte-Carlo Step: 0.786\n",
      "Current Monte-Carlo Step: 0.787\n",
      "Current Monte-Carlo Step: 0.788\n",
      "Current Monte-Carlo Step: 0.789\n",
      "Current Monte-Carlo Step: 0.79\n",
      "Current Monte-Carlo Step: 0.791\n",
      "Current Monte-Carlo Step: 0.792\n",
      "Current Monte-Carlo Step: 0.793\n",
      "Current Monte-Carlo Step: 0.794\n",
      "Current Monte-Carlo Step: 0.795\n",
      "Current Monte-Carlo Step: 0.796\n",
      "Current Monte-Carlo Step: 0.797\n",
      "Current Monte-Carlo Step: 0.798\n",
      "Current Monte-Carlo Step: 0.799\n",
      "Current Monte-Carlo Step: 0.8\n",
      "Current Monte-Carlo Step: 0.801\n",
      "Current Monte-Carlo Step: 0.802\n",
      "Current Monte-Carlo Step: 0.803\n",
      "Current Monte-Carlo Step: 0.804\n",
      "Current Monte-Carlo Step: 0.805\n",
      "Current Monte-Carlo Step: 0.806\n",
      "Current Monte-Carlo Step: 0.807\n",
      "Current Monte-Carlo Step: 0.808\n",
      "Current Monte-Carlo Step: 0.809\n",
      "Current Monte-Carlo Step: 0.81\n",
      "Current Monte-Carlo Step: 0.811\n",
      "Current Monte-Carlo Step: 0.812\n",
      "Current Monte-Carlo Step: 0.813\n",
      "Current Monte-Carlo Step: 0.814\n",
      "Current Monte-Carlo Step: 0.815\n",
      "Current Monte-Carlo Step: 0.816\n",
      "Current Monte-Carlo Step: 0.817\n",
      "Current Monte-Carlo Step: 0.818\n",
      "Current Monte-Carlo Step: 0.819\n",
      "Current Monte-Carlo Step: 0.82\n",
      "Current Monte-Carlo Step: 0.821\n",
      "Current Monte-Carlo Step: 0.822\n",
      "Current Monte-Carlo Step: 0.823\n",
      "Current Monte-Carlo Step: 0.824\n",
      "Current Monte-Carlo Step: 0.825\n",
      "Current Monte-Carlo Step: 0.826\n",
      "Current Monte-Carlo Step: 0.827\n",
      "Current Monte-Carlo Step: 0.828\n",
      "Current Monte-Carlo Step: 0.829\n",
      "Current Monte-Carlo Step: 0.83\n",
      "Current Monte-Carlo Step: 0.831\n",
      "Current Monte-Carlo Step: 0.832\n",
      "Current Monte-Carlo Step: 0.833\n",
      "Current Monte-Carlo Step: 0.834\n",
      "Current Monte-Carlo Step: 0.835\n",
      "Current Monte-Carlo Step: 0.836\n",
      "Current Monte-Carlo Step: 0.837\n",
      "Current Monte-Carlo Step: 0.838\n",
      "Current Monte-Carlo Step: 0.839\n",
      "Current Monte-Carlo Step: 0.84\n",
      "Current Monte-Carlo Step: 0.841\n",
      "Current Monte-Carlo Step: 0.842\n",
      "Current Monte-Carlo Step: 0.843\n",
      "Current Monte-Carlo Step: 0.844\n",
      "Current Monte-Carlo Step: 0.845\n",
      "Current Monte-Carlo Step: 0.846\n",
      "Current Monte-Carlo Step: 0.847\n",
      "Current Monte-Carlo Step: 0.848\n",
      "Current Monte-Carlo Step: 0.849\n",
      "Current Monte-Carlo Step: 0.85\n",
      "Current Monte-Carlo Step: 0.851\n",
      "Current Monte-Carlo Step: 0.852\n",
      "Current Monte-Carlo Step: 0.853\n",
      "Current Monte-Carlo Step: 0.854\n",
      "Current Monte-Carlo Step: 0.855\n",
      "Current Monte-Carlo Step: 0.856\n",
      "Current Monte-Carlo Step: 0.857\n",
      "Current Monte-Carlo Step: 0.858\n",
      "Current Monte-Carlo Step: 0.859\n",
      "Current Monte-Carlo Step: 0.86\n",
      "Current Monte-Carlo Step: 0.861\n",
      "Current Monte-Carlo Step: 0.862\n",
      "Current Monte-Carlo Step: 0.863\n",
      "Current Monte-Carlo Step: 0.864\n",
      "Current Monte-Carlo Step: 0.865\n",
      "Current Monte-Carlo Step: 0.866\n",
      "Current Monte-Carlo Step: 0.867\n",
      "Current Monte-Carlo Step: 0.868\n",
      "Current Monte-Carlo Step: 0.869\n",
      "Current Monte-Carlo Step: 0.87\n",
      "Current Monte-Carlo Step: 0.871\n",
      "Current Monte-Carlo Step: 0.872\n",
      "Current Monte-Carlo Step: 0.873\n",
      "Current Monte-Carlo Step: 0.874\n",
      "Current Monte-Carlo Step: 0.875\n",
      "Current Monte-Carlo Step: 0.876\n",
      "Current Monte-Carlo Step: 0.877\n",
      "Current Monte-Carlo Step: 0.878\n",
      "Current Monte-Carlo Step: 0.879\n",
      "Current Monte-Carlo Step: 0.88\n",
      "Current Monte-Carlo Step: 0.881\n",
      "Current Monte-Carlo Step: 0.882\n",
      "Current Monte-Carlo Step: 0.883\n",
      "Current Monte-Carlo Step: 0.884\n",
      "Current Monte-Carlo Step: 0.885\n",
      "Current Monte-Carlo Step: 0.886\n",
      "Current Monte-Carlo Step: 0.887\n",
      "Current Monte-Carlo Step: 0.888\n",
      "Current Monte-Carlo Step: 0.889\n",
      "Current Monte-Carlo Step: 0.89\n",
      "Current Monte-Carlo Step: 0.891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step: 0.892\n",
      "Current Monte-Carlo Step: 0.893\n",
      "Current Monte-Carlo Step: 0.894\n",
      "Current Monte-Carlo Step: 0.895\n",
      "Current Monte-Carlo Step: 0.896\n",
      "Current Monte-Carlo Step: 0.897\n",
      "Current Monte-Carlo Step: 0.898\n",
      "Current Monte-Carlo Step: 0.899\n",
      "Current Monte-Carlo Step: 0.9\n",
      "Current Monte-Carlo Step: 0.901\n",
      "Current Monte-Carlo Step: 0.902\n",
      "Current Monte-Carlo Step: 0.903\n",
      "Current Monte-Carlo Step: 0.904\n",
      "Current Monte-Carlo Step: 0.905\n",
      "Current Monte-Carlo Step: 0.906\n",
      "Current Monte-Carlo Step: 0.907\n",
      "Current Monte-Carlo Step: 0.908\n",
      "Current Monte-Carlo Step: 0.909\n",
      "Current Monte-Carlo Step: 0.91\n",
      "Current Monte-Carlo Step: 0.911\n",
      "Current Monte-Carlo Step: 0.912\n",
      "Current Monte-Carlo Step: 0.913\n",
      "Current Monte-Carlo Step: 0.914\n",
      "Current Monte-Carlo Step: 0.915\n",
      "Current Monte-Carlo Step: 0.916\n",
      "Current Monte-Carlo Step: 0.917\n",
      "Current Monte-Carlo Step: 0.918\n",
      "Current Monte-Carlo Step: 0.919\n",
      "Current Monte-Carlo Step: 0.92\n",
      "Current Monte-Carlo Step: 0.921\n",
      "Current Monte-Carlo Step: 0.922\n",
      "Current Monte-Carlo Step: 0.923\n",
      "Current Monte-Carlo Step: 0.924\n",
      "Current Monte-Carlo Step: 0.925\n",
      "Current Monte-Carlo Step: 0.926\n",
      "Current Monte-Carlo Step: 0.927\n",
      "Current Monte-Carlo Step: 0.928\n",
      "Current Monte-Carlo Step: 0.929\n",
      "Current Monte-Carlo Step: 0.93\n",
      "Current Monte-Carlo Step: 0.931\n",
      "Current Monte-Carlo Step: 0.932\n",
      "Current Monte-Carlo Step: 0.933\n",
      "Current Monte-Carlo Step: 0.934\n",
      "Current Monte-Carlo Step: 0.935\n",
      "Current Monte-Carlo Step: 0.936\n",
      "Current Monte-Carlo Step: 0.937\n",
      "Current Monte-Carlo Step: 0.938\n",
      "Current Monte-Carlo Step: 0.939\n",
      "Current Monte-Carlo Step: 0.94\n",
      "Current Monte-Carlo Step: 0.941\n",
      "Current Monte-Carlo Step: 0.942\n",
      "Current Monte-Carlo Step: 0.943\n",
      "Current Monte-Carlo Step: 0.944\n",
      "Current Monte-Carlo Step: 0.945\n",
      "Current Monte-Carlo Step: 0.946\n",
      "Current Monte-Carlo Step: 0.947\n",
      "Current Monte-Carlo Step: 0.948\n",
      "Current Monte-Carlo Step: 0.949\n",
      "Current Monte-Carlo Step: 0.95\n",
      "Current Monte-Carlo Step: 0.951\n",
      "Current Monte-Carlo Step: 0.952\n",
      "Current Monte-Carlo Step: 0.953\n",
      "Current Monte-Carlo Step: 0.954\n",
      "Current Monte-Carlo Step: 0.955\n",
      "Current Monte-Carlo Step: 0.956\n",
      "Current Monte-Carlo Step: 0.957\n",
      "Current Monte-Carlo Step: 0.958\n",
      "Current Monte-Carlo Step: 0.959\n",
      "Current Monte-Carlo Step: 0.96\n",
      "Current Monte-Carlo Step: 0.961\n",
      "Current Monte-Carlo Step: 0.962\n",
      "Current Monte-Carlo Step: 0.963\n",
      "Current Monte-Carlo Step: 0.964\n",
      "Current Monte-Carlo Step: 0.965\n",
      "Current Monte-Carlo Step: 0.966\n",
      "Current Monte-Carlo Step: 0.967\n",
      "Current Monte-Carlo Step: 0.968\n",
      "Current Monte-Carlo Step: 0.969\n",
      "Current Monte-Carlo Step: 0.97\n",
      "Current Monte-Carlo Step: 0.971\n",
      "Current Monte-Carlo Step: 0.972\n",
      "Current Monte-Carlo Step: 0.973\n",
      "Current Monte-Carlo Step: 0.974\n",
      "Current Monte-Carlo Step: 0.975\n",
      "Current Monte-Carlo Step: 0.976\n",
      "Current Monte-Carlo Step: 0.977\n",
      "Current Monte-Carlo Step: 0.978\n",
      "Current Monte-Carlo Step: 0.979\n",
      "Current Monte-Carlo Step: 0.98\n",
      "Current Monte-Carlo Step: 0.981\n",
      "Current Monte-Carlo Step: 0.982\n",
      "Current Monte-Carlo Step: 0.983\n",
      "Current Monte-Carlo Step: 0.984\n",
      "Current Monte-Carlo Step: 0.985\n",
      "Current Monte-Carlo Step: 0.986\n",
      "Current Monte-Carlo Step: 0.987\n",
      "Current Monte-Carlo Step: 0.988\n",
      "Current Monte-Carlo Step: 0.989\n",
      "Current Monte-Carlo Step: 0.99\n",
      "Current Monte-Carlo Step: 0.991\n",
      "Current Monte-Carlo Step: 0.992\n",
      "Current Monte-Carlo Step: 0.993\n",
      "Current Monte-Carlo Step: 0.994\n",
      "Current Monte-Carlo Step: 0.995\n",
      "Current Monte-Carlo Step: 0.996\n",
      "Current Monte-Carlo Step: 0.997\n",
      "Current Monte-Carlo Step: 0.998\n",
      "Current Monte-Carlo Step: 0.999\n",
      "Done Simulation Step\n"
     ]
    }
   ],
   "source": [
    "for i in range(N_Grid_Instances):\n",
    "    # Get Terminal Distribution Shape\n",
    "    # EM METHOD\n",
    "#     measures_locations_loop = Euler_Maruyama_Generator(x_0=x_Grid[i])\n",
    "    # DIRECT SAMPLING\n",
    "    measures_locations_loop = np.random.lognormal(np.exp(x_Grid[i]), 0.01, N_Monte_Carlo_Samples).reshape(-1,)\n",
    "    \n",
    "    # Append to List\n",
    "    measures_locations_list.append(measures_locations_loop.reshape(-1,1))\n",
    "    measures_weights_list.append(measure_weights)\n",
    "    \n",
    "    # Print Update User #\n",
    "    #-------------------#\n",
    "    print(\"Current Monte-Carlo Step:\",i/N_Grid_Instances)\n",
    "    \n",
    "# Update User\n",
    "print(\"Done Simulation Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# Initialization(s)\n",
    "## Initialize remaining part of f(X) to cover\n",
    "measures_locations_list_covering = measures_locations_list\n",
    "## Initialize Centers of Open Cover\n",
    "Centers_Wasserstein_Open_balls = np.array([])\n",
    "## Initialize counter\n",
    "current_counter_measures = 0\n",
    "\n",
    "# Update User\n",
    "print(len(measures_locations_list_covering))\n",
    "\n",
    "if N_Quantizers_to_parameterize  > 0:\n",
    "    # Build Cover\n",
    "    while len(measures_locations_list_covering)>N_Quantizers_to_parameterize:\n",
    "        # 1) Get Barycenter\n",
    "        #----------------------------------------------------------------------------------------------------#\n",
    "        # Get Barycenter\n",
    "        Wasserstein_barycenter_current = ot.lp.free_support_barycenter(measures_locations_list_covering, \n",
    "                                                                       measures_weights_list, \n",
    "                                                                       Init_Quantizer_generic.reshape(-1,1), \n",
    "                                                                       Init_Quantizer_generic)\n",
    "\n",
    "        # 2) Parse Data (Determine which data is closest to current barycenter)\n",
    "        #----------------------------------------------------------------------------------------------------#\n",
    "        # Initialize Disimilarity Matrix\n",
    "        Dissimilarity_matrix_ot = np.zeros(N_Grid_Instances)\n",
    "\n",
    "        # Compute Disimilarity Matrix\n",
    "        for i in range(N_Grid_Instances):\n",
    "            Dissimilarity_matrix_ot[i] = ot.emd2_1d(Wasserstein_barycenter_current,\n",
    "                                                    measures_locations_list_covering[i])\n",
    "\n",
    "    #         # Update User (Periodically)\n",
    "    #         if i % 50 == 0:\n",
    "    #             print(\"Disimilarity Matrix\",i,\"From Step:\",measures_locations_list_covering/N_Quantizers_to_parameterize)\n",
    "\n",
    "\n",
    "        # Decide which are remaning data\n",
    "        Boolean_List_Filter = Dissimilarity_matrix_ot.argsort()>=N_Quantizers_to_parameterize\n",
    "\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------#\n",
    "        # Update Remaining Samples\n",
    "        measures_locations_list_covering = list(compress(measures_locations_list_covering, Boolean_List_Filter))\n",
    "\n",
    "        # Update Size of Grid\n",
    "        N_Grid_Instances = len(measures_locations_list_covering)\n",
    "\n",
    "        # Update Collection of Barycenters\n",
    "        if current_counter_measures == 0:\n",
    "            Centers_Wasserstein_Open_balls = Wasserstein_barycenter_current\n",
    "        else:\n",
    "            Centers_Wasserstein_Open_balls = np.append(Centers_Wasserstein_Open_balls,Wasserstein_barycenter_current,1)\n",
    "\n",
    "\n",
    "        # 3) Update Counters\n",
    "        #---------------------------------------------------------------------------------------------------------------#\n",
    "        current_counter_measures = current_counter_measures + 1\n",
    "\n",
    "\n",
    "        # Update User #\n",
    "        #-------------#\n",
    "        print(\"Current Step:\", current_counter_measures/N_Quantizers_to_parameterize)\n",
    "\n",
    "        \n",
    "else:\n",
    "    for i in range(len(measures_locations_list_covering)):\n",
    "        # Update Collection of Barycenters\n",
    "        if current_counter_measures == 0:\n",
    "            Centers_Wasserstein_Open_balls = measures_locations_list_covering[i]\n",
    "        else:\n",
    "            Centers_Wasserstein_Open_balls = np.append(Centers_Wasserstein_Open_balls,measures_locations_list_covering[i],1)\n",
    "        # 3) Update Counters\n",
    "        #---------------------------------------------------------------------------------------------------------------#\n",
    "        current_counter_measures = current_counter_measures + 1\n",
    "\n",
    "        \n",
    "#---------------------------------------------------------------------------------------------------------------#\n",
    "## Get number of centers produced\n",
    "N_centers_produced = Centers_Wasserstein_Open_balls.shape[1]\n",
    "# Update User\n",
    "print(N_centers_produced,\"Centers were prodiced to cover sampled grid's image!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Classes\n",
    "Next we identify the index of the $\\{\\hat{\\mu}_n\\}$ *(build in the last step)* which is closest to any input datum $x \\in \\mathbb{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classes (In-Sample)\n",
    "Classifer_Wasserstein_Centers = np.zeros([N_Grid_Finess,N_centers_produced])\n",
    "# Classifer_Wasserstein_Centers = np.zeros(N_Grid_Finess)\n",
    "\n",
    "# Build Classes\n",
    "for x_index_current in range(N_Grid_Finess):\n",
    "    # (RE-)Initialize current distance vector\n",
    "    Distance_Vector_loop = np.zeros(N_centers_produced)\n",
    "    # Get Distances\n",
    "    for i in range(N_centers_produced):\n",
    "        Distance_Vector_loop[i] = ot.emd2_1d(measures_locations_list[0],\n",
    "                                             Centers_Wasserstein_Open_balls[:,i].reshape(-1,1))\n",
    "\n",
    "    # Get Classes (Boolean Values corresponding to which barycenter is closest)\n",
    "    Classifer_Wasserstein_Centers[x_index_current,] = np.min(Distance_Vector_loop)==Distance_Vector_loop\n",
    "#     Classifer_Wasserstein_Centers[x_index_current,] = np.argmin(Distance_Vector_loop)\n",
    "    \n",
    "# Covert to Integer Type\n",
    "Classifer_Wasserstein_Centers = Classifer_Wasserstein_Centers.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [1]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_centers_produced]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "32/32 [==============================] - 0s 568us/step\n",
      "32/32 [==============================] - 0s 591us/step\n"
     ]
    }
   ],
   "source": [
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter =n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = x_Grid, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers,\n",
    "                                                                                                        X_test = x_Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Type_A_timer_End = time.time() - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Centers_Wasserstein_Open_balls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5dabd8dcb7ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPredictions_Train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_classes_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCenters_Wasserstein_Open_balls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mPredictions_Test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_classes_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCenters_Wasserstein_Open_balls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 1000)"
     ]
    }
   ],
   "source": [
    "Predictions_Train = np.matmul(predicted_classes_train,Centers_Wasserstein_Open_balls.T)\n",
    "Predictions_Test = np.matmul(predicted_classes_test,Centers_Wasserstein_Open_balls.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "\n",
    "# Get Predicted Means\n",
    "predicted_means = Predictions_Train.mean(axis=1)\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in range(len(measures_locations_list)):\n",
    "    # Get Laws\n",
    "    W1_errors = np.append(W1_errors,ot.emd2_1d(Predictions_Train[x_i,].reshape(-1,1),\n",
    "                                               measures_locations_list[x_i]))\n",
    "    # Get Means\n",
    "    Mean_errors = np.array(predicted_means[x_i]-np.mean(measures_locations_list[x_i]))\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.mean(np.abs(W1_errors)),np.mean(W1_errors**2)])\n",
    "Mean_prediction_Performance = np.array([np.mean(np.abs(Mean_errors)),np.mean(Mean_errors**2)])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\"EX\":Mean_prediction_Performance},index=[\"MAE\",\"MSE\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+\"Type_A_Prediction.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "print(Type_A_Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 0\n",
    "for i in range(len(measures_locations_list)):\n",
    "    avg = avg + np.mean(measures_locations_list[i])\n",
    "avg = avg/len(measures_locations_list)\n",
    "# Update User\n",
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
