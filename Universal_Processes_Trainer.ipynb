{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many random polulations to visualize:\n",
    "Visualization_Size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "# N_Euler_Maruyama_Steps = 2\n",
    "N_Monte_Carlo_Samples = 4\n",
    "\n",
    "## Grid\n",
    "N_Grid_Finess = 20\n",
    "Max_Grid = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "*This hyperparameter describes the proportion of the data used as sample-barycenters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantization_Proportion = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Algorithm\n",
    "---\n",
    "Given a set of training inputs $\\mathbb{X}$ and a stochastic process $(X_t)_{t\\geq 0}$ which we can sample from:\n",
    "1. **For:** x in $\\mathbb{X}$:\n",
    "    - *Simulate:* $\\{x\\mapsto X_T(\\omega_n)\\}_{n=1}^N$\n",
    "    - *Set*: $\\hat{\\nu}_{x,T}\\triangleq \\frac1{N}\\sum_{n=1}^N \\delta_{X_T(\\omega_n)}$\n",
    "2. **Learn:** Wasserstein Barycenters $\\hat{\\mu}_1,\\dots,\\hat{\\mu}_N\n",
    "    \\in \\underset{{\\hat{\\mu}_n\\in\\mathscr{P}_{N}(\\mathbb{R}^d)}}{\\operatorname{argmin}}\n",
    "    \\, \\sum_{n=1}^N W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$\n",
    "3. **Train Classifier:** $\\hat{f}:x\\mapsto \\operatorname{n\\leq N}\\, W_1(\\hat{\\mu_n},\\hat{\\nu}_{x,T})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Internal (Hyper)-Parameter(s)\n",
    "*Initialize the hyperparameters which are fully-specified by the user-provided hyperparameter(s).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Grid\n",
    "This is $\\mathbb{X}$ and it represents the grid of initial states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Grid Instances:  20\n"
     ]
    }
   ],
   "source": [
    "# Get Input Data\n",
    "x_Grid = np.arange(start=-Max_Grid,\n",
    "                   stop=Max_Grid,\n",
    "                   step=(2*Max_Grid/N_Grid_Finess))\n",
    "\n",
    "# Get Number of Instances in Grid\n",
    "N_Grid_Instances = len(x_Grid)\n",
    "\n",
    "# Updater User\n",
    "print(\"\\u2022 Grid Instances: \", N_Grid_Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Counting Parameters\n",
    "Initialize the \"conting\" type parameters which will help us to determine the length of loops and to intialize object's size later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• 2  Centers will be produced; from a total datasize of:  20 !  (That's  0.1  percent).\n",
      "• Each Wasserstein-1 Ball should contain:  10 elements from the training set.\n"
     ]
    }
   ],
   "source": [
    "# Get Internal (Counting) Parameters\n",
    "N_Quantizers_to_parameterize = round(Quantization_Proportion*N_Grid_Finess)\n",
    "N_Elements_Per_Cluster = int(round(N_Grid_Instances/N_Quantizers_to_parameterize))\n",
    "\n",
    "# Update User\n",
    "print(\"\\u2022\",N_Quantizers_to_parameterize,\" Centers will be produced; from a total datasize of: \",N_Grid_Finess,\n",
    "      \"!  (That's \",Quantization_Proportion,\n",
    "      \" percent).\")\n",
    "print(\"\\u2022 Each Wasserstein-1 Ball should contain: \",\n",
    "      N_Elements_Per_Cluster, \n",
    "      \"elements from the training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Path\n",
    "$d X_t = \\alpha(t,x)dt + \\beta(t,x)dW_t ;\\qquad X_0 =x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(t,x):\n",
    "    return 0#np.sin(math.pi*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(t,x):\n",
    "    return 1#(t+1)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize List of Barycenters\n",
    "Wasserstein_Barycenters = []\n",
    "# Initialize Terminal-Time Empirical Measures\n",
    "measures_locations_list = []\n",
    "measures_weights_list = []\n",
    "# Initialize (Empirical) Weight(s)\n",
    "measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "# Initialize Quantizer\n",
    "Init_Quantizer_generic = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $\\{\\hat{\\nu}^{N}_{T,x}\\}_{x \\in \\mathbb{X}}$ Build Wasserstein Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 28620.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte-Carlo Step:\n",
      "Done Simulation Step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"Current Monte-Carlo Step:\")\n",
    "\n",
    "# Perform Monte-Carlo Data Generation\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    # Get Terminal Distribution Shape\n",
    "    ###\n",
    "    # DIRECT SAMPLING\n",
    "    measures_locations_loop = (np.random.normal(x_Grid[i],np.abs(x_Grid[i]), N_Monte_Carlo_Samples).reshape(-1,))/N_Monte_Carlo_Samples\n",
    "    \n",
    "    # Append to List\n",
    "    measures_locations_list.append(measures_locations_loop.reshape(-1,1))\n",
    "    measures_weights_list.append(measure_weights)\n",
    "    \n",
    "# Update User\n",
    "print(\"Done Simulation Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\":\n",
    "Let $\\{\\mu_n\\}_{n=1}^N\\subset\\mathcal{P}_1(\\mathbb{R}^d)$.  Then, the *sample barycenter* is defined by:\n",
    "1. $\\mathcal{M}^{(0)}\\triangleq \\left\\{\\hat{\\mu}_n\\right\\}_{n=1}^N$,\n",
    "2. For $1\\leq n\\leq \\mbox{N sample barycenters}$: \n",
    "    - $\n",
    "\\mu^{\\star}\\in \\underset{\\tilde{\\mu}\\in \\mathcal{M}^{(n)}}{\\operatorname{argmin}}\\, \\sum_{n=1}^N \\mathcal{W}_1\\left(\\mu^{\\star},\\mu_n\\right),\n",
    "$\n",
    "    - $\\mathcal{M}^{(n)}\\triangleq \\mathcal{M}^{(n-1)} - \\{\\mu^{\\star}\\},$\n",
    "*i.e., the closest generated measure form the random sample to all other elements of the random sample.*\n",
    "\n",
    "---\n",
    "**Note:** *We simplify the computational burden of getting the correct classes by putting this right into this next loop.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dissimilarity (Distance) Matrix\n",
    "*In this step we build a dissimularity matrix of the dataset on the Wasserstein-1 space.  Namely:*\n",
    "$$\n",
    "\\operatorname{Mat}_{\\# \\mathbb{X},\\# \\mathbb{X}}\\left(\\mathbb{R}\\right)\\ni D; \\text{ where}\\qquad \\, D_{i,j}\\triangleq \\mathcal{W}_1\\left(f(x_i),f(x_j)\\right)\n",
    ";\n",
    "$$\n",
    "*where $f\\in C\\left((\\mathcal{X},\\mathcal{P}_1(\\mathcal{Y})\\right)$ is the \"target\" function we are learning.*\n",
    "\n",
    "**Note**: *Computing the dissimularity matrix is the most costly part of the entire algorithm with a complexity of at-most $\\mathcal{O}\\left(E_{W} \\# \\mathbb{X})^2\\right)$ where $E_W$ denotes the complexity of a single Wasserstein-1 evaluation between two elements of the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 225.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😚  Begin Building Distance Matrix  😚\n",
      "😀  Done Building Distance Matrix 😀 !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Disimilarity Matrix\n",
    "Dissimilarity_matrix_ot = np.zeros([N_Grid_Instances,N_Grid_Instances])\n",
    "\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Building Distance Matrix\",\" \\U0001F61A\")\n",
    "# Build Disimilarity Matrix\n",
    "for i in tqdm(range(N_Grid_Instances)):\n",
    "    for j in range(N_Grid_Instances):\n",
    "        Dissimilarity_matrix_ot[i,j] = ot.emd2_1d(measures_locations_list[j],\n",
    "                                                  measures_locations_list[i])\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Building Distance Matrix\",\"\\U0001F600\",\"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Quantities to Loop Over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"Sample Barycenters\" and Generate Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Locations Matrix (Internal to Loop)\n",
    "measures_locations_list_current = copy.copy(measures_locations_list)\n",
    "Dissimilarity_matrix_ot_current = copy.copy(Dissimilarity_matrix_ot)\n",
    "\n",
    "# Initialize masker vector\n",
    "masker = np.ones(N_Grid_Instances)\n",
    "\n",
    "# Initialize Sorting Reference Vector (This helps us efficiently scroll through the disimularity matrix to identify the barycenter without having to re-compute the dissimultarity matrix of a sub-saple at every iteration (which is the most costly part of the algorithm!))\n",
    "Distances_Loop = Dissimilarity_matrix_ot_current.sum(axis=1)\n",
    "\n",
    "# Initialize Classes (In-Sample)\n",
    "Classifer_Wasserstein_Centers = np.zeros([N_Quantizers_to_parameterize,N_Grid_Instances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/usr/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n",
      "100%|██████████| 2/2 [00:00<00:00, 2168.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😚  Begin Identifying Sample Barycenters  😚\n",
      "😀  Done Identifying Sample Barycenters 😀 !\n",
      "[[0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"\\U0001F61A\",\" Begin Identifying Sample Barycenters\",\" \\U0001F61A\")\n",
    "\n",
    "# Identify Sample Barycenters\n",
    "for i in tqdm(range(N_Quantizers_to_parameterize)):    \n",
    "    # GET BARYCENTER #\n",
    "    #----------------#\n",
    "    ## Identify row with minimum total distance\n",
    "    Barycenter_index = int(Distances_Loop.argsort()[:1][0])\n",
    "    ## Get Barycenter\n",
    "    ## Update Barycenters Array ##\n",
    "    #----------------------------#\n",
    "    ### Get next Barycenter\n",
    "    new_barycenter_loop = measures_locations_list_current[Barycenter_index].reshape(-1,1)\n",
    "    ### Update Array of Barycenters\n",
    "    if i == 0:\n",
    "        # Initialize Barycenters Array\n",
    "        Barycenters_Array = new_barycenter_loop\n",
    "    else:\n",
    "        # Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,new_barycenter_loop,axis=-1)\n",
    "\n",
    "    # GET CLUSTER #\n",
    "    #-------------#\n",
    "    # Identify Cluster for this barycenter (which elements are closest to it)\n",
    "    Cluster_indices = (masker*Dissimilarity_matrix_ot_current[:,Barycenter_index]).argsort()[:N_Elements_Per_Cluster]\n",
    "    ## UPDATES Set  M^{(n)}  ##\n",
    "    #-------------------------#\n",
    "    Dissimilarity_matrix_ot_current[Cluster_indices,:] = 0\n",
    "    # Distance-Based Sorting\n",
    "    Distances_Loop[Cluster_indices] = math.inf\n",
    "\n",
    "    # Update Cluster\n",
    "    masker[Cluster_indices] = math.inf\n",
    "    \n",
    "    # Update Classes\n",
    "    Classifer_Wasserstein_Centers[i,Cluster_indices] = 1\n",
    "#     print(Cluster_indices)\n",
    "\n",
    "# Update User\n",
    "print(\"\\U0001F600\",\" Done Identifying Sample Barycenters\",\"\\U0001F600\",\"!\")\n",
    "print(Classifer_Wasserstein_Centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Classifier\n",
    "Prepare Labels/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training Deep Classifier\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# %run ParaGAN_Backend.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 876us/step - loss: 0.6437 - accuracy: 0.6500\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6500\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6500\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.6500\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6268 - accuracy: 0.6500\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6228 - accuracy: 0.6500\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.6500\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.7000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6109 - accuracy: 0.7000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5916 - accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.5629 - accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5586 - accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.5129 - accuracy: 0.8500\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.9000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.9000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.9000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.9000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.9000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.9000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.9000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.9000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.9000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.9000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.9000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.9500\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.9500\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.9500\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.9500\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.9500\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.9500\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.9500\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.9500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.9500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.9500\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.9500\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.9500\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.9500\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.9500\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.9500\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.9500\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.9500\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.9500\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.9500\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3127 - accuracy: 0.9000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.9000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.9000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3005 - accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.9000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.9000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.9000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.9500\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.9500\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.9500\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2783 - accuracy: 0.9500\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.9500\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2742 - accuracy: 0.9500\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.9500\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 959us/step\n",
      "1/1 [==============================] - 0s 943us/step\n"
     ]
    }
   ],
   "source": [
    "# Redefine (Dimension-related) Elements of Grid\n",
    "# param_grid_Deep_Classifier['input_dim'] = [1]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = x_Grid, \n",
    "                                                                                                        y_train = Classifer_Wasserstein_Centers.T,\n",
    "                                                                                                        X_test = x_Grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Weights\n",
    "Predicted_Weights = np.array([])\n",
    "for i in range(N_Quantizers_to_parameterize):\n",
    "    b = np.repeat(np.array(predicted_classes_train[:,i],dtype='float').reshape(-1,1),N_Monte_Carlo_Samples,axis=-1)\n",
    "    b = b/N_Monte_Carlo_Samples\n",
    "    if i ==0 :\n",
    "        Predicted_Weights = b\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=1)\n",
    "        \n",
    "# Format Points of Mass\n",
    "Barycenters_Array = Barycenters_Array.T.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many moments to comapre\n",
    "N_Moments_to_predict = 2\n",
    "## How many predictions\n",
    "Moment_Predictions = np.zeros([N_Grid_Instances,N_Moments_to_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00296065, 0.9970394 ], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes_train[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predicted_classes_train.shape)\n",
    "Barycenters_Array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           W1        EX       Var\n",
      "MAE  0.409163  1.452029  1.098069\n",
      "MSE  0.522864  2.108387  1.205756\n"
     ]
    }
   ],
   "source": [
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "\n",
    "# Get Predicted Means\n",
    "predicted_means = Predictions_Train.mean(axis=1)\n",
    "predicted_vars = np.sqrt((Predictions_Train**2).mean(axis=1))\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in range(len(measures_locations_list)):\n",
    "    # Get Laws\n",
    "    W1_errors = np.append(W1_errors,(ot.emd2_1d(Predictions_Train[x_i,].reshape(-1,),\n",
    "                                               measures_locations_list[x_i].reshape(-1,))))\n",
    "    # Get Means\n",
    "    Mean_errors = np.array(predicted_means[x_i]-np.mean(measures_locations_list[x_i]))\n",
    "    # Get Vars\n",
    "    Mean_var = np.array(predicted_vars[x_i]-np.mean(measures_locations_list[x_i]**2))\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.mean(np.abs(W1_errors)),np.mean(W1_errors**2)])\n",
    "Mean_prediction_Performance = np.array([np.mean(np.abs(Mean_errors)),np.mean(Mean_errors**2)])\n",
    "Var_prediction_Performance = np.array([np.mean(np.abs(Mean_var)),np.mean(Mean_var**2)])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\"EX\":Mean_prediction_Performance,\"Var\":Var_prediction_Performance},index=[\"MAE\",\"MSE\"])\n",
    "\n",
    "# Write Performance\n",
    "Type_A_Prediction.to_latex((results_tables_path+\"Type_A_Prediction.tex\"))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Update User\n",
    "print(Type_A_Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Performance\n",
    "Randomly subsample from output space and visualize empirical measures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjust if is number of plots to visualizes is larger than number of output distributions (But only if there is not enough data!)\n",
    "if N_Grid_Instances <= Visualization_Size**2:\n",
    "        Visualization_Size = int(round(np.sqrt(min(N_Grid_Instances,Visualization_Size**2)))-1)\n",
    "\n",
    "\n",
    "# Initialize Random Sample of input-output pairs to visualize\n",
    "plotting_distribution_indices = random.sample(range(N_Grid_Instances), (Visualization_Size)**2)\n",
    "\n",
    "# Generate Plot\n",
    "f, axarr = plt.subplots(Visualization_Size,Visualization_Size,figsize=(6, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.suptitle(\"Sample of Predictions\")\n",
    "for i in range(Visualization_Size):\n",
    "    for j in range(Visualization_Size):\n",
    "        # Get Current (Randomly chosen (uniformly)) Index\n",
    "        current_index = (i*Visualization_Size + j)\n",
    "        current_random_index = plotting_distribution_indices[current_index]\n",
    "        # Generate Current Plot\n",
    "        axarr[i,j].hist(Predictions_Train[current_random_index], alpha=0.5,label=\"Prediction\")\n",
    "        axarr[i,j].hist(measures_locations_list[current_random_index], alpha=0.5,label=\"Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
