{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Conditional Laws for Random-Fields - via:\n",
    "\n",
    "## Universal $\\mathcal{P}_1(\\mathbb{R})$-Deep Neural Model $\\mathcal{NN}_{1_{\\mathbb{R}^n},\\mathcal{D}}^{\\sigma:\\star}$.\n",
    "\n",
    "---\n",
    "\n",
    "By: [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/) - 2021.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Software/Hardware Testing or Real-Deal?\n",
    "trial_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Algorithm:\n",
    "---\n",
    "- Random $\\delta$-bounded partition on input space,\n",
    "- Train deep classifier on infered classes.\n",
    "---\n",
    "---\n",
    "---\n",
    "## Notes - Why the procedure is so computationally efficient?\n",
    "---\n",
    " - The sample barycenters do not require us to solve for any new Wasserstein-1 Barycenters; which is much more computationally costly,\n",
    " - Our training procedure never back-propages through $\\mathcal{W}_1$ since steps 2 and 3 are full-decoupled.  Therefore, training our deep classifier is (comparatively) cheap since it takes values in the standard $N$-simplex.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Auxiliaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Import time separately\n",
    "import time\n",
    "\n",
    "\n",
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\"\n",
    "\n",
    "\n",
    "### Set Seed\n",
    "random.seed(2021)\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Hyperparameter(s)\n",
    "- Ratio $\\frac{\\text{Testing Datasize}}{\\text{Training Datasize}}$.\n",
    "- Number of Training Points to Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = .2\n",
    "N_train_size = 10**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monte-Carlo\n",
    "N_Euler_Maruyama_Steps = 2\n",
    "N_Monte_Carlo_Samples = 10**3\n",
    "\n",
    "# End times for Time-Grid\n",
    "T_end = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial radis of $\\delta$-bounded random partition of $\\mathcal{X}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of Cover\n",
    "delta = 0.001\n",
    "Proportion_per_cluster = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Setting *N_Quantizers_to_parameterize* prevents any barycenters and sub-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation from Rough Neural-SDE\n",
    "Simulate via Euler-M method from:\n",
    "$$ \n",
    "X_T^x = x + \\int_0^T \\alpha(s,X_s^x)ds + \\int_0^T\\beta(s,X_s^s)dB_s^H.\n",
    "$$\n",
    "We seek to learn $\\mathbb{P}\\left(A^{\\top}X_1^x\\mid X_0^x = x\\right)$, where $A^{\\top}$ is an unknown $1\\times d$-matrix.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dim = 5\n",
    "\n",
    "width = 10**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_2a = np.random.uniform(size=np.array([problem_dim,width]),low=-.5,high=.5)\n",
    "W_1a = np.random.uniform(size=np.array([width,problem_dim]),low=-.5,high=.5)\n",
    "def alpha(t,x):\n",
    "    x_internal = x.reshape(-1,)\n",
    "#     x_internal = np.matmul(W_1a,x_internal)\n",
    "#     x_internal = np.matmul(W_2a,np.cos(x_internal))\n",
    "    x_internal = 0.01*x_internal\n",
    "    return x_internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_2b = np.random.uniform(size=np.array([(problem_dim**2),width]),low=-.5,high=.5)\n",
    "W_1b = np.random.uniform(size=np.array([width,problem_dim]),low=-.5,high=.5)\n",
    "def beta(t,x):\n",
    "#     x_internal = x.reshape(-1,)\n",
    "#     x_internal = np.matmul(W_1b,x_internal)\n",
    "#     x_internal = np.matmul(W_2b,np.maximum(0,np.array(x_internal)))\n",
    "#     x_internal = x_internal.reshape([problem_dim,problem_dim])\n",
    "#     # Ensure PSD\n",
    "#     x_internal = np.matmul(x_internal,x_internal.T)\n",
    "    x_internal = 0.001*np.diag(np.ones(problem_dim))\n",
    "    return x_internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughness Meta-parameters\n",
    " - Roughness is $H$,\n",
    " - Ratio_fBM_to_typical_vol is $\\eta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rougness = 0.5 # Hurst Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Unknown Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_unkown = np.random.normal(size=np.array([problem_dim,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate using Euler-Maruyama + Monte-Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Define Simulator Data Generator #\n",
    "###################################\n",
    "def Euler_Maruyama_Generator(x_0,\n",
    "                             N_Euler_Maruyama_Steps = 10,\n",
    "                             N_Monte_Carlo_Samples = 100,\n",
    "                             T_begin = 0,\n",
    "                             T_end = T_end,\n",
    "                             Hurst = 0.1): \n",
    "    #----------------------------#    \n",
    "    # DEFINE INTERNAL PARAMETERS #\n",
    "    #----------------------------#\n",
    "    # Internal Initialization(s)\n",
    "    ## Initialize current state\n",
    "    n_sample = 0\n",
    "    ## Initialize Incriments\n",
    "    dt = (T_end-T_begin)/N_Euler_Maruyama_Steps\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "    # Get Dimension\n",
    "    dim_x_0 = len(x_0)\n",
    "\n",
    "    #-----------------------------#    \n",
    "    # Generate Monte-Carlo Sample #\n",
    "    #-----------------------------#\n",
    "    for n_sample in range(N_Monte_Carlo_Samples):\n",
    "        # Initialize Current State \n",
    "        X_current = x_0\n",
    "        # Generate roughness\n",
    "        for fBM_path_i in range(dim_x_0):\n",
    "            sigma_rough_loop = FBM(n=N_Euler_Maruyama_Steps, \n",
    "                                   hurst=Hurst, \n",
    "                                   length=1, \n",
    "                                   method='daviesharte').fbm().reshape(1,-1)\n",
    "            if fBM_path_i == 0:\n",
    "                sigma_rough = sigma_rough_loop\n",
    "            else:\n",
    "                sigma_rough = np.append(sigma_rough,sigma_rough_loop,axis=0)\n",
    "\n",
    "    #     Perform Euler-Maruyama Simulation\n",
    "        for t in range((sigma_rough.shape[1]-1)):\n",
    "            # Update Internal Parameters\n",
    "            ## Get Current Time\n",
    "            t_current = t*((T_end - T_begin)/N_Euler_Maruyama_Steps)\n",
    "\n",
    "            # Update Generated Path\n",
    "            ## Generate Current State-Update Components\n",
    "            drift_t = alpha(t_current,X_current.reshape(-1,))*dt\n",
    "            vol_t = beta(t_current,X_current)\n",
    "            BH_t = (sigma_rough[:,(1+t)])\n",
    "            ## Compute Update\n",
    "            X_current = X_current + drift_t + (np.matmul(vol_t,BH_t))       \n",
    "\n",
    "        # Update Empirical Measure\n",
    "        X_current = X_current.reshape(-1,1)\n",
    "        if n_sample ==0:\n",
    "            X_T_Empirical = X_current\n",
    "        else:\n",
    "            X_T_Empirical = np.append(X_T_Empirical,X_current,axis=-1)\n",
    "\n",
    "    # Reshape\n",
    "    X_T_Empirical = X_T_Empirical.T\n",
    "    \n",
    "    # Get Output\n",
    "    Y_Empirical = np.matmul(X_T_Empirical,A_unkown)\n",
    "    \n",
    "    \n",
    "    # Add Stationary Uniform Noise\n",
    "#     if uniform_noise>0:\n",
    "#         X_T_Empirical = X_T_Empirical #+ np.random.uniform(low=-uniform_noise,high=uniform_noise,size=X_T_Empirical.shape())\n",
    "    return Y_Empirical\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "# Define Output Data Generator #\n",
    "################################\n",
    "def Euler_Maruyama_simulator(Grid_in,\n",
    "                             N_Monte_Carlo_Samples = N_Monte_Carlo_Samples,\n",
    "                             Rougness = Rougness,\n",
    "                             N_Euler_Maruyama_Steps = N_Euler_Maruyama_Steps):\n",
    "    #----------------------------#\n",
    "    ## Generate Data Using Grid ##\n",
    "    #----------------------------#\n",
    "    # Internal Parameters\n",
    "    N_Grid_Instances = Grid_in.shape[0]\n",
    "    # Initializations\n",
    "    measure_weights = np.ones(N_Monte_Carlo_Samples)/N_Monte_Carlo_Samples\n",
    "    measures_locations_list_internal = []\n",
    "    measures_weights_list_internal = []\n",
    "\n",
    "\n",
    "    # Perform Euler-Maruyama distritization + Monte-Carlo Sampling.\n",
    "    #----------------------------------------------------------------------------------------------#\n",
    "    # Perform Monte-Carlo Data Generation\n",
    "    for i in tqdm(range(N_Grid_Instances)):\n",
    "        x_loop = Grid_in[i,]\n",
    "        # Simulate Paths\n",
    "        paths_loop = Euler_Maruyama_Generator(x_0=x_loop,\n",
    "                                              N_Euler_Maruyama_Steps = N_Euler_Maruyama_Steps,\n",
    "                                              N_Monte_Carlo_Samples = N_Monte_Carlo_Samples,\n",
    "                                              T_begin = 0,\n",
    "                                              T_end = T_end,\n",
    "                                              Hurst = Rougness)\n",
    "\n",
    "        # Map numpy to list\n",
    "        measures_locations_loop = paths_loop#.tolist()\n",
    "\n",
    "        # Append to List\n",
    "        measures_locations_list_internal.append(measures_locations_loop)\n",
    "        measures_weights_list_internal.append(measure_weights)\n",
    "\n",
    "\n",
    "    return measures_locations_list_internal, measures_weights_list_internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test_size = int(np.round(N_train_size*train_test_ratio,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training Data (Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Training Set\n",
    "X_train = np.random.uniform(size=np.array([N_train_size,problem_dim]),low=.5,high=1.5)\n",
    "\n",
    "# Get Testing Set\n",
    "test_set_indices = np.random.choice(range(X_train.shape[0]),N_test_size)\n",
    "X_test = X_train[test_set_indices,]\n",
    "X_test = X_test + np.random.uniform(low=-(delta/np.sqrt(problem_dim)), \n",
    "                                    high = -(delta/np.sqrt(problem_dim)),\n",
    "                                    size = X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training Data (Outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.47it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get Training Data\n",
    "## Timer\n",
    "train_DATA_MC = time.time()\n",
    "## Do: Simulation\n",
    "Y_train_locations,Y_train_weights = Euler_Maruyama_simulator(X_train)\n",
    "# X_train = pd.DataFrame(X_train)\n",
    "## END: TIMER\n",
    "train_DATA_MC = time.time() - train_DATA_MC\n",
    "\n",
    "# Get Testing Data\n",
    "## Timer\n",
    "test_DATA_MC = time.time()\n",
    "## Do: Simulation\n",
    "Y_test_locations,Y_test_weights = Euler_Maruyama_simulator(X_test)\n",
    "# X_test = pd.DataFrame(X_test)\n",
    "## END: TIMER\n",
    "test_DATA_MC = time.time() - test_DATA_MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "#### Start Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Timer\n",
    "Type_A_timer_Begin = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\omega^{-1}(\\epsilon)$-Bounded Random Partitioner\n",
    "Generates a bounded random partition, in the sense of: [Geometry, Flows, and Graph-Partitioning Algorithms](https://cacm.acm.org/magazines/2008/10/515-geometry-flows-and-graph-partitioning-algorithms/fulltext?mobile=false), [A. Naor et al.](https://link.springer.com/article/10.1007/s00222-004-0400-5), as implemented in [Learning Sub-Patterns in Piece-Wise Continuous Functions](https://arxiv.org/abs/2010.15571)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "==============---------------------------------------------------=============\n",
      "Number of Classes/measures Which Were Produced: 58\n",
      "==============---------------------------------------------------=============\n",
      "===========================\n",
      "Training Classes Produced:\n",
      "===========================\n",
      "    0   1   2   3   4   5   6   7   8   9   ...  48  49  50  51  52  53  54  \\\n",
      "0    0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   1   \n",
      "1    0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "2    0   0   1   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "3    0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "4    0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
      "95   0   0   0   0   0   0   0   0   0   0  ...   0   0   1   0   0   0   0   \n",
      "96   0   0   0   0   0   0   1   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "97   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "98   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "99   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "\n",
      "    55  56  57  \n",
      "0    0   0   0  \n",
      "1    0   0   0  \n",
      "2    0   0   0  \n",
      "3    0   0   0  \n",
      "4    0   0   0  \n",
      "..  ..  ..  ..  \n",
      "95   0   0   0  \n",
      "96   0   0   0  \n",
      "97   0   0   0  \n",
      "98   0   0   0  \n",
      "99   0   0   0  \n",
      "\n",
      "[100 rows x 58 columns]\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize #\n",
    "#------------#\n",
    "X_training_remaining = np.copy(X_train)\n",
    "possible_indices_for_center = np.repeat(True,X_training_remaining.shape[0])\n",
    "indexing_set = np.array(range(X_training_remaining.shape[0]))\n",
    "\n",
    "# Tweak Radius of Balls\n",
    "# Note: To avoid \"too small\" of a delta\n",
    "dist_matrix = (distance_matrix(X_training_remaining[np.random.choice(indexing_set,max(1,round(X_training_remaining.shape[0]*.5)))],X_training_remaining[np.random.choice(indexing_set,max(1,round(X_training_remaining.shape[0]*.5)))]))\n",
    "dist_matrix = (dist_matrix[np.logical_not(dist_matrix == 0)]).reshape(-1,)\n",
    "delta = np.maximum(delta,np.quantile(dist_matrix,Proportion_per_cluster))\n",
    "# delta = np.quantile(dist_matrix,np.minimum(0.01,N_train_size/(((problem_dim)/(np.sqrt(1+problem_dim)*delta/4))**2)))\n",
    "\n",
    "\n",
    "# Build #\n",
    "#-------#\n",
    "while np.max(possible_indices_for_center)==True:  \n",
    "    # Randomize Radius\n",
    "    delta_loop = np.random.uniform(low=0,high=delta,size=1)[0]\n",
    "\n",
    "    # Get Random Center\n",
    "    random_center_loop_index = np.random.choice(indexing_set[possible_indices_for_center])\n",
    "    random_center_loop = (X_training_remaining[random_center_loop_index]).reshape([1,-1])\n",
    "\n",
    "    # Get Distances To Current Center\n",
    "    dist_mat_loop = np.sqrt(np.sum((random_center_loop-X_training_remaining)**2,axis=1))\n",
    "    ## Indentify which must lie in cluster but not counting previously removed elements\n",
    "    indices_cluster_loop = (dist_mat_loop<delta_loop)*possible_indices_for_center\n",
    "\n",
    "    # Update(s)\n",
    "    ## Outputs\n",
    "    if np.min(possible_indices_for_center)==True:\n",
    "        ## Initialize Classes\n",
    "        Train_classes = (indices_cluster_loop*1).reshape(-1,1)\n",
    "        ## PointMasses Center\n",
    "        Masses = int(random_center_loop_index)\n",
    "        # INITIALIZE: Barycenters Array\n",
    "        Barycenters_Array = (Y_train_locations[int(random_center_loop_index)]).reshape(-1,)\n",
    "    else:\n",
    "        ## Update Classes\n",
    "        Train_classes = np.append(Train_classes,(indices_cluster_loop*1).reshape(-1,1),axis=-1)\n",
    "        ## PointMasses Center\n",
    "        Masses = np.append(Masses,random_center_loop_index)\n",
    "        # UPDATE: Populate Barycenters Array\n",
    "        Barycenters_Array = np.append(Barycenters_Array,(Y_train_locations[int(random_center_loop_index)]).reshape(-1,),axis=-1)\n",
    "    ## Remove Clusterd Centers from Current Dataset\n",
    "    possible_indices_for_center = np.logical_not(indices_cluster_loop)*possible_indices_for_center\n",
    "\n",
    "# Format Training Classes\n",
    "Train_classes = pd.DataFrame(Train_classes)\n",
    "\n",
    "# Get Number of Classes\n",
    "N_Quantizers_to_parameterize = Train_classes.shape[1]\n",
    "\n",
    "# Update User #\n",
    "print(\"---------------\")\n",
    "print(\"==============---------------------------------------------------=============\")\n",
    "print(\"Number of Classes/measures Which Were Produced:\", N_Quantizers_to_parameterize)\n",
    "print(\"==============---------------------------------------------------=============\")\n",
    "print(\"===========================\")\n",
    "print(\"Training Classes Produced:\")\n",
    "print(\"===========================\")\n",
    "print(Train_classes)\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we train a deep (feed-forward) classifier:\n",
    "$$\n",
    "\\hat{f}\\triangleq \\operatorname{Softmax}_N\\circ W_J\\circ \\sigma \\bullet \\dots \\sigma \\bullet W_1,\n",
    "$$\n",
    "to identify which barycenter we are closest to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Deep Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Load Packages and CV Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n"
     ]
    }
   ],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('CV_Grid.py').read())\n",
    "# Re-Load Classifier Function(s)\n",
    "exec(open('Helper_Functions.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Deep Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Training Classifer Portion of Type-A Model\n",
      "==========================================\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   19.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:   19.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.0124 - accuracy: 0.1200\n",
      "Epoch 2/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.7741 - accuracy: 0.1700\n",
      "Epoch 3/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.5523 - accuracy: 0.1700\n",
      "Epoch 4/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5339 - accuracy: 0.1700\n",
      "Epoch 5/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4223 - accuracy: 0.2500\n",
      "Epoch 6/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.3887 - accuracy: 0.3300\n",
      "Epoch 7/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2108 - accuracy: 0.3000\n",
      "Epoch 8/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.0946 - accuracy: 0.2800\n",
      "Epoch 9/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.9292 - accuracy: 0.3400\n",
      "Epoch 10/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.7448 - accuracy: 0.3600\n",
      "Epoch 11/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.6053 - accuracy: 0.3500\n",
      "Epoch 12/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.3966 - accuracy: 0.3700\n",
      "Epoch 13/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.2654 - accuracy: 0.4300\n",
      "Epoch 14/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.9957 - accuracy: 0.4100\n",
      "Epoch 15/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8359 - accuracy: 0.5100\n",
      "Epoch 16/600\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6518 - accuracy: 0.5300\n",
      "Epoch 17/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.4889 - accuracy: 0.5300\n",
      "Epoch 18/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2846 - accuracy: 0.5300\n",
      "Epoch 19/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2646 - accuracy: 0.6000\n",
      "Epoch 20/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0270 - accuracy: 0.7100\n",
      "Epoch 21/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9356 - accuracy: 0.7000\n",
      "Epoch 22/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0285 - accuracy: 0.6200\n",
      "Epoch 23/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8470 - accuracy: 0.7100\n",
      "Epoch 24/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9152 - accuracy: 0.7500\n",
      "Epoch 25/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8751 - accuracy: 0.7300\n",
      "Epoch 26/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8823 - accuracy: 0.7400\n",
      "Epoch 27/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8513 - accuracy: 0.7100\n",
      "Epoch 28/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7033 - accuracy: 0.8000\n",
      "Epoch 29/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5444 - accuracy: 0.8200\n",
      "Epoch 30/600\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4354 - accuracy: 0.9000\n",
      "Epoch 31/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3716 - accuracy: 0.9500\n",
      "Epoch 32/600\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3527 - accuracy: 0.9300\n",
      "Epoch 33/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3248 - accuracy: 0.9100\n",
      "Epoch 34/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2621 - accuracy: 0.9400\n",
      "Epoch 35/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3294 - accuracy: 0.9400\n",
      "Epoch 36/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3549 - accuracy: 0.9200\n",
      "Epoch 37/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3418 - accuracy: 0.9100\n",
      "Epoch 38/600\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4378 - accuracy: 0.9000\n",
      "Epoch 39/600\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5942 - accuracy: 0.8600\n",
      "Epoch 40/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3206 - accuracy: 0.9300\n",
      "Epoch 41/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3738 - accuracy: 0.9000\n",
      "Epoch 42/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3049 - accuracy: 0.8900\n",
      "Epoch 43/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.8700\n",
      "Epoch 44/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.8200\n",
      "Epoch 45/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.8600\n",
      "Epoch 46/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3921 - accuracy: 0.8800\n",
      "Epoch 47/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3048 - accuracy: 0.9200\n",
      "Epoch 48/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2473 - accuracy: 0.9000\n",
      "Epoch 49/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1840 - accuracy: 0.9500\n",
      "Epoch 50/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1268 - accuracy: 0.9900\n",
      "Epoch 51/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1209 - accuracy: 0.9900\n",
      "Epoch 52/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 1.0000\n",
      "Epoch 53/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9900\n",
      "Epoch 54/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0762 - accuracy: 1.0000\n",
      "Epoch 55/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0569 - accuracy: 1.0000\n",
      "Epoch 56/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 1.0000\n",
      "Epoch 57/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0503 - accuracy: 1.0000\n",
      "Epoch 58/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0662 - accuracy: 0.9900\n",
      "Epoch 59/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 0.9800\n",
      "Epoch 60/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9900\n",
      "Epoch 61/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 62/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 63/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 64/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 65/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 66/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9900\n",
      "Epoch 67/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9900\n",
      "Epoch 68/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 69/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 70/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 71/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.9800\n",
      "Epoch 72/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0507 - accuracy: 0.9800\n",
      "Epoch 73/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0272 - accuracy: 0.9900\n",
      "Epoch 74/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9900\n",
      "Epoch 75/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 76/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 77/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 78/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 79/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0296 - accuracy: 0.9900\n",
      "Epoch 80/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9900\n",
      "Epoch 81/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 82/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 83/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 84/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 85/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 86/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 87/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 88/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 89/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 90/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 91/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 92/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 93/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 94/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 95/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 96/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 97/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 98/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 99/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 100/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 101/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 102/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 103/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 104/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 105/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 106/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 107/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 108/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 109/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 110/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 111/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 112/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 113/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 114/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 115/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 116/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 117/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 118/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 119/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 120/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 121/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 122/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 123/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 124/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 125/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 126/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 127/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 128/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 129/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 130/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 131/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 132/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 133/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 134/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 135/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 136/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 137/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 138/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 139/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 140/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 141/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 142/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 143/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 144/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 145/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 146/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 147/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 148/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 149/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 150/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 151/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 152/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 153/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 154/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 155/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 156/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 157/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 158/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 159/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 160/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 161/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 162/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 163/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 164/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 165/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 166/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 167/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 168/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 169/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 170/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 171/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 172/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 173/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 174/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 175/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 176/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 177/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 178/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 179/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 180/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 181/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 182/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 183/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 184/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 185/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 186/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 187/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 188/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 189/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 190/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 191/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 192/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 193/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 194/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 195/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 196/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 197/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 198/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 199/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 200/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 201/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 202/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 203/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 204/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 205/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 206/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 207/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 208/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 209/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 210/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 211/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 212/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 213/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.8619e-04 - accuracy: 1.0000\n",
      "Epoch 214/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.6408e-04 - accuracy: 1.0000\n",
      "Epoch 215/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.7052e-04 - accuracy: 1.0000\n",
      "Epoch 216/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.8374e-04 - accuracy: 1.0000\n",
      "Epoch 217/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.6785e-04 - accuracy: 1.0000\n",
      "Epoch 218/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.2509e-04 - accuracy: 1.0000\n",
      "Epoch 219/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.0517e-04 - accuracy: 1.0000\n",
      "Epoch 220/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.0866e-04 - accuracy: 1.0000\n",
      "Epoch 221/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.2767e-04 - accuracy: 1.0000\n",
      "Epoch 222/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.7548e-04 - accuracy: 1.0000\n",
      "Epoch 223/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.2832e-04 - accuracy: 1.0000\n",
      "Epoch 224/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.6728e-04 - accuracy: 1.0000\n",
      "Epoch 225/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1484e-04 - accuracy: 1.0000\n",
      "Epoch 226/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.3983e-04 - accuracy: 1.0000\n",
      "Epoch 227/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.1243e-04 - accuracy: 1.0000\n",
      "Epoch 228/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.7235e-04 - accuracy: 1.0000\n",
      "Epoch 229/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.2791e-04 - accuracy: 1.0000\n",
      "Epoch 230/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.3685e-04 - accuracy: 1.0000\n",
      "Epoch 231/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.1822e-04 - accuracy: 1.0000\n",
      "Epoch 232/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.9720e-04 - accuracy: 1.0000\n",
      "Epoch 233/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.8554e-04 - accuracy: 1.0000\n",
      "Epoch 234/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.8462e-04 - accuracy: 1.0000\n",
      "Epoch 235/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7308e-04 - accuracy: 1.0000\n",
      "Epoch 236/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7294e-04 - accuracy: 1.0000\n",
      "Epoch 237/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.6348e-04 - accuracy: 1.0000\n",
      "Epoch 238/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.4676e-04 - accuracy: 1.0000\n",
      "Epoch 239/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.3500e-04 - accuracy: 1.0000\n",
      "Epoch 240/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.5119e-04 - accuracy: 1.0000\n",
      "Epoch 241/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.5169e-04 - accuracy: 1.0000\n",
      "Epoch 242/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.5869e-04 - accuracy: 1.0000\n",
      "Epoch 243/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.4076e-04 - accuracy: 1.0000\n",
      "Epoch 244/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.1151e-04 - accuracy: 1.0000\n",
      "Epoch 245/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.1137e-04 - accuracy: 1.0000\n",
      "Epoch 246/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.7427e-04 - accuracy: 1.0000\n",
      "Epoch 247/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7619e-04 - accuracy: 1.0000\n",
      "Epoch 248/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 7.3352e-04 - accuracy: 1.0000\n",
      "Epoch 249/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.9752e-04 - accuracy: 1.0000\n",
      "Epoch 250/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8024e-04 - accuracy: 1.0000\n",
      "Epoch 251/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.7459e-04 - accuracy: 1.0000\n",
      "Epoch 252/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.0751e-04 - accuracy: 1.0000\n",
      "Epoch 253/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.1064e-04 - accuracy: 1.0000\n",
      "Epoch 254/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.7213e-04 - accuracy: 1.0000\n",
      "Epoch 255/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.6004e-04 - accuracy: 1.0000\n",
      "Epoch 256/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.9218e-04 - accuracy: 1.0000\n",
      "Epoch 257/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8095e-04 - accuracy: 1.0000\n",
      "Epoch 258/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.5510e-04 - accuracy: 1.0000\n",
      "Epoch 259/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.3838e-04 - accuracy: 1.0000\n",
      "Epoch 260/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.2030e-04 - accuracy: 1.0000\n",
      "Epoch 261/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.1471e-04 - accuracy: 1.0000\n",
      "Epoch 262/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.1745e-04 - accuracy: 1.0000\n",
      "Epoch 263/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.1510e-04 - accuracy: 1.0000\n",
      "Epoch 264/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.0648e-04 - accuracy: 1.0000\n",
      "Epoch 265/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.0010e-04 - accuracy: 1.0000\n",
      "Epoch 266/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.9401e-04 - accuracy: 1.0000\n",
      "Epoch 267/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.8643e-04 - accuracy: 1.0000\n",
      "Epoch 268/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.1092e-04 - accuracy: 1.0000\n",
      "Epoch 269/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.2181e-04 - accuracy: 1.0000\n",
      "Epoch 270/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1223e-04 - accuracy: 1.0000\n",
      "Epoch 271/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.9570e-04 - accuracy: 1.0000\n",
      "Epoch 272/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.6282e-04 - accuracy: 1.0000\n",
      "Epoch 273/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.5576e-04 - accuracy: 1.0000\n",
      "Epoch 274/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.5395e-04 - accuracy: 1.0000\n",
      "Epoch 275/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.4888e-04 - accuracy: 1.0000\n",
      "Epoch 276/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.3823e-04 - accuracy: 1.0000\n",
      "Epoch 277/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.3229e-04 - accuracy: 1.0000\n",
      "Epoch 278/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.2741e-04 - accuracy: 1.0000\n",
      "Epoch 279/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.2697e-04 - accuracy: 1.0000\n",
      "Epoch 280/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.2088e-04 - accuracy: 1.0000\n",
      "Epoch 281/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.1717e-04 - accuracy: 1.0000\n",
      "Epoch 282/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.1056e-04 - accuracy: 1.0000\n",
      "Epoch 283/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.0720e-04 - accuracy: 1.0000\n",
      "Epoch 284/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.0169e-04 - accuracy: 1.0000\n",
      "Epoch 285/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9652e-04 - accuracy: 1.0000\n",
      "Epoch 286/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9207e-04 - accuracy: 1.0000\n",
      "Epoch 287/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.9039e-04 - accuracy: 1.0000\n",
      "Epoch 288/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.8845e-04 - accuracy: 1.0000\n",
      "Epoch 289/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8447e-04 - accuracy: 1.0000\n",
      "Epoch 290/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7969e-04 - accuracy: 1.0000\n",
      "Epoch 291/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7725e-04 - accuracy: 1.0000\n",
      "Epoch 292/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7406e-04 - accuracy: 1.0000\n",
      "Epoch 293/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7499e-04 - accuracy: 1.0000\n",
      "Epoch 294/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7289e-04 - accuracy: 1.0000\n",
      "Epoch 295/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.7861e-04 - accuracy: 1.0000\n",
      "Epoch 296/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8941e-04 - accuracy: 1.0000\n",
      "Epoch 297/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.8106e-04 - accuracy: 1.0000\n",
      "Epoch 298/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.6769e-04 - accuracy: 1.0000\n",
      "Epoch 299/600\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.5861e-04 - accuracy: 1.0000\n",
      "Epoch 300/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.5519e-04 - accuracy: 1.0000\n",
      "Epoch 301/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.4910e-04 - accuracy: 1.0000\n",
      "Epoch 302/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.5298e-04 - accuracy: 1.0000\n",
      "Epoch 303/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.6789e-04 - accuracy: 1.0000\n",
      "Epoch 304/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.6945e-04 - accuracy: 1.0000\n",
      "Epoch 305/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.5487e-04 - accuracy: 1.0000\n",
      "Epoch 306/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.3922e-04 - accuracy: 1.0000\n",
      "Epoch 307/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.3545e-04 - accuracy: 1.0000\n",
      "Epoch 308/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.2877e-04 - accuracy: 1.0000\n",
      "Epoch 309/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.2448e-04 - accuracy: 1.0000\n",
      "Epoch 310/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1951e-04 - accuracy: 1.0000\n",
      "Epoch 311/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.1851e-04 - accuracy: 1.0000\n",
      "Epoch 312/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1508e-04 - accuracy: 1.0000\n",
      "Epoch 313/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1169e-04 - accuracy: 1.0000\n",
      "Epoch 314/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1053e-04 - accuracy: 1.0000\n",
      "Epoch 315/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1915e-04 - accuracy: 1.0000\n",
      "Epoch 316/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.1961e-04 - accuracy: 1.0000\n",
      "Epoch 317/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.0715e-04 - accuracy: 1.0000\n",
      "Epoch 318/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.9421e-04 - accuracy: 1.0000\n",
      "Epoch 319/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.9108e-04 - accuracy: 1.0000\n",
      "Epoch 320/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.9315e-04 - accuracy: 1.0000\n",
      "Epoch 321/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.9036e-04 - accuracy: 1.0000\n",
      "Epoch 322/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.8565e-04 - accuracy: 1.0000\n",
      "Epoch 323/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.8080e-04 - accuracy: 1.0000\n",
      "Epoch 324/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.7808e-04 - accuracy: 1.0000\n",
      "Epoch 325/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.8509e-04 - accuracy: 1.0000\n",
      "Epoch 326/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.8331e-04 - accuracy: 1.0000\n",
      "Epoch 327/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 3.7901e-04 - accuracy: 1.0000\n",
      "Epoch 328/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.6615e-04 - accuracy: 1.0000\n",
      "Epoch 329/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.6331e-04 - accuracy: 1.0000\n",
      "Epoch 330/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.8630e-04 - accuracy: 1.0000\n",
      "Epoch 331/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.9439e-04 - accuracy: 1.0000\n",
      "Epoch 332/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.8655e-04 - accuracy: 1.0000\n",
      "Epoch 333/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.6401e-04 - accuracy: 1.0000\n",
      "Epoch 334/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.5394e-04 - accuracy: 1.0000\n",
      "Epoch 335/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5723e-04 - accuracy: 1.0000\n",
      "Epoch 336/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5820e-04 - accuracy: 1.0000\n",
      "Epoch 337/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.5118e-04 - accuracy: 1.0000\n",
      "Epoch 338/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.4693e-04 - accuracy: 1.0000\n",
      "Epoch 339/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4675e-04 - accuracy: 1.0000\n",
      "Epoch 340/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.4523e-04 - accuracy: 1.0000\n",
      "Epoch 341/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4463e-04 - accuracy: 1.0000\n",
      "Epoch 342/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3776e-04 - accuracy: 1.0000\n",
      "Epoch 343/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2996e-04 - accuracy: 1.0000\n",
      "Epoch 344/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2520e-04 - accuracy: 1.0000\n",
      "Epoch 345/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4073e-04 - accuracy: 1.0000\n",
      "Epoch 346/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.4547e-04 - accuracy: 1.0000\n",
      "Epoch 347/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4385e-04 - accuracy: 1.0000\n",
      "Epoch 348/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4104e-04 - accuracy: 1.0000\n",
      "Epoch 349/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3290e-04 - accuracy: 1.0000\n",
      "Epoch 350/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2476e-04 - accuracy: 1.0000\n",
      "Epoch 351/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2067e-04 - accuracy: 1.0000\n",
      "Epoch 352/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1054e-04 - accuracy: 1.0000\n",
      "Epoch 353/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.0820e-04 - accuracy: 1.0000\n",
      "Epoch 354/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.0486e-04 - accuracy: 1.0000\n",
      "Epoch 355/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.0439e-04 - accuracy: 1.0000\n",
      "Epoch 356/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1514e-04 - accuracy: 1.0000\n",
      "Epoch 357/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2291e-04 - accuracy: 1.0000\n",
      "Epoch 358/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2262e-04 - accuracy: 1.0000\n",
      "Epoch 359/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1808e-04 - accuracy: 1.0000\n",
      "Epoch 360/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.0072e-04 - accuracy: 1.0000\n",
      "Epoch 361/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.9459e-04 - accuracy: 1.0000\n",
      "Epoch 362/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.9052e-04 - accuracy: 1.0000\n",
      "Epoch 363/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.8707e-04 - accuracy: 1.0000\n",
      "Epoch 364/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.8597e-04 - accuracy: 1.0000\n",
      "Epoch 365/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.9413e-04 - accuracy: 1.0000\n",
      "Epoch 366/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.9685e-04 - accuracy: 1.0000\n",
      "Epoch 367/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.9402e-04 - accuracy: 1.0000\n",
      "Epoch 368/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.8825e-04 - accuracy: 1.0000\n",
      "Epoch 369/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.8148e-04 - accuracy: 1.0000\n",
      "Epoch 370/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.7572e-04 - accuracy: 1.0000\n",
      "Epoch 371/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.7113e-04 - accuracy: 1.0000\n",
      "Epoch 372/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.7091e-04 - accuracy: 1.0000\n",
      "Epoch 373/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.6958e-04 - accuracy: 1.0000\n",
      "Epoch 374/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.7750e-04 - accuracy: 1.0000\n",
      "Epoch 375/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.7910e-04 - accuracy: 1.0000\n",
      "Epoch 376/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.7823e-04 - accuracy: 1.0000\n",
      "Epoch 377/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.7337e-04 - accuracy: 1.0000\n",
      "Epoch 378/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.6409e-04 - accuracy: 1.0000\n",
      "Epoch 379/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.5856e-04 - accuracy: 1.0000\n",
      "Epoch 380/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.5497e-04 - accuracy: 1.0000\n",
      "Epoch 381/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.5342e-04 - accuracy: 1.0000\n",
      "Epoch 382/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.5656e-04 - accuracy: 1.0000\n",
      "Epoch 383/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.5988e-04 - accuracy: 1.0000\n",
      "Epoch 384/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.6168e-04 - accuracy: 1.0000\n",
      "Epoch 385/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.5513e-04 - accuracy: 1.0000\n",
      "Epoch 386/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.4688e-04 - accuracy: 1.0000\n",
      "Epoch 387/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.4347e-04 - accuracy: 1.0000\n",
      "Epoch 388/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.4325e-04 - accuracy: 1.0000\n",
      "Epoch 389/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.4431e-04 - accuracy: 1.0000\n",
      "Epoch 390/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.4061e-04 - accuracy: 1.0000\n",
      "Epoch 391/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.3784e-04 - accuracy: 1.0000\n",
      "Epoch 392/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.3619e-04 - accuracy: 1.0000\n",
      "Epoch 393/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.3443e-04 - accuracy: 1.0000\n",
      "Epoch 394/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.3517e-04 - accuracy: 1.0000\n",
      "Epoch 395/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.3380e-04 - accuracy: 1.0000\n",
      "Epoch 396/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.3547e-04 - accuracy: 1.0000\n",
      "Epoch 397/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.3355e-04 - accuracy: 1.0000\n",
      "Epoch 398/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.3068e-04 - accuracy: 1.0000\n",
      "Epoch 399/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.2831e-04 - accuracy: 1.0000\n",
      "Epoch 400/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.2705e-04 - accuracy: 1.0000\n",
      "Epoch 401/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.2469e-04 - accuracy: 1.0000\n",
      "Epoch 402/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.2291e-04 - accuracy: 1.0000\n",
      "Epoch 403/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.2252e-04 - accuracy: 1.0000\n",
      "Epoch 404/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.2166e-04 - accuracy: 1.0000\n",
      "Epoch 405/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.2043e-04 - accuracy: 1.0000\n",
      "Epoch 406/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 2.1956e-04 - accuracy: 1.0000\n",
      "Epoch 407/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1674e-04 - accuracy: 1.0000\n",
      "Epoch 408/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.1509e-04 - accuracy: 1.0000\n",
      "Epoch 409/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1420e-04 - accuracy: 1.0000\n",
      "Epoch 410/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.1374e-04 - accuracy: 1.0000\n",
      "Epoch 411/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1221e-04 - accuracy: 1.0000\n",
      "Epoch 412/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1005e-04 - accuracy: 1.0000\n",
      "Epoch 413/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.1041e-04 - accuracy: 1.0000\n",
      "Epoch 414/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1060e-04 - accuracy: 1.0000\n",
      "Epoch 415/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0718e-04 - accuracy: 1.0000\n",
      "Epoch 416/600\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.0822e-04 - accuracy: 1.0000\n",
      "Epoch 417/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.0885e-04 - accuracy: 1.0000\n",
      "Epoch 418/600\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.0741e-04 - accuracy: 1.0000\n",
      "Epoch 419/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0485e-04 - accuracy: 1.0000\n",
      "Epoch 420/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0277e-04 - accuracy: 1.0000\n",
      "Epoch 421/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0148e-04 - accuracy: 1.0000\n",
      "Epoch 422/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9955e-04 - accuracy: 1.0000\n",
      "Epoch 423/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9837e-04 - accuracy: 1.0000\n",
      "Epoch 424/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9755e-04 - accuracy: 1.0000\n",
      "Epoch 425/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9997e-04 - accuracy: 1.0000\n",
      "Epoch 426/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9957e-04 - accuracy: 1.0000\n",
      "Epoch 427/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0235e-04 - accuracy: 1.0000\n",
      "Epoch 428/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0163e-04 - accuracy: 1.0000\n",
      "Epoch 429/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0046e-04 - accuracy: 1.0000\n",
      "Epoch 430/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9828e-04 - accuracy: 1.0000\n",
      "Epoch 431/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9497e-04 - accuracy: 1.0000\n",
      "Epoch 432/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9086e-04 - accuracy: 1.0000\n",
      "Epoch 433/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8840e-04 - accuracy: 1.0000\n",
      "Epoch 434/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8873e-04 - accuracy: 1.0000\n",
      "Epoch 435/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8683e-04 - accuracy: 1.0000\n",
      "Epoch 436/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8534e-04 - accuracy: 1.0000\n",
      "Epoch 437/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8482e-04 - accuracy: 1.0000\n",
      "Epoch 438/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8380e-04 - accuracy: 1.0000\n",
      "Epoch 439/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8285e-04 - accuracy: 1.0000\n",
      "Epoch 440/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8185e-04 - accuracy: 1.0000\n",
      "Epoch 441/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8170e-04 - accuracy: 1.0000\n",
      "Epoch 442/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8179e-04 - accuracy: 1.0000\n",
      "Epoch 443/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8095e-04 - accuracy: 1.0000\n",
      "Epoch 444/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8026e-04 - accuracy: 1.0000\n",
      "Epoch 445/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8150e-04 - accuracy: 1.0000\n",
      "Epoch 446/600\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.8126e-04 - accuracy: 1.0000\n",
      "Epoch 447/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8061e-04 - accuracy: 1.0000\n",
      "Epoch 448/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8010e-04 - accuracy: 1.0000\n",
      "Epoch 449/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7913e-04 - accuracy: 1.0000\n",
      "Epoch 450/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7957e-04 - accuracy: 1.0000\n",
      "Epoch 451/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7671e-04 - accuracy: 1.0000\n",
      "Epoch 452/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7444e-04 - accuracy: 1.0000\n",
      "Epoch 453/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7171e-04 - accuracy: 1.0000\n",
      "Epoch 454/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7161e-04 - accuracy: 1.0000\n",
      "Epoch 455/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.6992e-04 - accuracy: 1.0000\n",
      "Epoch 456/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6955e-04 - accuracy: 1.0000\n",
      "Epoch 457/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6684e-04 - accuracy: 1.0000\n",
      "Epoch 458/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.6596e-04 - accuracy: 1.0000\n",
      "Epoch 459/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6472e-04 - accuracy: 1.0000\n",
      "Epoch 460/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6355e-04 - accuracy: 1.0000\n",
      "Epoch 461/600\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.6337e-04 - accuracy: 1.0000\n",
      "Epoch 462/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6391e-04 - accuracy: 1.0000\n",
      "Epoch 463/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6307e-04 - accuracy: 1.0000\n",
      "Epoch 464/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6209e-04 - accuracy: 1.0000\n",
      "Epoch 465/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.6442e-04 - accuracy: 1.0000\n",
      "Epoch 466/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6624e-04 - accuracy: 1.0000\n",
      "Epoch 467/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.6770e-04 - accuracy: 1.0000\n",
      "Epoch 468/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.6577e-04 - accuracy: 1.0000\n",
      "Epoch 469/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.6173e-04 - accuracy: 1.0000\n",
      "Epoch 470/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.5853e-04 - accuracy: 1.0000\n",
      "Epoch 471/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.5869e-04 - accuracy: 1.0000\n",
      "Epoch 472/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.5980e-04 - accuracy: 1.0000\n",
      "Epoch 473/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.5948e-04 - accuracy: 1.0000\n",
      "Epoch 474/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.6266e-04 - accuracy: 1.0000\n",
      "Epoch 475/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6139e-04 - accuracy: 1.0000\n",
      "Epoch 476/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5731e-04 - accuracy: 1.0000\n",
      "Epoch 477/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5320e-04 - accuracy: 1.0000\n",
      "Epoch 478/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5260e-04 - accuracy: 1.0000\n",
      "Epoch 479/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.5115e-04 - accuracy: 1.0000\n",
      "Epoch 480/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5133e-04 - accuracy: 1.0000\n",
      "Epoch 481/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5011e-04 - accuracy: 1.0000\n",
      "Epoch 482/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.4851e-04 - accuracy: 1.0000\n",
      "Epoch 483/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4686e-04 - accuracy: 1.0000\n",
      "Epoch 484/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4596e-04 - accuracy: 1.0000\n",
      "Epoch 485/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 1.4513e-04 - accuracy: 1.0000\n",
      "Epoch 486/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.4464e-04 - accuracy: 1.0000\n",
      "Epoch 487/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4431e-04 - accuracy: 1.0000\n",
      "Epoch 488/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4372e-04 - accuracy: 1.0000\n",
      "Epoch 489/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4286e-04 - accuracy: 1.0000\n",
      "Epoch 490/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4164e-04 - accuracy: 1.0000\n",
      "Epoch 491/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4047e-04 - accuracy: 1.0000\n",
      "Epoch 492/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3985e-04 - accuracy: 1.0000\n",
      "Epoch 493/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3937e-04 - accuracy: 1.0000\n",
      "Epoch 494/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3867e-04 - accuracy: 1.0000\n",
      "Epoch 495/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3823e-04 - accuracy: 1.0000\n",
      "Epoch 496/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3889e-04 - accuracy: 1.0000\n",
      "Epoch 497/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4056e-04 - accuracy: 1.0000\n",
      "Epoch 498/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4075e-04 - accuracy: 1.0000\n",
      "Epoch 499/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3976e-04 - accuracy: 1.0000\n",
      "Epoch 500/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3729e-04 - accuracy: 1.0000\n",
      "Epoch 501/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3502e-04 - accuracy: 1.0000\n",
      "Epoch 502/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3404e-04 - accuracy: 1.0000\n",
      "Epoch 503/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3400e-04 - accuracy: 1.0000\n",
      "Epoch 504/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3353e-04 - accuracy: 1.0000\n",
      "Epoch 505/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3294e-04 - accuracy: 1.0000\n",
      "Epoch 506/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3224e-04 - accuracy: 1.0000\n",
      "Epoch 507/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3100e-04 - accuracy: 1.0000\n",
      "Epoch 508/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3057e-04 - accuracy: 1.0000\n",
      "Epoch 509/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3233e-04 - accuracy: 1.0000\n",
      "Epoch 510/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3104e-04 - accuracy: 1.0000\n",
      "Epoch 511/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3049e-04 - accuracy: 1.0000\n",
      "Epoch 512/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3020e-04 - accuracy: 1.0000\n",
      "Epoch 513/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2922e-04 - accuracy: 1.0000\n",
      "Epoch 514/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2887e-04 - accuracy: 1.0000\n",
      "Epoch 515/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2968e-04 - accuracy: 1.0000\n",
      "Epoch 516/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2860e-04 - accuracy: 1.0000\n",
      "Epoch 517/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2755e-04 - accuracy: 1.0000\n",
      "Epoch 518/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2668e-04 - accuracy: 1.0000\n",
      "Epoch 519/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2552e-04 - accuracy: 1.0000\n",
      "Epoch 520/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2603e-04 - accuracy: 1.0000\n",
      "Epoch 521/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2590e-04 - accuracy: 1.0000\n",
      "Epoch 522/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2712e-04 - accuracy: 1.0000\n",
      "Epoch 523/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2788e-04 - accuracy: 1.0000\n",
      "Epoch 524/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2664e-04 - accuracy: 1.0000\n",
      "Epoch 525/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2392e-04 - accuracy: 1.0000\n",
      "Epoch 526/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2011e-04 - accuracy: 1.0000\n",
      "Epoch 527/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2074e-04 - accuracy: 1.0000\n",
      "Epoch 528/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2174e-04 - accuracy: 1.0000\n",
      "Epoch 529/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2274e-04 - accuracy: 1.0000\n",
      "Epoch 530/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2355e-04 - accuracy: 1.0000\n",
      "Epoch 531/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2111e-04 - accuracy: 1.0000\n",
      "Epoch 532/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1865e-04 - accuracy: 1.0000\n",
      "Epoch 533/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1762e-04 - accuracy: 1.0000\n",
      "Epoch 534/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1561e-04 - accuracy: 1.0000\n",
      "Epoch 535/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1500e-04 - accuracy: 1.0000\n",
      "Epoch 536/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1542e-04 - accuracy: 1.0000\n",
      "Epoch 537/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1700e-04 - accuracy: 1.0000\n",
      "Epoch 538/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1338e-04 - accuracy: 1.0000\n",
      "Epoch 539/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1378e-04 - accuracy: 1.0000\n",
      "Epoch 540/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1386e-04 - accuracy: 1.0000\n",
      "Epoch 541/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1385e-04 - accuracy: 1.0000\n",
      "Epoch 542/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1259e-04 - accuracy: 1.0000\n",
      "Epoch 543/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1157e-04 - accuracy: 1.0000\n",
      "Epoch 544/600\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1038e-04 - accuracy: 1.0000\n",
      "Epoch 545/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0957e-04 - accuracy: 1.0000\n",
      "Epoch 546/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0888e-04 - accuracy: 1.0000\n",
      "Epoch 547/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0825e-04 - accuracy: 1.0000\n",
      "Epoch 548/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0773e-04 - accuracy: 1.0000\n",
      "Epoch 549/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0706e-04 - accuracy: 1.0000\n",
      "Epoch 550/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0723e-04 - accuracy: 1.0000\n",
      "Epoch 551/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0734e-04 - accuracy: 1.0000\n",
      "Epoch 552/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0705e-04 - accuracy: 1.0000\n",
      "Epoch 553/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0629e-04 - accuracy: 1.0000\n",
      "Epoch 554/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0541e-04 - accuracy: 1.0000\n",
      "Epoch 555/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0438e-04 - accuracy: 1.0000\n",
      "Epoch 556/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0499e-04 - accuracy: 1.0000\n",
      "Epoch 557/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0592e-04 - accuracy: 1.0000\n",
      "Epoch 558/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0687e-04 - accuracy: 1.0000\n",
      "Epoch 559/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0610e-04 - accuracy: 1.0000\n",
      "Epoch 560/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0368e-04 - accuracy: 1.0000\n",
      "Epoch 561/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0173e-04 - accuracy: 1.0000\n",
      "Epoch 562/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0465e-04 - accuracy: 1.0000\n",
      "Epoch 563/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0491e-04 - accuracy: 1.0000\n",
      "Epoch 564/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0137e-04 - accuracy: 1.0000\n",
      "Epoch 565/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0040e-04 - accuracy: 1.0000\n",
      "Epoch 566/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0134e-04 - accuracy: 1.0000\n",
      "Epoch 567/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0066e-04 - accuracy: 1.0000\n",
      "Epoch 568/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0008e-04 - accuracy: 1.0000\n",
      "Epoch 569/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0003e-04 - accuracy: 1.0000\n",
      "Epoch 570/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.9893e-05 - accuracy: 1.0000\n",
      "Epoch 571/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.9063e-05 - accuracy: 1.0000\n",
      "Epoch 572/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.7839e-05 - accuracy: 1.0000\n",
      "Epoch 573/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.6551e-05 - accuracy: 1.0000\n",
      "Epoch 574/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.5632e-05 - accuracy: 1.0000\n",
      "Epoch 575/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.7021e-05 - accuracy: 1.0000\n",
      "Epoch 576/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.6815e-05 - accuracy: 1.0000\n",
      "Epoch 577/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.6114e-05 - accuracy: 1.0000\n",
      "Epoch 578/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.6207e-05 - accuracy: 1.0000\n",
      "Epoch 579/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.5965e-05 - accuracy: 1.0000\n",
      "Epoch 580/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.4404e-05 - accuracy: 1.0000\n",
      "Epoch 581/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.4020e-05 - accuracy: 1.0000\n",
      "Epoch 582/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.2862e-05 - accuracy: 1.0000\n",
      "Epoch 583/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.2356e-05 - accuracy: 1.0000\n",
      "Epoch 584/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.3023e-05 - accuracy: 1.0000\n",
      "Epoch 585/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.2792e-05 - accuracy: 1.0000\n",
      "Epoch 586/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.2054e-05 - accuracy: 1.0000\n",
      "Epoch 587/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1289e-05 - accuracy: 1.0000\n",
      "Epoch 588/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.0856e-05 - accuracy: 1.0000\n",
      "Epoch 589/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.0342e-05 - accuracy: 1.0000\n",
      "Epoch 590/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.9577e-05 - accuracy: 1.0000\n",
      "Epoch 591/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.9747e-05 - accuracy: 1.0000\n",
      "Epoch 592/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.8508e-05 - accuracy: 1.0000\n",
      "Epoch 593/600\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 9.0636e-05 - accuracy: 1.0000\n",
      "Epoch 594/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1163e-05 - accuracy: 1.0000\n",
      "Epoch 595/600\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.0123e-05 - accuracy: 1.0000\n",
      "Epoch 596/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.8771e-05 - accuracy: 1.0000\n",
      "Epoch 597/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.5649e-05 - accuracy: 1.0000\n",
      "Epoch 598/600\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 8.7511e-05 - accuracy: 1.0000\n",
      "Epoch 599/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.3966e-05 - accuracy: 1.0000\n",
      "Epoch 600/600\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.5504e-05 - accuracy: 1.0000\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 882us/step\n",
      "===============================================\n",
      "Training Classifer Portion of Type Model: Done!\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "print(\"==========================================\")\n",
    "print(\"Training Classifer Portion of Type-A Model\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "# Redefine (Dimension-related) Elements of Grid\n",
    "param_grid_Deep_Classifier['input_dim'] = [problem_dim]\n",
    "param_grid_Deep_Classifier['output_dim'] = [N_Quantizers_to_parameterize]\n",
    "\n",
    "# Train simple deep classifier\n",
    "predicted_classes_train, predicted_classes_test, N_params_deep_classifier, timer_output = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                        n_jobs = n_jobs, \n",
    "                                                                                                        n_iter = n_iter, \n",
    "                                                                                                        param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                        X_train = X_train, \n",
    "                                                                                                        y_train = Train_classes,\n",
    "                                                                                                        X_test = X_test)\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"Training Classifer Portion of Type Model: Done!\")\n",
    "print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Predicted Quantized Distributions\n",
    "- Each *row* of \"Predicted_Weights\" is the $\\beta\\in \\Delta_N$.\n",
    "- Each *Column* of \"Barycenters_Array\" denotes the $x_1,\\dots,x_N$ making up the points of the corresponding empirical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#---------------------------------------#\n",
      "Building Training Set (Regression): START\n",
      "#---------------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 167.65it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 371.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------------------#\n",
      "Building Training Set (Regression): END\n",
      "#-------------------------------------#\n",
      "#-------------------------------------#\n",
      "Building Test Set (Predictions): START\n",
      "#-------------------------------------#\n",
      "#-----------------------------------#\n",
      "Building Test Set (Predictions): END\n",
      "#-----------------------------------#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Format Weights\n",
    "## Train\n",
    "print(\"#---------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): START\")\n",
    "print(\"#---------------------------------------#\")\n",
    "for i in tqdm(range((X_train.shape[0]))):\n",
    "    for j in range(N_Quantizers_to_parameterize):\n",
    "        b_loop = np.repeat(predicted_classes_train[i,j],N_Monte_Carlo_Samples)\n",
    "        if j == 0:\n",
    "            b = b_loop\n",
    "        else:\n",
    "            b = np.append(b,b_loop)\n",
    "        b = b.reshape(-1,1)\n",
    "\n",
    "    if i == 0:\n",
    "        Predicted_Weights = b/np.sum(b)\n",
    "    else:\n",
    "        Predicted_Weights = np.append(Predicted_Weights,b,axis=-1)\n",
    "Predicted_Weights = Predicted_Weights.T\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Training Set (Regression): END\")\n",
    "print(\"#-------------------------------------#\")\n",
    "\n",
    "## Test\n",
    "print(\"#-------------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): START\")\n",
    "print(\"#-------------------------------------#\")\n",
    "for i in tqdm(range((X_test.shape[0]))):\n",
    "    for j in range(N_Quantizers_to_parameterize):\n",
    "        b_loop = np.repeat(predicted_classes_test[i,j],N_Monte_Carlo_Samples)\n",
    "        if j == 0:\n",
    "            b = b_loop\n",
    "        else:\n",
    "            b = np.append(b,b_loop)\n",
    "        b = b.reshape(-1,1)\n",
    "\n",
    "    if i == 0:\n",
    "        Predicted_Weights_test = b/np.sum(b)\n",
    "    else:\n",
    "        Predicted_Weights_test = np.append(Predicted_Weights_test,b,axis=-1)\n",
    "Predicted_Weights_test = Predicted_Weights_test.T\n",
    "print(\"#-----------------------------------#\")\n",
    "print(\"Building Test Set (Predictions): END\")\n",
    "print(\"#-----------------------------------#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Timer\n",
    "Type_A_timer_end = time.time()\n",
    "# Compute Lapsed Time Needed For Training\n",
    "Time_Lapse_Model_A = Type_A_timer_end - Type_A_timer_Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Complexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Complexity = pd.DataFrame({\"N_Centers\":N_Quantizers_to_parameterize,\n",
    "                                 \"N_Q\":N_Monte_Carlo_Samples,\n",
    "                                 \"N_Params\":N_params_deep_classifier,\n",
    "                                 \"Training Time\":Time_Lapse_Model_A,\n",
    "                                 \"T_Test/T_Test-MC\": (timer_output/test_DATA_MC),\n",
    "                                 \"Time Test\": timer_output,\n",
    "                                 \"Time EM-MC\": test_DATA_MC},index=[\"Model_Complexity_metrics\"])\n",
    "\n",
    "pd.set_option('display.float_format', '{:.4E}'.format)\n",
    "Model_Complexity.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+\"Latent_Width_NSDE\"+str(width)+\"Problemdimension\"+str(problem_dim)+\"__ModelComplexities.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Moment Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 70.61it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Training Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors = np.array([])\n",
    "Mean_errors = np.array([])\n",
    "Var_errors = np.array([])\n",
    "Skewness_errors = np.array([])\n",
    "Kurtosis_errors = np.array([])\n",
    "predictions_mean = np.array([])\n",
    "true_mean = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(X_train.shape[0])):    \n",
    "    # Get Laws\n",
    "    W1_loop = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(Y_train_locations[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights[x_i,].reshape(-1,),\n",
    "                         (np.array(Y_train_locations[x_i])).reshape(-1,))\n",
    "    W1_errors = np.append(W1_errors,W1_loop)\n",
    "    # Get Means\n",
    "    Mu_hat = np.sum((Predicted_Weights[x_i])*(Barycenters_Array))\n",
    "    Mu = np.mean(np.array(Y_train_locations[x_i]))\n",
    "    Mean_errors =  np.append(Mean_errors,(Mu_hat-Mu))\n",
    "    ## Update Erros\n",
    "    predictions_mean = np.append(predictions_mean,Mu_hat)\n",
    "    true_mean = np.append(true_mean,Mu)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat = np.sum((Barycenters_Array**2)*(Predicted_Weights[x_i]))\n",
    "    Var = np.mean(np.array(Y_train_locations[x_i])**2)\n",
    "    Var_errors = np.append(Var_errors,(Var_hat-Var)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat = np.sum((Barycenters_Array**3)*(Predicted_Weights[x_i]))\n",
    "    Skewness = np.mean(np.array(Y_train_locations[x_i])**3)\n",
    "    Skewness_errors = np.append(Skewness_errors,(abs(Skewness_hat-Skewness))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat = np.sum((Barycenters_Array**4)*(Predicted_Weights[x_i]))\n",
    "    Kurtosis = np.mean(np.array(Y_train_locations[x_i])**4)\n",
    "    Kurtosis_errors = np.append(Kurtosis_errors,(abs(Kurtosis_hat-Kurtosis))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "W1_95 = bootstrap(W1_errors, n=1000, func=np.mean)(.95)\n",
    "W1_99 = bootstrap(W1_errors, n=1000, func=np.mean)(.99)\n",
    "M_95 = bootstrap(predictions_mean, n=1000, func=np.mean)(.95)\n",
    "M_99 = bootstrap(predictions_mean, n=1000, func=np.mean)(.99)\n",
    "M_95_MC = bootstrap(true_mean, n=1000, func=np.mean)(.95)\n",
    "M_99_MC = bootstrap(true_mean, n=1000, func=np.mean)(.99)\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance = np.array([np.min(np.abs(W1_errors)),np.mean(np.abs(W1_errors)),np.max(np.abs(W1_errors))])\n",
    "Mean_prediction_Performance = np.array([np.min(np.abs(Mean_errors)),np.mean(np.abs(Mean_errors)),np.max(np.abs(Mean_errors))])\n",
    "Var_prediction_Performance = np.array([np.min(np.abs(Var_errors)),np.mean(np.abs(Var_errors)),np.max(np.abs(Var_errors))])\n",
    "Skewness_prediction_Performance = np.array([np.min(np.abs(Skewness_errors)),np.mean(np.abs(Skewness_errors)),np.max(np.abs(Skewness_errors))])\n",
    "Kurtosis_prediction_Performance = np.array([np.min(np.abs(Kurtosis_errors)),np.mean(np.abs(Kurtosis_errors)),np.max(np.abs(Kurtosis_errors))])\n",
    "\n",
    "Type_A_Prediction = pd.DataFrame({\"W1\":W1_Performance,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "Type_A_Predictions_and_confidence = pd.DataFrame({\"W1_99_Train\":W1_95,\n",
    "                                                  \"W1error_99_Train\":W1_99,\n",
    "                                                  \"M_95_Train\":M_95,\n",
    "                                                  \"M_99_Train\":M_99,\n",
    "                                                  \"MC_95_Train\":M_95_MC,\n",
    "                                                  \"MC_99_Train\":M_99_MC},index=[\"CL\",\"Mean\",\"CU\"])\n",
    "\n",
    "\n",
    "# Write Performance\n",
    "pd.set_option('display.float_format', '{:.4E}'.format)\n",
    "Type_A_Prediction.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+\"Latent_Width_NSDE\"+str(width)+\"Problemdimension\"+str(problem_dim)+\"__TypeAPrediction_Train.tex\"))\n",
    "pd.set_option('display.float_format', '{:.4E}'.format)\n",
    "(Type_A_Predictions_and_confidence.T).to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+\"Latent_Width_NSDE\"+str(width)+\"Problemdimension\"+str(problem_dim)+\"__TypeAPrediction_Train_predictions_w_confidence_intervals.tex\"))\n",
    "\n",
    "# #---------------------------------------------------------------------------------------------#\n",
    "# # Update User\n",
    "# Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Result(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:00<00:00, 74.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Test Set Performance Metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 70.95it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Test Set Performance Metrics\")\n",
    "\n",
    "# Initialize Wasserstein-1 Error Distribution\n",
    "W1_errors_test = np.array([])\n",
    "Mean_errors_test = np.array([])\n",
    "Var_errors_test = np.array([])\n",
    "Skewness_errors_test = np.array([])\n",
    "Kurtosis_errors_test = np.array([])\n",
    "# Initialize Prediction Metrics\n",
    "predictions_mean_test = np.array([])\n",
    "true_mean_test = np.array([])\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Populate Error Distribution\n",
    "for x_i in tqdm(range(X_test.shape[0])):    \n",
    "    # Get Laws\n",
    "    W1_loop_test = ot.emd2_1d(Barycenters_Array,\n",
    "                         np.array(Y_test_locations[x_i]).reshape(-1,),\n",
    "                         Predicted_Weights_test[x_i,].reshape(-1,),\n",
    "                         (np.array(Y_test_locations[x_i])).reshape(-1,))\n",
    "    W1_errors_test = np.append(W1_errors_test,W1_loop_test)\n",
    "    # Get Means\n",
    "    Mu_hat_test = np.sum((Predicted_Weights_test[x_i])*(Barycenters_Array))\n",
    "    Mu_test = np.mean(np.array(Y_test_locations[x_i]))\n",
    "    Mean_errors_test = np.append(Mean_errors_test,(Mu_hat_test-Mu_test))\n",
    "    ## Update Predictions\n",
    "    predictions_mean_test = np.append(predictions_mean_test,Mu_hat_test)\n",
    "    true_mean_test = np.append(true_mean_test,Mu_test)\n",
    "    # Get Var (non-centered)\n",
    "    Var_hat_test = np.sum((Barycenters_Array**2)*(Predicted_Weights_test[x_i]))\n",
    "    Var_test = np.mean(np.array(Y_test_locations[x_i])**2)\n",
    "    Var_errors_test = np.append(Var_errors_test,(Var_hat_test-Var_test)**2)\n",
    "    # Get skewness (non-centered)\n",
    "    Skewness_hat_test = np.sum((Barycenters_Array**3)*(Predicted_Weights_test[x_i]))\n",
    "    Skewness_test = np.mean(np.array(Y_test_locations[x_i])**3)\n",
    "    Skewness_errors_test = np.append(Skewness_errors_test,(abs(Skewness_hat_test-Skewness_test))**(1/3))\n",
    "    # Get skewness (non-centered)\n",
    "    Kurtosis_hat_test = np.sum((Barycenters_Array**4)*(Predicted_Weights_test[x_i]))\n",
    "    Kurtosis_test = np.mean(np.array(Y_test_locations[x_i])**4)\n",
    "    Kurtosis_errors_test = np.append(Kurtosis_errors_test,(abs(Kurtosis_hat_test-Kurtosis_test))**.25)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------#\n",
    "W1_95_test = bootstrap(W1_errors_test, n=1000, func=np.mean)(.95)\n",
    "W1_99_test = bootstrap(W1_errors_test, n=1000, func=np.mean)(.99)\n",
    "M_95_test = bootstrap(predictions_mean_test, n=1000, func=np.mean)(.95)\n",
    "M_99_test = bootstrap(predictions_mean_test, n=1000, func=np.mean)(.99)\n",
    "M_95_MC_test = bootstrap(true_mean_test, n=1000, func=np.mean)(.95)\n",
    "M_99_MC_test = bootstrap(true_mean_test, n=1000, func=np.mean)(.99)\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "# Compute Error Statistics/Descriptors\n",
    "W1_Performance_test = np.array([np.min(np.abs(W1_errors_test)),np.mean(np.abs(W1_errors_test)),np.max(np.abs(W1_errors_test))])\n",
    "Mean_prediction_Performance_test = np.array([np.min(np.abs(Mean_errors_test)),np.mean(np.abs(Mean_errors_test)),np.max(np.abs(Mean_errors_test))])\n",
    "Var_prediction_Performance_test = np.array([np.min(np.abs(Var_errors_test)),np.mean(np.abs(Var_errors_test)),np.max(np.abs(Var_errors_test))])\n",
    "Skewness_prediction_Performance_test = np.array([np.min(np.abs(Skewness_errors_test)),np.mean(np.abs(Skewness_errors_test)),np.max(np.abs(Skewness_errors_test))])\n",
    "Kurtosis_prediction_Performance_test = np.array([np.min(np.abs(Kurtosis_errors_test)),np.mean(np.abs(Kurtosis_errors_test)),np.max(np.abs(Kurtosis_errors_test))])\n",
    "\n",
    "Type_A_Prediction_test = pd.DataFrame({\"W1\":W1_Performance_test,\n",
    "                                  \"E[X']-E[X]\":Mean_prediction_Performance_test,\n",
    "                                  \"(E[X'^2]-E[X^2])^.5\":Var_prediction_Performance_test,\n",
    "                                  \"(E[X'^3]-E[X^3])^(1/3)\":Skewness_prediction_Performance_test,\n",
    "                                  \"(E[X'^4]-E[X^4])^.25\":Kurtosis_prediction_Performance_test},index=[\"Min\",\"MAE\",\"Max\"])\n",
    "\n",
    "Type_A_Predictions_and_confidence_test = pd.DataFrame({\"W1_99_Test\":W1_95_test,\n",
    "                                                       \"W1error_99_Test\":W1_99_test,\n",
    "                                                       \"M_95_Test\":M_95_test,\n",
    "                                                       \"M_99_Test\":M_99_test,\n",
    "                                                       \"MC_95_Test\":M_95_MC_test,\n",
    "                                                       \"MC_99_Test\":M_99_MC_test},index=[\"CL\",\"Mean\",\"CU\"])\n",
    "\n",
    "# Write Performance\n",
    "pd.set_option('display.float_format', '{:.4E}'.format)\n",
    "Type_A_Prediction_test.to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+\"Latent_Width_NSDE\"+str(width)+\"Problemdimension\"+str(problem_dim)+\"__TypeAPrediction_Test.tex\"))\n",
    "pd.set_option('display.float_format', '{:.4E}'.format)\n",
    "(Type_A_Predictions_and_confidence_test.T).to_latex((results_tables_path+str(\"Roughness_\")+str(Rougness)+\"Latent_Width_NSDE\"+str(width)+\"Problemdimension\"+str(problem_dim)+\"__TypeAPrediction_Test_predictions_w_confidence_intervals.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print for Terminal Legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------#\n",
      "Training-Set Performance\n",
      "#----------------------#\n",
      "            W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min 1.5430E+00  3.2919E-05           1.4398E-08              6.9778E-02   \n",
      "MAE 1.3997E+02  2.8547E+03           9.0365E+07              2.8567E+01   \n",
      "Max 7.1057E+02  4.0890E+03           2.8011E+08              4.0917E+01   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min            1.7259E-01  \n",
      "MAE            1.6067E+01  \n",
      "Max            2.3011E+01  \n",
      " \n",
      " \n",
      " \n",
      "#------------------#\n",
      "Test-Set Performance\n",
      "#------------------#\n",
      "            W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
      "Min 1.2226E+01  1.3708E-01           8.0305E-01              1.6369E+00   \n",
      "MAE 1.3653E+02  2.5211E+03           7.3363E+07              2.5311E+01   \n",
      "Max 6.2265E+02  4.0013E+03           2.5686E+08              4.0040E+01   \n",
      "\n",
      "     (E[X'^4]-E[X^4])^.25  \n",
      "Min            2.0892E+00  \n",
      "MAE            1.4294E+01  \n",
      "Max            2.2518E+01  \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"#----------------------#\")\n",
    "print(\"Training-Set Performance\")\n",
    "print(\"#----------------------#\")\n",
    "print(Type_A_Prediction)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(\"#------------------#\")\n",
    "print(\"Test-Set Performance\")\n",
    "print(\"#------------------#\")\n",
    "print(Type_A_Prediction_test)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>1.5430E+00</td>\n",
       "      <td>3.2919E-05</td>\n",
       "      <td>1.4398E-08</td>\n",
       "      <td>6.9778E-02</td>\n",
       "      <td>1.7259E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.3997E+02</td>\n",
       "      <td>2.8547E+03</td>\n",
       "      <td>9.0365E+07</td>\n",
       "      <td>2.8567E+01</td>\n",
       "      <td>1.6067E+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>7.1057E+02</td>\n",
       "      <td>4.0890E+03</td>\n",
       "      <td>2.8011E+08</td>\n",
       "      <td>4.0917E+01</td>\n",
       "      <td>2.3011E+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min 1.5430E+00  3.2919E-05           1.4398E-08              6.9778E-02   \n",
       "MAE 1.3997E+02  2.8547E+03           9.0365E+07              2.8567E+01   \n",
       "Max 7.1057E+02  4.0890E+03           2.8011E+08              4.0917E+01   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min            1.7259E-01  \n",
       "MAE            1.6067E+01  \n",
       "Max            2.3011E+01  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>E[X']-E[X]</th>\n",
       "      <th>(E[X'^2]-E[X^2])^.5</th>\n",
       "      <th>(E[X'^3]-E[X^3])^(1/3)</th>\n",
       "      <th>(E[X'^4]-E[X^4])^.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>1.2226E+01</td>\n",
       "      <td>1.3708E-01</td>\n",
       "      <td>8.0305E-01</td>\n",
       "      <td>1.6369E+00</td>\n",
       "      <td>2.0892E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.3653E+02</td>\n",
       "      <td>2.5211E+03</td>\n",
       "      <td>7.3363E+07</td>\n",
       "      <td>2.5311E+01</td>\n",
       "      <td>1.4294E+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>6.2265E+02</td>\n",
       "      <td>4.0013E+03</td>\n",
       "      <td>2.5686E+08</td>\n",
       "      <td>4.0040E+01</td>\n",
       "      <td>2.2518E+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            W1  E[X']-E[X]  (E[X'^2]-E[X^2])^.5  (E[X'^3]-E[X^3])^(1/3)  \\\n",
       "Min 1.2226E+01  1.3708E-01           8.0305E-01              1.6369E+00   \n",
       "MAE 1.3653E+02  2.5211E+03           7.3363E+07              2.5311E+01   \n",
       "Max 6.2265E+02  4.0013E+03           2.5686E+08              4.0040E+01   \n",
       "\n",
       "     (E[X'^4]-E[X^4])^.25  \n",
       "Min            2.0892E+00  \n",
       "MAE            1.4294E+01  \n",
       "Max            2.2518E+01  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type_A_Prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Centers</th>\n",
       "      <th>N_Q</th>\n",
       "      <th>N_Params</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>T_Test/T_Test-MC</th>\n",
       "      <th>Time Test</th>\n",
       "      <th>Time EM-MC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model_Complexity_metrics</th>\n",
       "      <td>58</td>\n",
       "      <td>1000</td>\n",
       "      <td>783558</td>\n",
       "      <td>4.6583E+01</td>\n",
       "      <td>1.0736E-02</td>\n",
       "      <td>4.7426E-02</td>\n",
       "      <td>4.4174E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          N_Centers   N_Q  N_Params  Training Time  \\\n",
       "Model_Complexity_metrics         58  1000    783558     4.6583E+01   \n",
       "\n",
       "                          T_Test/T_Test-MC  Time Test  Time EM-MC  \n",
       "Model_Complexity_metrics        1.0736E-02 4.7426E-02  4.4174E+00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
